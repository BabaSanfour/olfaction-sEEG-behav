{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_to_take(rep,mat):\n",
    "    if rep != 'Retrieval_new_rec/':\n",
    "        to_take, time = [54, 99], mat['time'][54:99]-3\n",
    "    else:\n",
    "        to_take, time = [39, 119], mat['time'][39:119]-5\n",
    "    return(to_take, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Ripples loaded\n",
      "(62, 45) (62,) (62, 3)\n",
      "(171, 45) (171,) (171, 3)\n",
      "(214, 45) (214,) (214, 3)\n",
      "(279, 45) (279,) (279, 3)\n",
      "(370, 45) (370,) (370, 3)\n",
      "(429, 45) (429,) (429, 3)\n",
      "all names ['CD' 'Frontal' 'INS' 'MTL' 'OFC_OLF' 'PHG_FuG' 'Parietal' 'aMTL'\n",
      " 'cingulate' 'occipital' 'olf' 'orbital' 'temp_cx']\n",
      "shapes pow1 (429, 45) pow0 (429, 45) da (429, 45) perm (429, 45, 100) su_codes (429,) s_elec (429,) s_labels (429,) s_channels (429,)\n",
      "(62, 45) (62,) (62, 3)\n",
      "(171, 45) (171,) (171, 3)\n",
      "(214, 45) (214,) (214, 3)\n",
      "(279, 45) (279,) (279, 3)\n",
      "(370, 45) (370,) (370, 3)\n",
      "(429, 45) (429,) (429, 3)\n",
      "all names ['CD' 'Frontal' 'INS' 'MTL' 'OFC_OLF' 'PHG_FuG' 'Parietal' 'aMTL'\n",
      " 'cingulate' 'occipital' 'olf' 'orbital' 'temp_cx']\n",
      "shapes pow1 (429, 45) pow0 (429, 45) da (429, 45) perm (429, 45, 100) su_codes (429,) s_elec (429,) s_labels (429,) s_channels (429,)\n",
      "(62, 45) (62,) (62, 3)\n",
      "(171, 45) (171,) (171, 3)\n",
      "(214, 45) (214,) (214, 3)\n",
      "(279, 45) (279,) (279, 3)\n",
      "(370, 45) (370,) (370, 3)\n",
      "(429, 45) (429,) (429, 3)\n",
      "all names ['CD' 'Frontal' 'INS' 'MTL' 'OFC_OLF' 'PHG_FuG' 'Parietal' 'aMTL'\n",
      " 'cingulate' 'occipital' 'olf' 'orbital' 'temp_cx']\n",
      "shapes pow1 (429, 45) pow0 (429, 45) da (429, 45) perm (429, 45, 100) su_codes (429,) s_elec (429,) s_labels (429,) s_channels (429,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SUM UP CLASSIF RESULTS for POWER\n",
    "new scripts with sklearn and ALL or AVERAGE values of POWER\n",
    "\"\"\"\n",
    "from brainpipe.system import study\n",
    "import numpy as np\n",
    "from os import listdir,makedirs\n",
    "from os.path import isfile, join,exists\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from brainpipe.statistics import perm_pvalue2level\n",
    "\n",
    "st = study('Ripples')\n",
    "conds = ['low','high']\n",
    "val = 'xpow'\n",
    "#reps = ['Encoding/', 'Retrieval_new_odors/', 'Retrieval_new_rec/']\n",
    "reps = ['Retrieval_new_odors/']\n",
    "average = False\n",
    "\n",
    "path_classif = join(st.path, 'classified/{}')\n",
    "clf_name = join(path_classif, '{}_LDA_clf_{}_{}_{}.npz')\n",
    "path_pow = join(st.path, 'feature/{}')\n",
    "pow_file = join(path_pow, '{}_cond={}_bipo_feat_norm.npz')\n",
    "path2save = path_classif\n",
    "\n",
    "subjects = ['FERJ','LEFC','SEMC','PIRJ','VACJ','CHAF']\n",
    "freqs = ['HFA','ripple','low_freq']\n",
    "\n",
    "## Create a npz file with all sources informations + POWER (subjects, coords, labels)\n",
    "for rep,freq in product(reps,freqs):\n",
    "    \n",
    "    su_codes, s_xyz, s_channels,s_labels = np.array([]),np.array([]),np.array([]),np.array([])\n",
    "    s_elec_pow0, s_elec_pow1, s_auc = np.array([]),np.array([]), np.array([])\n",
    "    s_elec, s_perm = np.array([]),np.array([])\n",
    "    for i,su in enumerate((subjects)): #sorted\n",
    "        \n",
    "        pow_mat = np.load(pow_file.format(rep,su,conds[0]),allow_pickle=True)\n",
    "        id_freq = [i for i,f in enumerate(pow_mat['fname']) if f==freq][0]\n",
    "        to_take, time = points_to_take(rep,pow_mat)\n",
    "        pow0 = pow_mat['xpow'][id_freq,:,to_take[0]:to_take[1],:]\n",
    "        pow1 = np.load(pow_file.format(rep,su,conds[1]))['xpow'][id_freq,:,to_take[0]:to_take[1],:]\n",
    "        classif = np.load(clf_name.format(rep,su,freq,conds[0],conds[1]),allow_pickle=True)\n",
    "        \n",
    "        if average == True:\n",
    "            pow0, pow1 = np.mean(pow0, axis=(1,2)), np.mean(pow1,axis=(1,2))\n",
    "        elif average == False:\n",
    "            pow0, pow1 = np.mean(pow0, axis=-1), np.mean(pow1, axis=-1)\n",
    "        \n",
    "        xyz, channels = classif['xyz'], classif['channels']\n",
    "        auc, names, perm = classif['auc'], classif['names'], classif['perm']\n",
    "        \n",
    "        s_xyz = np.vstack((s_xyz, xyz)) if np.size(s_xyz) else xyz\n",
    "        su_codes = np.hstack((su_codes,np.array([su]*xyz.shape[0]))) \\\n",
    "                                if np.size(su_codes) else np.array([su]*xyz.shape[0])\n",
    "        s_elec = np.hstack((s_elec,np.arange(xyz.shape[0]))) \\\n",
    "                                if np.size(s_elec) else np.arange(xyz.shape[0])\n",
    "        s_channels = np.hstack((s_channels, channels)) \\\n",
    "                                if np.size(s_channels) else channels\n",
    "        s_auc = np.vstack((s_auc, auc)) if np.size(s_auc) else auc\n",
    "        s_perm = np.vstack((s_perm,perm)) if np.size(s_perm) else perm\n",
    "        s_labels = np.hstack((s_labels, names)) if np.size(s_labels) else names\n",
    "        s_elec_pow0 = np.vstack((s_elec_pow0, pow0)) if np.size(s_elec_pow0) else pow0\n",
    "        s_elec_pow1 = np.vstack((s_elec_pow1, pow1)) if np.size(s_elec_pow1) else pow1\n",
    "        print(s_elec_pow0.shape, s_elec.shape, s_xyz.shape)\n",
    "    print('all names', np.unique(s_labels))\n",
    "    print ('shapes', 'pow1',s_elec_pow1.shape, 'pow0',s_elec_pow0.shape,'da', s_auc.shape, \n",
    "           'perm',s_perm.shape,'su_codes',su_codes.shape, 's_elec',s_elec.shape,\n",
    "          's_labels',s_labels.shape,'s_channels',s_channels.shape)\n",
    "    su_coord_label = {'su_codes':su_codes, 's_xyz':s_xyz, 's_labels':s_labels,\n",
    "                      's_elec_pow0':s_elec_pow0,'s_elec_pow1':s_elec_pow1,\n",
    "                      's_da':s_auc,'s_perm':s_perm,'s_elec':s_elec, 's_channels':s_channels,\n",
    "                     's_time':time}\n",
    "    file_source = 'All_subjects_sources_'+freq+'_'+conds[0]+'_'+conds[1]+'.npz'\n",
    "    np.savez(path2save.format(rep)+file_source,**su_coord_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a df with all information (elecs, max da, power when da is max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Ripples loaded\n"
     ]
    }
   ],
   "source": [
    "from brainpipe.system import study\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "conds = ['low','high']\n",
    "rep = 'Retrieval_new_odors/' #'Retrieval_new_odors/', 'Retrieval_new_rec/', 'Encoding/'\n",
    "st = study('Ripples')\n",
    "path_npz = join(st.path, 'classified/'+rep)\n",
    "f_form = 'All_subjects_sources_{}_{}_{}.npz'\n",
    "f_form = join(path_npz, f_form)\n",
    "dfname = '0_all_subjects_info_elecs.csv'\n",
    "df_all_name = '1_all_subjects_AUC_Pow_Time_bsl_all_freqs.csv'\n",
    "###############################################################################\n",
    "freqs = ['HFA','ripple','low_freq']\n",
    "data_type = 'pow'\n",
    "###############################################################################\n",
    "\n",
    "mat = np.load(f_form.format(freqs[0],conds[0],conds[1]),allow_pickle=True)\n",
    "subjects = mat['su_codes'][:,np.newaxis]\n",
    "elecs = mat['s_elec'][:,np.newaxis]\n",
    "s_Mai_RL = mat['s_labels'][:,np.newaxis]\n",
    "channels = mat['s_channels'][:,np.newaxis]\n",
    "elec_data = np.concatenate((subjects, s_Mai_RL,channels,elecs), axis=1)\n",
    "df0 = pd.DataFrame(elec_data, columns=['subjects','s_Mai_RL','channels','elecs_num'])\n",
    "df0.to_csv(path_npz+dfname)\n",
    "\n",
    "# load all electrodes information and create a df\n",
    "idx_all, pow0_all, pow1_all, da_all = np.array([]),np.array([]),np.array([]),np.array([])\n",
    "for freq in freqs:\n",
    "    mat = np.load(f_form.format(freq,conds[0],conds[1]),allow_pickle=True)\n",
    "    idx_elecs, pow0_elecs, pow1_elecs, da_elecs = np.array([]),np.array([]),np.array([]),np.array([])\n",
    "    for elec in range(elecs.shape[0]):\n",
    "        da, time = mat['s_da'][elec], mat['s_time']\n",
    "        da_th = np.percentile(da,95)\n",
    "        val0 = 's_elec_pow0' if data_type == 'pow' else 'rsa0'\n",
    "        val1 = 's_elec_pow1' if data_type == 'pow' else 'rsa1'\n",
    "        if np.size(da) > 1:\n",
    "            idx_elec = np.asarray([i for i,j in enumerate(da) if j >= da_th],dtype=int)\n",
    "            if len(idx_elec) < 1:\n",
    "                da_th = da_th - 0.001\n",
    "                idx_elec = np.asarray([i for i,j in enumerate(da) if j >= da_th],dtype=int)\n",
    "            first_time = time[idx_elec][0]\n",
    "            da_elec = np.mean(da[idx_elec])\n",
    "            pow0_elec = np.mean(mat[val0][elec][idx_elec])\n",
    "            pow1_elec = np.mean(mat[val1][elec][idx_elec])\n",
    "        else:\n",
    "            da_elec = da\n",
    "            pow0_elec = mat[val0][elec]\n",
    "            pow1_elec = mat[val1][elec]\n",
    "        pow0_elecs = np.hstack((pow0_elecs,pow0_elec)) if np.size(pow0_elecs) else pow0_elec\n",
    "        pow1_elecs = np.hstack((pow1_elecs, pow1_elec)) if np.size(pow1_elecs) else pow1_elec\n",
    "        idx_elecs = np.hstack((idx_elecs, first_time)) if np.size(idx_elecs) else first_time\n",
    "        da_elecs = np.hstack((da_elecs,da_elec)) if np.size(da_elecs) else da_elec\n",
    "    idx_all = np.vstack((idx_all, idx_elecs)) if np.size(idx_all) else idx_elecs\n",
    "    pow0_all= np.vstack((pow0_all, pow0_elecs)) if np.size(pow0_all) else pow0_elecs\n",
    "    pow1_all= np.vstack((pow1_all, pow1_elecs)) if np.size(pow1_all) else pow1_elecs\n",
    "    da_all = np.vstack((da_all, da_elecs)) if np.size(da_all) else da_elecs\n",
    "df2 = pd.DataFrame(da_all.T, columns=[freq+'_AUC' for freq in freqs])\n",
    "df3 = pd.DataFrame(pow0_all.T, columns=[freq+'_Pow0' for freq in freqs])\n",
    "df4 = pd.DataFrame(pow1_all.T, columns=[freq+'_Pow1' for freq in freqs])\n",
    "df5 = pd.DataFrame(idx_all.T, columns=[freq+'_first_T' for freq in freqs])\n",
    "df_all = pd.concat((df0,df2,df3,df4,df5),axis=1)\n",
    "df_all.to_csv(path_npz+df_all_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
