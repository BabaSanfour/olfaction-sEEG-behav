{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, MaxNLocator\n",
    "import scipy.io as sio\n",
    "\n",
    "from brainpipe.classification import *\n",
    "from brainpipe.system import study\n",
    "from brainpipe.feature import power, amplitude, sigfilt\n",
    "from brainpipe.visual import *\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import expon\n",
    "from scipy.stats import binom\n",
    "\n",
    "from brainpipe.statistics import *\n",
    "from os import path\n",
    "from mne.stats import *\n",
    "\n",
    "from mne.baseline import rescale\n",
    "from mne.filter import filter_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n"
     ]
    }
   ],
   "source": [
    "# where to find data\n",
    "st = study('Olfacto')\n",
    "score = 'Epi' #'Rec'\n",
    "if score == 'Epi':\n",
    "    path_data = path.join (st.path, 'database/TS_E_all_by_odor_th40_art400_30_250_5s_Good_Bad_EpiScore/')\n",
    "    save_path = path.join(st.path, 'classified/0_Classif_ERP_EpiScore_all_points_all_electrodes/')\n",
    "if score == 'Rec':\n",
    "    path_data = path.join (st.path, 'database/TS_E_all_by_odor_th40_art400_30_250_Good_Bad_RecScore/')\n",
    "    save_path = path.join(st.path, 'classified/0_Classif_ERP_RecScore_all_points_all_electrodes/')\n",
    "\n",
    "# ANALYSIS PARAMETERS\n",
    "low_pass_filter = 10.\n",
    "sf = 512.\n",
    "norm_mode = 'mean' #'ratio' 'mean' 'percent' \n",
    "baseline = [973 , 1024] #100ms before odor perception\n",
    "data_to_use = [973, 1536] #1000ms after odor\n",
    "time_points = data_to_use[1]-data_to_use[0]\n",
    "classif = ['lda']\n",
    "n_rep = 10 #bootstrap\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERPs Decoding - Good Bad Odors Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = True\n",
    "\n",
    "if test == True:\n",
    "    n_elec = {'PIRJ' :1}\n",
    "    subjects = ['PIRJ']\n",
    "else :\n",
    "    subjects = ['VACJ','SEMC','PIRJ','LEFC','MICP','CHAF'] \n",
    "    n_elec = {\n",
    "    'CHAF' : 107,\n",
    "    'VACJ' : 139, \n",
    "    'SEMC' : 107,\n",
    "    'PIRJ' : 106,\n",
    "    'LEFC' : 193,\n",
    "    'MICP' : 105,\n",
    "        }\n",
    "    \n",
    "elif test == 'subset': #HC, PHC, Amg, Pir\n",
    "    subjects = ['VACJ', 'SEMC','PIRJ','LEFC'] #MICP\n",
    "    n_elec = {\n",
    "    'VACJ' : [1,2,3,11,12,13,14,15,16,17,22,23,24,60,61,62],\n",
    "    'SEMC' : [0,1,2,3,4],\n",
    "    'PIRJ' : [0,1,2,3,4,11,12,13,14,15,16,22,23,24,25,26,33,34,35,36,37,38],\n",
    "    'LEFC' : [0,1,11,12,13,14,22,23,24,25,26,27],\n",
    "    'MICP' : [0,1,2,3,9,18,10,11,12,19,20,21,22,23,29,30,31,32,33,40,41,42,43,44],\n",
    "        }\n",
    "\n",
    "for su in subjects:\n",
    "    #Load files\n",
    "    data_bad = np.load(path.join(path_data, su+'_concat_odor_bad_bipo.npz'))\n",
    "    data_good = np.load(path.join(path_data, su+'_concat_odor_good_bipo.npz'))\n",
    "    data_bad, channels, names, data_good = data_bad['x'], data_bad['channel'], data_bad['label'], data_good['x']\n",
    "\n",
    "    for elec in range(0,n_elec[su]):\n",
    "    #for elec in n_elec[su]:\n",
    "        # Select data for one elec + name :\n",
    "        data_elec_bad = data_bad[elec,:,:]\n",
    "        data_elec_good = data_good[elec,:,:]\n",
    "        ntrials = str(data_elec_bad.shape[1])+'/'+ str(data_elec_good.shape[1])\n",
    "        channel, name = channels[elec], names[elec]\n",
    "        print (su, 'Channel : ', channel, 'Label : ', name,'Bad shape : ', \n",
    "               data_elec_bad.shape, 'Good shape : ', data_elec_good.shape)\n",
    "\n",
    "        #Filter data for one elec (all trials):\n",
    "        data_elec_bad = np.array(data_elec_bad, dtype='float64')\n",
    "        data_elec_good = np.array(data_elec_good, dtype='float64')\n",
    "        data_bad_to_filter = np.swapaxes(data_elec_bad, 0, 1)\n",
    "        data_good_to_filter = np.swapaxes(data_elec_good, 0, 1)\n",
    "        filtered_data_bad = filter_data(data_bad_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "        filtered_data_good = filter_data(data_good_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "        print ('Size of filtered data bad :', filtered_data_bad.shape, 'filtered data good : ', filtered_data_good.shape,)\n",
    "\n",
    "        #Normalize the non-averaged data (all trials)\n",
    "        times = np.arange(filtered_data_bad.shape[1])\n",
    "        print ('time points : ', times.shape)\n",
    "        norm_filtered_data_bad = rescale(filtered_data_bad, times=times, baseline=baseline, mode=norm_mode)\n",
    "        norm_filtered_data_good = rescale(filtered_data_good, times=times, baseline=baseline, mode=norm_mode)\n",
    "        print ('Size norm & filtered data 0 : ', norm_filtered_data_bad.shape, norm_filtered_data_good.shape,)\n",
    "\n",
    "        # Range of the data to compute\n",
    "        data_range = range(data_to_use[0], data_to_use[1])\n",
    "        sel_bad = norm_filtered_data_bad[:, data_range]\n",
    "        sel_good = norm_filtered_data_good[:, data_range,]\n",
    "        print ('-> Shape of bad data', sel_bad.shape, 'good data', sel_good.shape)\n",
    "\n",
    "        # Average the signal on consecutive windows\n",
    "        winSample = 10 #20ms in samples\n",
    "        n_pts = sel_bad.shape[1]\n",
    "        rmPoints = n_pts % winSample # Points to remove before splitting\n",
    "        shapeRmPoints = np.arange(n_pts-rmPoints).astype(int) # Number of points for round division\n",
    "        n_win = int(n_pts / winSample) # Number of segments\n",
    "\n",
    "        # Split and average data (trials, n_pts)\n",
    "        bad_split = np.array(np.split(sel_bad[:, shapeRmPoints], n_win, axis=1)) # n_win n_trials n_pts\n",
    "        bad_split = np.mean(bad_split, axis=2).swapaxes(0,1) # n-trials n_win\n",
    "        good_split = np.array(np.split(sel_good[:, shapeRmPoints], n_win, axis=1))\n",
    "        good_split = np.mean(good_split, axis=2).swapaxes(0,1)\n",
    "\n",
    "# ================================  STATISTICS FOR POWER  =====================================\n",
    "        T_rep, p_val_rep = np.array([]), np.array([])\n",
    "        da_rep, daperm_rep = np.array([]), np.array([])\n",
    "\n",
    "        first = True\n",
    "        for i in range(n_rep):\n",
    "            #reshape data to have the exact same nb of trials (mandatory for t-tests)\n",
    "            if bad_split.shape[0] > good_split.shape[0]:\n",
    "                bad_split_stat = bad_split[np.random.randint(bad_split.shape[0], size=good_split.shape[0]), :] #reshape bad_data to fit good_data shape\n",
    "                good_split_stat = good_split\n",
    "            elif bad_split.shape[0] < good_split.shape[0]:\n",
    "                bad_split_stat = bad_split\n",
    "                good_split_stat = good_split[np.random.randint(good_split.shape[0], size=bad_split.shape[0]), :]\n",
    "            else:\n",
    "                bad_split_stat = bad_split\n",
    "                good_split_stat = good_split\n",
    "            ntrials = bad_split.shape[0]\n",
    "            X = bad_split_stat - good_split_stat #the last dimension needs to be time\n",
    "            T0, p_values, H0 = permutation_t_test(X, n_permutations=100, tail=0, n_jobs=1, verbose=None)\n",
    "            T_rep = np.vstack((T_rep,T0)) if np.size(T_rep) else T0\n",
    "            p_val_rep = np.vstack((p_val_rep,p_values)) if np.size(p_val_rep) else p_values\n",
    "\n",
    "# =============================  CLASSIFICATION COMPUTATION ============================================================           \n",
    "\n",
    "            #create a data matrix, concatenate along the trial dimension\n",
    "            bad_good = np.concatenate((bad_split_stat, good_split_stat), axis=0)\n",
    "            print ('Size of the concatenated data: ', bad_good.shape, 'Number time windows : ', bad_good.shape[1])\n",
    "\n",
    "            #create label vector (0 for rest and 1 for odor)\n",
    "            y = [0]*bad_split_stat.shape[0] + [1]*good_split_stat.shape[0]\n",
    "            print ('Size of label for classif: ', len(y))\n",
    "\n",
    "            da_final = []\n",
    "            for i in range(bad_good.shape[1]):\n",
    "                if first:\n",
    "                    cv = StratifiedKFold(n_splits=10)\n",
    "                    clf = SVC(class_weight='balanced', kernel='rbf')\n",
    "                    params = {'C': expon(scale=100), 'gamma': expon(scale=.1)}\n",
    "                    RS = RandomizedSearchCV(estimator=clf,\n",
    "                                param_distributions=params,\n",
    "                                n_iter=100,\n",
    "                                n_jobs=-1,\n",
    "                                cv=cv)\n",
    "                    RS.fit(X=bad_good[:,i].reshape(-1,1), y=y)\n",
    "                    best_params = RS.best_params_\n",
    "                    best_params['class_weight'] = 'balanced'\n",
    "                    best_params['kernel'] = 'rbf'\n",
    "\n",
    "                # Define a cross validation:\n",
    "                cv = defCv(y, n_folds=10, cvtype='skfold', rep=10)\n",
    "                # Define classifier technique\n",
    "                clf = defClf(y=y, clf=classif, kern='rbf',\n",
    "                             C=best_params['C'], gamma=best_params['gamma'],\n",
    "                             class_weight=best_params['class_weight'])#,n_tree=200, random_state=100)\n",
    "                #Classify rest and odor\n",
    "                cl = classify(y, clf=clf, cvtype=cv)\n",
    "\n",
    "                # Evaluate the classifier on data:\n",
    "                da,pvalue,daperm = cl.fit(bad_good[:,i].reshape(-1,1), n_perm=100,method='bino',mf=False)\n",
    "                da_final.append(da.tolist())\n",
    "            da = np.asarray(da_final).squeeze().swapaxes(0,1)\n",
    "            print(da.shape)\n",
    "            print ('decoding accuracy',da.shape, 'pvalues ', pvalue.shape,)\n",
    "            da_rep = np.vstack((da_rep,da)) if np.size(da_rep) else da\n",
    "            first = False\n",
    "\n",
    "# =============================== TAKE MAX STATS TO PLOT =====================================\n",
    "        # Take the max pvalues for each time window\n",
    "        idx_pval_max = []\n",
    "        for s in range(n_win):\n",
    "            pval_max = p_val_rep[:,s].max()\n",
    "            idx_pval_max.append(pval_max)\n",
    "        np.save(path2save+su+'_pval_stats_Bad_vs_Good_ERP_'+str(name)+'_('+str(elec)+')',idx_pval_max)\n",
    "\n",
    "        #Save da accuracy\n",
    "        np.save(path2save+su+'_da_Bad_vs_Good_ERP_'+classif+'_'+str(name)+'_('+str(elec)+')',da_rep)\n",
    "\n",
    "# ============================== PLOT ERPs ANALYSIS + STATS & DECODING ACCURACY ===================================================\n",
    "        # data to plot\n",
    "        bad_good_plot = np.concatenate((bad_split, good_split), axis=0)\n",
    "        y_plot = [0]*bad_split.shape[0] + [1]*good_split.shape[0]\n",
    "\n",
    "        # plot and figure parameters\n",
    "        xfmt = ScalarFormatter(useMathText=True)\n",
    "        xfmt.set_powerlimits((0,3))\n",
    "        fig = plt.figure(1,figsize=(7,7))\n",
    "        title = 'ERP and DA for '+su+' Good/Bad '+str(channel)+' '+str(name)+' ('+str(elec)+') ntrials:'+str(ntrials)\n",
    "        fig.suptitle(title, fontsize=12)\n",
    "        times_plot = 1000 * np.arange((baseline[0] - baseline[1]), len(shapeRmPoints)-baseline[1]+baseline[0],winSample) / sf\n",
    "        #print (times_plot)\n",
    "        lines = [0] #time vector is in ms\n",
    "\n",
    "        # Plot the ERPs\n",
    "        plt.subplot(211)\n",
    "        BorderPlot(times_plot, bad_good_plot, y=y_plot, kind='sem', alpha=0.2, color=['b','m'], \n",
    "                   linewidth=2, ncol=1, xlabel='Time (ms)',ylabel = r' $\\mu$V', legend=['bad','good'])\n",
    "        addLines(plt.gca(), vLines=lines, vColor=['r'], vWidth=[2], hLines=[0], \n",
    "                 hColor=['#000000'], hWidth=[2])\n",
    "        addPval(plt.gca(), idx_pval_max, p=0.05, x=times_plot, y=5, color='0.5', lw=2)\n",
    "        addPval(plt.gca(), idx_pval_max, p=0.01, x=times_plot, y=0.2, color='0.7', lw=2)\n",
    "        addPval(plt.gca(), idx_pval_max, p=0.001, x=times_plot, y=0.3, color='0.9', lw=2)\n",
    "        rmaxis(plt.gca(), ['right', 'top'])\n",
    "        plt.legend(loc=0, handletextpad=0.1, frameon=False)\n",
    "        plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "\n",
    "        # Plot DA for the ERPs\n",
    "        plt.subplot(212)\n",
    "        BorderPlot(times_plot, da_rep, color='b', kind='std',xlabel='Time (ms)', ylim=[da.min()-10,da.max()+10],\n",
    "                   ylabel='Decoding accuracy (%)',linewidth=2,alpha=0.3)\n",
    "        rmaxis(plt.gca(), ['right', 'top'])\n",
    "        addLines(plt.gca(), vLines=lines, vWidth=[2], vColor=['r'], hLines=[50], \n",
    "                 hColor=['#000000'], hWidth=[2])\n",
    "        plt.legend(loc=0, handletextpad=0.1, frameon=False)   \n",
    "        plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "        th_0_05 = 100*np.around(binom.isf(0.05, bad_split.shape[0], 0.5)/bad_split.shape[0],2)\n",
    "        th_0_01 = 100*np.around(binom.isf(0.01, bad_split.shape[0], 0.5)/bad_split.shape[0],2)\n",
    "        th_0_001 = 100*np.around(binom.isf(0.001, bad_split.shape[0], 0.5)/bad_split.shape[0],2)\n",
    "        plt.plot(times_plot, th_0_05*np.ones(len(times_plot)), '--', color='orange', \n",
    "                  linewidth=2, label= str(th_0_05)+' - p < .05')\n",
    "        plt.plot(times_plot, th_0_01*np.ones(len(times_plot)), '--', color='orangered', \n",
    "                  linewidth=2, label= str(th_0_01)+' - p < .01')\n",
    "        plt.plot(times_plot, th_0_001*np.ones(len(times_plot)), '--', color='r', \n",
    "                      linewidth=2, label= str(th_0_001)+' - p < .001')\n",
    "\n",
    "# =========================== SAVE FIGURES & CLEAN MEMORY ==========================================================================\n",
    "        #Save the plot\n",
    "        fname = path.join(path2save, su+'_Bad_vs_Good_ERP_'+classif+'_'+str(name)+'_('+str(elec)+').png')\n",
    "        fig.savefig(fname, dpi=300, bbox_inches='tight')\n",
    "        plt.clf()\n",
    "        plt.close()    \n",
    "        del bad_split, good_split, good_split_stat, bad_split_stat\n",
    "    del data_bad, data_good, channels, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = study('Olfacto')\n",
    "path_data = path.join (st.path, 'feature/8_PLV_EPISCORE_Good_Bad_across_time_subset/')\n",
    "\n",
    "da= np.load(path_data+'LEFC_bad_plv_theta_elec_(0)_Amg-pPirT.npy')\n",
    "print(da.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times_plot = 1000 * np.arange((baseline[0] - baseline[1]), len(shapeRmPoints)-baseline[1]+baseline[0],winSample) / sf\n",
    "print (len(shapeRmPoints))\n",
    "print (len(times_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st = study('Olfacto')\n",
    "path_data = path.join (st.path, 'database/TS_E_all_by_odor_th40_art400_30_250_5s_Good_Bad_EpiScore/')\n",
    "path2save = path.join (st.path, 'classified/8_Classif_ERP_EPISCORE_Bad_Good_across_time_win20ms_subset/lda/')\n",
    "\n",
    "test = 'subset'\n",
    "classifs = ['lda']\n",
    "\n",
    "if test == True:\n",
    "    n_elec = {'VACJ' :50}\n",
    "    subjects = ['VACJ']\n",
    "    \n",
    "elif test == False :\n",
    "    subjects = ['SEMC','PIRJ','LEFC','MICP','CHAF','VACJ'] \n",
    "    n_elec = {\n",
    "    'CHAF' : 107,\n",
    "    'VACJ' : 139, \n",
    "    'SEMC' : 107,\n",
    "    'PIRJ' : 106,\n",
    "    'LEFC' : 193,\n",
    "    'MICP' : 105,\n",
    "        }\n",
    "    \n",
    "elif test == 'subset': #HC, PHC, Amg, Pir\n",
    "    subjects = ['MICP', 'VACJ', 'SEMC','PIRJ','LEFC'] #'MICP\n",
    "    n_elec = {\n",
    "    'VACJ' : [1,2,3,11,12,13,14,15,16,17,22,23,24,60,61,62],\n",
    "    'SEMC' : [0,1,2,3,4],\n",
    "    'PIRJ' : [0,1,2,3,4,11,12,13,14,15,16,22,23,24,25,26,33,34,35,36,37,38],\n",
    "    'LEFC' : [0,1,11,12,13,14,22,23,24,25,26,27],\n",
    "    'MICP' : [0,1,2,3,9,18,10,11,12,19,20,21,22,23,29,30,31,32,33,40,41,42,43,44],\n",
    "        }\n",
    "\n",
    "for classif in classifs:\n",
    "    for su in subjects:\n",
    "        #Load files\n",
    "        data_bad = np.load(path.join(path_data, su+'_concat_odor_bad_bipo.npz'))\n",
    "        data_good = np.load(path.join(path_data, su+'_concat_odor_good_bipo.npz'))\n",
    "        data_bad, channels, names, data_good = data_bad['x'], data_bad['channel'], data_bad['label'], data_good['x']\n",
    "\n",
    "        #for elec in range(0,n_elec[su]):\n",
    "        for elec in n_elec[su]:\n",
    "            # Select data for one elec + name :\n",
    "            data_elec_bad = data_bad[elec,:,:]\n",
    "            data_elec_good = data_good[elec,:,:]\n",
    "            ntrials = str(data_elec_bad.shape[1])+'/'+ str(data_elec_good.shape[1])\n",
    "            channel, name = channels[elec], names[elec]\n",
    "            print (su, 'Channel : ', channel, 'Label : ', name,'Bad shape : ', \n",
    "                   data_elec_bad.shape, 'Good shape : ', data_elec_good.shape)\n",
    "\n",
    "            #Filter data for one elec (all trials):\n",
    "            data_elec_bad = np.array(data_elec_bad, dtype='float64')\n",
    "            data_elec_good = np.array(data_elec_good, dtype='float64')\n",
    "            data_bad_to_filter = np.swapaxes(data_elec_bad, 0, 1)\n",
    "            data_good_to_filter = np.swapaxes(data_elec_good, 0, 1)\n",
    "            filtered_data_bad = filter_data(data_bad_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "            filtered_data_good = filter_data(data_good_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "            print ('Size of filtered data bad :', filtered_data_bad.shape, 'filtered data good : ', filtered_data_good.shape,)\n",
    "\n",
    "            #Normalize the non-averaged data (all trials)\n",
    "            times = np.arange(filtered_data_bad.shape[1])\n",
    "            print ('time points : ', times.shape)\n",
    "            norm_filtered_data_bad = rescale(filtered_data_bad, times=times, baseline=baseline, mode=norm_mode)\n",
    "            norm_filtered_data_good = rescale(filtered_data_good, times=times, baseline=baseline, mode=norm_mode)\n",
    "            print ('Size norm & filtered data 0 : ', norm_filtered_data_bad.shape, norm_filtered_data_good.shape,)\n",
    "\n",
    "            # Range of the data to compute\n",
    "            data_range = range(data_to_use[0], data_to_use[1])\n",
    "            sel_bad = norm_filtered_data_bad[:, data_range]\n",
    "            sel_good = norm_filtered_data_good[:, data_range,]\n",
    "            print ('-> Shape of bad data', sel_bad.shape, 'good data', sel_good.shape)\n",
    "\n",
    "            # Average the signal on consecutive windows\n",
    "            winSample = 10 #20ms in samples\n",
    "            n_pts = sel_bad.shape[1]\n",
    "            rmPoints = n_pts % winSample # Points to remove before splitting\n",
    "            shapeRmPoints = np.arange(n_pts-rmPoints).astype(int) # Number of points for round division\n",
    "            n_win = int(n_pts / winSample) # Number of segments\n",
    "\n",
    "            # Split and average data (trials, n_pts)\n",
    "            bad_split = np.array(np.split(sel_bad[:, shapeRmPoints], n_win, axis=1)) # n_win n_trials n_pts\n",
    "            bad_split = np.mean(bad_split, axis=2).swapaxes(0,1) # n-trials n_win\n",
    "            good_split = np.array(np.split(sel_good[:, shapeRmPoints], n_win, axis=1))\n",
    "            good_split = np.mean(good_split, axis=2).swapaxes(0,1)\n",
    "\n",
    "# ================================  STATISTICS FOR POWER  =====================================\n",
    "            n_rep = 10\n",
    "            T_rep, p_val_rep = np.array([]), np.array([])\n",
    "            da_rep, daperm_rep = np.array([]), np.array([])\n",
    "            alpha = 0.05\n",
    "            \n",
    "            for i in range(n_rep):\n",
    "                #reshape data to have the exact same nb of trials (mandatory for t-tests)\n",
    "                if bad_split.shape[0] > good_split.shape[0]:\n",
    "                    bad_split_stat = bad_split[np.random.randint(bad_split.shape[0], size=good_split.shape[0]), :] #reshape bad_data to fit good_data shape\n",
    "                    good_split_stat = good_split\n",
    "                elif bad_split.shape[0] < good_split.shape[0]:\n",
    "                    bad_split_stat = bad_split\n",
    "                    good_split_stat = good_split[np.random.randint(good_split.shape[0], size=bad_split.shape[0]), :]\n",
    "                else :\n",
    "                    bad_split_stat = bad_split\n",
    "                    good_split_stat = good_split                    \n",
    "                ntrials = bad_split.shape[0]\n",
    "                X = bad_split_stat - good_split_stat #the last dimension needs to be time\n",
    "                T0, p_values, H0 = permutation_t_test(X, n_permutations=1000, tail=0, n_jobs=1, verbose=None)\n",
    "                T_rep = np.vstack((T_rep,T0)) if np.size(T_rep) else T0\n",
    "                p_val_rep = np.vstack((p_val_rep,p_values)) if np.size(p_val_rep) else p_values\n",
    "\n",
    "# =============================  CLASSIFICATION COMPUTATION ============================================================           \n",
    "                                    \n",
    "                #create a data matrix, concatenate along the trial dimension\n",
    "                bad_good = np.concatenate((bad_split_stat, good_split_stat), axis=0)\n",
    "                print ('Size of the concatenated data: ', bad_good.shape, 'Number time windows : ', bad_good.shape[1])\n",
    "\n",
    "                #create label vector (0 for rest and 1 for odor)\n",
    "                y = [0]*bad_split_stat.shape[0] + [1]*good_split_stat.shape[0]\n",
    "                print ('Size of label for classif: ', len(y))\n",
    "\n",
    "                # Define a cross validation:\n",
    "                cv = defCv(y, n_folds=10, cvtype='skfold', rep=10)\n",
    "                # Define classifier technique\n",
    "                clf = defClf(y=y, clf=classif, kern='rbf')#,n_tree=200, random_state=100)\n",
    "                #Classify rest and odor\n",
    "                cl = classify(y, clf=clf, cvtype=cv)\n",
    "\n",
    "                # Evaluate the classifier on data:\n",
    "                da,pvalue,daperm = cl.fit(bad_good, n_perm=100,method='bino',mf=False)\n",
    "                print(da.shape)\n",
    "                print ('decoding accuracy',da.shape, 'pvalues ', pvalue.shape,)\n",
    "            da_rep = np.vstack((da_rep,da)) if np.size(da_rep) else da\n",
    "            print (da_rep.shape)\n",
    "                \n",
    "# =============================== TAKE MAX STATS TO PLOT =====================================\n",
    "            # Take the max pvalues for each time window\n",
    "            idx_pval_max = []\n",
    "            for s in range(n_win):\n",
    "                pval_max = p_val_rep[:,s].max()\n",
    "                idx_pval_max.append(pval_max)\n",
    "            np.save(path2save+su+'_pval_stats_Bad_vs_Good_ERP_'+str(name)+'_('+str(elec)+')',idx_pval_max)\n",
    "\n",
    "            #Save da accuracy\n",
    "            np.save(path2save+su+'_da_Bad_vs_Good_ERP_'+classif+'_'+str(name)+'_('+str(elec)+')',da_rep)\n",
    "\n",
    "# ============================== PLOT ERPs ANALYSIS + STATS & DECODING ACCURACY ===================================================\n",
    "            # data to plot\n",
    "            bad_good_plot = np.concatenate((bad_split, good_split), axis=0)\n",
    "            y_plot = [0]*bad_split.shape[0] + [1]*good_split.shape[0]\n",
    "\n",
    "            # plot and figure parameters\n",
    "            xfmt = ScalarFormatter(useMathText=True)\n",
    "            xfmt.set_powerlimits((0,3))\n",
    "            fig = plt.figure(1,figsize=(7,7))\n",
    "            title = 'ERP and DA for '+su+' Good/Bad '+str(channel)+' '+str(name)+' ('+str(elec)+') ntrials:'+str(ntrials)\n",
    "            fig.suptitle(title, fontsize=12)\n",
    "            times_plot = 1000 * np.arange((baseline[0] - baseline[1]), len(shapeRmPoints)-baseline[1]+baseline[0],winSample) / sf\n",
    "            #print (times_plot)\n",
    "            lines = [0] #time vector is in ms\n",
    "\n",
    "            # Plot the ERPs\n",
    "            plt.subplot(211)\n",
    "            BorderPlot(times_plot, bad_good_plot, y=y_plot, kind='sem', alpha=0.2, color=['b','m'], \n",
    "                       linewidth=2, ncol=1, xlabel='Time (ms)',ylabel = r' $\\mu$V', legend=['bad','good'])\n",
    "            addLines(plt.gca(), vLines=lines, vColor=['r'], vWidth=[2], hLines=[0], \n",
    "                     hColor=['#000000'], hWidth=[2])\n",
    "            addPval(plt.gca(), idx_pval_max, p=0.05, x=times_plot, y=5, color='0.5', lw=2)\n",
    "            addPval(plt.gca(), idx_pval_max, p=0.01, x=times_plot, y=0.2, color='0.7', lw=2)\n",
    "            addPval(plt.gca(), idx_pval_max, p=0.001, x=times_plot, y=0.3, color='0.9', lw=2)\n",
    "            rmaxis(plt.gca(), ['right', 'top'])\n",
    "            plt.legend(loc=0, handletextpad=0.1, frameon=False)\n",
    "            plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "\n",
    "            # Plot DA for the ERPs\n",
    "            plt.subplot(212)\n",
    "            BorderPlot(times_plot, da_rep, color='b', kind='std',xlabel='Time (ms)', ylim=[da.min()-10,da.max()+10],\n",
    "                       ylabel='Decoding accuracy (%)',linewidth=2,alpha=0.3)\n",
    "            rmaxis(plt.gca(), ['right', 'top'])\n",
    "            addLines(plt.gca(), vLines=lines, vWidth=[2], vColor=['r'], hLines=[50], \n",
    "                     hColor=['#000000'], hWidth=[2])\n",
    "            plt.legend(loc=0, handletextpad=0.1, frameon=False)   \n",
    "            plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "            th_0_05 = 100*np.around(binom.isf(0.05, bad_split.shape[0], 0.5)/bad_split.shape[0],2)\n",
    "            th_0_01 = 100*np.around(binom.isf(0.01, bad_split.shape[0], 0.5)/bad_split.shape[0],2)\n",
    "            th_0_001 = 100*np.around(binom.isf(0.001, bad_split.shape[0], 0.5)/bad_split.shape[0],2)\n",
    "            plt.plot(times_plot, th_0_05*np.ones(len(times_plot)), '--', color='orange', \n",
    "                      linewidth=2, label= str(th_0_05)+' - p < .05')\n",
    "            plt.plot(times_plot, th_0_01*np.ones(len(times_plot)), '--', color='orangered', \n",
    "                      linewidth=2, label= str(th_0_01)+' - p < .01')\n",
    "            plt.plot(times_plot, th_0_001*np.ones(len(times_plot)), '--', color='r', \n",
    "                          linewidth=2, label= str(th_0_001)+' - p < .001')\n",
    "\n",
    "# =========================== SAVE FIGURES & CLEAN MEMORY ==========================================================================\n",
    "            #Save the plot\n",
    "            fname = path.join(path2save, su+'_Bad_vs_Good_ERP_'+classif+'_'+str(name)+'_('+str(elec)+').png')\n",
    "            fig.savefig(fname, dpi=300, bbox_inches='tight')\n",
    "            plt.clf()\n",
    "            plt.close()    \n",
    "            del bad_split, good_split, good_split_stat, bad_split_stat\n",
    "        del data_bad, data_good, channels, names"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
