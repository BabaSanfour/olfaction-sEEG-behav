{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification Power Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "#%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "from brainpipe.classification import *\n",
    "from brainpipe.system import study\n",
    "from brainpipe.feature import power, amplitude, sigfilt\n",
    "\n",
    "from brainpipe.statistics import *\n",
    "from os import path\n",
    "import mne\n",
    "from mne.viz import plot_topomap\n",
    "from mne import pick_types, find_layout\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Rest cond 500ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rest = 500ms out of 1s 250-750ms\n",
    "st = study('Olfacto')\n",
    "subjects = ['CHAF', 'SEMC', 'VACJ','PIRJ', 'MICP', 'LEFC']\n",
    "\n",
    "for su in subjects:\n",
    "    file = su+'_E1E2_concat_allfilter1_bipo.npz'\n",
    "    loadname = path.join(st.path, 'database/TS_E_all_cond_by_block_trigs_th40_art400_30_250', file)\n",
    "    print('-> Select data in: '+loadname)\n",
    "    mat = np.load(loadname)['x']\n",
    "\n",
    "    #Generate the files\n",
    "    print (mat.shape)\n",
    "    rest = mat[:,128:384,:]\n",
    "    print (rest.shape,)\n",
    "\n",
    "    #save the files\n",
    "    saverest = loadname.replace('_E1', '_rest_E1').replace('250', '250/Classif_new')\n",
    "    np.savez(saverest, x=rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating expectation and odor perception conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Odor = expectation + perception\n",
    "#Expect (0.5s before) Percept (3s following)\n",
    "\n",
    "st = study('Olfacto')\n",
    "\n",
    "files = st.search('odor_E1E2_concat_allfilter1_bipo.npz', folder='database/TS_E_all_cond_by_block_trigs_th40_art400_30_250')\n",
    "\n",
    "for fi in files:\n",
    "    loadname = path.join(st.path, 'database/TS_E_all_cond_by_block_trigs_th40_art400_30_250', fi)\n",
    "    print('-> Select data in: '+loadname)\n",
    "    mat = np.load(loadname)['x']\n",
    "\n",
    "    #Generate the files\n",
    "    print (mat.shape)\n",
    "    expect = mat[:,:256,:]\n",
    "    percept = mat[:,256:,:]\n",
    "    print (expect.shape, percept.shape)\n",
    "\n",
    "    #save the files\n",
    "    saveexpect = loadname.replace('odor', 'expect').replace('250', '250/Classif_new')\n",
    "    savepercept = loadname.replace('odor', 'percept').replace('250', '250/Classif_new')\n",
    "    np.savez(saveexpect, x=expect)\n",
    "    np.savez(savepercept, x=percept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating percept by second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Percept (3s following)\n",
    "# creation of 24 windows of 500ms with 25% d'overlap (décale de 125ms)\n",
    "\n",
    "st = study('Olfacto')\n",
    "files = st.search('_percept_E1E2_concat_allfilter1_bipo.npz', folder='database/TS_E_all_cond_by_block_trigs_th40_art400_30_250/Classif_new/')\n",
    "\n",
    "for fi in files:\n",
    "    loadname = path.join(st.path, 'database/TS_E_all_cond_by_block_trigs_th40_art400_30_250/Classif_new/', fi)\n",
    "    mat = np.load(loadname)['x']\n",
    "    n_windows = int((mat.shape[1]-64*3) / 64) #64 samples = 125ms\n",
    "    print ('Size of Percept file: ', mat.shape, 'Length of data :', mat.shape[1], 'Nb of windows: ', n_windows)\n",
    "\n",
    "    for i in range(n_windows):\n",
    "        percept = mat[:,(i)*64:256+(i)*64,:]\n",
    "        print (i, 'bornes prises :', (i)*64, 256+(i)*64)\n",
    "        print ('file size : ', percept.shape)\n",
    "        \n",
    "        filename = loadname.replace('percept', 'percept_'+str(i))\n",
    "        np.savez(filename, x=percept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate mean power files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all files include in the database\n",
    "st = study('Olfacto')\n",
    "files = st.search('_E1E2_concat_allfilter1_bipo_power.npz', folder='feature/Power_Encoding_Rest_Expect_Percept_500ms_windows')\n",
    "n_freq = 6\n",
    "\n",
    "for fi in files:\n",
    "    for freq in range(0, n_freq, 1):\n",
    "        # Load file (nb_freq, n_elec, n_pts, n_trials):\n",
    "        loadname = path.join(st.path, 'feature/Power_Encoding_Rest_Expect_Percept_500ms_windows', fi)\n",
    "        print('-> Compute mean on: '+loadname)\n",
    "        mat = np.load(loadname)\n",
    "        x, fname = mat['xpow'], mat['fname']\n",
    "        x = x[freq,:,:,:] #selection of the freq range\n",
    "        print (x.shape)\n",
    "        x = np.mean(x, axis = 1) #mean across time points\n",
    "        print (x.shape)\n",
    "        x = x.swapaxes(0, 1)\n",
    "        print (x.shape) #trials and elecs\n",
    "        savename = loadname.replace('_power.npz', '_meanpow_'+str(fname[freq])+'.npz')\n",
    "        #print (savename)\n",
    "        np.savez(savename, x=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & concatenate power files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing files \n",
    "st = study('Olfacto')\n",
    "pathfiles = path.join(st.path, 'feature/MeanPower_E_all_cond_by_block_trigs_filter1_500art/')\n",
    "elecfiles = path.join(st.path, 'database/TS_E_all_cond_by_block_trigs_filter1_500art/Odor_rest/')\n",
    "path2save = path.join(st.path, 'classified/TS_E_all_cond_by_block_trigs_filter1_500art')\n",
    "\n",
    "#theta alpha gamma30-60 gamma60-120\n",
    "odor_data = np.load(path.join(pathfiles, 'SEMC_expect_E1E2_concat_allfilter1_bipo_meanpow_delta.npz'))['x']\n",
    "rest_data = np.load(path.join(pathfiles, 'SEMC_rest_E1E2_concat_allfilter1_bipo_meanpow_delta.npz'))['x']\n",
    "print (odor_data.shape, rest_data.shape)\n",
    "elec = np.load(path.join(elecfiles, 'SEMC_odor_E1E2_concat_allfilter1_bipo.npz'))['channel']\n",
    "print (elec.shape)\n",
    "#create a data matrix, concatenate along the trial dimension\n",
    "odor_rest = np.concatenate((odor_data, rest_data), axis=0)\n",
    "print (odor_rest.shape)\n",
    "\n",
    "#create label vector (0 for rest and 1 for odor)\n",
    "label = [1]*odor_data.shape[0] + [0]*rest_data.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classifier and Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a cross validation:\n",
    "cv = defCv(label, cvtype='skfold', n_folds=3, rep=50)\n",
    "print (cv)\n",
    "\n",
    "# Define classifier technique\n",
    "clf = defClf(label, clf='svm') #,n_tree=200, random_state=100)\n",
    "print (clf)\n",
    "\n",
    "#Classify rest and odor\n",
    "cl = classify(label, clf=clf, cvtype=cv)\n",
    "#print(cl)\n",
    "\n",
    "# Evaluate the classifier on data:\n",
    "da,pvalue,daperm = cl.fit(odor_rest, grp=elec, n_perm=100,method='label_rnd')\n",
    "da_mean = np.mean(da,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "da_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig1 = plt.figure(1, figsize=(20,10))\n",
    "\n",
    "cl.daplot(da_mean, daperm=daperm, chance_method='perm', rmax=['top', 'right'],\n",
    "        dpax=['bottom', 'left'], cmap='magma', ylim=[40,100], chance_unique=True,chance_level = 0.01,\n",
    "        chance_color='darkgreen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate classifier for all freq bands and subjects + Figures\n",
    "### Analysis subject by subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "CHAF (6, 103, 7, 40)\n",
      "CHAF (6, 103, 1, 40)\n",
      "(40, 103) (40, 103)\n",
      "Channels :  (103,) <U9 Labels :  (103,) <U9\n",
      "Size of the concatenated data:  (80, 103) Number of features :  103\n",
      "Size of label for classif:  80\n",
      "10-times, 10 Stratified k-folds\n",
      "LinearDiscriminantAnalysis(n_components=None, priors=array([ 0.5,  0.5]),\n",
      "              shrinkage=None, solver='svd', store_covariance=False,\n",
      "              tol=0.0001)\n",
      "size decoding accuracy :  (10, 103)\n",
      "saving --» /media/karim/Datas4To/Analyses_Intra_EM_Odor/Olfacto/classified/1_Classif_Windows_Encoding_th40_art400_30_250_by_label_500ms_windows/DA_lda_CHAF_theta_Window_0_0.01.png\n",
      "(40, 103) (40, 103)\n",
      "Channels :  (103,) <U9 Labels :  (103,) <U9\n",
      "Size of the concatenated data:  (80, 103) Number of features :  103\n",
      "Size of label for classif:  80\n",
      "10-times, 10 Stratified k-folds\n",
      "LinearDiscriminantAnalysis(n_components=None, priors=array([ 0.5,  0.5]),\n",
      "              shrinkage=None, solver='svd', store_covariance=False,\n",
      "              tol=0.0001)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-20ab20b11264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# Evaluate the classifier on data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdaperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0modor_rest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_perm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label_rnd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mda_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'size decoding accuracy : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/site-packages/brainpipe/clf/_classification.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, mf, center, grp, method, n_perm, rndstate, n_jobs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 cvs = Parallel(n_jobs=n_jobs)(delayed(_cvscore)(\n\u001b[1;32m    176\u001b[0m                         x[k], y_sh[i], clone(self._clf), self._cv.cvr[0])\n\u001b[0;32m--> 177\u001b[0;31m                         for i, k in iteract)\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;31m# -> Full randomization :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0;31m# a working pool as they expect.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0;31m# Stop dispatching any new job in the async callback thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Importing files \n",
    "st = study('Olfacto')\n",
    "pathfiles = path.join(st.path, 'feature/2_Power_Encoding_Odor_rest_th40_art400_30_250_across_time_nooverlap/')\n",
    "elecfiles = path.join(st.path, 'database/TS_E_all_cond_by_block_trigs_th40_art400_30_250_5s_concatOK/')\n",
    "path2save = path.join(st.path, 'classified/1_Classif_Windows_Encoding_th40_art400_30_250_by_label_500ms_windows/')\n",
    "\n",
    "subjects = ['CHAF','SEMC','VACJ','PIRJ', 'MICP', 'LEFC']\n",
    "freq_bands = ['delta', 'theta', 'alpha', 'beta', 'gamma30-60', 'gamma60-150']\n",
    "nfreq, nwin = 6, 7\n",
    "classifier = 'lda'\n",
    "\n",
    "for su in subjects:\n",
    "    odor_file = np.load(pathfiles+su+'_E1E2_concat_all_bipo_new_odor_power.npz')['xpow']\n",
    "    print (su, odor_file.shape)\n",
    "    rest_file = np.load(pathfiles+su+'_E1E2_concat_all_bipo_new_rest_power.npz')['xpow']\n",
    "    print (su, rest_file.shape)\n",
    "\n",
    "    for win in range(nwin):\n",
    "        for freq in range(1, nfreq):\n",
    "            odor_data = np.swapaxes(odor_file[freq,:,win,:], 0,1)\n",
    "            rest_data = np.swapaxes(rest_file[freq,:,0,:], 0, 1)\n",
    "            print (odor_data.shape, rest_data.shape)\n",
    "            elec = np.load(path.join(elecfiles, su+'_E1E2_concat_all_bipo_new.npz'))['channel']\n",
    "            elec_label = np.load(path.join(elecfiles, su+'_E1E2_concat_all_bipo_new.npz'))['label']\n",
    "            elec_label = np.array(elec_label, dtype='<U9')\n",
    "            print ('Channels : ', elec.shape, elec.dtype,\n",
    "                      'Labels : ', elec_label.shape, elec_label.dtype)\n",
    "\n",
    "            #create a data matrix, concatenate along the trial dimension\n",
    "            odor_rest = np.concatenate((odor_data, rest_data), axis=0)\n",
    "            print ('Size of the concatenated data: ', odor_rest.shape,\n",
    "                      'Number of features : ', odor_rest.shape[1])\n",
    "\n",
    "            #create label vector (0 for rest and 1 for odor)\n",
    "            label = [1]*odor_data.shape[0] + [0]*rest_data.shape[0]\n",
    "            print ('Size of label for classif: ', len(label))\n",
    "\n",
    "            # Define a cross validation:\n",
    "            cv = defCv(label, n_folds=10, cvtype='skfold', rep=10)\n",
    "            print (cv)\n",
    "\n",
    "            # Define classifier technique\n",
    "            clf = defClf(label, clf='lda') #,n_tree=200, random_state=100)\n",
    "            print (clf)\n",
    "\n",
    "            #Classify rest and odor\n",
    "            cl = classify(label, clf=clf, cvtype=cv)\n",
    "\n",
    "            # Evaluate the classifier on data:\n",
    "            da,pvalue,daperm = cl.fit(odor_rest, grp=elec, n_perm=200,method='label_rnd')\n",
    "            da_mean = np.mean(da,axis=0)\n",
    "            print ('size decoding accuracy : ', da.shape)\n",
    "\n",
    "            #Save information\n",
    "            np.save(path2save+su+'_da_'+freq_bands[freq]+'_Window_'+str(win)+'_'+classifier,{'da_'+freq_bands[freq]+'_Window_'+str(win): da})\n",
    "            np.save(path2save+su+'_pvalue_'+freq_bands[freq]+'_Window_'+str(win)+'_'+classifier,{'pvalue_'+freq_bands[freq]+'_Window_'+str(win): pvalue})\n",
    "            np.save(path2save+su+'_da_perm_'+freq_bands[freq]+'_Window_'+str(win)+'_'+classifier,{'da_perm_'+freq_bands[freq]+'_Window_'+str(win): daperm})\n",
    "\n",
    "            #Generate the figure and save the plot\n",
    "            title = 'Classif_Encoding_'+su+'_'+freq_bands[freq]+'_Window_'+str(win)+'_p<0.01'\n",
    "\n",
    "            fig1 = plt.figure(1, figsize=(20,10))\n",
    "            fig1.suptitle(title, fontsize=\"x-large\")\n",
    "            cl.daplot(da_mean, daperm=daperm, chance_method='perm', rmax=['top', 'right'],\n",
    "            dpax=['bottom', 'left'], cmap='magma', ylim=[40,100], chance_unique=True, chance_level = 0.01,\n",
    "            chance_color='darkgreen',)\n",
    "\n",
    "            fname = path.join(path2save, su+'_DA_'+classifier+'_'+freq_bands[freq]+'_Window_'+str(win)+'_p.01.png')\n",
    "            fig1.savefig(fname, dpi=300, bbox_inches='tight')\n",
    "            print ('saving --»' ,fname)\n",
    "            cl.info.to_excel(path2save+su+'_DA_'+classifier+'_'+freq_bands[freq]+'_Window_'+str(win)+'_p.01.xlsx')\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "        del da_mean, da, daperm, pvalue, elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
