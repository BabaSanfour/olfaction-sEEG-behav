{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, MaxNLocator\n",
    "import scipy.io as sio\n",
    "\n",
    "from brainpipe.classification import *\n",
    "from brainpipe.system import study\n",
    "from brainpipe.feature import PLV\n",
    "from brainpipe.visual import *\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import expon\n",
    "\n",
    "from brainpipe.statistics import *\n",
    "from os import path\n",
    "from mne.stats import *\n",
    "from scipy.stats import binom\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification across time for all freq bands and subjects\n",
    "### Encoding Good vs Bad odors - SVM optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "label elec 1 aHC&aHC-Ent label elec 2 aHC\n",
      "plv bad all (23, 2560)\n",
      "plv bad all (17, 2560)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3199:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b16346ddd429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0melec2_bad_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melec2_bad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mdefPlv_bad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mplv_bad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalues_bad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefPlv_bad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melec1_bad_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0melec2_bad_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_perm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_perm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mplv_bad_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplv_bad_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplv_bad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplv_bad_all\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mplv_bad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mplv_bad_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplv_bad_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/site-packages/brainpipe/feat/coupling/cfc.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mxelec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxelec2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         data = np.array(Parallel(n_jobs=n_jobs)(delayed(_plvfilt)(\n\u001b[0;32m--> 964\u001b[0;31m                     xcat[e, ...], self) for e in range(xcat.shape[0])))\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0mxp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnelec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnelec1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0;31m# a working pool as they expect.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0;31m# Stop dispatching any new job in the async callback thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Importing files \n",
    "st = study('Olfacto')\n",
    "pathfiles = path.join(st.path, 'feature/8_PLV_EPISCORE_Good_Bad_across_time_subset/')\n",
    "pathdata = path.join(st.path, 'database/TS_E_all_by_odor_th40_art400_30_250_5s_Good_Bad_EpiScore/')\n",
    "path2save = path.join(st.path, 'classified/8_Classif_PLV_EPISCORE_Good_Bad_across_time_700ms_step100ms_subset/svm_optimized/')\n",
    "\n",
    "test = 'subset' \n",
    "classifs = ['svm']\n",
    "fname = ['delta', 'theta', 'alpha', 'beta', 'gamma30-60', 'gamma60-150']\n",
    "\n",
    "if test == True:\n",
    "    subjects = ['PIRJ']\n",
    "    n_elec_list = {'PIRJ' :1}\n",
    "    \n",
    "elif test == False :\n",
    "    subjects = ['SEMC','PIRJ','LEFC','MICP','CHAF','VACJ'] \n",
    "    n_elec_list = {\n",
    "    'CHAF' : 107,\n",
    "    'VACJ' : 139, \n",
    "    'SEMC' : 107,\n",
    "    'PIRJ' : 106,\n",
    "    'LEFC' : 193,\n",
    "    'MICP' : 105,\n",
    "        }\n",
    "\n",
    "elif test == 'subset': #HC, PHC, Amg, Pir\n",
    "    subjects = ['SEMC','PIRJ','LEFC','MICP','VACJ']\n",
    "    n_elec_list = {\n",
    "    'VACJ' : [1,2,3,11,12,13,14,15,16,17,22,23,24,60,61,62],\n",
    "    'SEMC' : [0,1,2,3,4],\n",
    "    'PIRJ' : [0,1,2,3,4,11,12,13,14,15,16,22,23,24,25,26,33,34,35,36,37,38],\n",
    "    'LEFC' : [0,1,11,12,13,14,22,23,24,25,26,27],\n",
    "    'MICP' : [0,1,2,3,9,18,10,11,12,19,20,21,22,23,29,30,31,32,33,40,41,42,43,44],\n",
    "        }\n",
    "        \n",
    "# Parameters for the PLV\n",
    "freq = [[2, 4], [5, 7], [8, 13], [13, 30], [30, 60], [60, 150]] \n",
    "fname = ['delta', 'theta', 'alpha', 'beta', 'gamma30-60', 'gamma60-150'] \n",
    "n_perm = 1\n",
    "sf = 512\n",
    "method = 'hilbert'\n",
    "\n",
    "for su in subjects:\n",
    "    elec_pairs = list(combinations(n_elec_list[su],2))\n",
    "    for pair in range(len(elec_pairs)):\n",
    "        #Data elec 1\n",
    "        elec1_bad = np.load(path.join(pathdata, su+'_concat_odor_bad_bipo.npz'))['x'][elec_pairs[pair][0]]\n",
    "        elec1_good = np.load(path.join(pathdata, su+'_concat_odor_good_bipo.npz'))['x'][elec_pairs[pair][0]]\n",
    "        elec1_label = np.load(path.join(pathdata, su+'_concat_odor_bad_bipo.npz'))['label'][elec_pairs[pair][0]]\n",
    "        #Data elec 2\n",
    "        elec2_bad = np.load(path.join(pathdata, su+'_concat_odor_bad_bipo.npz'))['x'][elec_pairs[pair][1]]\n",
    "        elec2_good = np.load(path.join(pathdata, su+'_concat_odor_good_bipo.npz'))['x'][elec_pairs[pair][1]]\n",
    "        elec2_label = np.load(path.join(pathdata, su+'_concat_odor_bad_bipo.npz'))['label'][elec_pairs[pair][1]]\n",
    "        print('label elec 1',elec1_label, 'label elec 2', elec2_label)\n",
    "        \n",
    "        n_pts, n_trials_bad, n_trials_good = elec2_good.shape[0], elec2_bad.shape[1], elec2_good.shape[1]\n",
    "\n",
    "        for i,f in enumerate(freq):\n",
    "            plv_bad_all, plv_good_all = np.array([]), np.array([])\n",
    "            for t in range(n_trials_bad):\n",
    "                #Compute PLV for the bad condition\n",
    "                elec1_bad_trial = elec1_bad[:,t][:,np.newaxis]\n",
    "                elec2_bad_trial = elec2_bad[:,t][:,np.newaxis]\n",
    "                defPlv_bad = PLV(sf=sf, npts=n_pts, f=f, method=method, cycle=3)\n",
    "                plv_bad, pvalues_bad = defPlv_bad.get(elec1_bad_trial,elec2_bad_trial,n_perm = n_perm)\n",
    "                plv_bad_all = np.vstack((plv_bad_all,plv_bad)) if np.size(plv_bad_all) else plv_bad\n",
    "            plv_bad_all = np.squeeze(plv_bad_all)\n",
    "            print('plv bad all', plv_bad_all.shape)\n",
    "            \n",
    "            for t in range(n_trials_good):\n",
    "                #Compute PLV for the bad condition\n",
    "                elec1_good_trial = elec1_good[:,t][:,np.newaxis]\n",
    "                elec2_good_trial = elec2_good[:,t][:,np.newaxis]\n",
    "                defPlv_good = PLV(sf=sf, npts=n_pts, f=f, method=method, cycle=3)\n",
    "                plv_good, pvalues_good = defPlv_good.get(elec1_good_trial,elec2_good_trial,n_perm = n_perm)\n",
    "                plv_good_all = np.vstack((plv_good_all,plv_good)) if np.size(plv_good_all) else plv_good\n",
    "            plv_good_all = np.squeeze(plv_good_all)\n",
    "            print('plv good all', plv_good_all.shape)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing files \n",
    "st = study('Olfacto')\n",
    "pathfiles = path.join(st.path, 'feature/8_PLV_EPISCORE_Good_Bad_across_time_subset/')\n",
    "pathdata = path.join(st.path, 'database/TS_E_all_by_odor_th40_art400_30_250_5s_Good_Bad_EpiScore/')\n",
    "path2save = path.join(st.path, 'classified/8_Classif_PLV_EPISCORE_Good_Bad_across_time_700ms_step100ms_subset/svm_optimized/')\n",
    "\n",
    "test = 'subset' \n",
    "classifs = ['svm']\n",
    "fname = ['delta', 'theta', 'alpha', 'beta', 'gamma30-60', 'gamma60-150']\n",
    "\n",
    "if test == True:\n",
    "    subjects = ['PIRJ']\n",
    "    n_elec_list = {'PIRJ' :1}\n",
    "    \n",
    "elif test == False :\n",
    "    subjects = ['SEMC','PIRJ','LEFC','MICP','CHAF','VACJ'] \n",
    "    n_elec_list = {\n",
    "    'CHAF' : 107,\n",
    "    'VACJ' : 139, \n",
    "    'SEMC' : 107,\n",
    "    'PIRJ' : 106,\n",
    "    'LEFC' : 193,\n",
    "    'MICP' : 105,\n",
    "        }\n",
    "\n",
    "elif test == 'subset': #HC, PHC, Amg, Pir\n",
    "    subjects = ['SEMC','PIRJ','LEFC','MICP','VACJ']\n",
    "    n_elec_list = {\n",
    "    'VACJ' : [1,2,3,11,12,13,14,15,16,17,22,23,24,60,61,62],\n",
    "    'SEMC' : [0,1,2,3,4],\n",
    "    'PIRJ' : [0,1,2,3,4,11,12,13,14,15,16,22,23,24,25,26,33,34,35,36,37,38],\n",
    "    'LEFC' : [0,1,11,12,13,14,22,23,24,25,26,27],\n",
    "    'MICP' : [0,1,2,3,9,18,10,11,12,19,20,21,22,23,29,30,31,32,33,40,41,42,43,44],\n",
    "        }\n",
    "        \n",
    "# Parameters for the PLV\n",
    "freq = [[2, 4], [5, 7], [8, 13], [13, 30], [30, 60], [60, 150]] \n",
    "fname = ['delta', 'theta', 'alpha', 'beta', 'gamma30-60', 'gamma60-150'] \n",
    "n_perm = 1\n",
    "sf = 512\n",
    "method = 'hilbert'\n",
    "\n",
    "for su in subjects:\n",
    "    elec_pairs = list(combinations(n_elec_list[su],2))\n",
    "    for pair in range(len(elec_pairs)):\n",
    "        #Data elec 1\n",
    "        elec1_bad = np.load(path.join(pathdata, su+'_concat_odor_bad_bipo.npz'))['x'][elec_pairs[pair][0]]\n",
    "        elec1_good = np.load(path.join(pathdata, su+'_concat_odor_good_bipo.npz'))['x'][elec_pairs[pair][0]]\n",
    "        elec1_label = np.load(path.join(pathdata, su+'_concat_odor_bad_bipo.npz'))['label'][elec_pairs[pair][0]]\n",
    "        #Data elec 2\n",
    "        elec2_bad = np.load(path.join(pathdata, su+'_concat_odor_bad_bipo.npz'))['x'][elec_pairs[pair][1]]\n",
    "        elec2_good = np.load(path.join(pathdata, su+'_concat_odor_good_bipo.npz'))['x'][elec_pairs[pair][1]]\n",
    "        elec2_label = np.load(path.join(pathdata, su+'_concat_odor_bad_bipo.npz'))['label'][elec_pairs[pair][1]]\n",
    "        print('label elec 1',elec1_label, 'label elec 2', elec2_label)\n",
    "        \n",
    "        n_pts, n_trials_bad, n_trials_good = elec2_good.shape[0], elec2_bad.shape[1], elec2_good.shape[1]\n",
    "\n",
    "        for i,f in enumerate(freq):\n",
    "            plv_bad_all, plv_good_all = np.array([]), np.array([])\n",
    "            for t in range(n_trials_bad):\n",
    "                #Compute PLV for the bad condition\n",
    "                elec1_bad_trial = elec1_bad[:,t][:,np.newaxis]\n",
    "                elec2_bad_trial = elec2_bad[:,t][:,np.newaxis]\n",
    "                defPlv_bad = PLV(sf=sf, npts=n_pts, f=f, method=method, cycle=3)\n",
    "                plv_bad, pvalues_bad = defPlv_bad.get(elec1_bad_trial,elec2_bad_trial,n_perm = n_perm)\n",
    "                plv_bad_all = np.vstack((plv_bad_all,plv_bad)) if np.size(plv_bad_all) else plv_bad\n",
    "            plv_bad_all = np.squeeze(plv_bad_all)\n",
    "            print('plv bad all', plv_bad_all.shape)\n",
    "            \n",
    "            for t in range(n_trials_good):\n",
    "                #Compute PLV for the bad condition\n",
    "                elec1_good_trial = elec1_good[:,t][:,np.newaxis]\n",
    "                elec2_good_trial = elec2_good[:,t][:,np.newaxis]\n",
    "                defPlv_good = PLV(sf=sf, npts=n_pts, f=f, method=method, cycle=3)\n",
    "                plv_good, pvalues_good = defPlv_good.get(elec1_good_trial,elec2_good_trial,n_perm = n_perm)\n",
    "                plv_good_all = np.vstack((plv_good_all,plv_good)) if np.size(plv_good_all) else plv_good\n",
    "            plv_good_all = np.squeeze(plv_good_all)\n",
    "            print('plv good all', plv_good_all.shape)\n",
    "            \n",
    "#============================= STATISTICS FOR PLV VALUES =====================================\n",
    "            #Statistics for PLV values across time in Bad & Good conditions\n",
    "            n_rep = 10\n",
    "            T_rep, p_val_rep = np.array([]), np.array([])\n",
    "            da_rep, daperm_rep = np.array([]), np.array([])             \n",
    "                \n",
    "            first = True\n",
    "            for i in range(n_rep):\n",
    "                #reshape data to have the exact same nb of trials (mandatory for t-tests)\n",
    "                if plv_bad_all.shape[0] > plv_good_all.shape[0]:\n",
    "                    plv_bad_all = bad_data[np.random.randint(bad_data.shape[0], size=good_data.shape[0]), :] #reshape bad_data to fit good_data shape\n",
    "                    plv_good_all = plv_good_all\n",
    "                elif plv_bad_all.shape[0] < plv_good_all.shape[0]:\n",
    "                    plv_good_all = good_data[np.random.randint(good_data.shape[0], size=bad_data.shape[0]), :]\n",
    "                    plv_bad_all = plv_bad_all\n",
    "                elif plv_bad_all.shape[0] == plv_good_all.shape[0]:\n",
    "                    plv_bad_all = plv_bad_all\n",
    "                    plv_good_all = plv_good_all\n",
    "                ntrials = plv_good_all.shape[0]\n",
    "                X = plv_bad_all - plv_good_all #the last dimension needs to be time\n",
    "                T0, p_values, H0 = permutation_t_test(X, n_permutations=1000, tail=0, n_jobs=1, verbose=None)\n",
    "                T_rep = np.vstack((T_rep,T0)) if np.size(T_rep) else T0\n",
    "                p_val_rep = np.vstack((p_val_rep,p_values)) if np.size(p_val_rep) else p_values\n",
    "            \n",
    "            #DA for PLV values across time in Bad and Good conditions\n",
    "            #create a data matrix, concatenate along the trial dimension\n",
    "            bad_good = np.concatenate((plv_bad, plv_good), axis=0)\n",
    "            all_plv = np.squeeze(all_plv)\n",
    "            print ('Size of the concatenated data: ', bad_good.shape, 'Number of features : ', bad_good.shape[1])\n",
    "\n",
    "            #create label vector (0 for rest and 1 for odor)\n",
    "            y = [0]*bad_data.shape[0] + [1]*good_data.shape[0]\n",
    "            print ('Size of label for classif: ', len(y))\n",
    "\n",
    "                da_final = []\n",
    "                for i in range(bad_good.shape[1]):\n",
    "                    if first:\n",
    "                        cv = StratifiedKFold(n_splits=10)\n",
    "                        clf = SVC(class_weight='balanced', kernel='rbf')\n",
    "                        params = {'C': expon(scale=100), 'gamma': expon(scale=.1)}\n",
    "                        RS = RandomizedSearchCV(estimator=clf,\n",
    "                                    param_distributions=params,\n",
    "                                    n_iter=100,\n",
    "                                    n_jobs=-1,\n",
    "                                    cv=cv)\n",
    "                        RS.fit(X=bad_good[:,i].reshape(-1,1), y=y)\n",
    "                        best_params = RS.best_params_\n",
    "                        best_params['class_weight'] = 'balanced'\n",
    "                        best_params['kernel'] = 'rbf'\n",
    "\n",
    "                    # Define a cross validation:\n",
    "                    cv = defCv(y, n_folds=10, cvtype='skfold', rep=10)\n",
    "                    # Define classifier technique\n",
    "                    clf = defClf(y=y, clf=classif, kern='rbf',\n",
    "                                 C=best_params['C'], gamma=best_params['gamma'],\n",
    "                                 class_weight=best_params['class_weight'])#,n_tree=200, random_state=100)\n",
    "                    #Classify rest and odor\n",
    "                    cl = classify(y, clf=clf, cvtype=cv)\n",
    "\n",
    "                    # Evaluate the classifier on data:\n",
    "                    da,pvalue,daperm = cl.fit(bad_good[:,i].reshape(-1,1), n_perm=100,method='bino',mf=False)\n",
    "                    da_final.append(da.tolist())\n",
    "                da = np.asarray(da_final).squeeze().swapaxes(0,1)\n",
    "                print(da.shape)\n",
    "                print ('decoding accuracy',da.shape, 'pvalues ', pvalue.shape,)\n",
    "                da_rep = np.vstack((da_rep,da)) if np.size(da_rep) else da\n",
    "                first = False\n",
    "\n",
    "# =============================== TAKE MAX STATS TO PLOT =====================================\n",
    "            # Take the max pvalues for each time window\n",
    "            idx_pval_max = []\n",
    "            for s in range(nwin):\n",
    "                pval_max = p_val_rep[:,s].max()\n",
    "                idx_pval_max.append(pval_max)\n",
    "            #print (p_val_rep.shape, idx_pval_max)\n",
    "\n",
    "            #Save da accuracy\n",
    "            np.save(path2save+su+'_da_Bad_vs_Good__'+str(freq_name)+'_'+classif+'_'+str(elec_label)+'_('+str(elec_num)+')',da_rep)\n",
    "\n",
    "# ============================== PLOT POWER ANALYSIS + STATS & DECODING ACCURACY ===================================================\n",
    "            # data to plot\n",
    "            bad_to_plot = np.load(path.join(pathfiles, su+'_concat_odor_bad_bipo_power.npz'))['xpow'][freq,elec_num]\n",
    "            bad_to_plot = bad_to_plot.swapaxes(0,1)\n",
    "            good_to_plot = np.load(path.join(pathfiles, su+'_concat_odor_good_bipo_power.npz'))['xpow'][freq,elec_num] #take power for one freq band, one elec\n",
    "            good_to_plot = good_to_plot.swapaxes(0,1)\n",
    "            bad_good_plot = np.concatenate((bad_to_plot, good_to_plot), axis=0)\n",
    "            y_plot = [0]*bad_to_plot.shape[0] + [1]*good_to_plot.shape[0]\n",
    "\n",
    "            # plot and figure parameters\n",
    "            xfmt = ScalarFormatter(useMathText=True)\n",
    "            xfmt.set_powerlimits((0,3))\n",
    "            fig = plt.figure(1,figsize=(7,7))\n",
    "            step = 3700/ bad_to_plot.shape[1]\n",
    "            time = np.arange(-700, 3000, step)\n",
    "            print (len(time))\n",
    "            title = 'Power and DA for '+str(freq_name)+' '+su+' '+classif+' '+str(elec_label)+' ('+str(elec_num)+')'\n",
    "            fig.suptitle(title, fontsize=12)\n",
    "\n",
    "            # Plot the ERPs and the stats\n",
    "            plt.subplot(211)\n",
    "            BorderPlot(time, bad_good_plot, y=y_plot, kind='sem', alpha=0.2, color=['b', 'm'], \n",
    "                       linewidth=2, ncol=1, xlabel='Time (ms)', ylabel = r' $\\mu$V', \n",
    "                       legend = ['bad', 'good'])\n",
    "            addPval(plt.gca(), idx_pval_max, p=0.05, x=time, y=5, color='0.5', lw=2)\n",
    "            addPval(plt.gca(), idx_pval_max, p=0.01, x=time, y=0.2, color='0.7', lw=2)\n",
    "            addPval(plt.gca(), idx_pval_max, p=0.001, x=time, y=0.3, color='0.9', lw=2)\n",
    "            addLines(plt.gca(), vLines=[0], vColor=['black'], vWidth=[2], hLines=[0], \n",
    "                     hColor=['#000000'], hWidth=[2])\n",
    "            rmaxis(plt.gca(), ['right', 'top'])\n",
    "            plt.legend(loc=0, handletextpad=0.1, frameon=False)\n",
    "            plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "\n",
    "            #Plot the da\n",
    "            plt.subplot(212)\n",
    "            BorderPlot(time, da_rep, color='darkslateblue', kind='std',xlabel='Time (ms)', ylim=[da.min()-10,da.max()+10],\n",
    "                       ylabel='Decoding accuracy (%)',linewidth=2,alpha=0.3)\n",
    "            rmaxis(plt.gca(), ['right', 'top'])\n",
    "            addLines(plt.gca(), vLines=[0], vColor=['black'], vWidth=[2], hLines=[50], \n",
    "                     hColor=['#000000'], hWidth=[2])\n",
    "            plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "            th_0_05 = 100*np.around(binom.isf(0.05, good_data.shape[0], 0.5)/good_data.shape[0],2)\n",
    "            th_0_01 = 100*np.around(binom.isf(0.01, good_data.shape[0], 0.5)/good_data.shape[0],2)\n",
    "            th_0_001 = 100*np.around(binom.isf(0.001, good_data.shape[0], 0.5)/good_data.shape[0],2)\n",
    "            plt.plot(time, th_0_05*np.ones(len(time)), '--', color='orange', \n",
    "                      linewidth=2, label= str(th_0_05)+' - p < .05')\n",
    "            plt.plot(time, th_0_01*np.ones(len(time)), '--', color='orangered', \n",
    "                      linewidth=2, label= str(th_0_01)+' - p < .01')\n",
    "            plt.plot(time, th_0_001*np.ones(len(time)), '--', color='r', \n",
    "                      linewidth=2, label= str(th_0_001)+' - p < .001')\n",
    "            plt.legend(loc=0, handletextpad=0.1, frameon=False)\n",
    "\n",
    "# =========================== SAVE FIGURES & CLEAN MEMORY ==========================================================================\n",
    "            #Save the plot\n",
    "            fname = path.join(path2save, su + '_'+freq_name+'_'+str(elec_label)+'_('+str(elec_num)+')_'+'0.01.png')\n",
    "            fig.savefig(fname, dpi=300, bbox_inches='tight')\n",
    "            print ('saving --»' ,fname)\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "            del bad_good, good_data, bad_data, elec, elec_label, freq_name, da, daperm, pvalue, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "       \n",
    "        \n",
    "#Plot PLV values and labels\n",
    "plot_title = 'Plot PLV for '+su+' '+cond+' '+fname[i]+' elec('+str(elec)+') '+str(elec_label)\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "fig.suptitle(plot_title, fontsize=16, y=1., fontweight='bold')\n",
    "step = 3700/ elec_data.shape[1]\n",
    "time = np.arange(-700, 3000, step)\n",
    "\n",
    "        defPlv.plot2D(fig, plv, xvec=time, vmin=0, vmax=0.8,xlabel='Temps', \n",
    "                      ylabel='Electrodes', cmap='jet', cblabel='LTM - Olfactory')\n",
    "        addLines(plt.gca(), vLines=[0], vColor=['black'], vWidth=[2], vShape=['-'])\n",
    "        print (all_label)\n",
    "        plt.yticks(np.arange(len(all_label))+0.5,all_label)\n",
    "        fig.savefig(path2save +su+'_'+cond+'_plv_'+fname[i]+'_elec_('+str(elec)+')_'+str(elec_label)+'.png',dpi=300, bbox_inches='tight')\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "del elec, all_data, all_label, elec_data, elec_label\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classif Power without optimization \n",
    "### Good Bad for EPI score and REC score (lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing files \n",
    "st = study('Olfacto')\n",
    "pathfiles = path.join(st.path, 'feature/7_Power_E1E2_Odor_Good_Bad_700_100_RecScore/')\n",
    "elecfiles = path.join(st.path, 'database/TS_E_all_by_odor_th40_art400_30_250_Good_Bad_RecScore/')\n",
    "path2save = path.join(st.path, 'classified/8_Classif_Power_RECSCORE_Good_Bad_across_time_700ms_step100ms_subset/lda/')\n",
    "\n",
    "test = 'subset' \n",
    "classifs = ['lda']\n",
    "\n",
    "if test == True:\n",
    "    n_elec = {'VACJ' :1}\n",
    "    subjects = ['VACJ']\n",
    "    nfreq = 1\n",
    "    \n",
    "elif test == False :\n",
    "    subjects = ['SEMC','PIRJ','LEFC','MICP','CHAF','VACJ'] \n",
    "    n_elec = {\n",
    "    'CHAF' : 107,\n",
    "    'VACJ' : 139, \n",
    "    'SEMC' : 107,\n",
    "    'PIRJ' : 106,\n",
    "    'LEFC' : 193,\n",
    "    'MICP' : 105,\n",
    "        }\n",
    "    nfreq = 6\n",
    "    \n",
    "elif test == 'subset': #HC, PHC, Amg, Pir\n",
    "    subjects = ['SEMC','PIRJ','LEFC','MICP','VACJ'] \n",
    "    n_elec = {\n",
    "    'VACJ' : [1,2,3,11,12,13,14,15,16,17,22,23,24,60,61,62],\n",
    "    'SEMC' : [0,1,2,3,4],\n",
    "    'PIRJ' : [0,1,2,3,4,11,12,13,14,15,16,22,23,24,25,26,33,34,35,36,37,38],\n",
    "    'LEFC' : [0,1,11,12,13,14,22,23,24,25,26,27],\n",
    "    'MICP' : [0,1,2,3,9,18,10,11,12,19,20,21,22,23,29,30,31,32,33,40,41,42,43,44],\n",
    "        }\n",
    "    nfreq = 6\n",
    "    \n",
    "for classif in classifs:\n",
    "    for su in subjects:\n",
    "        #for elec_num in range(n_elec[su]):\n",
    "        for elec_num in n_elec[su]:\n",
    "            for freq in range(nfreq):\n",
    "                #files & data to load\n",
    "                bad_data = np.load(path.join(pathfiles, su+'_concat_odor_bad_bipo_power.npz'))['xpow'][freq,elec_num] #take power for one freq band, one elec\n",
    "                bad_data = bad_data.swapaxes(0,1)\n",
    "                good_data = np.load(path.join(pathfiles, su+'_concat_odor_good_bipo_power.npz'))['xpow'][freq,elec_num] #take power for one freq band, one elec\n",
    "                good_data = good_data.swapaxes(0,1)\n",
    "                nwin = good_data.shape[1]\n",
    "                print ('bad shape: ', bad_data.shape, 'good shape: ', good_data.shape)\n",
    "                elec = np.load(path.join(elecfiles, su+'_concat_odor_bad_bipo.npz'))['channel'][elec_num]\n",
    "                elec_label = np.load(path.join(elecfiles, su+'_concat_odor_bad_bipo.npz'))['label'][elec_num]\n",
    "                freq_name = np.load(path.join(pathfiles, su+'_concat_odor_bad_bipo_power.npz'))['fname'][freq]\n",
    "                print ('elec ', elec, 'elec_label ', elec_label)\n",
    "\n",
    "# ================================  STATISTICS FOR POWER  =====================================\n",
    "                n_rep = 10\n",
    "                T_rep, p_val_rep = np.array([]), np.array([])\n",
    "                da_rep, daperm_rep = np.array([]), np.array([])\n",
    "                alpha = 0.05\n",
    "                \n",
    "                for i in range(n_rep):\n",
    "                    #reshape data to have the exact same nb of trials (mandatory for t-tests)\n",
    "                    if bad_data.shape[0] > good_data.shape[0]:\n",
    "                        bad_data = bad_data[np.random.randint(bad_data.shape[0], size=good_data.shape[0]), :] #reshape bad_data to fit good_data shape\n",
    "                    if bad_data.shape[0] < good_data.shape[0]:\n",
    "                        good_data = good_data[np.random.randint(good_data.shape[0], size=bad_data.shape[0]), :]\n",
    "                    ntrials = bad_data.shape[0]\n",
    "                    X = bad_data - good_data #the last dimension needs to be time\n",
    "                    T0, p_values, H0 = permutation_t_test(X, n_permutations=1000, tail=0, n_jobs=1, verbose=None)\n",
    "                    T_rep = np.vstack((T_rep,T0)) if np.size(T_rep) else T0\n",
    "                    p_val_rep = np.vstack((p_val_rep,p_values)) if np.size(p_val_rep) else p_values\n",
    "\n",
    "# =============================  CLASSIFICATION COMPUTATION ============================================================           \n",
    "                    #create a data matrix, concatenate along the trial dimension\n",
    "                    bad_good = np.concatenate((bad_data, good_data), axis=0)\n",
    "                    print ('Size of the concatenated data: ', bad_good.shape, 'Number of features : ', bad_good.shape[1])\n",
    "\n",
    "                    #create label vector (0 for rest and 1 for odor)\n",
    "                    y = [0]*bad_data.shape[0] + [1]*good_data.shape[0]\n",
    "                    print ('Size of label for classif: ', len(y))\n",
    "                    \n",
    "                    # Define a cross validation:\n",
    "                    cv = defCv(y, n_folds=10, cvtype='skfold', rep=10)\n",
    "                    # Define classifier technique\n",
    "                    clf = defClf(y=y, clf=classif, kern='rbf')#,n_tree=200, random_state=100)\n",
    "                    #Classify rest and odor\n",
    "                    cl = classify(y, clf=clf, cvtype=cv)\n",
    "\n",
    "                    # Evaluate the classifier on data:\n",
    "                    da,pvalue,daperm = cl.fit(bad_good, n_perm=100,method='bino',mf=False)\n",
    "                    da_rep = np.vstack((da_rep,da)) if np.size(da_rep) else da\n",
    "                    \n",
    "# =============================== TAKE MAX STATS TO PLOT =====================================\n",
    "                # Take the max pvalues for each time window\n",
    "                idx_pval_max = []\n",
    "                for s in range(nwin):\n",
    "                    pval_max = p_val_rep[:,s].max()\n",
    "                    idx_pval_max.append(pval_max)\n",
    "                #print (p_val_rep.shape, idx_pval_max)\n",
    "\n",
    "                #Save da accuracy\n",
    "                np.save(path2save+su+'_da_Bad_vs_Good__'+str(freq_name)+'_'+classif+'_'+str(elec_label)+'_('+str(elec_num)+')',da_rep)\n",
    "\n",
    "# ============================== PLOT POWER ANALYSIS + STATS & DECODING ACCURACY ===================================================\n",
    "                # data to plot\n",
    "                bad_to_plot = np.load(path.join(pathfiles, su+'_concat_odor_bad_bipo_power.npz'))['xpow'][freq,elec_num]\n",
    "                bad_to_plot = bad_to_plot.swapaxes(0,1)\n",
    "                good_to_plot = np.load(path.join(pathfiles, su+'_concat_odor_good_bipo_power.npz'))['xpow'][freq,elec_num] #take power for one freq band, one elec\n",
    "                good_to_plot = good_to_plot.swapaxes(0,1)\n",
    "                bad_good_plot = np.concatenate((bad_to_plot, good_to_plot), axis=0)\n",
    "                y_plot = [0]*bad_to_plot.shape[0] + [1]*good_to_plot.shape[0]\n",
    "    \n",
    "                # plot and figure parameters\n",
    "                xfmt = ScalarFormatter(useMathText=True)\n",
    "                xfmt.set_powerlimits((0,3))\n",
    "                fig = plt.figure(1,figsize=(7,7))\n",
    "                step = 3700/ bad_to_plot.shape[1]\n",
    "                time = np.arange(-700, 3000, step)\n",
    "                print (len(time))\n",
    "                title = 'Power and DA for '+str(freq_name)+' '+su+' '+classif+' '+str(elec_label)+' ('+str(elec_num)+')'\n",
    "                fig.suptitle(title, fontsize=12)\n",
    "\n",
    "                # Plot the ERPs and the stats\n",
    "                plt.subplot(211)\n",
    "                BorderPlot(time, bad_good_plot, y=y_plot, kind='sem', alpha=0.2, color=['b', 'm'], \n",
    "                           linewidth=2, ncol=1, xlabel='Time (ms)', ylabel = r' $\\mu$V', \n",
    "                           legend = ['bad', 'good'])\n",
    "                addPval(plt.gca(), idx_pval_max, p=0.05, x=time, y=5, color='0.5', lw=2)\n",
    "                addPval(plt.gca(), idx_pval_max, p=0.01, x=time, y=0.2, color='0.7', lw=2)\n",
    "                addPval(plt.gca(), idx_pval_max, p=0.001, x=time, y=0.3, color='0.9', lw=2)\n",
    "                addLines(plt.gca(), vLines=[0], vColor=['black'], vWidth=[2], hLines=[0], \n",
    "                         hColor=['#000000'], hWidth=[2])\n",
    "                rmaxis(plt.gca(), ['right', 'top'])\n",
    "                plt.legend(loc=0, handletextpad=0.1, frameon=False)\n",
    "                plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "\n",
    "                #Plot the da\n",
    "                plt.subplot(212)\n",
    "                BorderPlot(time, da_rep, color='darkslateblue', kind='std',xlabel='Time (ms)', ylim=[da.min()-10,da.max()+10],\n",
    "                           ylabel='Decoding accuracy (%)',linewidth=2,alpha=0.3)\n",
    "                rmaxis(plt.gca(), ['right', 'top'])\n",
    "                addLines(plt.gca(), vLines=[0], vColor=['black'], vWidth=[2], hLines=[50], \n",
    "                         hColor=['#000000'], hWidth=[2])\n",
    "                plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "                th_0_05 = 100*np.around(binom.isf(0.05, good_data.shape[0], 0.5)/good_data.shape[0],2)\n",
    "                th_0_01 = 100*np.around(binom.isf(0.01, good_data.shape[0], 0.5)/good_data.shape[0],2)\n",
    "                th_0_001 = 100*np.around(binom.isf(0.001, good_data.shape[0], 0.5)/good_data.shape[0],2)\n",
    "                plt.plot(time, th_0_05*np.ones(len(time)), '--', color='orange', \n",
    "                          linewidth=2, label= str(th_0_05)+' - p < .05')\n",
    "                plt.plot(time, th_0_01*np.ones(len(time)), '--', color='orangered', \n",
    "                          linewidth=2, label= str(th_0_01)+' - p < .01')\n",
    "                plt.plot(time, th_0_001*np.ones(len(time)), '--', color='r', \n",
    "                          linewidth=2, label= str(th_0_001)+' - p < .001')\n",
    "                plt.legend(loc=0, handletextpad=0.1, frameon=False)\n",
    "\n",
    "# =========================== SAVE FIGURES & CLEAN MEMORY ==========================================================================\n",
    "                #Save the plot\n",
    "                fname = path.join(path2save, su + '_'+freq_name+'_'+str(elec_label)+'_('+str(elec_num)+')_'+'0.01.png')\n",
    "                fig.savefig(fname, dpi=300, bbox_inches='tight')\n",
    "                print ('saving --»' ,fname)\n",
    "                plt.clf()\n",
    "                plt.close()\n",
    "                del bad_good, good_data, bad_data, elec, elec_label, freq_name, da, daperm, pvalue, y\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
