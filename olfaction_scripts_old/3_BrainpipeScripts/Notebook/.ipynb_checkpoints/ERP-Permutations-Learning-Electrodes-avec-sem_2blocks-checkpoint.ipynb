{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing files and modules\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "#%matplotlib notebook\n",
    "from brainpipe.system import study\n",
    "from brainpipe.visual import *\n",
    "from brainpipe.statistics import *\n",
    "from mne.baseline import rescale\n",
    "from mne.filter import filter_data\n",
    "from mne.stats import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_pass_filter = 10.\n",
    "sf = 512.\n",
    "norm_mode = 'mean' #'ratio' 'mean' 'percent' \n",
    "baseline = [896 , 1024]\n",
    "data_to_use = [896, 1536]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ERPs and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = study('Olfacto')\n",
    "path_data = path.join (st.path, 'database/TS_E_all_cond_by_block_trigs_th40_art400_30_250_5s_learning2blocks/')\n",
    "elec = 4\n",
    "\n",
    "#Load files\n",
    "name_early = 'PIRJ_E1E2_concat_early_bipo.npz'\n",
    "name_late = 'PIRJ_E1E2_concat_late_bipo.npz'\n",
    "data_early = np.load(path.join(path_data, name_early))\n",
    "data_late = np.load(path.join(path_data, name_late))\n",
    "data_early, channel, label, data_late = data_early['x'], data_early['channel'], data_early['label'], data_late['x']\n",
    "\n",
    "# Select data for one elec + name :\n",
    "data_elec_early = data_early[elec,:,:]\n",
    "data_elec_late = data_late[elec,:,:]\n",
    "ntrials = len(data_elec_early[2])\n",
    "print ('Channel : ', channel[elec], 'Label : ', label[elec], 'N_trials :', ntrials, 'One elec shape : ', data_elec_early.shape)\n",
    "\n",
    "#Filter data for one elec (all trials):\n",
    "data_elec_early = np.array(data_elec_early, dtype='float64')\n",
    "data_elec_late = np.array(data_elec_late, dtype='float64')\n",
    "data_early_to_filter = np.swapaxes(data_elec_early, 0, 1)\n",
    "data_late_to_filter = np.swapaxes(data_elec_late, 0, 1)\n",
    "filtered_data_early = filter_data(data_early_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "filtered_data_late = filter_data(data_late_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "print ('Size of filtered data early :', filtered_data_early.shape, 'filtered data late : ', filtered_data_late.shape,)\n",
    "\n",
    "#Normalize the non-averaged data (all trials)\n",
    "times = np.arange(filtered_data_early.shape[1])\n",
    "print ('time points : ', times.shape)\n",
    "norm_filtered_data_early = rescale(filtered_data_early, times=times, baseline=baseline, mode=norm_mode)\n",
    "norm_filtered_data_late = rescale(filtered_data_late, times=times, baseline=baseline, mode=norm_mode)\n",
    "print ('Size norm & filtered data 0 : ', norm_filtered_data_early.shape, norm_filtered_data_late.shape,)\n",
    "\n",
    "# =======================================  STATISTICS  =====================================\n",
    "# Range of the data to compute\n",
    "data_range = range(data_to_use[0], data_to_use[1])\n",
    "\n",
    "# Get all three learning files (Filtered data)\n",
    "data_learn_0 = norm_filtered_data_early[:, data_range]\n",
    "data_learn_1 = norm_filtered_data_late[:, data_range,]\n",
    "print ('-> Shape of the selected data for learn 0', data_learn_0.shape, 'learn 1', data_learn_1.shape,)\n",
    "\n",
    "#reshape data to have the exact same nb od trials (mandatory for t-tests)\n",
    "data_learn_0_rand = data_learn_0[np.random.randint(data_learn_0.shape[0], size=data_learn_1.shape[0]), :] #reshape early_data to fit late_data shape\n",
    "print ('rand early matrix', data_learn_0_rand.shape)\n",
    "X = data_learn_0_rand - data_learn_1 #the last dimension needs to be time\n",
    "T0, p_values, H0 = permutation_t_test(X, n_permutations=1000, tail=0, n_jobs=1, verbose=None)\n",
    "\n",
    "# =======================PREPARE DATA TO PLOT AND PLOT THE ERPs=====================================\n",
    "# Data to plot :\n",
    "data_learn_to_plot = np.concatenate([data_learn_0_rand, data_learn_1,], axis=0)\n",
    "data_learn_to_plot = data_learn_to_plot.swapaxes(0,1)\n",
    "print('-> Shape of data to plot : ', data_learn_to_plot.shape)\n",
    "\n",
    "# Time vector & label vector:\n",
    "times_plot = 1000 * np.arange((baseline[0] - baseline[1]), data_learn_to_plot.shape[0]-baseline[1] + baseline[0],) / sf\n",
    "print('-> Shape of time vector : ', times_plot.shape)\n",
    "label_learn_0 = np.zeros(data_learn_0_rand.shape[0], dtype='int64')\n",
    "label_learn_1 = np.ones(data_learn_1.shape[0], dtype='int64')\n",
    "print('label size and values : 0 : ', label_learn_0.shape, '1 : ', label_learn_1.shape,)\n",
    "y = np.concatenate([label_learn_0, label_learn_1,])\n",
    "print('-> the y label', y.shape)\n",
    "\n",
    "#Prepare the plot\n",
    "fig = plt.figure(0, figsize=(12, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "ax.set_xlabel('Times (ms)', fontsize=12)\n",
    "ax.set_ylabel('Potential', fontsize=12)\n",
    "\n",
    "#Plot the Data\n",
    "BorderPlot(times_plot, data_learn_to_plot, y=y, kind='sem', alpha=0.2, color=['m','b'], linewidth=2, ncol=1, legend= ['Early Learning', 'Late Learning'],\n",
    "          title='PIRJ_ERP_Odor_bipo_'+norm_mode+'_'+str(channel[elec])+'_'+str(label[elec])+' elec_num: '+str(elec)+'_ntrials:'+str(ntrials),)\n",
    "plt.gca()\n",
    "lines = [0] #time vector is in ms\n",
    "addPval(plt.gca(), p_values, p=0.05, x=times_plot, y=0.5, color='m', lw=3)\n",
    "addLines(plt.gca(), vLines=lines, vColor=['firebrick'], vWidth=[2], hLines=[0], hColor=['#000000'], hWidth=[2])\n",
    "plt.legend(fontsize='small')\n",
    "plt.grid()\n",
    "plt.show()         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all ERPs with stats for learning cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = study('Olfacto')\n",
    "path_data = path.join (st.path, 'database/TS_E_all_cond_by_block_trigs_th40_art400_30_250_5s_learning2blocks/')\n",
    "subjects = ['SEMC','PIRJ','LEFC','MICP','CHAF','VACJ',] \n",
    "nelec=10\n",
    "\n",
    "for su in subjects:\n",
    "    for elec in range(nelec):\n",
    "        name_early = su+'_E1E2_concat_early_bipo.npz'\n",
    "        data_early = np.load(path.join(path_data, name_early))\n",
    "        data_early = data_early['channel'][elec]\n",
    "        print (su, data_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "st = study('Olfacto')\n",
    "path_data = path.join (st.path, 'database/TS_E_all_cond_by_block_trigs_th40_art400_30_250_5s_learning2blocks/')\n",
    "\n",
    "subjects = ['SEMC','PIRJ','LEFC','MICP','CHAF','VACJ',] \n",
    "\n",
    "n_elec = {\n",
    "    'CHAF' : 107,\n",
    "    'VACJ' : 139, \n",
    "    'SEMC' : 107,\n",
    "    'PIRJ' : 106,\n",
    "    'LEFC' : 193,\n",
    "    'MICP' : 105,\n",
    "}\n",
    "\n",
    "\n",
    "for su in subjects:\n",
    "    for elec in range(0, n_elec[su],1):\n",
    "        #Load files\n",
    "        name_early = su+'_E1E2_concat_early_bipo.npz'\n",
    "        name_late = su+'_E1E2_concat_late_bipo.npz'\n",
    "        data_early = np.load(path.join(path_data, name_early))\n",
    "        data_late = np.load(path.join(path_data, name_late))\n",
    "        data_early, channel, label, data_late = data_early['x'], data_early['channel'], data_early['label'], data_late['x']\n",
    "\n",
    "        # Select data for one elec + name :\n",
    "        data_elec_early = data_early[elec,:,:]\n",
    "        data_elec_late = data_late[elec,:,:]\n",
    "        ntrials = len(data_elec_early[2])\n",
    "        print ('Channel : ', channel[elec], 'Label : ', label[elec], 'N_trials :', ntrials, 'One elec shape : ', data_elec_early.shape)\n",
    "\n",
    "        #Filter data for one elec (all trials):\n",
    "        data_elec_early = np.array(data_elec_early, dtype='float64')\n",
    "        data_elec_late = np.array(data_elec_late, dtype='float64')\n",
    "        data_early_to_filter = np.swapaxes(data_elec_early, 0, 1)\n",
    "        data_late_to_filter = np.swapaxes(data_elec_late, 0, 1)\n",
    "        filtered_data_early = filter_data(data_early_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "        filtered_data_late = filter_data(data_late_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "        print ('Size of filtered data early :', filtered_data_early.shape, 'filtered data late : ', filtered_data_late.shape,)     \n",
    "\n",
    "        #Normalize the non-averaged data (all trials)\n",
    "        times = np.arange(filtered_data_early.shape[1])\n",
    "        print ('time points : ', times.shape)\n",
    "        norm_filtered_data_early = rescale(filtered_data_early, times=times, baseline=baseline, mode=norm_mode)\n",
    "        norm_filtered_data_late = rescale(filtered_data_late, times=times, baseline=baseline, mode=norm_mode)\n",
    "        print ('Size norm & filtered data 0 : ', norm_filtered_data_early.shape, norm_filtered_data_late.shape,)\n",
    "\n",
    "        # =======================================  STATISTICS  =====================================\n",
    "        # Range of the data to compute\n",
    "        data_range = range(data_to_use[0], data_to_use[1])\n",
    "\n",
    "        # Get all three learning files (Filtered data)\n",
    "        data_learn_0 = norm_filtered_data_early[:, data_range]\n",
    "        data_learn_1 = norm_filtered_data_late[:, data_range,]\n",
    "        print ('-> Shape of the selected data for learn 0', data_learn_0.shape, 'learn 1', data_learn_1.shape,)\n",
    "\n",
    "        #reshape data to have the exact same nb od trials (mandatory for t-tests)\n",
    "        data_learn_0_rand = data_learn_0[np.random.randint(data_learn_0.shape[0], size=data_learn_1.shape[0]), :] #reshape early_data to fit late_data shape\n",
    "        print ('rand early matrix', data_learn_0_rand.shape)\n",
    "        X = data_learn_0_rand - data_learn_1 #the last dimension needs to be time\n",
    "        T0, p_values, H0 = permutation_t_test(X, n_permutations=1000, tail=0, n_jobs=1, verbose=None)\n",
    "\n",
    "        # =======================PREPARE DATA TO PLOT AND PLOT THE ERPs=====================================            \n",
    "        if p_values.min() <= 0.05:\n",
    "            # Data to plot :\n",
    "            data_learn_to_plot = np.concatenate([data_learn_0_rand, data_learn_1,], axis=0)\n",
    "            data_learn_to_plot = data_learn_to_plot.swapaxes(0,1)\n",
    "            print('-> Shape of data to plot : ', data_learn_to_plot.shape)\n",
    "\n",
    "            # Time vector & label vector:\n",
    "            times_plot = 1000 * np.arange((baseline[0] - baseline[1]), data_learn_to_plot.shape[0]-baseline[1] + baseline[0],) / sf\n",
    "            print('-> Shape of time vector : ', times_plot.shape)\n",
    "            label_learn_0 = np.zeros(data_learn_0_rand.shape[0], dtype='int64')\n",
    "            label_learn_1 = np.ones(data_learn_1.shape[0], dtype='int64')\n",
    "            print('label size and values : 0 : ', label_learn_0.shape, '1 : ', label_learn_1.shape,)\n",
    "            y = np.concatenate([label_learn_0, label_learn_1,])\n",
    "            print('-> the y label', y.shape)\n",
    "\n",
    "            #Prepare the plot\n",
    "            fig = plt.figure(0, figsize=(12, 7))\n",
    "            ax = fig.add_subplot(111)\n",
    "            fig.subplots_adjust(top=0.85)\n",
    "            ax.set_xlabel('Times (ms)', fontsize=12)\n",
    "            ax.set_ylabel('Potential', fontsize=12)\n",
    "\n",
    "            #Plot the Data\n",
    "            BorderPlot(times_plot, data_learn_to_plot, y=y, kind='sem', alpha=0.2, color=['m', 'b'], linewidth=2, ncol=1, legend= ['Early Learning', 'Late Learning'],\n",
    "                      title=su+'_ERP_Odor_bipo_'+norm_mode+'_'+str(channel[elec])+'_'+str(label[elec])+' elec_num: '+str(elec)+'_ntrials:'+str(ntrials),)\n",
    "            plt.gca()\n",
    "            lines = [0] #time vector is in ms\n",
    "            addPval(plt.gca(), p_values, p=0.05, x=times_plot, y=2, color='c', lw=3)\n",
    "            addLines(plt.gca(), vLines=lines, vColor=['firebrick'], vWidth=[2], hLines=[0], hColor=['#000000'], hWidth=[2])\n",
    "            plt.legend(fontsize='small')\n",
    "            plt.grid()\n",
    "            #plt.show()         \n",
    "\n",
    "    # =========================  SAVE PLOTS of ERPs   =================================================\n",
    "            rep = path.join(st.path, 'feature/ERP_Encoding_all_bipo_250ms_mean_thr40_art400_30_250_learning_2blocks/Significant',su)\n",
    "            fname = (rep + '_E1E2_ERP_concat_all_bipo_' + channel [elec] +'_'+str(elec)+'_'+label[elec]+'.png')\n",
    "            print (fname)\n",
    "            plt.savefig(fname, dpi=300, bbox_inches='tight')\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "        del channel, ntrials, label, data_learn_0_rand, data_learn_0, data_learn_1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
