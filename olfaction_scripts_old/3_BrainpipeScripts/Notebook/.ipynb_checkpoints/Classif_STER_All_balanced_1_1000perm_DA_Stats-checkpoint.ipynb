{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, MaxNLocator\n",
    "import scipy.io as sio\n",
    "\n",
    "from brainpipe.classification import *\n",
    "from brainpipe.system import study\n",
    "from brainpipe.feature import power, amplitude, sigfilt\n",
    "from brainpipe.visual import *\n",
    "from brainpipe.statistics import *\n",
    "from scipy.stats import *\n",
    "\n",
    "from os import path\n",
    "from mne.stats import *\n",
    "from mne.baseline import rescale\n",
    "from mne.filter import filter_data\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n"
     ]
    }
   ],
   "source": [
    "# where to find data\n",
    "st = study('Olfacto')\n",
    "score = 'Rec' #'Rec'\n",
    "if score == 'Epi':\n",
    "    path_data = path.join (st.path, 'database/TS_E_all_by_odor_th40_art400_30_250_5s_Good_Bad_EpiScore/')\n",
    "    save_path = path.join(st.path, 'classified/All_balanced_1_1000perm_DA_stats/')\n",
    "if score == 'Rec':\n",
    "    path_data = path.join (st.path, 'database/TS_E_all_by_odor_th40_art400_30_250_Good_Bad_RecScore/')\n",
    "    save_path = path.join(st.path, 'classified/0_Classif_ERP_RecScore_all_electrodes/')\n",
    "\n",
    "# ANALYSIS PARAMETERS\n",
    "low_pass_filter = 10.\n",
    "sf = 512.\n",
    "norm_mode = 'mean' #'ratio' 'mean' 'percent' \n",
    "baseline = [973 , 1024] #100ms before odor perception\n",
    "data_to_use = [973, 1536] #1000ms after odor\n",
    "time_points = data_to_use[1]-data_to_use[0]\n",
    "classif = 'lda'\n",
    "n_rep = 1 #bootstrap\n",
    "alpha = 0.05\n",
    "winSample = 10 #in samples = 20ms\n",
    "minsucc = 3 #nb of continuous samples to be significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERPs Decoding - Good Bad Odors Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIRJ Channel :  b2-b1 Label :  aHC Bad shape :  (2560, 13) Good shape :  (2560, 15)\n",
      "Setting up low-pass filter at 10 Hz\n",
      "h_trans_bandwidth chosen to be 2.5 Hz\n",
      "Filter length of 1352 samples (2.641 sec) selected\n",
      "Setting up low-pass filter at 10 Hz\n",
      "h_trans_bandwidth chosen to be 2.5 Hz\n",
      "Filter length of 1352 samples (2.641 sec) selected\n",
      "Size of filtered data bad : (13, 2560) filtered data good :  (15, 2560)\n",
      "time points :  (2560,)\n",
      "Applying baseline correction (mode: mean)\n",
      "Applying baseline correction (mode: mean)\n",
      "Size norm & filtered data 0 :  (13, 2560) (15, 2560)\n",
      "-> Shape of bad data (13, 563) good data (15, 563)\n",
      "balanced data :  (13, 56) (13, 56)\n",
      "(13, 1000, 56) (13, 1000, 56)\n",
      "(1000, 56)\n",
      "[-1.8404192093221812, 1.8404192093221812] [-2.6882365729993345, 2.6882365729993345] [-4.2575867002976704, 4.2575867002976704]\n",
      "(56,) 1.32703039944 -2.19189729898\n",
      "Size of the concatenated data:  (26, 56) Number time windows :  56\n",
      "Size of label for classif:  26\n",
      "th_perm :  69.2307692308 76.9230769231 92.3076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karim/anaconda3/lib/python3.5/site-packages/matplotlib/axes/_axes.py:545: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6e79a5b0407d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m#Save plots and stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignif\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mname_t0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinSample\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'ms/Significant/stat/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msu\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_t0_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_('\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m').npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0mname_tperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinSample\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'ms/Significant/stat/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msu\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_tperm_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_('\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m').npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mname_pval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinSample\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'ms/Significant/stat/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msu\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_pvals_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_('\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m').npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label' is not defined"
     ]
    }
   ],
   "source": [
    "test = True\n",
    "\n",
    "if test == True:\n",
    "    n_elec = {'PIRJ' :1}\n",
    "    subjects = ['PIRJ']\n",
    "else :\n",
    "    subjects = ['MICP','VACJ','SEMC','PIRJ','LEFC','CHAF'] \n",
    "    n_elec = {\n",
    "    'CHAF' : 107,\n",
    "    'VACJ' : 139, \n",
    "    'SEMC' : 107,\n",
    "    'PIRJ' : 106,\n",
    "    'LEFC' : 193,\n",
    "    'MICP' : 105,\n",
    "        }\n",
    "\n",
    "for su in subjects:\n",
    "    #Load files\n",
    "    data_bad = np.load(path.join(path_data, su+'_concat_odor_bad_bipo.npz'))\n",
    "    data_good = np.load(path.join(path_data, su+'_concat_odor_good_bipo.npz'))\n",
    "    data_bad, channels, names, data_good = data_bad['x'], data_bad['channel'], data_bad['label'], data_good['x']\n",
    "\n",
    "    for elec in range(0,n_elec[su]):\n",
    "    #for elec in n_elec[su]:\n",
    "        # Select data for one elec + name :\n",
    "        data_elec_bad = data_bad[elec,:,:]\n",
    "        data_elec_good = data_good[elec,:,:]\n",
    "        ntrials = str(data_elec_bad.shape[1])+'/'+ str(data_elec_good.shape[1])\n",
    "        channel, name = channels[elec], names[elec]\n",
    "        print (su, 'Channel : ', channel, 'Label : ', name,'Bad shape : ', \n",
    "               data_elec_bad.shape, 'Good shape : ', data_elec_good.shape)\n",
    "\n",
    "        #Filter data for one elec (all trials):\n",
    "        data_elec_bad = np.array(data_elec_bad, dtype='float64')\n",
    "        data_elec_good = np.array(data_elec_good, dtype='float64')\n",
    "        data_bad_to_filter = np.swapaxes(data_elec_bad, 0, 1)\n",
    "        data_good_to_filter = np.swapaxes(data_elec_good, 0, 1)\n",
    "        filtered_data_bad = filter_data(data_bad_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "        filtered_data_good = filter_data(data_good_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "        print ('Size of filtered data bad :', filtered_data_bad.shape, 'filtered data good : ', filtered_data_good.shape,)\n",
    "\n",
    "        #Normalize the non-averaged data (all trials)\n",
    "        times = np.arange(filtered_data_bad.shape[1])\n",
    "        print ('time points : ', times.shape)\n",
    "        norm_filtered_data_bad = rescale(filtered_data_bad, times=times, baseline=baseline, mode=norm_mode)\n",
    "        norm_filtered_data_good = rescale(filtered_data_good, times=times, baseline=baseline, mode=norm_mode)\n",
    "        print ('Size norm & filtered data 0 : ', norm_filtered_data_bad.shape, norm_filtered_data_good.shape,)\n",
    "\n",
    "        # Range of the data to compute\n",
    "        data_range = range(data_to_use[0], data_to_use[1])\n",
    "        bad_sel = norm_filtered_data_bad[:, data_range]\n",
    "        good_sel = norm_filtered_data_good[:, data_range,]\n",
    "        print ('-> Shape of bad data', bad_sel.shape, 'good data', good_sel.shape)\n",
    "        \n",
    "        # Average the signal on consecutive windows\n",
    "        n_pts = bad_sel.shape[1]\n",
    "        rmPoints = n_pts % winSample # Points to remove before splitting\n",
    "        shapeRmPoints = np.arange(n_pts-rmPoints).astype(int) # Number of points for round division\n",
    "        n_win = int(n_pts / winSample) # Number of segments\n",
    "\n",
    "        # Split and average data (trials, n_pts)\n",
    "        bad_split = np.array(np.split(bad_sel[:, shapeRmPoints], n_win, axis=1)) # n_win n_trials n_pts\n",
    "        bad_split = np.mean(bad_split, axis=2).swapaxes(0,1) # n-trials n_win\n",
    "        good_split = np.array(np.split(good_sel[:, shapeRmPoints], n_win, axis=1))\n",
    "        good_split = np.mean(good_split, axis=2).swapaxes(0,1)\n",
    "\n",
    "# ==========================  BALANCED CONDITIONS - Bootstrap  =====================================\n",
    "        if bad_split.shape[0] > good_split.shape[0]:\n",
    "            bad_sel_stat = bad_split[np.random.randint(bad_split.shape[0], size=good_split.shape[0]), :] #reshape bad_data to fit good_data shape\n",
    "            good_sel_stat = good_split\n",
    "        elif bad_split.shape[0] < good_split.shape[0]:\n",
    "            bad_sel_stat = bad_split\n",
    "            good_sel_stat = good_split[np.random.randint(good_split.shape[0], size=bad_split.shape[0]), :]\n",
    "        else:\n",
    "            bad_sel_stat, good_sel_stat = bad_split, good_split\n",
    "        print ('balanced data : ', bad_sel_stat.shape, good_sel_stat.shape)\n",
    "# ===========================  STATISTICS  =====================================\n",
    "        # Permutations and t test of the data\n",
    "        bad_perm, good_perm = perm_swap(bad_sel_stat, good_sel_stat, n_perm=1000, axis=0)\n",
    "        bad_perm, good_perm = np.swapaxes(bad_perm,0,1), np.swapaxes(good_perm,0,1)\n",
    "        print(bad_perm.shape, good_perm.shape)\n",
    "        Tperm, _ = ttest_ind(bad_perm, good_perm, equal_var=False)\n",
    "        print(Tperm.shape)\n",
    "        thr_0_5_stat = [-perm_pvalue2level(Tperm, p=0.05, maxst=True)[0],perm_pvalue2level(Tperm, p=0.05, maxst=True)[0]]\n",
    "        thr_0_1_stat = [-perm_pvalue2level(Tperm, p=0.01, maxst=True)[0],perm_pvalue2level(Tperm, p=0.01, maxst=True)[0]]\n",
    "        thr_0_0_1_stat = [-perm_pvalue2level(Tperm, p=0.001, maxst=True)[0],perm_pvalue2level(Tperm, p=0.001, maxst=True)[0]]\n",
    "        print(thr_0_5_stat,thr_0_1_stat,thr_0_0_1_stat)\n",
    "        T0, _  = ttest_ind(bad_split, good_split, equal_var=False)\n",
    "        print(T0.shape, T0.max(), T0.min())\n",
    "        \n",
    "        # Create the pvalue vector to plot\n",
    "        pvals = []\n",
    "        for i in range(T0.shape[0]):\n",
    "            if T0[i] < thr_0_0_1_stat[0] or T0[i] > thr_0_0_1_stat[1]:\n",
    "                pval = pvals.append(0.0009)\n",
    "            elif T0[i] < thr_0_1_stat[0] or T0[i] > thr_0_1_stat[1]:\n",
    "                pval = pvals.append(0.009)\n",
    "            elif T0[i] < thr_0_5_stat[0] or T0[i] > thr_0_5_stat[1]:\n",
    "                pval = pvals.append(0.04)\n",
    "            else:\n",
    "                pval = pvals.append(1)\n",
    "                \n",
    "# =============================  CLASSIFICATION COMPUTATION ============================================================           \n",
    "        #create a data matrix, concatenate along the trial dimension\n",
    "        bad_good = np.concatenate((bad_sel_stat, good_sel_stat), axis=0)\n",
    "        print ('Size of the concatenated data: ', bad_good.shape, 'Number time windows : ', bad_good.shape[1])\n",
    "        #create label vector (0 for rest and 1 for odor)\n",
    "        y = [0]*bad_sel_stat.shape[0] + [1]*good_sel_stat.shape[0]\n",
    "        print ('Size of label for classif: ', len(y))\n",
    "        # Define a cross validation:\n",
    "        cv = defCv(y, n_folds=10, cvtype='skfold', rep=10)\n",
    "        # Define classifier technique\n",
    "        clf = defClf(y=y, clf=classif)#,n_tree=200, random_state=100)\n",
    "        #Classify rest and odor\n",
    "        cl = classify(y, clf=clf, cvtype=cv)\n",
    "        # Evaluate the classifier on data:\n",
    "        da,pvalues,daperm = cl.fit(bad_good, n_perm=1000,method='full_rnd', mf=False)\n",
    "        #print(pvalues.shape, pvalues.min(), pvalues.max())\n",
    "        th_0_05_perm = perm_pvalue2level(daperm, p=0.05, maxst=True)\n",
    "        th_0_01_perm = perm_pvalue2level(daperm, p=0.01, maxst=True)\n",
    "        th_0_001_perm = perm_pvalue2level(daperm, p=0.001, maxst=True)\n",
    "        print('th_perm : ', th_0_05_perm[0], th_0_01_perm[0], th_0_001_perm[0])\n",
    "\n",
    "# ============================== PLOT ERPs ANALYSIS + STATS & DECODING ACCURACY ===================================================\n",
    "        # plot and figure parameters\n",
    "        xfmt = ScalarFormatter(useMathText=True)\n",
    "        xfmt.set_powerlimits((0,3))\n",
    "        fig = plt.figure(1,figsize=(7,7))\n",
    "        title = 'ERPs-Stats-DA for '+su+' Good/Bad '+str(channel)+' '+str(name)+' ('+str(elec)+') ntrials:'+str(ntrials)\n",
    "        fig.suptitle(title, fontsize=12)\n",
    "        times_plot = 1000 * np.arange((baseline[0] - baseline[1]), len(shapeRmPoints)-baseline[1]+baseline[0],winSample) / sf\n",
    "\n",
    "        # Plot the ERPs + STATS\n",
    "        plt.subplot(211)\n",
    "        BorderPlot(times_plot, bad_good, y=y, kind='sem', alpha=0.2, color=['b','m'], \n",
    "                   linewidth=2, ncol=1, xlabel='Time (ms)',ylabel = r' $\\mu$V', legend=['bad','good'])\n",
    "        addLines(plt.gca(), vLines=[0], vColor=['r'], vWidth=[2], hLines=[0], \n",
    "                 hColor=['#000000'], hWidth=[2])\n",
    "        addPval(plt.gca(), pvals, p=0.05, x=times_plot, y=2, color='orange', lw=2, minsucc=minsucc)\n",
    "        addPval(plt.gca(), pvals, p=0.01, x=times_plot, y=2, color='orangered', lw=2,minsucc=minsucc)\n",
    "        addPval(plt.gca(), pvals, p=0.001, x=times_plot, y=2, color='r', lw=2,minsucc=minsucc)\n",
    "        rmaxis(plt.gca(), ['right', 'top'])\n",
    "        plt.legend(loc=0, handletextpad=0.1, frameon=False)\n",
    "        plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "\n",
    "        # Plot DA for the ERPs\n",
    "        plt.subplot(212)\n",
    "        BorderPlot(times_plot, da, color='b', kind='sem',xlabel='Time (ms)', \n",
    "                   ylim=[da.min()-10,da.max()+10], ylabel='Decoding accuracy (%)',\n",
    "                   linewidth=2, alpha=0.3)\n",
    "        rmaxis(plt.gca(), ['right', 'top'])\n",
    "        addLines(plt.gca(), vLines=[0], vWidth=[2], vColor=['r'], hLines=[50], \n",
    "                 hColor=['#000000'], hWidth=[2])\n",
    "        plt.legend(loc=0, handletextpad=0.1, frameon=False)   \n",
    "        plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "        plt.plot(times_plot, th_0_05_perm*np.ones(len(times_plot)), '--', color='orange', linewidth=2)\n",
    "        plt.plot(times_plot, th_0_01_perm*np.ones(len(times_plot)), '--', color='orangered', linewidth=2)\n",
    "        plt.plot(times_plot, th_0_001_perm*np.ones(len(times_plot)), '--', color='r', linewidth=2)\n",
    "        \n",
    "        # Criteria to be significant\n",
    "        pvals = np.ravel(pvals)\n",
    "        underp = np.where(pvals < alpha)[0]\n",
    "        pvsplit = np.split(underp, np.where(np.diff(underp) != 1)[0]+1)\n",
    "        signif = [True for k in pvsplit if len(k) >= minsucc]\n",
    "        \n",
    "        #Save plots and stats\n",
    "        if len(signif) >=1:\n",
    "            name_t0 = (save_path +str(round((winSample*1000)/512))+'ms/Significant/stat/'+su +'_t0_' + score +'_'+str(name)+'_('+str(elec)+').npy')\n",
    "            name_tperm = (save_path +str(round((winSample*1000)/512))+'ms/Significant/stat/'+su +'_tperm_' + score +'_'+str(name)+'_('+str(elec)+').npy')\n",
    "            name_pval = (save_path +str(round((winSample*1000)/512))+'ms/Significant/stat/'+su +'_pvals_' + score +'_'+str(name)+'_('+str(elec)+').npy')\n",
    "            name_da = (save_path +str(round((winSample*1000)/512))+'ms/Significant/da/'+su +'_da_' + score +'_'+str(name)+'_('+str(elec)+').npy')\n",
    "            name_daperm = (save_path +str(round((winSample*1000)/512))+'ms/Significant/da/'+su +'_daperm_' + score +'_'+str(name)+'_('+str(elec)+').npy')\n",
    "            plot_name = (save_path +str(round((winSample*1000)/512))+'ms/Significant/fig'+su +'_ERPs_'  + score +'_'+str(name)+'_('+str(elec)+').png')\n",
    "        else:\n",
    "            name_t0 = (save_path +str(round((winSample*1000)/512))+'ms/Not_Significant/stat/'+su +'_t0_' + score +'_'+str(name)+'_('+str(elec)+').npy')\n",
    "            name_tperm = (save_path +str(round((winSample*1000)/512))+'ms/Not_Significant/stat/'+su +'_tperm_' + score +'_'+str(name)+'_('+str(elec)+').npy')\n",
    "            name_pval = (save_path +str(round((winSample*1000)/512))+'ms/Not_Significant/stat/'+su +'_pvals_' + score +'_'+str(name)+'_('+str(elec)+').npy')\n",
    "            name_da = (save_path +str(round((winSample*1000)/512))+'ms/Not_Significant/da/'+su +'_da_' + score +'_'+str(name)+'_('+str(elec)+').npy')\n",
    "            name_daperm = (save_path +str(round((winSample*1000)/512))+'ms/Not_Significant/da/'+su +'_daperm_' + score +'_'+str(name)+'_('+str(elec)+').npy')\n",
    "            plot_name = (save_path +str(round((winSample*1000)/512))+'ms/Not_Significant/fig'+su +'_ERPs_'  + score +'_'+str(name)+'_('+str(elec)+').png')\n",
    "        \n",
    "        np.save(name_t0, T0)\n",
    "        np.save(name_tperm, Tperm)\n",
    "        np.save(name_pval, pvals)\n",
    "        np.save(name_da, da)\n",
    "        np.save(name_daperm, daperm)\n",
    "        plt.savefig(plot_name, dpi=300, bbox_inches='tight')\n",
    "        plt.clf()\n",
    "        plt.close() \n",
    "        del bad_sel, good_sel, good_sel_stat, bad_sel_stat, bad_split, good_split\n",
    "    del data_bad, data_good, channels, names"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
