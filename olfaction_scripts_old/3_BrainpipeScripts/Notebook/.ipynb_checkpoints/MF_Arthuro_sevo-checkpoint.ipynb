{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification\n",
      "Feature selection\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import savemat, loadmat\n",
    "from time import time\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import LeavePGroupsOut, RandomizedSearchCV, cross_val_score, StratifiedShuffleSplit,permutation_test_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "import sys\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS, ExhaustiveFeatureSelector as EFS\n",
    "from scipy.stats import expon\n",
    "\n",
    "def elapsed_time(t0, t1):\n",
    "    \"\"\"Time lapsed between t0 and t1.\n",
    "\n",
    "    Returns the time (from time.time()) between t0 and t1 in a\n",
    "    more readable fashion.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t0: float,\n",
    "        time.time() initial measure of time\n",
    "        (eg. at the begining of the script)\n",
    "    t1: float,\n",
    "        time.time() time at the end of the script\n",
    "        or the execution of a function.\n",
    "    \"\"\"\n",
    "    lapsed = abs(t1-t0)\n",
    "    m, h, j = 60, 3600, 24*3600\n",
    "    nbj = lapsed // j\n",
    "    nbh = (lapsed - j * nbj) // h\n",
    "    nbm = (lapsed - j * nbj - h * nbh) // m\n",
    "    nbs = lapsed - j * nbj - h * nbh - m * nbm\n",
    "    if lapsed > m:\n",
    "        if lapsed > h:\n",
    "            if lapsed > j:\n",
    "                Time = \"%ij, %ih:%im:%is\" % (nbj, nbh, nbm, nbs)\n",
    "            else:\n",
    "                Time = \"%ih:%im:%is\" % (nbh, nbm, nbs)\n",
    "        else:\n",
    "            Time = \"%im:%is\" % (nbm, nbs)\n",
    "    else:\n",
    "        Time = \"%is\" % nbs\n",
    "    return Time\n",
    "\n",
    "\n",
    "data_path = '/media/karim/4TB_drive/Final_DFA_analysis/60sec/classif/MF_Arthuro/data_new/'\n",
    "save_path = '/media/karim/4TB_drive/Final_DFA_analysis/60sec/classif/MF_Arthuro/results/'\n",
    "\n",
    "con_list = ['conscious', 'unconscious']\n",
    "subjects = ['Sub_S2', 'Sub_S3','Sub_S4','Sub_S5','Sub_S6','Sub_S8','Sub_S10']\n",
    "temp_con = '_conscious_'\n",
    "temp_uncon = '_unconscious_'\n",
    "\n",
    "path = '/media/karim/4TB_drive/Final_DFA_analysis/60sec/'\n",
    "path1 = '/media/karim/4TB_drive/New_new_Pow_Amp_Sigfilt_analysis/Amplitude/amplitude_split/'\n",
    "\n",
    "Cx = 'alpha'\n",
    "\n",
    "n_perm = 1000\n",
    "params = {'C': expon(scale=100), 'gamma': expon(scale=.1)}\n",
    "\n",
    "fs = 500 \n",
    "n_sec = 30\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    t0 = time()\n",
    "\n",
    "    print('Classification')\n",
    "    da, daperm = [],[]\n",
    "    for rep in range(100):\n",
    "\n",
    "        k = 0\n",
    "        groups = []\n",
    "\n",
    "        conscious, unconscious = [],[]\n",
    "        con_sizes, uncon_sizes = [],[]\n",
    "#         X = np.array([]).reshape(0,126)\n",
    "        X = np.array([]).reshape(0,63)\n",
    "        y = np.array([]).reshape(0,)\n",
    "        for num, k in enumerate(subjects):\n",
    "    #         print('Load '+ k + '(' + str(num) +')')\n",
    "\n",
    "            # Unconscious :\n",
    "#             uncon = loadmat(path + k + temp_uncon  +Cx+  '_dfa_60sec_5_50sec.mat')['beta']\n",
    "            uncon = loadmat(path1 + k + temp_uncon  +Cx+  '_amplitude_split.mat')['uncon']\n",
    "\n",
    "#             con = loadmat(path + k + temp_con  +Cx+  '_dfa_60sec_5_50sec.mat')['beta']\n",
    "            con = loadmat(path1 + k + temp_con  +Cx+  '_amplitude_split.mat')['con']\n",
    "\n",
    "            assert con.shape[0]==uncon.shape[0],\"attention, con et uncon pas le même nb d'elec\"\n",
    "            if con.shape[0] == 65:\n",
    "                elec = np.ones(shape = (con.shape[0]),dtype = bool)\n",
    "                elec[[39,44]] = False\n",
    "                con = con[elec,:]\n",
    "                uncon = uncon[elec,:]\n",
    "\n",
    "#             uncon1 = loadmat(path1 + k + temp_uncon  +Cx1+  '_amplitude_split.mat')['uncon']\n",
    "#             uncon = np.concatenate((uncon, uncon1), axis=0)\n",
    "\n",
    "#             con1 = loadmat(path1 + k + temp_con  +Cx1+  '_amplitude_split.mat')['con']\n",
    "#             con = np.concatenate((con, con1), axis=0)\n",
    "\n",
    "            data = np.concatenate((con, uncon), axis=1)\n",
    "            data = data.T\n",
    "            labels = np.asarray([1] * con.shape[1] + [0] * uncon.shape[1])\n",
    "\n",
    "            quantity_of_class = {'0': np.where(labels == 0)[0].shape[0],\n",
    "                                 '1': np.where(labels == 1)[0].shape[0]}\n",
    "\n",
    "            nb_minority_class = min(quantity_of_class['0'], quantity_of_class['1'])\n",
    "\n",
    "            for ii in quantity_of_class.keys():\n",
    "                if nb_minority_class == quantity_of_class[ii]:\n",
    "                    minority_class = int(ii)\n",
    "\n",
    "            if minority_class == 0:\n",
    "                major_class = 1\n",
    "            else:\n",
    "                major_class = 0\n",
    "\n",
    "            # Génération d'un index aléatoire de la classe majoritaire au nombre de la classe minoritaire\n",
    "            major_class_index = np.random.choice(np.where(labels==major_class)[0], nb_minority_class, replace=False)        # Récupération de l'index de la classe minoritaire\n",
    "            minor_class_index = np.where(labels==minority_class)[0]\n",
    "\n",
    "            # Création de la base de donnée et des labels balanced\n",
    "            data = np.concatenate([data[major_class_index], data[minor_class_index]])\n",
    "            labels = [major_class]*nb_minority_class + [minority_class]*nb_minority_class\n",
    "            labels = np.asarray(labels, dtype=int)\n",
    "            groups += [num]*len(labels)\n",
    "            X = np.concatenate((X, data))\n",
    "            y = np.concatenate((y, labels))\n",
    "\n",
    "    #     print(X.shape, y.shape)\n",
    "        file_name = 'result_classif_'+Cx+'.mat'\n",
    "    #     if not os.path.isfile(save_path + file_name):\n",
    "        t3 = time()\n",
    "        cv = LeavePGroupsOut(n_groups=1)\n",
    "    #     cv = StratifiedShuffleSplit(n_splits=10)\n",
    "        clf = SVC(kernel='rbf')\n",
    "\n",
    "        sfs1 = SFS(clf, \n",
    "               k_features=(1,63), \n",
    "               forward=True, \n",
    "               floating=False, \n",
    "               verbose=0,\n",
    "               scoring='accuracy',\n",
    "               cv=5)\n",
    "        print('Feature selection')\n",
    "        sfs1 = sfs1.fit(X, y)\n",
    "\n",
    "        X_backup = X\n",
    "        X = X[:,sfs1.k_feature_idx_]\n",
    "\n",
    "\n",
    "        clf = SVC(kernel='rbf', class_weight='balanced')\n",
    "\n",
    "    #     for train_index, test_index in cv.split(X, y, groups):\n",
    "    #         X_train, X_test = X[train_index], X[test_index]\n",
    "    #         y_train, y_test = y[train_index], y[test_index]\n",
    "    #         clf = SVC(kernel='rbf')\n",
    "    #         clf.fit(X_train, y_train)\n",
    "    #         accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "        print('Hyperparameter optimization')\n",
    "        RS = RandomizedSearchCV(estimator=clf,\n",
    "                                param_distributions=params,\n",
    "                                n_iter=1000,\n",
    "                                n_jobs=-1,\n",
    "                                cv=cv).fit(X, y, groups=groups)\n",
    "        best_params = RS.best_params_\n",
    "        clf.set_params(C=best_params['C'])\n",
    "        clf.set_params(gamma=best_params['gamma'])\n",
    "\n",
    "#         accuracy.append(cross_val_score(estimator=clf, X=X, y=y, groups=groups, cv=cv))\n",
    "        score, permutation_score, _ = permutation_test_score(estimator=clf, \n",
    "                                X=X, y=y, groups=groups, cv=cv,\n",
    "                                n_permutations=n_perm, n_jobs=-1)\n",
    "        da.append(score)\n",
    "        daperm.append(permutation_score)\n",
    "        \n",
    "        print('accuracy : %0.2f (+/- %0.2f)' %\n",
    "              (np.mean(da), np.std(da)))\n",
    "\n",
    "        savemat('%s%s' %\n",
    "                (save_path, file_name),\n",
    "                {'data': da})\n",
    "        \n",
    "mean_da = np.mean(da)\n",
    "file_name1 = 'result_classif_'+Cx+'_mean.mat'\n",
    "savemat('%s%s' %\n",
    "        (save_path, file_name1),\n",
    "        {'data': mean_da})\n",
    "print('total time lapsed : %s' % elapsed_time(t0, time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_accuracy = np.mean(accuracy)\n",
    "file_name1 = 'result_classif_alpha_mean.mat'\n",
    "savemat('%s%s' %\n",
    "        (save_path, file_name1),\n",
    "        {'data': mean_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76384650713891011"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_accuracy"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
