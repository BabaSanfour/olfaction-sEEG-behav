{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing files and modules\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "#%matplotlib notebook\n",
    "from brainpipe.system import study\n",
    "from brainpipe.visual import *\n",
    "from brainpipe.statistics import *\n",
    "from mne.baseline import rescale\n",
    "from mne.filter import filter_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_pass_filter = 10.\n",
    "sf = 512.\n",
    "norm_mode = 'mean' #'ratio' 'mean' 'percent' \n",
    "baseline = [640 , 768]\n",
    "data_to_use = [768, 1536]\n",
    "n_perm = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ERPs and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st = study('Olfacto')\n",
    "path_data = path.join (st.path, 'database/TS_E_all_cond_by_block_trigs_th40_art400_30_250_learningOK/')\n",
    "elec = 32\n",
    "\n",
    "#Load files\n",
    "name_early = 'CHAF_E1E2_concat_learning_0_bipo.npz'\n",
    "name_middle = 'CHAF_E1E2_concat_learning_1_bipo.npz'\n",
    "name_late = 'CHAF_E1E2_concat_learning_2_bipo.npz'\n",
    "data_early = np.load(path.join(path_data, name_early))\n",
    "data_middle = np.load(path.join(path_data, name_middle))\n",
    "data_late = np.load(path.join(path_data, name_late))\n",
    "data_early, channel, label = data_early['x'], data_early['channel'], data_early['label']\n",
    "data_middle, data_late = data_middle['x'], data_late['x']\n",
    "\n",
    "# Select data for one elec + name :\n",
    "data_elec_0 = data_early[elec,:,:]\n",
    "data_elec_1 = data_middle[elec,:,:]\n",
    "data_elec_2 = data_late[elec,:,:]\n",
    "ntrials = len(data_elec_0[2])\n",
    "print ('Channel : ', channel[elec], 'Label : ', label[elec], 'N_trials :', ntrials, 'One elec shape : ', data_elec_0.shape)\n",
    "\n",
    "#Filter data for one elec (all trials):\n",
    "data_elec_0 = np.array(data_elec_0, dtype='float64')\n",
    "data_elec_1 = np.array(data_elec_1, dtype='float64')\n",
    "data_elec_2 = np.array(data_elec_2, dtype='float64')\n",
    "data_0_to_filter = np.swapaxes(data_elec_0, 0, 1)\n",
    "data_1_to_filter = np.swapaxes(data_elec_1, 0, 1)\n",
    "data_2_to_filter = np.swapaxes(data_elec_2, 0, 1)\n",
    "filtered_data_0 = filter_data(data_0_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "filtered_data_1 = filter_data(data_1_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "filtered_data_2 = filter_data(data_2_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "#filtered_data_0 = np.swapaxes(filtered_data_0, 0, 1)\n",
    "#filtered_data_1 = np.swapaxes(filtered_data_1, 0, 1)\n",
    "#filtered_data_2 = np.swapaxes(filtered_data_2, 0, 1)\n",
    "print ('Size of filtered data 0 :', filtered_data_0.shape, 'filtered data 1 : ', filtered_data_1.shape, 'filtered data 2 : ', filtered_data_2.shape)\n",
    "\n",
    "#Normalize the non-averaged data (all trials)\n",
    "times = np.arange(filtered_data_0.shape[1])\n",
    "print ('time points : ', times.shape)\n",
    "#filtered_data_to_norm = np.swapaxes(filtered_data, 0, 1)\n",
    "norm_filtered_data_0 = rescale(filtered_data_0, times=times, baseline=baseline, mode=norm_mode)\n",
    "norm_filtered_data_1 = rescale(filtered_data_1, times=times, baseline=baseline, mode=norm_mode)\n",
    "norm_filtered_data_2 = rescale(filtered_data_2, times=times, baseline=baseline, mode=norm_mode)\n",
    "norm_filtered_data_0 = np.swapaxes(norm_filtered_data_0, 0, 1)\n",
    "norm_filtered_data_1 = np.swapaxes(norm_filtered_data_1, 0, 1)\n",
    "norm_filtered_data_2 = np.swapaxes(norm_filtered_data_2, 0, 1)\n",
    "print ('Size norm & filtered data 0 : ', norm_filtered_data_0.shape, norm_filtered_data_1.shape, norm_filtered_data_2.shape)\n",
    "\n",
    "# =======================================  STATISTICS  =====================================\n",
    "# Range of the data to compute\n",
    "data_range = range(data_to_use[0], data_to_use[1])\n",
    "\n",
    "# Get all three learning files (Filtered data)\n",
    "data_learn_0 = norm_filtered_data_0[data_range, :]\n",
    "data_learn_1 = norm_filtered_data_1[data_range, :]\n",
    "data_learn_2 = norm_filtered_data_2[data_range, :]\n",
    "print ('-> Shape of the selected data for learn 0', data_learn_0.shape, 'learn 1', data_learn_1.shape, 'learn 2', data_learn_2.shape)\n",
    "\n",
    "# Swap data across trials (dim 1) :\n",
    "perm_learn_0_1 = perm_swap(data_learn_0, data_learn_1, axis=1, n_perm=n_perm)[0]\n",
    "perm_learn_0_2 = perm_swap(data_learn_0, data_learn_2, axis=1, n_perm=n_perm)[0]\n",
    "perm_learn_1_2 = perm_swap(data_learn_1, data_learn_2, axis=1, n_perm=n_perm)[0]\n",
    "print('-> Shape of permuted learn 0/1 : ', perm_learn_0_1.shape, 'learn 0/2 : ', perm_learn_0_2.shape, 'learn 1/2 : ', perm_learn_1_2.shape)\n",
    "\n",
    "# Take the mean across time :\n",
    "perm_learn_0_1_mean = perm_learn_0_1.mean(2)\n",
    "perm_learn_0_2_mean = perm_learn_0_2.mean(2)\n",
    "perm_learn_1_2_mean = perm_learn_1_2.mean(2)\n",
    "print('-> Shape of meaned permuted learn 0/1 : ', perm_learn_0_1_mean.shape, 'learn 0/2 : ', perm_learn_0_2_mean.shape, 'learn 1/2 : ', perm_learn_1_2_mean.shape)\n",
    "\n",
    "# Get p-values from the permuted data :\n",
    "p_vals_0_1 = perm_2pvalue(data_learn_0.mean(1), perm_learn_0_1_mean, n_perm=n_perm, threshold=None, tail=2)\n",
    "p_vals_0_2 = perm_2pvalue(data_learn_2.mean(1), perm_learn_0_2_mean, n_perm=n_perm, threshold=None, tail=2)\n",
    "p_vals_1_2 = perm_2pvalue(data_learn_1.mean(1), perm_learn_1_2_mean, n_perm=n_perm, threshold=None, tail=2)\n",
    "print('-> Shape of p-values learn 0/1 : ', p_vals_0_1.shape, 'learn 0/2 : ', p_vals_0_2.shape, 'learn 1/2 : ', p_vals_1_2.shape)\n",
    "\n",
    "## Test if there's significant p-values after multiplt comparison :\n",
    "print('-> Significant p-values learn 0/1? ', p_vals_0_1.min() <= 0.05)\n",
    "print('-> Significant p-values learn 0/2? ', p_vals_0_2.min() <= 0.05)\n",
    "print('-> Significant p-values learn 1/2? ', p_vals_1_2.min() <= 0.05)\n",
    "\n",
    "# =======================PREPARE DATA TO PLOT AND PLOT THE ERPs=====================================\n",
    "# Data to plot :\n",
    "data_learn_0_to_plot = norm_filtered_data_0[range(baseline[0], data_to_use[1])]\n",
    "data_learn_1_to_plot = norm_filtered_data_1[range(baseline[0], data_to_use[1])]\n",
    "data_learn_2_to_plot = norm_filtered_data_2[range(baseline[0], data_to_use[1])]\n",
    "data_learn_to_plot = np.concatenate([data_learn_0_to_plot, data_learn_1_to_plot, data_learn_2_to_plot], axis=1)\n",
    "print('-> Shape of filtered data to plot : ', data_learn_to_plot.shape)\n",
    "\n",
    "# Time vector & label vector:\n",
    "times_plot = 1000 * np.arange((baseline[0] - baseline[1]), data_learn_to_plot.shape[0]-baseline[1] + baseline[0],) / sf\n",
    "print('-> Shape of time vector : ', times_plot.shape)\n",
    "label_learn_0 = np.zeros(data_learn_0_to_plot[1].shape, dtype='int64')\n",
    "label_learn_1 = np.ones(data_learn_1_to_plot[1].shape, dtype='int64')\n",
    "label_learn_2 = np.full(data_learn_2_to_plot[1].shape, 2, dtype='int64')\n",
    "print('label size and values : 0 : ', label_learn_0.shape, '1 : ', label_learn_1.shape, '2 : ', label_learn_2.shape,)\n",
    "y = np.concatenate([label_learn_0, label_learn_1, label_learn_2])\n",
    "print('-> the y label', y.shape)\n",
    "\n",
    "# P-values to plot :\n",
    "p_vals_0_1_to_plot = np.insert(p_vals_0_1, 0, 10 * np.ones((baseline[1] - baseline[0],)))\n",
    "p_vals_0_2_to_plot = np.insert(p_vals_0_2, 0, 10 * np.ones((baseline[1] - baseline[0],)))\n",
    "p_vals_1_2_to_plot = np.insert(p_vals_1_2, 0, 10 * np.ones((baseline[1] - baseline[0],)))\n",
    "print('-> Shape of p-values to plot :', p_vals_0_1_to_plot.shape, p_vals_0_2_to_plot.shape, p_vals_1_2_to_plot.shape)\n",
    "\n",
    "#Prepare the plot\n",
    "fig = plt.figure(0, figsize=(12, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "ax.set_xlabel('Times (ms)', fontsize=12)\n",
    "ax.set_ylabel('Potential', fontsize=12)\n",
    "\n",
    "#Plot the Data\n",
    "BorderPlot(times_plot, data_learn_to_plot, y=y, kind='sem', alpha=0.2, color=['m','c', 'b'], linewidth=2, ncol=1, legend= ['Early Learning', 'Medium Learning', 'Late Learning'],\n",
    "          title='CHAF_ERP_Odor_bipo_'+norm_mode+'_'+str(channel[elec])+'_'+str(label[elec])+' elec_num: '+str(elec)+'_ntrials:'+str(ntrials),)\n",
    "plt.gca()\n",
    "lines = [0] #time vector is in ms\n",
    "addPval(plt.gca(), p_vals_0_1_to_plot, p=0.05, x=times_plot, y=0.5, color='m', lw=3)\n",
    "addPval(plt.gca(), p_vals_0_2_to_plot, p=0.05, x=times_plot, y=1, color='b', lw=3)\n",
    "addPval(plt.gca(), p_vals_1_2_to_plot, p=0.05, x=times_plot, y=1.5, color='c', lw=3)\n",
    "addLines(plt.gca(), vLines=lines, vColor=['firebrick'], vWidth=[2], hLines=[0], hColor=['#000000'], hWidth=[2])\n",
    "plt.legend(fontsize='small')\n",
    "plt.grid()\n",
    "plt.show()         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all ERPs with stats for learning cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = study('Olfacto')\n",
    "path_data = path.join (st.path, 'database/TS_E_all_cond_by_block_trigs_th40_art400_30_250_learningOK/')\n",
    "\n",
    "subjects = ['SEMC','PIRJ','LEFC','MICP',] #'CHAF','VACJ',\n",
    "\n",
    "n_elec = {\n",
    "    'CHAF' : 107,\n",
    "    'VACJ' : 139, \n",
    "    'SEMC' : 107,\n",
    "    'PIRJ' : 106,\n",
    "    'LEFC' : 193,\n",
    "    'MICP' : 105,\n",
    "}\n",
    "\n",
    "for su in subjects:\n",
    "    for elec in range(0, n_elec[su],1):\n",
    "        #Load files\n",
    "        name_early = su+'_E1E2_concat_learning_0_bipo.npz'\n",
    "        name_middle = su+'_E1E2_concat_learning_1_bipo.npz'\n",
    "        name_late = su+'_E1E2_concat_learning_2_bipo.npz'\n",
    "        data_early = np.load(path.join(path_data, name_early))\n",
    "        data_middle = np.load(path.join(path_data, name_middle))\n",
    "        data_late = np.load(path.join(path_data, name_late))\n",
    "        data_early, channel, label = data_early['x'], data_early['channel'], data_early['label']\n",
    "        data_middle, data_late = data_middle['x'], data_late['x']\n",
    "\n",
    "        # Select data for one elec + name :\n",
    "        data_elec_0 = data_early[elec,:,:]\n",
    "        data_elec_1 = data_middle[elec,:,:]\n",
    "        data_elec_2 = data_late[elec,:,:]\n",
    "        ntrials = len(data_elec_0[2])\n",
    "        print ('Channel : ', channel[elec], 'Label : ', label[elec], 'N_trials :', ntrials, 'One elec shape : ', data_elec_0.shape)\n",
    "\n",
    "        #Filter data for one elec (all trials):\n",
    "        data_elec_0 = np.array(data_elec_0, dtype='float64')\n",
    "        data_elec_1 = np.array(data_elec_1, dtype='float64')\n",
    "        data_elec_2 = np.array(data_elec_2, dtype='float64')\n",
    "        data_0_to_filter = np.swapaxes(data_elec_0, 0, 1)\n",
    "        data_1_to_filter = np.swapaxes(data_elec_1, 0, 1)\n",
    "        data_2_to_filter = np.swapaxes(data_elec_2, 0, 1)\n",
    "        filtered_data_0 = filter_data(data_0_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "        filtered_data_1 = filter_data(data_1_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "        filtered_data_2 = filter_data(data_2_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "        print ('Size of filtered data 0 :', filtered_data_0.shape, 'filtered data 1 : ', filtered_data_1.shape, 'filtered data 2 : ', filtered_data_2.shape)\n",
    "\n",
    "        #Normalize the non-averaged data (all trials)\n",
    "        times = np.arange(filtered_data_0.shape[1])\n",
    "        print ('time points : ', times.shape)\n",
    "        #filtered_data_to_norm = np.swapaxes(filtered_data, 0, 1)\n",
    "        norm_filtered_data_0 = rescale(filtered_data_0, times=times, baseline=baseline, mode=norm_mode)\n",
    "        norm_filtered_data_1 = rescale(filtered_data_1, times=times, baseline=baseline, mode=norm_mode)\n",
    "        norm_filtered_data_2 = rescale(filtered_data_2, times=times, baseline=baseline, mode=norm_mode)\n",
    "        norm_filtered_data_0 = np.swapaxes(norm_filtered_data_0, 0, 1)\n",
    "        norm_filtered_data_1 = np.swapaxes(norm_filtered_data_1, 0, 1)\n",
    "        norm_filtered_data_2 = np.swapaxes(norm_filtered_data_2, 0, 1)\n",
    "        print ('Size norm & filtered data 0 : ', norm_filtered_data_0.shape, norm_filtered_data_1.shape, norm_filtered_data_2.shape)\n",
    "\n",
    "        # =======================================  STATISTICS  =====================================\n",
    "        # Range of the data to compute\n",
    "        data_range = range(data_to_use[0], data_to_use[1])\n",
    "\n",
    "        # Get all three learning files (Filtered data)\n",
    "        data_learn_0 = norm_filtered_data_0[data_range, :]\n",
    "        data_learn_1 = norm_filtered_data_1[data_range, :]\n",
    "        data_learn_2 = norm_filtered_data_2[data_range, :]\n",
    "        print ('-> Shape of the selected data for learn 0', data_learn_0.shape, 'learn 1', data_learn_1.shape, 'learn 2', data_learn_2.shape)\n",
    "\n",
    "        # Swap data across trials (dim 1) :\n",
    "        perm_learn_0_1 = perm_swap(data_learn_0, data_learn_1, axis=1, n_perm=n_perm)[0]\n",
    "        perm_learn_0_2 = perm_swap(data_learn_0, data_learn_2, axis=1, n_perm=n_perm)[0]\n",
    "        perm_learn_1_2 = perm_swap(data_learn_1, data_learn_2, axis=1, n_perm=n_perm)[0]\n",
    "        print('-> Shape of permuted learn 0/1 : ', perm_learn_0_1.shape, 'learn 0/2 : ', perm_learn_0_2.shape, 'learn 1/2 : ', perm_learn_1_2.shape)\n",
    "\n",
    "        # Take the mean across time :\n",
    "        perm_learn_0_1_mean = perm_learn_0_1.mean(2)\n",
    "        perm_learn_0_2_mean = perm_learn_0_2.mean(2)\n",
    "        perm_learn_1_2_mean = perm_learn_1_2.mean(2)\n",
    "        print('-> Shape of meaned permuted learn 0/1 : ', perm_learn_0_1_mean.shape, 'learn 0/2 : ', perm_learn_0_2_mean.shape, 'learn 1/2 : ', perm_learn_1_2_mean.shape)\n",
    "\n",
    "        # Get p-values from the permuted data :\n",
    "        p_vals_0_1 = perm_2pvalue(data_learn_0.mean(1), perm_learn_0_1_mean, n_perm=n_perm, threshold=None, tail=2)\n",
    "        p_vals_0_2 = perm_2pvalue(data_learn_2.mean(1), perm_learn_0_2_mean, n_perm=n_perm, threshold=None, tail=2)\n",
    "        p_vals_1_2 = perm_2pvalue(data_learn_1.mean(1), perm_learn_1_2_mean, n_perm=n_perm, threshold=None, tail=2)\n",
    "        print('-> Shape of p-values learn 0/1 : ', p_vals_0_1.shape, 'learn 0/2 : ', p_vals_0_2.shape, 'learn 1/2 : ', p_vals_1_2.shape)\n",
    "\n",
    "        ## Test if there's significant p-values after multiplt comparison :\n",
    "        print('-> Significant p-values learn 0/1? ', p_vals_0_1.min() <= 0.05)\n",
    "        print('-> Significant p-values learn 0/2? ', p_vals_0_2.min() <= 0.05)\n",
    "        print('-> Significant p-values learn 1/2? ', p_vals_1_2.min() <= 0.05)\n",
    "\n",
    "        # =======================PREPARE DATA TO PLOT AND PLOT THE ERPs=====================================\n",
    "        # Data to plot :\n",
    "        data_learn_0_to_plot = norm_filtered_data_0[range(baseline[0], data_to_use[1])]\n",
    "        data_learn_1_to_plot = norm_filtered_data_1[range(baseline[0], data_to_use[1])]\n",
    "        data_learn_2_to_plot = norm_filtered_data_2[range(baseline[0], data_to_use[1])]\n",
    "        data_learn_to_plot = np.concatenate([data_learn_0_to_plot, data_learn_1_to_plot, data_learn_2_to_plot], axis=1)\n",
    "        print('-> Shape of filtered data to plot : ', data_learn_to_plot.shape)\n",
    "\n",
    "        # Time vector & label vector:\n",
    "        times_plot = 1000 * np.arange((baseline[0] - baseline[1]), data_learn_to_plot.shape[0]-baseline[1] + baseline[0],) / sf\n",
    "        print('-> Shape of time vector : ', times_plot.shape)\n",
    "        label_learn_0 = np.zeros(data_learn_0_to_plot[1].shape, dtype='int64')\n",
    "        label_learn_1 = np.ones(data_learn_1_to_plot[1].shape, dtype='int64')\n",
    "        label_learn_2 = np.full(data_learn_2_to_plot[1].shape, 2, dtype='int64')\n",
    "        print('label size and values : 0 : ', label_learn_0.shape, '1 : ', label_learn_1.shape, '2 : ', label_learn_2.shape,)\n",
    "        y = np.concatenate([label_learn_0, label_learn_1, label_learn_2])\n",
    "        print('-> the y label', y.shape)\n",
    "\n",
    "        # P-values to plot :\n",
    "        p_vals_0_1_to_plot = np.insert(p_vals_0_1, 0, 10 * np.ones((baseline[1] - baseline[0],)))\n",
    "        p_vals_0_2_to_plot = np.insert(p_vals_0_2, 0, 10 * np.ones((baseline[1] - baseline[0],)))\n",
    "        p_vals_1_2_to_plot = np.insert(p_vals_1_2, 0, 10 * np.ones((baseline[1] - baseline[0],)))\n",
    "        print('-> Shape of p-values to plot :', p_vals_0_1_to_plot.shape, p_vals_0_2_to_plot.shape, p_vals_1_2_to_plot.shape)\n",
    "\n",
    "        #Prepare the plot\n",
    "        fig = plt.figure(0, figsize=(12, 7))\n",
    "        ax = fig.add_subplot(111)\n",
    "        fig.subplots_adjust(top=0.85)\n",
    "        ax.set_xlabel('Times (ms)', fontsize=12)\n",
    "        ax.set_ylabel('Potential', fontsize=12)\n",
    "\n",
    "        #Plot the Data\n",
    "        BorderPlot(times_plot, data_learn_to_plot, y=y, kind='sem', alpha=0.2, color=['m','c', 'b'], linewidth=2, ncol=1, legend= ['Early Learning', 'Medium Learning', 'Late Learning'],\n",
    "                  title=su+'_ERP_Odor_bipo_'+norm_mode+'_'+str(channel[elec])+'_'+str(label[elec])+' elec_num: '+str(elec)+'_ntrials:'+str(ntrials),)\n",
    "        plt.gca()\n",
    "        lines = [0] #time vector is in ms\n",
    "        addPval(plt.gca(), p_vals_0_1_to_plot, p=0.05, x=times_plot, y=0.5, color='m', lw=3)\n",
    "        addPval(plt.gca(), p_vals_0_2_to_plot, p=0.05, x=times_plot, y=1, color='b', lw=3)\n",
    "        addPval(plt.gca(), p_vals_1_2_to_plot, p=0.05, x=times_plot, y=1.5, color='c', lw=3)\n",
    "        addLines(plt.gca(), vLines=lines, vColor=['firebrick'], vWidth=[2], hLines=[0], hColor=['#000000'], hWidth=[2])\n",
    "        plt.legend(fontsize='small')\n",
    "        plt.grid()\n",
    "        #plt.show()         \n",
    "\n",
    "# =========================SAVE PLOTS of ERPs=================================================\n",
    "        rep = path.join(st.path, 'feature/ERP_Encoding_all_bipo_250ms_mean_thr40_art400_30_250_learningOK/',su)\n",
    "        fname = (rep + '_E1E2_ERP_concat_all_bipo_' + channel [elec] +'_'+str(elec)+'_'+label[elec]+'.png')\n",
    "        print (fname)\n",
    "        plt.savefig(fname, dpi=300, bbox_inches='tight')\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "    del data_early, data_middle, data_late, channel, ntrials, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
