{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, MaxNLocator\n",
    "import scipy.io as sio\n",
    "\n",
    "from brainpipe.classification import *\n",
    "from brainpipe.system import study\n",
    "from brainpipe.feature import power, amplitude, sigfilt\n",
    "from brainpipe.visual import *\n",
    "from brainpipe.statistics import *\n",
    "\n",
    "from os import path\n",
    "from mne.stats import *\n",
    "from mne.baseline import rescale\n",
    "from mne.filter import filter_data\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# where to find data\n",
    "st = study('Olfacto')\n",
    "score = 'Rec' #'Rec'\n",
    "if score == 'Epi':\n",
    "    path_data = path.join (st.path, 'database/TS_E_all_by_odor_th40_art400_30_250_5s_Good_Bad_EpiScore/')\n",
    "    save_path = path.join(st.path, 'classified/0_Classif_ERP_EpiScore_all_electrodes/')\n",
    "if score == 'Rec':\n",
    "    path_data = path.join (st.path, 'database/TS_E_all_by_odor_th40_art400_30_250_Good_Bad_RecScore/')\n",
    "    save_path = path.join(st.path, 'classified/0_Classif_ERP_RecScore_all_electrodes/')\n",
    "\n",
    "# ANALYSIS PARAMETERS\n",
    "low_pass_filter = 10.\n",
    "sf = 512.\n",
    "norm_mode = 'mean' #'ratio' 'mean' 'percent' \n",
    "baseline = [973 , 1024] #100ms before odor perception\n",
    "data_to_use = [973, 1536] #1000ms after odor\n",
    "time_points = data_to_use[1]-data_to_use[0]\n",
    "classif = 'lda'\n",
    "n_rep = 1 #bootstrap\n",
    "alpha = 0.05\n",
    "winSample = 10 #in samples = 20ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERPs Decoding - Good Bad Odors Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = False\n",
    "\n",
    "if test == True:\n",
    "    n_elec = {'PIRJ' :1}\n",
    "    \n",
    "    subjects = ['PIRJ']\n",
    "    \n",
    "else :\n",
    "    subjects = ['LEFC','CHAF'] #'MICP','VACJ','SEMC','PIRJ',\n",
    "    n_elec = {\n",
    "    'CHAF' : 107,\n",
    "    'VACJ' : 139, \n",
    "    'SEMC' : 107,\n",
    "    'PIRJ' : 106,\n",
    "    'LEFC' : 193,\n",
    "    'MICP' : 105,\n",
    "        }\n",
    "\n",
    "for su in subjects:\n",
    "    #Load files\n",
    "    data_bad = np.load(path.join(path_data, su+'_concat_odor_bad_bipo.npz'))\n",
    "    data_good = np.load(path.join(path_data, su+'_concat_odor_good_bipo.npz'))\n",
    "    data_bad, channels, names, data_good = data_bad['x'], data_bad['channel'], data_bad['label'], data_good['x']\n",
    "\n",
    "    for elec in range(0,n_elec[su]):\n",
    "    #for elec in n_elec[su]:\n",
    "        tic = time.clock()\n",
    "        # Select data for one elec + name :\n",
    "        data_elec_bad = data_bad[elec,:,:]\n",
    "        data_elec_good = data_good[elec,:,:]\n",
    "        ntrials = str(data_elec_bad.shape[1])+'/'+ str(data_elec_good.shape[1])\n",
    "        channel, name = channels[elec], names[elec]\n",
    "        print (su, 'Channel : ', channel, 'Label : ', name,'Bad shape : ', \n",
    "               data_elec_bad.shape, 'Good shape : ', data_elec_good.shape)\n",
    "\n",
    "        #Filter data for one elec (all trials):\n",
    "        data_elec_bad = np.array(data_elec_bad, dtype='float64')\n",
    "        data_elec_good = np.array(data_elec_good, dtype='float64')\n",
    "        data_bad_to_filter = np.swapaxes(data_elec_bad, 0, 1)\n",
    "        data_good_to_filter = np.swapaxes(data_elec_good, 0, 1)\n",
    "        filtered_data_bad = filter_data(data_bad_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "        filtered_data_good = filter_data(data_good_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "        print ('Size of filtered data bad :', filtered_data_bad.shape, 'filtered data good : ', filtered_data_good.shape,)\n",
    "\n",
    "        #Normalize the non-averaged data (all trials)\n",
    "        times = np.arange(filtered_data_bad.shape[1])\n",
    "        print ('time points : ', times.shape)\n",
    "        norm_filtered_data_bad = rescale(filtered_data_bad, times=times, baseline=baseline, mode=norm_mode)\n",
    "        norm_filtered_data_good = rescale(filtered_data_good, times=times, baseline=baseline, mode=norm_mode)\n",
    "        print ('Size norm & filtered data 0 : ', norm_filtered_data_bad.shape, norm_filtered_data_good.shape,)\n",
    "\n",
    "        # Range of the data to compute\n",
    "        data_range = range(data_to_use[0], data_to_use[1])\n",
    "        bad_sel = norm_filtered_data_bad[:, data_range]\n",
    "        good_sel = norm_filtered_data_good[:, data_range,]\n",
    "        print ('-> Shape of bad data', bad_sel.shape, 'good data', good_sel.shape)\n",
    "        \n",
    "        # Average the signal on consecutive windows\n",
    "        n_pts = bad_sel.shape[1]\n",
    "        rmPoints = n_pts % winSample # Points to remove before splitting\n",
    "        shapeRmPoints = np.arange(n_pts-rmPoints).astype(int) # Number of points for round division\n",
    "        n_win = int(n_pts / winSample) # Number of segments\n",
    "\n",
    "        # Split and average data (trials, n_pts)\n",
    "        bad_split = np.array(np.split(bad_sel[:, shapeRmPoints], n_win, axis=1)) # n_win n_trials n_pts\n",
    "        bad_split = np.mean(bad_split, axis=2).swapaxes(0,1) # n-trials n_win\n",
    "        good_split = np.array(np.split(good_sel[:, shapeRmPoints], n_win, axis=1))\n",
    "        good_split = np.mean(good_split, axis=2).swapaxes(0,1)\n",
    "\n",
    "# ==========================  BALANCED CONDITIONS - Bootstrap  =====================================\n",
    "        da_rep, daperm_rep = np.array([]), np.array([])\n",
    "        bad_rep, good_rep = np.array([]), np.array([])\n",
    "        for i in range(n_rep):\n",
    "            if bad_split.shape[0] > good_split.shape[0]:\n",
    "                bad_sel_stat = bad_split[np.random.randint(bad_split.shape[0], size=good_split.shape[0]), :] #reshape bad_data to fit good_data shape\n",
    "                good_sel_stat = good_split\n",
    "            elif bad_split.shape[0] < good_split.shape[0]:\n",
    "                bad_sel_stat = bad_split\n",
    "                good_sel_stat = good_split[np.random.randint(good_split.shape[0], size=bad_split.shape[0]), :]\n",
    "            else:\n",
    "                bad_sel_stat, good_sel_stat = bad_split, good_split\n",
    "            print ('balanced data : ', bad_sel_stat.shape, good_sel_stat.shape)\n",
    "                \n",
    "# =============================  CLASSIFICATION COMPUTATION ============================================================           \n",
    "            #create a data matrix, concatenate along the trial dimension\n",
    "            bad_good = np.concatenate((bad_sel_stat, good_sel_stat), axis=0)\n",
    "            #print ('Size of the concatenated data: ', bad_good.shape, 'Number time windows : ', bad_good.shape[1])\n",
    "\n",
    "            #create label vector (0 for rest and 1 for odor)\n",
    "            y = [0]*bad_sel_stat.shape[0] + [1]*good_sel_stat.shape[0]\n",
    "            #print ('Size of label for classif: ', len(y))\n",
    "\n",
    "            # Define a cross validation:\n",
    "            cv = defCv(y, n_folds=10, cvtype='skfold', rep=10)\n",
    "            # Define classifier technique\n",
    "            clf = defClf(y=y, clf=classif)#,n_tree=200, random_state=100)\n",
    "            #Classify rest and odor\n",
    "            cl = classify(y, clf=clf, cvtype=cv)\n",
    "            # Evaluate the classifier on data:\n",
    "            da,pvalue,daperm = cl.fit(bad_good, n_perm=1000,method='full_rnd',mf=False)\n",
    "            # Save da, daperm and bootstrapped data\n",
    "            da_rep = np.vstack((da_rep,da)) if np.size(da_rep) else da\n",
    "            daperm_rep = np.vstack((daperm_rep,daperm)) if np.size(daperm_rep) else daperm\n",
    "            bad_rep = np.vstack((bad_rep,bad_sel_stat)) if np.size(bad_rep) else bad_sel_stat\n",
    "            good_rep = np.vstack((good_rep,good_sel_stat)) if np.size(good_rep) else good_sel_stat\n",
    "        print ('Bootstrap da&data : ', 'da_rep',da_rep.shape, 'daperm_rep',daperm_rep.shape,\n",
    "                  'bad rep', bad_rep.shape, 'good_rep', good_rep.shape)\n",
    "        \n",
    "        #Save all bootstraps for good and bad conditions\n",
    "        level_0_5 = perm_pvalue2level(daperm_rep, p=0.05, maxst=False)\n",
    "        level_0_1 = perm_pvalue2level(daperm_rep, p=0.01, maxst=False)\n",
    "        level_0_0_1 = perm_pvalue2level(daperm_rep, p=0.001, maxst=False)\n",
    "        th_0_05 = level_0_5.max()\n",
    "        th_0_01 = level_0_1.max()\n",
    "        th_0_001 = level_0_0_1.max()\n",
    "        print('levels', th_0_05, th_0_01, th_0_001)\n",
    "        \n",
    "# ============================== PLOT ERPs ANALYSIS + STATS & DECODING ACCURACY ===================================================\n",
    "        # data to plot\n",
    "        bad_good_plot = np.concatenate((bad_rep, good_rep), axis=0)\n",
    "        y_plot = [0]*bad_rep.shape[0] + [1]*good_rep.shape[0]\n",
    "\n",
    "        # plot and figure parameters\n",
    "        xfmt = ScalarFormatter(useMathText=True)\n",
    "        xfmt.set_powerlimits((0,3))\n",
    "        fig = plt.figure(1,figsize=(7,7))\n",
    "        title = 'ERP and DA for '+su+' Good/Bad '+str(channel)+' '+str(name)+' ('+str(elec)+') ntrials:'+str(ntrials)\n",
    "        fig.suptitle(title, fontsize=12)\n",
    "        times_plot = 1000 * np.arange((baseline[0] - baseline[1]), len(shapeRmPoints)-baseline[1]+baseline[0],winSample) / sf\n",
    "\n",
    "        # Plot the ERPs\n",
    "        plt.subplot(211)\n",
    "        BorderPlot(times_plot, bad_good_plot, y=y_plot, kind='sem', alpha=0.2, color=['b','m'], \n",
    "                   linewidth=2, ncol=1, xlabel='Time (ms)',ylabel = r' $\\mu$V', legend=['bad','good'])\n",
    "        addLines(plt.gca(), vLines=[0], vColor=['r'], vWidth=[2], hLines=[0], \n",
    "                 hColor=['#000000'], hWidth=[2])\n",
    "        rmaxis(plt.gca(), ['right', 'top'])\n",
    "        plt.legend(loc=0, handletextpad=0.1, frameon=False)\n",
    "        plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "\n",
    "        # Plot DA for the ERPs\n",
    "        plt.subplot(212)\n",
    "        BorderPlot(times_plot, da_rep, color='b', kind='sem',xlabel='Time (ms)', \n",
    "                   ylim=[da_rep.min()-10,da_rep.max()+10], ylabel='Decoding accuracy (%)',\n",
    "                   linewidth=2, alpha=0.3)\n",
    "        rmaxis(plt.gca(), ['right', 'top'])\n",
    "        addLines(plt.gca(), vLines=[0], vWidth=[2], vColor=['r'], hLines=[50], \n",
    "                 hColor=['#000000'], hWidth=[2])\n",
    "        plt.legend(loc=0, handletextpad=0.1, frameon=False)   \n",
    "        plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "        plt.plot(times_plot, th_0_05*np.ones(len(times_plot)), '--', color='orange', \n",
    "                  linewidth=2)\n",
    "        plt.plot(times_plot, th_0_01*np.ones(len(times_plot)), '--', color='orangered', \n",
    "                  linewidth=2)\n",
    "        plt.plot(times_plot, th_0_001*np.ones(len(times_plot)), '--', color='r', \n",
    "                      linewidth=2)\n",
    "        \n",
    "        #Save plots\n",
    "        if (da_rep.mean(axis=0)).max() >= level_0_5.max():\n",
    "            np.save(save_path+str(round((winSample*1000)/512))+'ms/Significant/'+su+'_da_Bad_vs_Good_ERP_'+classif+'_'+str(name)+'_('+str(elec)+')',da_rep)\n",
    "            np.save(save_path+str(round((winSample*1000)/512))+'ms/Significant/'+su+'_daperm_Bad_vs_Good_ERP_'+classif+'_'+str(name)+'_('+str(elec)+')',daperm_rep)\n",
    "            fname = save_path+str(round((winSample*1000)/512))+'ms/Significant/'+su+'_da_Bad_vs_Good_ERP_'+classif+'_'+str(name)+'_('+str(elec)+').png'\n",
    "        else:\n",
    "            np.save(save_path+str(round((winSample*1000)/512))+'ms/'+su+'_da_Bad_vs_Good_ERP_'+classif+'_'+str(name)+'_('+str(elec)+')',da_rep)\n",
    "            np.save(save_path+str(round((winSample*1000)/512))+'ms/'+su+'_daperm_Bad_vs_Good_ERP_'+classif+'_'+str(name)+'_('+str(elec)+')',daperm_rep)\n",
    "            fname = save_path+str(round((winSample*1000)/512))+'ms/'+su+'_da_Bad_vs_Good_ERP_'+classif+'_'+str(name)+'_('+str(elec)+').png'\n",
    "        fig.savefig(fname, dpi=300, bbox_inches='tight')\n",
    "        plt.clf()\n",
    "        plt.close()    \n",
    "        toc = time.clock()\n",
    "        print(round(toc-tic,2))\n",
    "        del bad_sel, good_sel, good_sel_stat, bad_sel_stat\n",
    "    del data_bad, data_good, channels, names"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
