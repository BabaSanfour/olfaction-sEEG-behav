{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing files and modules\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "%matplotlib notebook\n",
    "from brainpipe.system import study\n",
    "from brainpipe.visual import *\n",
    "from brainpipe.statistics import *\n",
    "from mne.baseline import rescale\n",
    "from mne.filter import filter_data\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "from detect_peaks import detect_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_pass_filter = 10.\n",
    "sf = 512.\n",
    "norm_mode = 'mean' #'ratio' 'mean' 'percent' \n",
    "baseline = [640 , 768] #-250ms Ã  0ms\n",
    "data_to_use = [768, 1536]\n",
    "n_perm = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ERPs and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st = study('Olfacto')\n",
    "path_data = path.join (st.path, 'database/TS_E_all_cond_by_block_trigs_th40_art400_30_250_5s_concatOK/')\n",
    "\n",
    "subjects = ['CHAF','VACJ','SEMC','PIRJ','LEFC','MICP',]\n",
    "\n",
    "conds = ['all']\n",
    "\n",
    "n_elec = {\n",
    "    'CHAF' : 107,\n",
    "    'VACJ' : 139, \n",
    "    'SEMC' : 107,\n",
    "    'PIRJ' : 106,\n",
    "    'LEFC' : 193,\n",
    "    'MICP' : 105,\n",
    "}\n",
    "\n",
    "for su in subjects:\n",
    "    for elec in range(0, n_elec[su],1):\n",
    "        for cond in conds:\n",
    "            filename = su+'_E1E2_concat_all_bipo_new.npz'\n",
    "            print (filename)\n",
    "            data_all = np.load(path.join(path_data, filename))\n",
    "            data, channel, label = data_all['x'], data_all['channel'], data_all['label']\n",
    "            #data, channel = data_all['x'], [data_all['channel'][i][0] for i in range(len(data_all['channel']))]\n",
    "            #label = [data_all['label'][i][0] for i in range(len(data_all['label']))]\n",
    "            \n",
    "            # Select data for one elec + name :\n",
    "            data_elec = data[elec,:,:]\n",
    "            ntrials = len(data_elec[2])\n",
    "            print ('\\nOriginal data : ', data.shape, 'Channel : ', channel[elec], 'Label : ', label[elec], 'N_trials :', ntrials, 'One elec shape : ', data_elec.shape)\n",
    "\n",
    "            #Filter data for one elec (all trials):\n",
    "            data = np.array(data_elec, dtype='float64')\n",
    "            data_to_filter = np.swapaxes(data, 0, 1)\n",
    "            filtered_data = filter_data(data_to_filter, sfreq=512, l_freq=None, h_freq=low_pass_filter, method='fir', phase='zero-double')\n",
    "            filtered_data = np.swapaxes(filtered_data, 0, 1)\n",
    "            print ('Size of filtered data:', filtered_data.shape,)\n",
    "\n",
    "            #Normalize the non-averaged data (all trials)\n",
    "            times = np.arange(filtered_data.shape[0])\n",
    "            print ('time points : ', times.shape)\n",
    "            filtered_data_to_norm = np.swapaxes(filtered_data, 0, 1)\n",
    "            norm_filtered_data = rescale(filtered_data_to_norm, times=times, baseline=baseline, mode=norm_mode)\n",
    "            norm_filtered_data = np.swapaxes(norm_filtered_data, 0, 1)\n",
    "            print ('Size norm & filtered data : ', norm_filtered_data.shape,)\n",
    "\n",
    "# =======================================SELECT DATA FOR STATISTICS=====================================\n",
    "            # Define a range vector for the baseline and data :\n",
    "            baseline_range = range(baseline[0], baseline[1])\n",
    "            data_range = range(data_to_use[0], data_to_use[1])\n",
    "            \n",
    "            #Get the baseline and data from the FILTERED data :\n",
    "            baseline_tr = filtered_data[baseline_range, :]\n",
    "            data_elec_tr = filtered_data[data_range, :]\n",
    "\n",
    "            # Mean the baseline across time (increase consistency) :\n",
    "            baseline_tr = baseline_tr.mean(0)[np.newaxis, ...]\n",
    "            print('-> Shape of the baseline : ', baseline_tr.shape,' and the selected data :', data_elec_tr.shape)\n",
    "            \n",
    "            # Repeat the baseline by the nb of temporal time points (for swap function)\n",
    "            baseline_tr_rep = np.tile(baseline_tr, (data_elec_tr.shape[0], 1))\n",
    "            print('-> Shape of repeated baseline :', baseline_tr_rep.shape)\n",
    "            \n",
    "            # Swap RAW data and baseline across trials (dim 1) :\n",
    "            perm_data = perm_swap(baseline_tr_rep, data_elec_tr, axis=1, n_perm=n_perm)[0]\n",
    "            print('-> Shape of permuted data / baseline : ', perm_data.shape)\n",
    "\n",
    "            # Take the mean across time :\n",
    "            perm_data_mean = perm_data.mean(2)\n",
    "            print('-> Shape of meaned permuted data / baseline : ', perm_data_mean.shape)\n",
    "\n",
    "            # Get p-values from the permuted data :\n",
    "            p_vals = perm_2pvalue(data_elec_tr.mean(1), perm_data_mean, n_perm=n_perm, threshold=None, tail=2)\n",
    "            print('-> Shape of non-corrected p-values : ', p_vals.shape)\n",
    "\n",
    "            # Correct across time :\n",
    "            perm_corr = maxstat(perm_data, axis=2)[..., 0]\n",
    "            print('-> Shape of maxstat perm : ', perm_corr.shape)\n",
    "\n",
    "            # Get p-values from the permuted data :\n",
    "            p_vals_corr = perm_2pvalue(data_elec_tr.mean(1), perm_corr, n_perm=n_perm, threshold=None, tail=2)\n",
    "            print('-> Shape of corrected p-values : ', p_vals_corr.shape)\n",
    "\n",
    "            # Test if there's significant p-values after multiplt comparison :\n",
    "            print('-> Significant p-values after mutiple comparison? ', p_vals_corr.min() <= 0.05)\n",
    "\n",
    "# =======================PREPARE DATA TO PLOT AND PLOT THE ERPs=====================================\n",
    "            # Data to plot :\n",
    "            #data_to_plot = norm_data[range(baseline[0], data_to_use[1])]\n",
    "            #print('-> Shape of data to plot : ', data_to_plot.shape)\n",
    "            filtered_data_to_plot = norm_filtered_data[range(baseline[0], data_to_use[1])]\n",
    "            print('-> Shape of filtered data to plot : ', filtered_data_to_plot.shape)\n",
    "\n",
    "            # Time vector :\n",
    "            times_plot = 1000 * np.arange((baseline[0] - baseline[1]), filtered_data_to_plot.shape[0]-baseline[1] + baseline[0],) / sf\n",
    "            #times_plot = 1000 * np.arange(-baseline[1], filtered_data_to_plot.shape[0]-baseline[1],) / sf\n",
    "            print('-> Shape of time vector : ', times_plot.shape)\n",
    "\n",
    "            # P-values to plot :\n",
    "            p_vals_to_plot = np.insert(p_vals, 0, 10 * np.ones((data_to_use[0] - baseline[0],)))\n",
    "            p_vals_corr_to_plot = np.insert(p_vals_corr, 0, 10 * np.ones((data_to_use[0] - baseline[0],)))\n",
    "            print('-> Shape of p-values to plot :', p_vals_to_plot.shape, p_vals_corr_to_plot.shape)\n",
    "\n",
    "            #Prepare the plot\n",
    "            fig = plt.figure(0, figsize=(12, 7))\n",
    "            ax = fig.add_subplot(111)\n",
    "            fig.subplots_adjust(top=0.85)\n",
    "            ax.set_xlabel('Times (ms)', fontsize=12)\n",
    "            ax.set_ylabel('Potential', fontsize=12)\n",
    "\n",
    "            #Plot the Data\n",
    "            #plt.plot(times_plot, data_to_plot, '#808080', linewidth=1, label='data')\n",
    "            #plt.plot(times_plot, filtered_data_to_plot, 'g-', linewidth=2, label='filtered data < '+str(low_pass_filter)+'Hz')\n",
    "            BorderPlot(times_plot, filtered_data_to_plot, kind='sem', color='', alpha=0.2, linewidth=2, ncol=1, \n",
    "                      title=su+'_ERP_Odor_bipo_'+norm_mode+'_'+channel[elec]+'_'+label[elec]+' elec_num: '+str(elec)+'_ntrials:'+str(ntrials),) #legend= roi+'_filter < '+str(low_pass_filter)+'Hz'\n",
    "            plt.gca()\n",
    "            lines = [0] #time vector is in ms\n",
    "            addPval(plt.gca(), p_vals_to_plot, p=0.05, x=times_plot, y=0.5, color='darkred', lw=3)\n",
    "            addPval(plt.gca(), p_vals_to_plot, p=0.01, x=times_plot, y=1, color='darkblue', lw=4)\n",
    "            addPval(plt.gca(), p_vals_corr_to_plot, p=0.05, x=times_plot, y=2, color='red', lw=3)\n",
    "            addPval(plt.gca(), p_vals_corr_to_plot, p=0.01, x=times_plot, y=3, color='dodgerblue', lw=4)\n",
    "            addLines(plt.gca(), vLines=lines, vColor=['firebrick']*2, vWidth=[2]*2, hLines=[0], hColor=['#000000'], hWidth=[2])\n",
    "            plt.grid()\n",
    "            #plt.legend(fontsize='small')\n",
    "            #plt.show()         \n",
    "                 \n",
    "# =========================SAVE PLOTS of ERPs=================================================\n",
    "            rep = path.join(st.path, 'feature/ERP_Encoding_all_bipo_250ms_mean_thr40_art400_30_250/',su)\n",
    "            fname = (rep + '_E1E2_ERP_concat_all_bipo_' + channel [elec] +'_'+str(elec)+'_'+label[elec]+'.png')\n",
    "            print (fname)\n",
    "            plt.savefig(fname, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "del x, channel, n_elec, n_trials, label"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
