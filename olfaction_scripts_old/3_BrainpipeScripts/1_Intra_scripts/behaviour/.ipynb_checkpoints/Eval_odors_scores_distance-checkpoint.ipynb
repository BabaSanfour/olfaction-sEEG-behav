{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load Lucile evaluation data and average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            PARTICIPANT  hedo_scaled  fam_scaled  emo_scaled\n",
      "Stimulus                                                                    \n",
      "9 Decen-1-ol                         45     3.376000    4.180000    4.787556\n",
      "Acétate linalyle                     51     2.804706    5.250980    5.168235\n",
      "Basilic comores                      75     4.664000    5.736533    5.290667\n",
      "Birch oil                            48     5.185000    7.656250    6.267083\n",
      "Carotte                              80     3.818250    5.196500    5.574500\n",
      "Citronellol                          53     2.628302    4.672830    5.961132\n",
      "Musc                                 77     2.671688    4.914545    6.187273\n",
      "Octine carbonate de méthyl           50     2.856800    4.577600    5.853600\n",
      "Salicylate cis-3-hexanyl             81     3.399012    4.909136    5.172346\n",
      "Stémone                              77     2.856883    4.549610    5.547792\n",
      "Tabac                                46     4.271739    4.480435    5.238261\n",
      "Tomate                               81     6.439259    6.786914    6.269877\n",
      "#number of participants in total 84\n",
      ">>> average nb of participants 63.666666666666664\n"
     ]
    }
   ],
   "source": [
    "###### import numpy as np\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "#MICP is not included (only his memory perf can be used, no RT data)\n",
    "PATH = '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "df_name = join(PATH,'EvalsOdeurs_Lucile.xlsx')\n",
    "df_od_AL = join(PATH, 'Recap_Odeurs_Evaluations.xlsx')\n",
    "df_save = join(PATH, 'Eval_Odors_avg.csv')\n",
    "\n",
    "studies = ['Etude1.1','Etude1.2','Etude2']\n",
    "col_sel = ['PARTICIPANT','Stimulus','hedo_scaled','fam_scaled','emo_scaled']\n",
    "\n",
    "df_tot = pd.DataFrame([])\n",
    "for stud in studies:\n",
    "    df = pd.read_excel(df_name,sheet_name=stud)\n",
    "    df_sel = df[col_sel].dropna()\n",
    "    df_tot = df_tot.append(df_sel)\n",
    "df_tot.to_csv(df_save, columns=col_sel)\n",
    "#get a consistent odor name\n",
    "df_tot = df_tot.replace('Basilic Comores', 'Basilic comores')\n",
    "df_tot = df_tot.replace('Acétate Linalyle', 'Acétate linalyle')\n",
    "\n",
    "df_su = df_tot.groupby(['Stimulus']).agg({'PARTICIPANT' : 'count', 'hedo_scaled':np.mean,\n",
    "                                         'fam_scaled':'mean', 'emo_scaled':'mean'})\n",
    "print(df_su)\n",
    "print('#number of participants in total',len(np.unique(df_tot[['PARTICIPANT']])))\n",
    "print('>>> average nb of participants', np.mean(df_su[['PARTICIPANT']].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "A = [2.67,6.32,2.86,4.76,3.82,3.73,5.86,4.00,2.86,2.62,5.19,2.80,3.38,4.27,5.83,4.66,6.43,4.96]\n",
    "B = [4.91,5.64,4.54,4.62,5.2,4.19237472766885,5.91401597676108,4.9,4.58,4.67,7.66,5.25,4.18,4.48,4.84684095860566,5.73,6.78,4.47671194839592,]\n",
    "R,p = pearsonr(A,B)\n",
    "print(R,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def tpsim_btw_2odors(pow_o1,pow_o2,stat='pearson',average=True):\n",
    "    \"\"\"\n",
    "    Compute tpsim between 2 odors \n",
    "    Parameters\n",
    "    ----------\n",
    "    pow_o1, pow_o2 : array (npts x ntrials)\n",
    "    stat : string\n",
    "            The stat correlation method to use. 'pearson' or 'spearman'\n",
    "    Returns\n",
    "    -------\n",
    "    tpsim : array (Average TPSim between 2 ODORS)\n",
    "    \"\"\"\n",
    "    \n",
    "    corr = stats.pearsonr if stat == 'pearson' else stats.spearmanr\n",
    "    sim_trials = np.array([])\n",
    "    ncombs = len([a for a,_ in product(range(pow_o1.shape[-1]),range(pow_o2.shape[-1]))])\n",
    "    for t0, t1 in product(range(pow_o1.shape[-1]),range(pow_o2.shape[-1])):\n",
    "        R, _ = corr(pow_o1[:,t0],pow_o2[:,t1])\n",
    "        sim_trials = np.vstack((sim_trials,1-R)) if np.size(sim_trials) else np.array(1-R)\n",
    "    if ncombs == 1:\n",
    "        sim_trials = np.array(sim_trials)[np.newaxis][np.newaxis]\n",
    "    if average == True:\n",
    "        sim_trials = np.mean(sim_trials)\n",
    "    return sim_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "28 61\n",
      "(61, 30, 1) (61, 30, 3)\n",
      "[5.64223228] [3.67]\n",
      "3.86 3\n",
      "2.75\n",
      "(61, 30, 1) (61, 30, 1)\n",
      "[4.62] [3.67]\n",
      "1.32 1\n",
      "0.91\n",
      "(61, 30, 1) (61, 30, 1)\n",
      "[5.01830065] [3.67]\n",
      "4.1 1\n",
      "1.96\n",
      "(61, 30, 1) (61, 30, 3)\n",
      "[3.66136529] [3.67]\n",
      "41.0 3\n",
      "0.84\n",
      "(61, 30, 1) (61, 30, 3)\n",
      "[3.92062455] [3.67]\n",
      "15.68 3\n",
      "0.9\n",
      "(61, 30, 1) (61, 30, 4)\n",
      "[5.91401598] [3.67]\n",
      "27.07 4\n",
      "2.51\n",
      "(61, 30, 1) (61, 30, 5)\n",
      "[4.32472767] [3.67]\n",
      "55.03 5\n",
      "1.87\n",
      "(61, 30, 3) (61, 30, 1)\n",
      "[4.62] [0.67]\n",
      "4.29 3\n",
      "1.87\n",
      "(61, 30, 3) (61, 30, 1)\n",
      "[5.01830065] [0.67]\n",
      "6.69 3\n",
      "0.85\n",
      "(61, 30, 3) (61, 30, 3)\n",
      "[3.66136529] [0.67]\n",
      "44.1 9\n",
      "3.53\n",
      "(61, 30, 3) (61, 30, 3)\n",
      "[3.92062455] [0.67]\n",
      "18.73 9\n",
      "2.37\n",
      "(61, 30, 3) (61, 30, 4)\n",
      "[5.91401598] [0.67]\n",
      "30.0 12\n",
      "0.54\n",
      "(61, 30, 3) (61, 30, 5)\n",
      "[4.32472767] [0.67]\n",
      "58.0 15\n",
      "1.43\n",
      "(61, 30, 1) (61, 30, 1)\n",
      "[5.01830065] [4.67]\n",
      "2.83 1\n",
      "1.06\n",
      "(61, 30, 1) (61, 30, 3)\n",
      "[3.66136529] [4.67]\n",
      "40.02 3\n",
      "1.67\n",
      "(61, 30, 1) (61, 30, 3)\n",
      "[3.92062455] [4.67]\n",
      "14.66 3\n",
      "0.7\n",
      "(61, 30, 1) (61, 30, 4)\n",
      "[5.91401598] [4.67]\n",
      "26.02 4\n",
      "1.7\n",
      "(61, 30, 1) (61, 30, 5)\n",
      "[4.32472767] [4.67]\n",
      "54.01 5\n",
      "1.05\n",
      "(61, 30, 1) (61, 30, 3)\n",
      "[3.66136529] [7.33]\n",
      "37.41 3\n",
      "2.71\n",
      "(61, 30, 1) (61, 30, 3)\n",
      "[3.92062455] [7.33]\n",
      "12.04 3\n",
      "1.51\n",
      "(61, 30, 1) (61, 30, 4)\n",
      "[5.91401598] [7.33]\n",
      "23.34 4\n",
      "0.9\n",
      "(61, 30, 1) (61, 30, 5)\n",
      "[4.32472767] [7.33]\n",
      "51.34 5\n",
      "0.69\n",
      "(61, 30, 3) (61, 30, 3)\n",
      "[3.92062455] [44.67]\n",
      "25.37 9\n",
      "1.33\n",
      "(61, 30, 3) (61, 30, 4)\n",
      "[5.91401598] [44.67]\n",
      "14.21 12\n",
      "3.33\n",
      "(61, 30, 3) (61, 30, 5)\n",
      "[4.32472767] [44.67]\n",
      "14.2 15\n",
      "2.46\n",
      "(61, 30, 3) (61, 30, 4)\n",
      "[5.91401598] [19.33]\n",
      "11.4 12\n",
      "2.31\n",
      "(61, 30, 3) (61, 30, 5)\n",
      "[4.32472767] [19.33]\n",
      "39.35 15\n",
      "1.14\n",
      "(61, 30, 4) (61, 30, 5)\n",
      "[4.32472767] [30.67]\n",
      "28.0 20\n",
      "1.59\n",
      "(61, 185) (185,) (185,) (185,) (185,)\n",
      "28 27\n",
      "(27, 30, 11) (27, 30, 5)\n",
      "[5.64223228] [2]\n",
      "2.06 55\n",
      "0.93\n",
      "(27, 30, 11) (27, 30, 2)\n",
      "[4.34088598] [2]\n",
      "1.96 22\n",
      "2.0\n",
      "(27, 30, 11) (27, 30, 16)\n",
      "[5.80319535] [2]\n",
      "0.53 176\n",
      "1.04\n",
      "(27, 30, 11) (27, 30, 6)\n",
      "[3.59697712] [2]\n",
      "56.74 66\n",
      "3.01\n",
      "(27, 30, 11) (27, 30, 4)\n",
      "[3.66136529] [2]\n",
      "2.78 44\n",
      "2.71\n",
      "(27, 30, 11) (27, 30, 4)\n",
      "[4.62] [2]\n",
      "5.44 44\n",
      "1.1\n",
      "(27, 30, 11) (27, 30, 7)\n",
      "[5.24] [2]\n",
      "28.71 77\n",
      "1.61\n",
      "(27, 30, 5) (27, 30, 2)\n",
      "[4.34088598] [0]\n",
      "2.94 10\n",
      "2.75\n",
      "(27, 30, 5) (27, 30, 16)\n",
      "[5.80319535] [0]\n",
      "1.9 80\n",
      "0.91\n",
      "(27, 30, 5) (27, 30, 6)\n",
      "[3.59697712] [0]\n",
      "58.76 30\n",
      "3.82\n",
      "(27, 30, 5) (27, 30, 4)\n",
      "[3.66136529] [0]\n",
      "4.43 20\n",
      "3.53\n",
      "(27, 30, 5) (27, 30, 4)\n",
      "[4.62] [0]\n",
      "7.49 20\n",
      "1.87\n",
      "(27, 30, 5) (27, 30, 7)\n",
      "[5.24] [0]\n",
      "30.74 35\n",
      "2.09\n",
      "(27, 30, 2) (27, 30, 16)\n",
      "[5.80319535] [1.67]\n",
      "1.53 32\n",
      "2.12\n",
      "(27, 30, 2) (27, 30, 6)\n",
      "[3.59697712] [1.67]\n",
      "57.01 12\n",
      "1.09\n",
      "(27, 30, 2) (27, 30, 4)\n",
      "[3.66136529] [1.67]\n",
      "1.73 8\n",
      "0.84\n",
      "(27, 30, 2) (27, 30, 4)\n",
      "[4.62] [1.67]\n",
      "5.73 8\n",
      "0.91\n",
      "(27, 30, 2) (27, 30, 7)\n",
      "[5.24] [1.67]\n",
      "29.0 14\n",
      "0.97\n",
      "(27, 30, 16) (27, 30, 6)\n",
      "[3.59697712] [1.67]\n",
      "57.05 96\n",
      "3.21\n",
      "(27, 30, 16) (27, 30, 4)\n",
      "[3.66136529] [1.67]\n",
      "2.62 64\n",
      "2.95\n",
      "(27, 30, 16) (27, 30, 4)\n",
      "[4.62] [1.67]\n",
      "5.7 64\n",
      "1.36\n",
      "(27, 30, 16) (27, 30, 7)\n",
      "[5.24] [1.67]\n",
      "29.02 112\n",
      "1.29\n",
      "(27, 30, 6) (27, 30, 4)\n",
      "[3.66136529] [58.67]\n",
      "55.34 24\n",
      "0.31\n",
      "(27, 30, 6) (27, 30, 4)\n",
      "[4.62] [58.67]\n",
      "51.37 24\n",
      "1.95\n",
      "(27, 30, 6) (27, 30, 7)\n",
      "[5.24] [58.67]\n",
      "28.02 42\n",
      "2.02\n",
      "(27, 30, 4) (27, 30, 4)\n",
      "[4.62] [3.33]\n",
      "4.23 16\n",
      "1.67\n",
      "(27, 30, 4) (27, 30, 7)\n",
      "[5.24] [3.33]\n",
      "27.35 28\n",
      "1.8\n",
      "(27, 30, 4) (27, 30, 7)\n",
      "[5.24] [7.33]\n",
      "23.35 28\n",
      "0.79\n",
      "(27, 1251) (1251,) (1251,) (1251,) (1251,)\n",
      "21 18\n",
      "(18, 30, 7) (18, 30, 6)\n",
      "[4.32472767] [1.67]\n",
      "2.12 42\n",
      "1.87\n",
      "(18, 30, 7) (18, 30, 1)\n",
      "[5.01830065] [1.67]\n",
      "1.84 7\n",
      "1.96\n",
      "(18, 30, 7) (18, 30, 4)\n",
      "[4.62] [1.67]\n",
      "11.03 28\n",
      "0.91\n",
      "(18, 30, 7) (18, 30, 8)\n",
      "[4.19237473] [1.67]\n",
      "15.0 56\n",
      "0.23\n",
      "(18, 30, 7) (18, 30, 6)\n",
      "[5.91401598] [1.67]\n",
      "35.05 42\n",
      "2.51\n",
      "(18, 30, 7) (18, 30, 5)\n",
      "[4.47671195] [1.67]\n",
      "9.06 35\n",
      "1.07\n",
      "(18, 30, 6) (18, 30, 1)\n",
      "[5.01830065] [0.67]\n",
      "1.0 6\n",
      "0.69\n",
      "(18, 30, 6) (18, 30, 4)\n",
      "[4.62] [0.67]\n",
      "12.04 24\n",
      "1.05\n",
      "(18, 30, 6) (18, 30, 8)\n",
      "[4.19237473] [0.67]\n",
      "16.13 48\n",
      "2.04\n",
      "(18, 30, 6) (18, 30, 6)\n",
      "[5.91401598] [0.67]\n",
      "36.0 36\n",
      "1.59\n",
      "(18, 30, 6) (18, 30, 5)\n",
      "[4.47671195] [0.67]\n",
      "10.03 30\n",
      "0.82\n",
      "(18, 30, 1) (18, 30, 4)\n",
      "[4.62] [1.67]\n",
      "11.04 4\n",
      "1.06\n",
      "(18, 30, 1) (18, 30, 8)\n",
      "[4.19237473] [1.67]\n",
      "15.13 8\n",
      "2.17\n",
      "(18, 30, 1) (18, 30, 6)\n",
      "[5.91401598] [1.67]\n",
      "35.0 6\n",
      "0.9\n",
      "(18, 30, 1) (18, 30, 5)\n",
      "[4.47671195] [1.67]\n",
      "9.03 5\n",
      "0.95\n",
      "(18, 30, 4) (18, 30, 8)\n",
      "[4.19237473] [12.67]\n",
      "4.13 32\n",
      "1.12\n",
      "(18, 30, 4) (18, 30, 6)\n",
      "[5.91401598] [12.67]\n",
      "24.03 24\n",
      "1.7\n",
      "(18, 30, 4) (18, 30, 5)\n",
      "[4.47671195] [12.67]\n",
      "2.01 20\n",
      "0.25\n",
      "(18, 30, 8) (18, 30, 6)\n",
      "[5.91401598] [16.67]\n",
      "20.11 48\n",
      "2.74\n",
      "(18, 30, 8) (18, 30, 5)\n",
      "[4.47671195] [16.67]\n",
      "6.13 40\n",
      "1.26\n",
      "(18, 30, 6) (18, 30, 5)\n",
      "[4.47671195] [36.67]\n",
      "26.02 30\n",
      "1.69\n",
      "(18, 571) (571,) (571,) (571,) (571,)\n",
      "28 39\n",
      "(39, 30, 3) (39, 30, 3)\n",
      "[3.59697712] [1.67]\n",
      "3.55 9\n",
      "3.56\n",
      "(39, 30, 3) (39, 30, 2)\n",
      "[4.24567901] [1.67]\n",
      "2.89 6\n",
      "2.18\n",
      "(39, 30, 3) (39, 30, 3)\n",
      "[3.63776325] [1.67]\n",
      "3.22 9\n",
      "2.69\n",
      "(39, 30, 3) (39, 30, 2)\n",
      "[4.84684096] [1.67]\n",
      "41.0 6\n",
      "0.79\n",
      "(39, 30, 3) (39, 30, 2)\n",
      "[5.24] [1.67]\n",
      "4.68 6\n",
      "1.8\n",
      "(39, 30, 3) (39, 30, 3)\n",
      "[5.80319535] [1.67]\n",
      "29.01 9\n",
      "0.64\n",
      "(39, 30, 3) (39, 30, 4)\n",
      "[4.18] [1.67]\n",
      "33.76 12\n",
      "3.02\n",
      "(39, 30, 3) (39, 30, 2)\n",
      "[4.24567901] [3.67]\n",
      "1.28 6\n",
      "1.4\n",
      "(39, 30, 3) (39, 30, 3)\n",
      "[3.63776325] [3.67]\n",
      "1.3 9\n",
      "1.12\n",
      "(39, 30, 3) (39, 30, 2)\n",
      "[4.84684096] [3.67]\n",
      "39.1 6\n",
      "3.01\n",
      "(39, 30, 3) (39, 30, 2)\n",
      "[5.24] [3.67]\n",
      "2.61 6\n",
      "2.02\n",
      "(39, 30, 3) (39, 30, 3)\n",
      "[5.80319535] [3.67]\n",
      "27.1 9\n",
      "3.21\n",
      "(39, 30, 3) (39, 30, 4)\n",
      "[4.18] [3.67]\n",
      "31.66 12\n",
      "0.65\n",
      "(39, 30, 2) (39, 30, 3)\n",
      "[3.63776325] [4]\n",
      "0.35 6\n",
      "0.62\n",
      "(39, 30, 2) (39, 30, 2)\n",
      "[4.84684096] [4]\n",
      "38.7 4\n",
      "1.62\n",
      "(39, 30, 2) (39, 30, 2)\n",
      "[5.24] [4]\n",
      "2.0 4\n",
      "1.0\n",
      "(39, 30, 2) (39, 30, 3)\n",
      "[5.80319535] [4]\n",
      "26.69 6\n",
      "1.9\n",
      "(39, 30, 2) (39, 30, 4)\n",
      "[4.18] [4]\n",
      "31.34 8\n",
      "0.96\n",
      "(39, 30, 3) (39, 30, 2)\n",
      "[4.84684096] [4.33]\n",
      "38.37 6\n",
      "2.02\n",
      "(39, 30, 3) (39, 30, 2)\n",
      "[5.24] [4.33]\n",
      "1.67 6\n",
      "1.6\n",
      "(39, 30, 3) (39, 30, 3)\n",
      "[5.80319535] [4.33]\n",
      "26.37 9\n",
      "2.48\n",
      "(39, 30, 3) (39, 30, 4)\n",
      "[4.18] [4.33]\n",
      "31.01 12\n",
      "0.99\n",
      "(39, 30, 2) (39, 30, 2)\n",
      "[5.24] [42.67]\n",
      "36.7 4\n",
      "1.61\n",
      "(39, 30, 2) (39, 30, 3)\n",
      "[5.80319535] [42.67]\n",
      "12.01 6\n",
      "1.04\n",
      "(39, 30, 2) (39, 30, 4)\n",
      "[4.18] [42.67]\n",
      "7.74 8\n",
      "2.54\n",
      "(39, 30, 2) (39, 30, 3)\n",
      "[5.80319535] [6]\n",
      "24.7 6\n",
      "1.29\n",
      "(39, 30, 2) (39, 30, 4)\n",
      "[4.18] [6]\n",
      "29.34 8\n",
      "1.38\n",
      "(39, 30, 3) (39, 30, 4)\n",
      "[4.18] [30.67]\n",
      "5.09 12\n",
      "2.61\n",
      "(39, 210) (210,) (210,) (210,) (210,)\n",
      "28 53\n",
      "(53, 30, 4) (53, 30, 7)\n",
      "[3.63776325] [3.33]\n",
      "2.85 28\n",
      "2.81\n",
      "(53, 30, 4) (53, 30, 4)\n",
      "[5.610181] [3.33]\n",
      "0.69 16\n",
      "0.35\n",
      "(53, 30, 4) (53, 30, 6)\n",
      "[4.24567901] [3.33]\n",
      "1.66 24\n",
      "2.26\n",
      "(53, 30, 4) (53, 30, 10)\n",
      "[4.18] [3.33]\n",
      "2.67 40\n",
      "3.02\n",
      "(53, 30, 4) (53, 30, 3)\n",
      "[5.01830065] [3.33]\n",
      "1.35 12\n",
      "0.9\n",
      "(53, 30, 4) (53, 30, 3)\n",
      "[3.92062455] [3.33]\n",
      "2.61 12\n",
      "2.31\n",
      "(53, 30, 4) (53, 30, 3)\n",
      "[4.32472767] [3.33]\n",
      "4.0 12\n",
      "1.59\n",
      "(53, 30, 7) (53, 30, 4)\n",
      "[5.610181] [1]\n",
      "3.51 28\n",
      "2.69\n",
      "(53, 30, 7) (53, 30, 6)\n",
      "[4.24567901] [1]\n",
      "3.0 42\n",
      "0.62\n",
      "(53, 30, 7) (53, 30, 10)\n",
      "[4.18] [1]\n",
      "3.43 70\n",
      "0.99\n"
     ]
    }
   ],
   "source": [
    "from brainpipe.system import study\n",
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from utils import odor_su_score\n",
    "\"\"\"\n",
    "Compute similarity btw all odors by subject for all electrodes\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_pow = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_odor_all_elecsFT/')\n",
    "pow_path = join(path_pow, '{}_odor_{}_bipo_all_{}_6freqs.npz')\n",
    "path2save = join(st.path, 'feature/TPSim_3groups_{}/similarity_matrix_btw_v=1_elecs=all/')\n",
    "tps_save = join(path2save, 'TPS_{}_{}_{}_btw_odors_mean={}_sheet_{}.npz')\n",
    "\n",
    "PATH = '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "df_od_avg = join(PATH, 'Recap_Odeurs_Evaluations.xlsx')\n",
    "###############################################################################\n",
    "exp, mean = 'Enc', False#Ret, Enc\n",
    "stat = 'pearson'\n",
    "shortcut = ['E','R'] if exp == 'Enc_Ret' else [exp[0],exp[0]]\n",
    "if not exists(path2save.format(exp)):\n",
    "    makedirs(path2save.format(exp))\n",
    "###############################################################################\n",
    "freqs, f_id = ['theta'], 1\n",
    "odors_su = {'CHAF': [1,2,4,5,3,8,7,9], #low than high\n",
    "            'LEFC': [15,2,1,16,14,3,4,17],\n",
    "            'PIRJ': [1,9,5,4,6,7,18], #missing odor 15\n",
    "            'VACJ': [11,14,12,10,15,17,16,13],\n",
    "            'SEMC': [7,10,11,12,13,5,8,9],\n",
    "            'FERJ': [7,2,16,17,12,1,5,13]}\n",
    "\n",
    "sheet = 'Final' #,'Final_Lucile','Final_avg']\n",
    "#Final (just 2 odors added from Lucile) Final Lucile (all data available from Lucile taken)\n",
    "#Final avg (Lucile's and my data are averaged when possible)\n",
    "col_sel = ['od_num','odors','Pleasantness','Familiarity']\n",
    "dims = ['Pleasantness','Familiarity']\n",
    "\n",
    "df = pd.read_excel(df_od_avg,sheet_name=sheet)\n",
    "\n",
    "for su,freq in product(odors_su,freqs):\n",
    "    ncomb = len([o1+o2 for o1,o2 in combinations(odors_su[su],2)])\n",
    "    mat_ = np.load(pow_path.format(su,str(odors_su[su][0]),shortcut[0]),allow_pickle=True)\n",
    "    chans, labels, xyz = mat_['channels'], mat_['labels'], mat_['xyz']\n",
    "    nelecs = len(chans)\n",
    "    tps_list = np.array([])\n",
    "    print(ncomb,nelecs)\n",
    "    list_comb, dist_pleas, dist_fam = np.array([]),np.array([]),np.array([])\n",
    "    dist_pleas_fam, dist_sc_pl, dist_sc_fam = np.array([]), np.array([]), np.array([])\n",
    "    \n",
    "    for o1, o2 in combinations(odors_su[su],2):\n",
    "        mat_o1 = np.load(pow_path.format(su,str(o1),shortcut[0]))\n",
    "        pow_o1 = mat_o1['xpow'][f_id,:,17:47,:] #nelecs,npts,ntrials\n",
    "        mat_o2 = np.load(pow_path.format(su,str(o2),shortcut[1]))\n",
    "        pow_o2 = mat_o2['xpow'][f_id,:,17:47,:] #nelecs,npts,ntrials\n",
    "        nvals = len([a for a,b in product(range(pow_o1.shape[-1]), range(pow_o2.shape[-1]))])\n",
    "        print(pow_o1.shape, pow_o2.shape)\n",
    "        pleas_o1 = df.loc[df['od_num']=='O'+str(o1)].iloc[:,2].values\n",
    "        fam_o1 = df.loc[df['od_num']=='O'+str(o1)].iloc[:,3].values\n",
    "        pleas_o2 = df.loc[df['od_num']=='O'+str(o2)].iloc[:,2].values\n",
    "        fam_o2 = df.loc[df['od_num']=='O'+str(o2)].iloc[:,3].values\n",
    "        sc_o1, sc_o2 = [odor_su_score[su][o1]], [odor_su_score[su][o2]]\n",
    "        a, b = np.array([pleas_o1,fam_o1]), np.array([pleas_o2,fam_o2])\n",
    "        c, d = np.array([pleas_o1,sc_o1]), np.array([pleas_o2,sc_o2])\n",
    "        e, f = np.array([sc_o1,fam_o1]), np.array([sc_o2,fam_o2])\n",
    "        dist_pl = np.round(np.linalg.norm(pleas_o1-pleas_o2),2)\n",
    "        dist_pl_fam = np.round(np.linalg.norm(a-b),2)\n",
    "        dist_f = np.round(np.linalg.norm(fam_o1-fam_o2),2)\n",
    "        dist_score_pl = np.round(np.linalg.norm(c-d),2)\n",
    "        dist_score_fam = np.round(np.linalg.norm(e-f),2)\n",
    "        \n",
    "        if mean == False:\n",
    "            list_comb = np.hstack((list_comb,[str(o1)+'_'+str(o2)]*nvals)) if np.size(list_comb) else [str(o1)+'_'+str(o2)]*nvals\n",
    "            dist_pleas = np.hstack((dist_pleas,[dist_pl]*nvals)) if np.size(dist_pleas) else [dist_pl]*nvals \n",
    "            dist_pleas_fam = np.hstack((dist_pleas_fam,[dist_pl_fam]*nvals)) if np.size(dist_pleas_fam) else [dist_pl_fam]*nvals \n",
    "            dist_fam = np.hstack((dist_fam,[dist_f]*nvals)) if np.size(dist_fam) else [dist_f]*nvals\n",
    "            dist_sc_pl = np.hstack((dist_sc_pl,[dist_score_pl]*nvals)) if np.size(dist_sc_pl) else [dist_score_pl]*nvals\n",
    "            dist_sc_fam = np.hstack((dist_sc_fam,[dist_score_fam]*nvals)) if np.size(dist_sc_fam) else [dist_score_fam]*nvals\n",
    "        else: \n",
    "            dist_pleas = np.hstack((dist_pleas,dist_pl)) if np.size(dist_pleas) else dist_pl\n",
    "            dist_fam = np.hstack((dist_fam,dist_f)) if np.size(dist_fam) else dist_f\n",
    "            list_comb = np.hstack((list_comb,str(o1)+'_'+str(o2))) if np.size(list_comb) else str(o1)+'_'+str(o2)\n",
    "        \n",
    "        od_tps = np.array([])   \n",
    "        for elec in range(nelecs):\n",
    "            tps_ = tpsim_btw_2odors(pow_o1[elec],pow_o2[elec],\n",
    "                                                stat=stat,average=mean).swapaxes(0,1)\n",
    "            od_tps = np.concatenate((od_tps,tps_),axis=0) if np.size(od_tps) else tps_\n",
    "        tps_list = np.concatenate((tps_list,od_tps),axis=1) if np.size(tps_list) else od_tps\n",
    "    print(tps_list.shape,list_comb.shape,dist_fam.shape,dist_pleas.shape,dist_sc_pl.shape)\n",
    "    np.savez(tps_save.format(exp,stat,su,freq,mean,sheet),tps=tps_list,comb=list_comb,pleas=dist_pleas,\n",
    "                fam=dist_fam,channels=chans,labels=labels, xyz=xyz,pl_fam=dist_pleas_fam,\n",
    "            sc_pl=dist_sc_pl, sc_fam= dist_sc_fam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from brainpipe.system import study\n",
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from utils import odor_groups_3wgth\n",
    "\"\"\"\n",
    "Compute similarity btw LOW and HIGH MEM GROUPS by subject for all electrodes\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_pow = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_odor_all_elecsFT/')\n",
    "pow_path = join(path_pow, '{}_odor_{}_bipo_all_{}_6freqs.npz')\n",
    "path2save = join(st.path, 'feature/TPSim_3groups_{}/similarity_matrix_btw_v=1_elecs=all/')\n",
    "tps_save = join(path2save, 'TPS_{}_{}_{}_{}_btw_odors_mean={}_sheet_{}.npz')\n",
    "\n",
    "PATH = '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "df_od_avg = join(PATH, 'Recap_Odeurs_Evaluations.xlsx')\n",
    "###############################################################################\n",
    "exp, mean = 'Enc', False#Ret, Enc\n",
    "stat = 'pearson'\n",
    "shortcut = ['E','R'] if exp == 'Enc_Ret' else [exp[0],exp[0]]\n",
    "if not exists(path2save.format(exp)):\n",
    "    makedirs(path2save.format(exp))\n",
    "###############################################################################\n",
    "freqs, f = ['theta'], 1\n",
    "sheet = 'Final_Lucile' #,'Final_Lucile','Final_avg']\n",
    "#Final (just 2 odors added from Lucile) Final Lucile (all data available from Lucile taken)\n",
    "#Final avg (Lucile's and my data are averaged when possible)\n",
    "col_sel = ['od_num','odors','Pleasantness','Familiarity']\n",
    "conds = ['low','mid','high']\n",
    "dims = ['Pleasantness','Familiarity']\n",
    "\n",
    "df = pd.read_excel(df_od_avg,sheet_name=sheet)\n",
    "\n",
    "for su,freq in product(odor_groups_3wgth,freqs):\n",
    "    for cond in conds:\n",
    "        for od in odor_groups_3wgth[su][cond]:\n",
    "            print(su,cond,od)\n",
    "            ncomb = len([o1+o2 for o1,o2 in combinations(odors_su[su],2)])\n",
    "            mat_ = np.load(pow_path.format(su,str(odors_su[su][0]),shortcut[0]),allow_pickle=True)\n",
    "            chans, labels, xyz = mat_['channels'], mat_['labels'], mat_['xyz']\n",
    "            nelecs = len(chans)\n",
    "            tps_list = np.array([])\n",
    "            print(ncomb,nelecs)\n",
    "            list_comb, dist_pleas, dist_fam = np.array([]),np.array([]),np.array([])\n",
    "            dist_pleas_fam = np.array([])\n",
    "    \n",
    "            for o1, o2 in combinations(odor_groups_3wgth[su][cond],2):\n",
    "                mat_o1 = np.load(pow_path.format(su,str(o1),shortcut[0]))\n",
    "                pow_o1 = mat_o1['xpow'][f,:,17:47,:] #nelecs,npts,ntrials\n",
    "                mat_o2 = np.load(pow_path.format(su,str(o2),shortcut[1]))\n",
    "                pow_o2 = mat_o2['xpow'][f,:,17:47,:] #nelecs,npts,ntrials\n",
    "                nvals = len([a for a,b in product(range(pow_o1.shape[-1]), range(pow_o2.shape[-1]))])\n",
    "                print(pow_o1.shape, pow_o2.shape)\n",
    "                pleas_o1 = df.loc[df['od_num']=='O'+str(o1)].iloc[:,2].values\n",
    "                fam_o1 = df.loc[df['od_num']=='O'+str(o1)].iloc[:,3].values\n",
    "                pleas_o2 = df.loc[df['od_num']=='O'+str(o2)].iloc[:,2].values\n",
    "                fam_o2 = df.loc[df['od_num']=='O'+str(o2)].iloc[:,3].values\n",
    "                a, b = np.array([pleas_o1,fam_o1]), np.array([pleas_o2,fam_o2])\n",
    "                dist_pl = np.round(np.linalg.norm(pleas_o1-pleas_o2),2)\n",
    "                dist_pl_fam = np.round(np.linalg.norm(a-b),2)\n",
    "                dist_f = np.round(np.linalg.norm(fam_o1-fam_o2),2)\n",
    "\n",
    "                if mean == False:\n",
    "                    list_comb = np.hstack((list_comb,[str(o1)+'_'+str(o2)]*nvals)) if np.size(list_comb) else np.array([str(o1)+'_'+str(o2)]*nvals)\n",
    "                    dist_pleas = np.hstack((dist_pleas,[dist_pl]*nvals)) if np.size(dist_pleas) else np.array([dist_pl]*nvals )\n",
    "                    dist_pleas_fam = np.hstack((dist_pleas_fam,[dist_pl_fam]*nvals)) if np.size(dist_pleas_fam) else np.array([dist_pl_fam]*nvals )\n",
    "                    dist_fam = np.hstack((dist_fam,[dist_f]*nvals)) if np.size(dist_fam) else np.array([dist_f]*nvals)\n",
    "                else: \n",
    "                    dist_pleas = np.hstack((dist_pleas,dist_pl)) if np.size(dist_pleas) else dist_pl\n",
    "                    dist_fam = np.hstack((dist_fam,dist_f)) if np.size(dist_fam) else dist_f\n",
    "                    list_comb = np.hstack((list_comb,str(o1)+'_'+str(o2))) if np.size(list_comb) else str(o1)+'_'+str(o2)\n",
    "\n",
    "                od_tps = np.array([])   \n",
    "                for elec in range(nelecs):\n",
    "                    tps_ = tpsim_btw_2odors(pow_o1[elec],pow_o2[elec],\n",
    "                                                        stat=stat,average=mean).swapaxes(0,1)\n",
    "                    od_tps = np.concatenate((od_tps,tps_),axis=0) if np.size(od_tps) else tps_\n",
    "                tps_list = np.concatenate((tps_list,od_tps),axis=1) if np.size(tps_list) else od_tps\n",
    "            print(tps_list.shape,list_comb.shape,dist_fam.shape,dist_pleas.shape)\n",
    "            np.savez(tps_save.format(exp,stat,su,cond,freq,mean,sheet),tps=tps_list,comb=list_comb,pleas=dist_pleas,\n",
    "                        fam=dist_fam,channels=chans,labels=labels, xyz=xyz,pl_fam=dist_pleas_fam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlate TPSim and odor characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import odor_groups_3wgth, rename_elecs\n",
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "from scipy.stats import pearsonr, kendalltau\n",
    "from mne.stats import bonferroni_correction, fdr_correction\n",
    "\n",
    "st = study('Olfacto')\n",
    "exp = 'Enc'#'Enc'\n",
    "freqs = ['theta'] #freqname in filename\n",
    "path_pow = join(st.path, 'feature/TPSim_3groups_'+exp+'/similarity_matrix_btw_v=1_elecs=all/')\n",
    "filename = join(path_pow, 'TPS_pearson_{}_{}_btw_odors_mean=False_sheet_{}.npz')\n",
    "df_name = join(path_pow, '{}_correl_rdm_{}_{}_mean=False_{}.csv') #su, conds0, conds1, freq\n",
    "rois_sel = ['aHC','MFG','ACC','IFG','Amg','pPirT','PHG','Ins_olf','OFC_olf','SFG']\n",
    "sheets = ['Final']\n",
    "# cond = 'high'\n",
    "\n",
    "for sheet in sheets:\n",
    "    for freq in freqs:\n",
    "        subjects_c, elecs_c, labels_c = np.array([]), np.array([]), np.array([])\n",
    "        channels_c, x_c, y_c, z_c = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "        R_vals_pl, R_vals_fam, R_vals_pl_fam = np.array([]), np.array([]), np.array([])\n",
    "        p_vals_pl, ps_fdr_pl, ps_bf_pl = np.array([]), np.array([]), np.array([])\n",
    "        p_vals_fam, ps_fdr_fam, ps_bf_fam = np.array([]), np.array([]), np.array([])\n",
    "        p_vals_pl_fam, ps_fdr_pl_fam, ps_bf_pl_fam = np.array([]), np.array([]), np.array([])\n",
    "\n",
    "        for su in odor_groups_3wgth:\n",
    "            #load similarity btw odors and distance pleasantness and familiarity\n",
    "            # ['tps', 'comb', 'pleas', 'fam', 'channels', 'labels', 'xyz']\n",
    "            mat0 = np.load(filename.format(su,cond,freq,sheet),allow_pickle=True)\n",
    "\n",
    "            #select electrodes\n",
    "            labels, channels = mat0['labels'], mat0['channels']\n",
    "            x, y, z = mat0['xyz'][:,0], mat0['xyz'][:,1], mat0['xyz'][:,2]\n",
    "            labels_new = rename_elecs(labels,x,y,z)\n",
    "            idx_sel = [i for i,lab in enumerate(labels_new) if lab in rois_sel]\n",
    "            nelecs = len(idx_sel)\n",
    "            print(su,nelecs,mat0['tps'].shape,mat0['channels'].shape)\n",
    "            labels, channels = labels_new[idx_sel], channels[idx_sel]\n",
    "            x, y, z = x[idx_sel], y[idx_sel], z[idx_sel]\n",
    "\n",
    "            tps_sim, pleas, fam = mat0['tps'], np.ravel(mat0['pleas']), np.ravel(mat0['fam'])\n",
    "            pl_fam, sc_pl, sc_fam = mat0['pl_fam'], mat0['pl_fam'], mat0['pl_fam']\n",
    "            print(su,freq,'pl',pleas.shape,'fam',fam.shape,'pl_fam',pl_fam.shape)\n",
    "\n",
    "            #compute stats // correlate distance btw odors\n",
    "            R_pl, unc_p_pl, R_fam, unc_p_fam = [], [], [], []\n",
    "            R_pl_fam, unc_pl_fam = [], []\n",
    "            for elec in range(nelecs):\n",
    "                R1, p1 = kendalltau(tps_sim[elec],pleas)\n",
    "                R3, p3 = kendalltau(tps_sim[elec],pl_fam)\n",
    "                R2, p2 = kendalltau(tps_sim[elec],fam)\n",
    "                R_pl.append(R1), unc_p_pl.append(p1)\n",
    "                R_fam.append(R2), unc_p_fam.append(p2)\n",
    "                R_pl_fam.append(R3), unc_pl_fam.append(p3)\n",
    "            _, p_fdr_pl = fdr_correction(unc_p_pl)\n",
    "            _, p_fdr_fam = fdr_correction(unc_p_fam)\n",
    "            _, p_fdr_pl_fam = fdr_correction(unc_pl_fam)\n",
    "            _, p_bf_pl = bonferroni_correction(unc_p_pl)\n",
    "            _, p_bf_fam = bonferroni_correction(unc_p_fam)\n",
    "            _, p_bf_pl_fam = bonferroni_correction(unc_pl_fam)\n",
    "\n",
    "            #Fill the csv file with elec infos and stats\n",
    "            subjects_c = np.hstack((subjects_c,np.array([su]*nelecs))) if np.size(subjects_c) else np.array([su]*nelecs)\n",
    "            elecs_c = np.hstack((elecs_c,np.arange(nelecs))) if np.size(elecs_c) else np.arange(nelecs)\n",
    "            labels_c = np.hstack((labels_c,labels)) if np.size(labels_c) else labels\n",
    "            channels_c = np.hstack((channels_c,channels)) if np.size(channels_c) else channels\n",
    "            x_c = np.hstack((x_c,x)) if np.size(x_c) else x\n",
    "            y_c = np.hstack((y_c,y)) if np.size(y_c) else y\n",
    "            z_c = np.hstack((z_c,z)) if np.size(z_c) else z\n",
    "\n",
    "            R_vals_pl = np.hstack((R_vals_pl,R_pl)) if np.size(R_vals_pl) else R_pl\n",
    "            R_vals_fam = np.hstack((R_vals_fam,R_fam)) if np.size(R_vals_fam) else R_fam\n",
    "            R_vals_pl_fam = np.hstack((R_vals_pl_fam,R_pl_fam)) if np.size(R_vals_pl_fam) else R_pl_fam\n",
    "\n",
    "            p_vals_pl = np.hstack((p_vals_pl,unc_p_pl)) if np.size(p_vals_pl) else unc_p_pl\n",
    "            p_vals_fam = np.hstack((p_vals_fam,unc_p_fam)) if np.size(p_vals_fam) else unc_p_fam\n",
    "            p_vals_pl_fam = np.hstack((p_vals_pl_fam,unc_pl_fam)) if np.size(p_vals_pl_fam) else unc_pl_fam\n",
    "\n",
    "            ps_fdr_pl = np.hstack((ps_fdr_pl,p_fdr_pl)) if np.size(ps_fdr_pl) else p_fdr_pl\n",
    "            ps_fdr_fam = np.hstack((ps_fdr_fam,p_fdr_fam)) if np.size(ps_fdr_fam) else p_fdr_fam\n",
    "            ps_fdr_pl_fam = np.hstack((ps_fdr_pl_fam,p_fdr_pl_fam)) if np.size(ps_fdr_pl_fam) else p_fdr_pl_fam\n",
    "\n",
    "            ps_bf_pl= np.hstack((ps_bf_pl,p_bf_pl)) if np.size(ps_bf_pl) else p_bf_pl\n",
    "            ps_bf_fam = np.hstack((ps_bf_fam,p_bf_fam)) if np.size(ps_bf_fam) else p_bf_fam\n",
    "            ps_bf_pl_fam = np.hstack((ps_bf_pl_fam,p_bf_pl_fam)) if np.size(ps_bf_pl_fam) else p_bf_pl_fam\n",
    "\n",
    "        data = np.concatenate((subjects_c[:,np.newaxis],labels_c[:,np.newaxis],\n",
    "                    channels_c[:,np.newaxis],x_c[:,np.newaxis],y_c[:,np.newaxis],\n",
    "                    z_c[:,np.newaxis],elecs_c[:,np.newaxis],\n",
    "                    R_vals_pl[:,np.newaxis],p_vals_pl[:,np.newaxis],ps_fdr_pl[:,np.newaxis],\n",
    "                               ps_bf_pl[:,np.newaxis],\n",
    "                    R_vals_fam[:,np.newaxis],p_vals_fam[:,np.newaxis],ps_fdr_fam[:,np.newaxis],\n",
    "                               ps_bf_fam[:,np.newaxis],\n",
    "                    R_vals_pl_fam[:,np.newaxis],p_vals_pl_fam[:,np.newaxis],ps_fdr_pl_fam[:,np.newaxis],\n",
    "                               ps_bf_pl_fam[:,np.newaxis]),axis=1)\n",
    "        df = pd.DataFrame(data, columns=['subjects','labels','channels','x','y','z','elecs_num',\n",
    "                    'R_pl','unc_pl','fdr_pl','bonf_pl','R_fam','unc_fam','fdr_fam','bonf_fam',\n",
    "                    'R_pl_fam','unc_pl_fam','fdr_pl_fam','bonf_pl_fam'])\n",
    "        print(df.shape)\n",
    "        df.to_csv(df_name.format('All_subjects','pleas_fam',freq,sheet),index=False)           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summarize stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from brainpipe.system import study\n",
    "from collections import Counter\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "st = study('Olfacto')\n",
    "fold, freq, sheet = 'Enc', 'theta', 'Final'\n",
    "olf_regions = ['Amg','pPirT','OFC_olf','Ins_olf']\n",
    "# cond = 'high'\n",
    "path_file = path.join(st.path, \n",
    "                  'feature/TPSim_3groups_'+fold+'/similarity_matrix_btw_v=1_elecs=all/')\n",
    "df_name = path.join(path_file, \n",
    "                'All_subjects_correl_rdm_pleas_fam_'+freq+'_mean=False_'+sheet+'.csv') #su, conds0, conds1, freq\n",
    "df_save = path.join(path_file, \n",
    "                'All_subjects_correl_{}_{}_'+freq+'_'+sheet+'_mean=False_{}.csv')\n",
    "\n",
    "thrs = [0.05]\n",
    "corrections = ['fdr_']#['fdr_','bonf_']\n",
    "dims = ['pl','fam']\n",
    "# dims = ['pl_fam']\n",
    "\n",
    "df_init = pd.read_csv(df_name)\n",
    "print('Initial df shape', df_init.shape,df_init.columns)\n",
    "\n",
    "for th, dim, corr in product(thrs,dims,corrections):\n",
    "    df_sel = df_init.loc[df_init[corr+dim]<th]\n",
    "    df_sel['sign'] = ['similar' if t > 0 else 'different' for t in df_sel['R_'+dim]]\n",
    "    print('\\n stats at p < ',th, 'correction : ',corr, df_sel.shape, 'for dimension',dim)\n",
    "    print(Counter(df_sel['labels']))\n",
    "\n",
    "    rois = np.unique(df_sel['labels'])\n",
    "    for roi in rois:\n",
    "        df_roi = df_sel.loc[df_sel['labels']==roi]\n",
    "        df_inc = df_roi.loc[df_roi['sign']=='different'].groupby(['subjects']).count()\n",
    "        df_dec = df_roi.loc[df_roi['sign']=='similar'].groupby(['subjects']).count()\n",
    "#         if roi in ['pPirT','Amg']:\n",
    "#             print(df_roi)\n",
    "        if (df_dec.shape[0] >= 3) or (df_dec.shape[0] >=2 and roi in olf_regions): # we only consider positive correlations\n",
    "            print(roi, 'NB of subjects with SIMILAR',df_dec.shape[0],' subjects')\n",
    "            df_plot = df_roi.loc[df_roi['sign']=='similar']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "#             df_plot.to_csv(df_save.format(roi,corr+str(th),dim,cond))\n",
    "            print(df_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VACJ    aHC  b'3-b'2 -23.85 -21.0 -11.80          4  0.148549   \n",
    "173     LEFC    aHC    b3-b2  34.55 -20.3 -10.85          2  0.096729   \n",
    "207     FERJ    aHC  b'4-b'3 -30.45 -17.2 -13.40          9  0.097063   \n",
    "212     FERJ    aHC    d4-d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainpipe.system import study\n",
    "from collections import Counter\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "st = study('Olfacto')\n",
    "fold, freq, sheet = 'Enc', 'theta', 'Final'\n",
    "# cond = 'high'\n",
    "path_file = path.join(st.path, \n",
    "                  'feature/TPSim_3groups_'+fold+'/similarity_matrix_btw_v=1_elecs=all/')\n",
    "df_name = path.join(path_file, \n",
    "                'All_subjects_correl_rdm_pleas_fam_'+freq+'_mean=False_'+sheet+'.csv') #su, conds0, conds1, freq\n",
    "df_save = path.join(path_file, \n",
    "                'All_subjects_correl_{}_{}_{}_'+freq+'_'+sheet+'_mean=False_{}.csv')\n",
    "\n",
    "thrs = [0.05]\n",
    "corrections = ['fdr_']#['fdr_','bonf_']\n",
    "dims = ['fam','pl','pl_fam']\n",
    "rois = ['aHC','OFC_olf']\n",
    "olf_regions = ['OFC_olf']\n",
    "\n",
    "df_init = pd.read_csv(df_name)\n",
    "print('Initial df shape', df_init.shape,df_init.columns)\n",
    "\n",
    "for th, dim, corr in product(thrs,dims,corrections):\n",
    "    for roi in rois:\n",
    "        df_roi = df_init.loc[df_init['labels']==roi]\n",
    "        pvals = [p if not math.isnan(p) else 1 for p in df_roi['unc_'+dim].values]\n",
    "        df_roi['new_pvalues'] = fdr_correction(pvals)[1]\n",
    "#         print(df_roi[['subjects','labels','channels','R_fam',\n",
    "#                      'unc_fam', 'fdr_fam', 'new_pvalues']].loc[df_roi['unc_fam']<th])\n",
    "        df_sel = df_roi.loc[df_roi['new_pvalues']<th]\n",
    "        df_sel['sign'] = ['similar' if t > 0 else 'different' for t in df_sel['R_'+dim]]\n",
    "        print('\\n stats at p < ',th, 'correction : ',corr, df_sel.shape, 'for dimension',dim)\n",
    "        print(Counter(df_sel['labels']))\n",
    "\n",
    "        df_dec = df_sel.loc[df_sel['sign']=='similar'].groupby(['subjects']).count()\n",
    "        if (df_dec.shape[0] >= 3) or (df_dec.shape[0] >=2 and roi in olf_regions):\n",
    "            print(roi, 'NB of subjects with SIMILAR',df_dec.shape[0],' subjects')\n",
    "            df_plot = df_sel.loc[df_sel['sign']=='similar']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "#             df_plot.to_csv(df_save.format(roi,corr+str(th),cond,dim))\n",
    "            print(df_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "//// PLEASANTNESS + FAMILIARITY ////\n",
    "Final OFC (2 patients 3 elecs)\n",
    "Final avg OFC (3 patients 5 elecs) + MFG (3 patients 4 elecs)\n",
    "\n",
    "//// FAMILIARITY ////\n",
    "Final OFC (2P,3elecs), MFG (3P, 5elecs)\n",
    "Final avg MFG (3P,6elecs), OFC (2P 2elecs 2 sens), aHC (3P,4elecs)\n",
    "\n",
    "//// PLEASANTNESS ////\n",
    "Final OFC (3P, 4elecs)\n",
    "Final avg OFC (3P, 4elecs)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from brainpipe.system import study\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "st = study('Olfacto')\n",
    "PATH = '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "filename = 'Recap_Odeurs_Evaluations.xlsx'\n",
    "PATH_SAVE = join(st.path, 'feature/TPSim_3groups_Enc/similarity_matrix_btw/')\n",
    "savename = 'dist_pl_fam_all_odors_pleas.npz'\n",
    "\n",
    "df = pd.read_excel(PATH+filename, sheet_name='Final')\n",
    "odors = df[['od_num']].values[:,0]\n",
    "#odors = [14,10,3,8,13,6,12,9,1,18,4,15,5,17,11,2,16,7] #ordered by Fam\n",
    "odors = [10,1,12,3,9,13,6,5,8,14,16,4,18,11,15,7,2,17] #ordered by Pleas\n",
    "#odors = [10,3,9,1,13,12,6,14,8,5,4,18,16,15,7,2,11,17] #fam * pleas\n",
    "#odors = [10,3,9,13,1,6,12,14,8,5,4,18,16,15,7,2,11,17] #fam + pleas\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "dist_f, dist_p, dist_fp = [], [], []\n",
    "for o1,o2 in combinations(odors,2):\n",
    "    f1 = df.loc[df['od_num']=='O'+str(o1)]['Familiarity'].values\n",
    "    f2 = df.loc[df['od_num']=='O'+str(o2)]['Familiarity'].values\n",
    "    p1 = df.loc[df['od_num']=='O'+str(o1)]['Pleasantness'].values\n",
    "    p2 = df.loc[df['od_num']=='O'+str(o2)]['Pleasantness'].values\n",
    "    fp1, fp2 = np.array([f1,p1]), np.array([f2,p2])\n",
    "    dist_f.append(np.round(np.linalg.norm(f1-f2),2))\n",
    "    dist_p.append(np.round(np.linalg.norm(p1-p2),2))\n",
    "    dist_fp.append(np.round(np.linalg.norm(fp1-fp2),2))\n",
    "print(len(dist_f))\n",
    "np.savez(PATH_SAVE+savename,d_f=np.array(dist_f),d_p=np.array(dist_p),\n",
    "        d_fp=np.array(dist_fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot odors RDM matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import cm\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.manifold import MDS\n",
    "\"\"\"\n",
    "Plot TPSim matrices (RDM) for all odors (Familiarity Pleasantness, both)\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_npz = join(st.path,'feature/TPSim_3groups_Enc/')\n",
    "path_pow = join(path_npz, 'similarity_matrix_btw/dist_pl_fam_all_odors_pleas.npz')\n",
    "savename = join(path_npz, 'distance_graphs/Plot_distance_{}_all_odors_pleas.png')\n",
    "###############################################################################\n",
    "exp = 'Enc' #Ret, Enc\n",
    "###############################################################################\n",
    "new_order = [10,1,12,3,9,13,6,5,8,14,16,4,18,11,15,7,2,17] #Pleas order\n",
    "#new_order = [10,3,9,1,13,12,6,14,8,5,4,18,16,15,7,2,11,17] #fam * pleas\n",
    "#new_order = [10,3,9,13,1,6,12,14,8,5,4,18,16,15,7,2,11,17] #fam + pleas\n",
    "#new_order = [14,10,3,8,13,6,12,9,1,18,4,15,5,17,11,2,16,7] #Fam order\n",
    "mat = np.load(path_pow)\n",
    "features = mat.files\n",
    "\n",
    "for feat in features:\n",
    "    combs = mat[feat]\n",
    "    n_od = 18\n",
    "    idx = list(np.arange(1,n_od+1))\n",
    "    tri = np.zeros((n_od, n_od))\n",
    "    tri[np.triu_indices(n_od,1)] = combs\n",
    "    tri[np.tril_indices(n_od, -1)] = tri.T[np.tril_indices(n_od, -1)]\n",
    "\n",
    "    model = MDS(n_components=2, dissimilarity='precomputed', random_state=1)\n",
    "    out = model.fit_transform(tri)\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(8,3))\n",
    "    colors = 'black'\n",
    "    markers = 'o'\n",
    "\n",
    "    for i, txt in enumerate(idx):\n",
    "        ax1.scatter(out[i,0], out[i,1], c=colors, marker=markers)\n",
    "        ax1.annotate('O'+str(txt), (out[i,0], out[i,1]))\n",
    "    ax1.set_xlabel('component 1')\n",
    "    ax1.set_ylabel('component 2')\n",
    "    #ax1.axis('equal')\n",
    "        \n",
    "    #subplot #1 Graph 2D \n",
    "    cmap = cm.get_cmap('jet', 30)\n",
    "    cax = ax2.imshow(tri, vmin=0,interpolation=\"none\", cmap=cmap)\n",
    "    ax2.set_xticks(np.arange(n_od))\n",
    "    ax2.set_yticks(np.arange(n_od))\n",
    "    ax2.set_xticklabels(new_order,fontsize=11)\n",
    "    ax2.set_yticklabels(new_order,fontsize=11)\n",
    "    plt.colorbar(cax)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    title = 'Distance btw odors in {} domaine )'.format(feat)\n",
    "    fig.suptitle(title, fontsize=12)\n",
    "    \n",
    "    plt.savefig(savename.format(feat))\n",
    "    plt.savefig(savename.format(feat).replace('.png','.pdf'))\n",
    "    plt.clf()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "filename = 'Recap_Odeurs_Evaluations.xlsx'\n",
    "PATH_SAVE = join(st.path, 'feature/TPSim_3groups_Enc/distance_graphs/')\n",
    "savename = 'Correl_Fam_Pleas.png'\n",
    "\n",
    "df = pd.read_excel(PATH+filename, sheet_name='Final')\n",
    "pleas = df[['Pleasantness']]\n",
    "fam = df[['Familiarity']]\n",
    "R,p = pearsonr(pleas.values[:,0],fam.values[:,0])\n",
    "print(R,p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
