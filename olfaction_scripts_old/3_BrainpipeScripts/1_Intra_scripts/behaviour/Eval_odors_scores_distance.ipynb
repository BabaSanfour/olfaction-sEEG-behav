{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load Lucile evaluation data and average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### import numpy as np\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "#MICP is not included (only his memory perf can be used, no RT data)\n",
    "PATH = '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "df_name = join(PATH,'EvalsOdeurs_Lucile.xlsx')\n",
    "df_od_AL = join(PATH, 'Recap_Odeurs_Evaluations.xlsx')\n",
    "df_save = join(PATH, 'Eval_Odors_avg.csv')\n",
    "\n",
    "studies = ['Etude1.1','Etude1.2','Etude2']\n",
    "col_sel = ['PARTICIPANT','Stimulus','hedo_scaled','fam_scaled','emo_scaled']\n",
    "\n",
    "df_tot = pd.DataFrame([])\n",
    "for stud in studies:\n",
    "    df = pd.read_excel(df_name,sheet_name=stud)\n",
    "    df_sel = df[col_sel].dropna()\n",
    "    df_tot = df_tot.append(df_sel)\n",
    "df_tot.to_csv(df_save, columns=col_sel)\n",
    "#get a consistent odor name\n",
    "df_tot = df_tot.replace('Basilic Comores', 'Basilic comores')\n",
    "df_tot = df_tot.replace('Acétate Linalyle', 'Acétate linalyle')\n",
    "\n",
    "df_su = df_tot.groupby(['Stimulus']).agg({'PARTICIPANT' : 'count', 'hedo_scaled':np.mean,\n",
    "                                         'fam_scaled':'mean', 'emo_scaled':'mean'})\n",
    "print(df_su)\n",
    "print('#number of participants in total',len(np.unique(df_tot[['PARTICIPANT']])))\n",
    "print('>>> average nb of participants', np.mean(df_su[['PARTICIPANT']].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "A = [2.67,6.32,2.86,4.76,3.82,3.73,5.86,4.00,2.86,2.62,5.19,2.80,3.38,4.27,5.83,4.66,6.43,4.96]\n",
    "B = [4.91,5.64,4.54,4.62,5.2,4.19237472766885,5.91401597676108,4.9,4.58,4.67,7.66,5.25,4.18,4.48,4.84684095860566,5.73,6.78,4.47671194839592,]\n",
    "R,p = pearsonr(A,B)\n",
    "print(R,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def tpsim_btw_2odors(pow_o1,pow_o2,stat='pearson',average=True):\n",
    "    \"\"\"\n",
    "    Compute tpsim between 2 odors \n",
    "    Parameters\n",
    "    ----------\n",
    "    pow_o1, pow_o2 : array (npts x ntrials)\n",
    "    stat : string\n",
    "            The stat correlation method to use. 'pearson' or 'spearman'\n",
    "    Returns\n",
    "    -------\n",
    "    tpsim : array (Average TPSim between 2 ODORS)\n",
    "    \"\"\"\n",
    "    \n",
    "    corr = stats.pearsonr if stat == 'pearson' else stats.spearmanr\n",
    "    sim_trials = np.array([])\n",
    "    ncombs = len([a for a,_ in product(range(pow_o1.shape[-1]),range(pow_o2.shape[-1]))])\n",
    "    for t0, t1 in product(range(pow_o1.shape[-1]),range(pow_o2.shape[-1])):\n",
    "        R, _ = corr(pow_o1[:,t0],pow_o2[:,t1])\n",
    "        sim_trials = np.vstack((sim_trials,1-R)) if np.size(sim_trials) else np.array(1-R)\n",
    "    if ncombs == 1:\n",
    "        sim_trials = np.array(sim_trials)[np.newaxis][np.newaxis]\n",
    "    if average == True:\n",
    "        sim_trials = np.mean(sim_trials)\n",
    "    return sim_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from brainpipe.system import study\n",
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "import pandas as pd\n",
    "from itertools import product, combinations\n",
    "import numpy as np\n",
    "from utils import odor_su_score\n",
    "\"\"\"\n",
    "Compute similarity btw all odors by subject for all electrodes\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_pow = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_odor_all_elecsFT/')\n",
    "pow_path = join(path_pow, '{}_odor_{}_bipo_all_{}_6freqs_EL.npz')\n",
    "path2save = join(st.path, 'feature/TPSim_3groups_{}/similarity_matrix_btw_v=1_elecs=all_early_late/')\n",
    "tps_save = join(path2save, 'TPS_{}_{}_{}_btw_odors_mean={}_sheet_{}_late.npz')\n",
    "\n",
    "PATH = '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "df_od_avg = join(PATH, 'Recap_Odeurs_Evaluations.xlsx')\n",
    "###############################################################################\n",
    "exp, mean = 'Enc', False#Ret, Enc\n",
    "stat = 'pearson'\n",
    "shortcut = ['E','R'] if exp == 'Enc_Ret' else [exp[0],exp[0]]\n",
    "if not exists(path2save.format(exp)):\n",
    "    makedirs(path2save.format(exp))\n",
    "###############################################################################\n",
    "freqs, f_id = ['theta'], 1\n",
    "odors_su = {'CHAF': [1,2,4,5,3,8,7,9], #low than high\n",
    "            'LEFC': [15,2,1,16,14,3,4,17],\n",
    "            'PIRJ': [1,9,5,4,6,7,18], #missing odor 15\n",
    "            'VACJ': [11,14,12,10,15,17,16,13],\n",
    "            'SEMC': [7,10,11,12,13,5,8,9],\n",
    "            'FERJ': [7,2,16,17,12,1,5,13]}\n",
    "\n",
    "sheet = 'Final' #,'Final_Lucile','Final_avg']\n",
    "#Final (just 2 odors added from Lucile) Final Lucile (all data available from Lucile taken)\n",
    "#Final avg (Lucile's and my data are averaged when possible)\n",
    "col_sel = ['od_num','odors','Pleasantness','Familiarity']\n",
    "dims = ['Pleasantness','Familiarity']\n",
    "\n",
    "df = pd.read_excel(df_od_avg,sheet_name=sheet)\n",
    "\n",
    "for su,freq in product(odors_su,freqs):\n",
    "    ncomb = len([o1+o2 for o1,o2 in combinations(odors_su[su],2)])\n",
    "    mat_ = np.load(pow_path.format(su,str(odors_su[su][0]),shortcut[0]),allow_pickle=True)\n",
    "    chans, labels, xyz = mat_['channels'], mat_['labels'], mat_['xyz']\n",
    "    nelecs = len(chans)\n",
    "    tps_list = np.array([])\n",
    "    print(ncomb,nelecs)\n",
    "    list_comb, dist_pleas, dist_fam = np.array([]),np.array([]),np.array([])\n",
    "    dist_pleas_fam, dist_sc_pl, dist_sc_fam = np.array([]), np.array([]), np.array([])\n",
    "    \n",
    "    for o1, o2 in combinations(odors_su[su],2):\n",
    "        mat_o1 = np.load(pow_path.format(su,str(o1),shortcut[0]))\n",
    "        mat_o2 = np.load(pow_path.format(su,str(o2),shortcut[1]))\n",
    "        if (mat_o1['xpow_L'].shape[0] > 0) & (mat_o2['xpow_L'].shape[0] > 0):\n",
    "            pow_o1 = mat_o1['xpow_L'][f_id,:,17:47,:] #nelecs,npts,ntrials\n",
    "            pow_o2 = mat_o2['xpow_L'][f_id,:,17:47,:] #nelecs,npts,ntrials\n",
    "            nvals = len([a for a,b in product(range(pow_o1.shape[-1]), range(pow_o2.shape[-1]))])\n",
    "            pleas_o1 = df.loc[df['od_num']=='O'+str(o1)].iloc[:,2].values\n",
    "            fam_o1 = df.loc[df['od_num']=='O'+str(o1)].iloc[:,3].values\n",
    "            pleas_o2 = df.loc[df['od_num']=='O'+str(o2)].iloc[:,2].values\n",
    "            fam_o2 = df.loc[df['od_num']=='O'+str(o2)].iloc[:,3].values\n",
    "            sc_o1, sc_o2 = [odor_su_score[su][o1]], [odor_su_score[su][o2]]\n",
    "            a, b = np.array([pleas_o1,fam_o1]), np.array([pleas_o2,fam_o2])\n",
    "            c, d = np.array([pleas_o1,fam_o1,sc_o1]), np.array([pleas_o2,fam_o2,sc_o2])\n",
    "            e, f = np.array([fam_o1,sc_o1]), np.array([fam_o2,sc_o2])\n",
    "            dist_pl = np.round(np.linalg.norm(pleas_o1-pleas_o2),2)\n",
    "            dist_pl_fam = np.round(np.linalg.norm(a-b),2)\n",
    "            dist_f = np.round(np.linalg.norm(fam_o1-fam_o2),2)\n",
    "            dist_score_pl = np.round(np.linalg.norm(c-d),2)\n",
    "            dist_score_fam = np.round(np.linalg.norm(e-f),2)\n",
    "\n",
    "            if mean == False:\n",
    "                list_comb = np.hstack((list_comb,[str(o1)+'_'+str(o2)]*nvals)) if np.size(list_comb) else [str(o1)+'_'+str(o2)]*nvals\n",
    "                dist_pleas = np.hstack((dist_pleas,[dist_pl]*nvals)) if np.size(dist_pleas) else [dist_pl]*nvals \n",
    "                dist_pleas_fam = np.hstack((dist_pleas_fam,[dist_pl_fam]*nvals)) if np.size(dist_pleas_fam) else [dist_pl_fam]*nvals \n",
    "                dist_fam = np.hstack((dist_fam,[dist_f]*nvals)) if np.size(dist_fam) else [dist_f]*nvals\n",
    "                dist_sc_pl = np.hstack((dist_sc_pl,[dist_score_pl]*nvals)) if np.size(dist_sc_pl) else [dist_score_pl]*nvals\n",
    "                dist_sc_fam = np.hstack((dist_sc_fam,[dist_score_fam]*nvals)) if np.size(dist_sc_fam) else [dist_score_fam]*nvals\n",
    "            else: \n",
    "                dist_pleas = np.hstack((dist_pleas,dist_pl)) if np.size(dist_pleas) else dist_pl\n",
    "                dist_fam = np.hstack((dist_fam,dist_f)) if np.size(dist_fam) else dist_f\n",
    "                list_comb = np.hstack((list_comb,str(o1)+'_'+str(o2))) if np.size(list_comb) else str(o1)+'_'+str(o2)\n",
    "        \n",
    "            od_tps = np.array([])   \n",
    "            for elec in range(nelecs):\n",
    "                tps_ = tpsim_btw_2odors(pow_o1[elec],pow_o2[elec],\n",
    "                                                    stat=stat,average=mean).swapaxes(0,1)\n",
    "                od_tps = np.concatenate((od_tps,tps_),axis=0) if np.size(od_tps) else tps_\n",
    "            tps_list = np.concatenate((tps_list,od_tps),axis=1) if np.size(tps_list) else od_tps\n",
    "    print(tps_list.shape,list_comb.shape,dist_fam.shape,dist_pleas.shape,dist_sc_pl.shape)\n",
    "    np.savez(tps_save.format(exp,stat,su,freq,mean,sheet),tps=tps_list,comb=list_comb,pleas=dist_pleas,\n",
    "                fam=dist_fam,channels=chans,labels=labels, xyz=xyz,pl_fam=dist_pleas_fam,\n",
    "            sc_pl=dist_sc_pl, sc_fam= dist_sc_fam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from brainpipe.system import study\n",
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from utils import odor_groups_3wgth\n",
    "\"\"\"\n",
    "Compute similarity btw LOW and HIGH MEM GROUPS by subject for all electrodes\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_pow = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_odor_all_elecsFT/')\n",
    "pow_path = join(path_pow, '{}_odor_{}_bipo_all_{}_6freqs.npz')\n",
    "path2save = join(st.path, 'feature/TPSim_3groups_{}/similarity_matrix_btw_v=1_elecs=all/')\n",
    "tps_save = join(path2save, 'TPS_{}_{}_{}_{}_btw_odors_mean={}_sheet_{}.npz')\n",
    "\n",
    "PATH = '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "df_od_avg = join(PATH, 'Recap_Odeurs_Evaluations.xlsx')\n",
    "###############################################################################\n",
    "exp, mean = 'Enc', False#Ret, Enc\n",
    "stat = 'pearson'\n",
    "shortcut = ['E','R'] if exp == 'Enc_Ret' else [exp[0],exp[0]]\n",
    "if not exists(path2save.format(exp)):\n",
    "    makedirs(path2save.format(exp))\n",
    "###############################################################################\n",
    "freqs, f = ['theta'], 1\n",
    "sheet = 'Final_Lucile' #,'Final_Lucile','Final_avg']\n",
    "#Final (just 2 odors added from Lucile) Final Lucile (all data available from Lucile taken)\n",
    "#Final avg (Lucile's and my data are averaged when possible)\n",
    "col_sel = ['od_num','odors','Pleasantness','Familiarity']\n",
    "conds = ['low','mid','high']\n",
    "dims = ['Pleasantness','Familiarity']\n",
    "\n",
    "df = pd.read_excel(df_od_avg,sheet_name=sheet)\n",
    "\n",
    "for su,freq in product(odor_groups_3wgth,freqs):\n",
    "    for cond in conds:\n",
    "        for od in odor_groups_3wgth[su][cond]:\n",
    "            print(su,cond,od)\n",
    "            ncomb = len([o1+o2 for o1,o2 in combinations(odors_su[su],2)])\n",
    "            mat_ = np.load(pow_path.format(su,str(odors_su[su][0]),shortcut[0]),allow_pickle=True)\n",
    "            chans, labels, xyz = mat_['channels'], mat_['labels'], mat_['xyz']\n",
    "            nelecs = len(chans)\n",
    "            tps_list = np.array([])\n",
    "            print(ncomb,nelecs)\n",
    "            list_comb, dist_pleas, dist_fam = np.array([]),np.array([]),np.array([])\n",
    "            dist_pleas_fam = np.array([])\n",
    "    \n",
    "            for o1, o2 in combinations(odor_groups_3wgth[su][cond],2):\n",
    "                mat_o1 = np.load(pow_path.format(su,str(o1),shortcut[0]))\n",
    "                pow_o1 = mat_o1['xpow'][f,:,17:47,:] #nelecs,npts,ntrials\n",
    "                mat_o2 = np.load(pow_path.format(su,str(o2),shortcut[1]))\n",
    "                pow_o2 = mat_o2['xpow'][f,:,17:47,:] #nelecs,npts,ntrials\n",
    "                nvals = len([a for a,b in product(range(pow_o1.shape[-1]), range(pow_o2.shape[-1]))])\n",
    "                print(pow_o1.shape, pow_o2.shape)\n",
    "                pleas_o1 = df.loc[df['od_num']=='O'+str(o1)].iloc[:,2].values\n",
    "                fam_o1 = df.loc[df['od_num']=='O'+str(o1)].iloc[:,3].values\n",
    "                pleas_o2 = df.loc[df['od_num']=='O'+str(o2)].iloc[:,2].values\n",
    "                fam_o2 = df.loc[df['od_num']=='O'+str(o2)].iloc[:,3].values\n",
    "                a, b = np.array([pleas_o1,fam_o1]), np.array([pleas_o2,fam_o2])\n",
    "                dist_pl = np.round(np.linalg.norm(pleas_o1-pleas_o2),2)\n",
    "                dist_pl_fam = np.round(np.linalg.norm(a-b),2)\n",
    "                dist_f = np.round(np.linalg.norm(fam_o1-fam_o2),2)\n",
    "\n",
    "                if mean == False:\n",
    "                    list_comb = np.hstack((list_comb,[str(o1)+'_'+str(o2)]*nvals)) if np.size(list_comb) else np.array([str(o1)+'_'+str(o2)]*nvals)\n",
    "                    dist_pleas = np.hstack((dist_pleas,[dist_pl]*nvals)) if np.size(dist_pleas) else np.array([dist_pl]*nvals )\n",
    "                    dist_pleas_fam = np.hstack((dist_pleas_fam,[dist_pl_fam]*nvals)) if np.size(dist_pleas_fam) else np.array([dist_pl_fam]*nvals )\n",
    "                    dist_fam = np.hstack((dist_fam,[dist_f]*nvals)) if np.size(dist_fam) else np.array([dist_f]*nvals)\n",
    "                else: \n",
    "                    dist_pleas = np.hstack((dist_pleas,dist_pl)) if np.size(dist_pleas) else dist_pl\n",
    "                    dist_fam = np.hstack((dist_fam,dist_f)) if np.size(dist_fam) else dist_f\n",
    "                    list_comb = np.hstack((list_comb,str(o1)+'_'+str(o2))) if np.size(list_comb) else str(o1)+'_'+str(o2)\n",
    "\n",
    "                od_tps = np.array([])   \n",
    "                for elec in range(nelecs):\n",
    "                    tps_ = tpsim_btw_2odors(pow_o1[elec],pow_o2[elec],\n",
    "                                                        stat=stat,average=mean).swapaxes(0,1)\n",
    "                    od_tps = np.concatenate((od_tps,tps_),axis=0) if np.size(od_tps) else tps_\n",
    "                tps_list = np.concatenate((tps_list,od_tps),axis=1) if np.size(tps_list) else od_tps\n",
    "            print(tps_list.shape,list_comb.shape,dist_fam.shape,dist_pleas.shape)\n",
    "            np.savez(tps_save.format(exp,stat,su,cond,freq,mean,sheet),tps=tps_list,comb=list_comb,pleas=dist_pleas,\n",
    "                        fam=dist_fam,channels=chans,labels=labels, xyz=xyz,pl_fam=dist_pleas_fam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlate TPSim and odor characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import odor_groups_3wgth, rename_elecs\n",
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "from scipy.stats import pearsonr, kendalltau\n",
    "from mne.stats import bonferroni_correction, fdr_correction\n",
    "\n",
    "st = study('Olfacto')\n",
    "exp = 'Enc'#'Enc'\n",
    "freqs = ['theta'] #freqname in filename\n",
    "path_pow = join(st.path, 'feature/TPSim_3groups_'+exp+ \\\n",
    "                        '/similarity_matrix_btw_v=1_elecs=all_early_late/')\n",
    "filename = join(path_pow, 'TPS_pearson_{}_{}_btw_odors_mean=False_sheet_{}_late.npz')\n",
    "df_name = join(path_pow, '{}_correl_rdm_{}_{}_mean=False_{}_L.csv') #su, conds0, conds1, freq\n",
    "rois_sel = ['aHC','MFG','ACC','IFG','Amg','pPirT','PHG','Ins_olf','OFC_olf','SFG']\n",
    "sheets = ['Final']\n",
    "# cond = 'high'\n",
    "\n",
    "for sheet in sheets:\n",
    "    for freq in freqs:\n",
    "        subjects_c, elecs_c, labels_c = np.array([]), np.array([]), np.array([])\n",
    "        channels_c, x_c, y_c, z_c = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "        R_vals_pl, R_vals_fam, R_vals_pl_fam = np.array([]), np.array([]), np.array([])\n",
    "        R_vals_sc_pl, R_vals_sc_fam = np.array([]), np.array([])\n",
    "        p_vals_pl, ps_fdr_pl, ps_bf_pl = np.array([]), np.array([]), np.array([])\n",
    "        p_vals_fam, ps_fdr_fam, ps_bf_fam = np.array([]), np.array([]), np.array([])\n",
    "        p_vals_pl_fam, ps_fdr_pl_fam, ps_bf_pl_fam = np.array([]), np.array([]), np.array([])\n",
    "        p_vals_sc_pl, ps_fdr_sc_pl, ps_bf_sc_pl = np.array([]), np.array([]), np.array([])\n",
    "        p_vals_sc_fam, ps_fdr_sc_fam, ps_bf_sc_fam = np.array([]), np.array([]), np.array([])\n",
    "\n",
    "        for su in odor_groups_3wgth:\n",
    "            #load similarity btw odors and distance pleasantness and familiarity\n",
    "            # ['tps', 'comb', 'pleas', 'fam', 'channels', 'labels', 'xyz']\n",
    "            mat0 = np.load(filename.format(su,freq,sheet),allow_pickle=True)\n",
    "\n",
    "            #select electrodes\n",
    "            labels, channels = mat0['labels'], mat0['channels']\n",
    "            x, y, z = mat0['xyz'][:,0], mat0['xyz'][:,1], mat0['xyz'][:,2]\n",
    "            labels_new = rename_elecs(labels,x,y,z)\n",
    "            idx_sel = [i for i,lab in enumerate(labels_new) if lab in rois_sel]\n",
    "            nelecs = len(idx_sel)\n",
    "            print(su,nelecs,mat0['tps'].shape,mat0['channels'].shape)\n",
    "            labels, channels = labels_new[idx_sel], channels[idx_sel]\n",
    "            x, y, z = x[idx_sel], y[idx_sel], z[idx_sel]\n",
    "\n",
    "            tps_sim, pleas, fam = mat0['tps'], np.ravel(mat0['pleas']), np.ravel(mat0['fam'])\n",
    "            pl_fam, sc_pl, sc_fam = mat0['pl_fam'], mat0['sc_pl'], mat0['sc_fam']\n",
    "            print(su,freq,'pl',pleas.shape,'fam',fam.shape,'pl_fam',pl_fam.shape)\n",
    "\n",
    "            #compute stats // correlate distance btw odors\n",
    "            R_pl, unc_p_pl, R_fam, unc_p_fam = [], [], [], []\n",
    "            R_pl_fam, unc_pl_fam = [], []\n",
    "            R_sc_pl, unc_sc_pl, R_sc_fam, unc_sc_fam = [], [],[], []\n",
    "            for elec in range(nelecs):\n",
    "                R1, p1 = kendalltau(tps_sim[elec],pleas)\n",
    "                R3, p3 = kendalltau(tps_sim[elec],pl_fam)\n",
    "                R2, p2 = kendalltau(tps_sim[elec],fam)\n",
    "                R4, p4 = kendalltau(tps_sim[elec],sc_pl)\n",
    "                R5, p5 = kendalltau(tps_sim[elec],sc_fam)\n",
    "                R_pl.append(R1), unc_p_pl.append(p1)\n",
    "                R_fam.append(R2), unc_p_fam.append(p2)\n",
    "                R_pl_fam.append(R3), unc_pl_fam.append(p3)\n",
    "                R_sc_pl.append(R4), unc_sc_pl.append(p4)\n",
    "                R_sc_fam.append(R5), unc_sc_fam.append(p5)\n",
    "            _, p_fdr_pl = fdr_correction(unc_p_pl)\n",
    "            _, p_fdr_fam = fdr_correction(unc_p_fam)\n",
    "            _, p_fdr_pl_fam = fdr_correction(unc_pl_fam)\n",
    "            _, p_fdr_sc_pl = fdr_correction(unc_sc_pl)\n",
    "            _, p_fdr_sc_fam = fdr_correction(unc_sc_fam)\n",
    "            \n",
    "            _, p_bf_pl = bonferroni_correction(unc_p_pl)\n",
    "            _, p_bf_fam = bonferroni_correction(unc_p_fam)\n",
    "            _, p_bf_pl_fam = bonferroni_correction(unc_pl_fam)\n",
    "            _, p_bf_sc_fam = bonferroni_correction(unc_sc_fam)\n",
    "            _, p_bf_sc_pl = bonferroni_correction(unc_sc_pl)\n",
    "\n",
    "            #Fill the csv file with elec infos and stats\n",
    "            subjects_c = np.hstack((subjects_c,np.array([su]*nelecs))) if np.size(subjects_c) else np.array([su]*nelecs)\n",
    "            elecs_c = np.hstack((elecs_c,np.arange(nelecs))) if np.size(elecs_c) else np.arange(nelecs)\n",
    "            labels_c = np.hstack((labels_c,labels)) if np.size(labels_c) else labels\n",
    "            channels_c = np.hstack((channels_c,channels)) if np.size(channels_c) else channels\n",
    "            x_c = np.hstack((x_c,x)) if np.size(x_c) else x\n",
    "            y_c = np.hstack((y_c,y)) if np.size(y_c) else y\n",
    "            z_c = np.hstack((z_c,z)) if np.size(z_c) else z\n",
    "\n",
    "            R_vals_pl = np.hstack((R_vals_pl,R_pl)) if np.size(R_vals_pl) else R_pl\n",
    "            R_vals_fam = np.hstack((R_vals_fam,R_fam)) if np.size(R_vals_fam) else R_fam\n",
    "            R_vals_pl_fam = np.hstack((R_vals_pl_fam,R_pl_fam)) if np.size(R_vals_pl_fam) else R_pl_fam\n",
    "            R_vals_sc_fam = np.hstack((R_vals_sc_fam,R_sc_fam)) if np.size(R_vals_sc_fam) else R_sc_fam\n",
    "            R_vals_sc_pl = np.hstack((R_vals_sc_pl,R_sc_pl)) if np.size(R_vals_sc_pl) else R_sc_pl\n",
    "\n",
    "            p_vals_pl = np.hstack((p_vals_pl,unc_p_pl)) if np.size(p_vals_pl) else unc_p_pl\n",
    "            p_vals_fam = np.hstack((p_vals_fam,unc_p_fam)) if np.size(p_vals_fam) else unc_p_fam\n",
    "            p_vals_pl_fam = np.hstack((p_vals_pl_fam,unc_pl_fam)) if np.size(p_vals_pl_fam) else unc_pl_fam\n",
    "            p_vals_sc_fam = np.hstack((p_vals_sc_fam,unc_sc_fam)) if np.size(p_vals_sc_fam) else unc_sc_fam\n",
    "            p_vals_sc_pl = np.hstack((p_vals_sc_pl,unc_sc_pl)) if np.size(p_vals_sc_pl) else unc_sc_pl\n",
    "\n",
    "            ps_fdr_pl = np.hstack((ps_fdr_pl,p_fdr_pl)) if np.size(ps_fdr_pl) else p_fdr_pl\n",
    "            ps_fdr_fam = np.hstack((ps_fdr_fam,p_fdr_fam)) if np.size(ps_fdr_fam) else p_fdr_fam\n",
    "            ps_fdr_pl_fam = np.hstack((ps_fdr_pl_fam,p_fdr_pl_fam)) if np.size(ps_fdr_pl_fam) else p_fdr_pl_fam\n",
    "            ps_fdr_sc_fam = np.hstack((ps_fdr_sc_fam,p_fdr_sc_fam)) if np.size(ps_fdr_sc_fam) else p_fdr_sc_fam\n",
    "            ps_fdr_sc_pl = np.hstack((ps_fdr_sc_pl,p_fdr_sc_pl)) if np.size(ps_fdr_sc_pl) else p_fdr_sc_pl\n",
    "\n",
    "            ps_bf_pl= np.hstack((ps_bf_pl,p_bf_pl)) if np.size(ps_bf_pl) else p_bf_pl\n",
    "            ps_bf_fam = np.hstack((ps_bf_fam,p_bf_fam)) if np.size(ps_bf_fam) else p_bf_fam\n",
    "            ps_bf_pl_fam = np.hstack((ps_bf_pl_fam,p_bf_pl_fam)) if np.size(ps_bf_pl_fam) else p_bf_pl_fam\n",
    "            ps_bf_sc_fam = np.hstack((ps_bf_sc_fam,p_bf_sc_fam)) if np.size(ps_bf_sc_fam) else p_bf_sc_fam\n",
    "            ps_bf_sc_pl = np.hstack((ps_bf_sc_pl,p_bf_sc_pl)) if np.size(ps_bf_sc_pl) else p_bf_sc_pl\n",
    "\n",
    "        data = np.concatenate((subjects_c[:,np.newaxis],labels_c[:,np.newaxis],\n",
    "                    channels_c[:,np.newaxis],x_c[:,np.newaxis],y_c[:,np.newaxis],\n",
    "                    z_c[:,np.newaxis],elecs_c[:,np.newaxis],\n",
    "                    R_vals_pl[:,np.newaxis],p_vals_pl[:,np.newaxis],ps_fdr_pl[:,np.newaxis],\n",
    "                               ps_bf_pl[:,np.newaxis],\n",
    "                    R_vals_fam[:,np.newaxis],p_vals_fam[:,np.newaxis],ps_fdr_fam[:,np.newaxis],\n",
    "                               ps_bf_fam[:,np.newaxis],\n",
    "                    R_vals_pl_fam[:,np.newaxis],p_vals_pl_fam[:,np.newaxis],ps_fdr_pl_fam[:,np.newaxis],\n",
    "                               ps_bf_pl_fam[:,np.newaxis],\n",
    "                    R_vals_sc_fam[:,np.newaxis],p_vals_sc_fam[:,np.newaxis],ps_fdr_sc_fam[:,np.newaxis],\n",
    "                               ps_bf_sc_fam[:,np.newaxis],\n",
    "                    R_vals_sc_pl[:,np.newaxis],p_vals_sc_pl[:,np.newaxis],ps_fdr_sc_pl[:,np.newaxis],\n",
    "                               ps_bf_sc_pl[:,np.newaxis]),axis=1)\n",
    "        df = pd.DataFrame(data, columns=['subjects','labels','channels','x','y','z','elecs_num',\n",
    "                    'R_pl','unc_pl','fdr_pl','bonf_pl','R_fam','unc_fam','fdr_fam','bonf_fam',\n",
    "                    'R_pl_fam','unc_pl_fam','fdr_pl_fam','bonf_pl_fam',\n",
    "                    'R_sc_fam','unc_sc_fam','fdr_sc_fam','bonf_sc_fam',\n",
    "                    'R_sc_pl','unc_sc_pl','fdr_sc_pl','bonf_sc_pl'])\n",
    "        print(df.shape)\n",
    "        df.to_csv(df_name.format('All_subjects','pleas_fam_score',freq,sheet),index=False)           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summarize stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from brainpipe.system import study\n",
    "from collections import Counter\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "st = study('Olfacto')\n",
    "fold, freq, sheet = 'Enc', 'theta', 'Final'\n",
    "olf_regions = ['Amg','pPirT','OFC_olf','Ins_olf']\n",
    "# cond = 'high'\n",
    "path_file = path.join(st.path, 'feature/TPSim_3groups_'+fold+\\\n",
    "                      '/similarity_matrix_btw_v=1_elecs=all_early_late/')\n",
    "df_name = path.join(path_file, \n",
    "            'All_subjects_correl_rdm_pleas_fam_score_'+freq+'_mean=False_'+sheet+'_L.csv') #su, conds0, conds1, freq\n",
    "df_save = path.join(path_file, \n",
    "                'All_subjects_correl_{}_{}_'+freq+'_'+sheet+'_mean=False_{}_L.csv')\n",
    "\n",
    "thrs = [0.05]\n",
    "corrections = ['fdr_']#['fdr_','bonf_']\n",
    "dims = ['pl','fam','pl_fam']\n",
    "# dims = ['pl_fam']\n",
    "\n",
    "df_init = pd.read_csv(df_name)\n",
    "print('Initial df shape', df_init.shape,df_init.columns)\n",
    "\n",
    "for th, dim, corr in product(thrs,dims,corrections):\n",
    "    df_sel = df_init.loc[df_init[corr+dim]<th]\n",
    "    df_sel['sign'] = ['similar' if t > 0 else 'different' for t in df_sel['R_'+dim]]\n",
    "    print('\\n stats at p < ',th, 'correction : ',corr, df_sel.shape, 'for dimension',dim)\n",
    "    print(Counter(df_sel['labels']))\n",
    "\n",
    "    rois = np.unique(df_sel['labels'])\n",
    "    for roi in rois:\n",
    "        df_roi = df_sel.loc[df_sel['labels']==roi]\n",
    "        df_inc = df_roi.loc[df_roi['sign']=='different'].groupby(['subjects']).count()\n",
    "        df_dec = df_roi.loc[df_roi['sign']=='similar'].groupby(['subjects']).count()\n",
    "#         if roi in ['pPirT','Amg']:\n",
    "#             print(df_roi)\n",
    "        if (df_dec.shape[0] >= 3) or (df_dec.shape[0] >=2 and roi in olf_regions): # we only consider positive correlations\n",
    "            print(roi, 'NB of subjects with SIMILAR',df_dec.shape[0],' subjects')\n",
    "            df_plot = df_roi.loc[df_roi['sign']=='similar']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "#             df_plot.to_csv(df_save.format(roi,corr+str(th),dim,cond))\n",
    "#             print(df_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Only consider specific ROIs and not ALL brain regions\"\"\"\n",
    "from brainpipe.system import study\n",
    "from mne.stats import bonferroni_correction, fdr_correction\n",
    "from collections import Counter\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "st = study('Olfacto')\n",
    "fold, freq, sheet = 'Enc', 'theta', 'Final'\n",
    "# cond = 'high'\n",
    "path_file = path.join(st.path, \n",
    "          'feature/TPSim_3groups_'+fold+'/similarity_matrix_btw_v=1_elecs=all_early_late/')\n",
    "df_name = path.join(path_file, \n",
    "                'All_subjects_correl_rdm_pleas_fam_score_'+freq+'_mean=False_'+sheet+'_E.csv') #su, conds0, conds1, freq\n",
    "df_save = path.join(path_file, \n",
    "                'All_subjects_correl_{}_{}_{}_'+freq+'_'+sheet+'_mean=False_{}_E.csv')\n",
    "\n",
    "thrs = [0.05]\n",
    "corrections = ['unc_']#['fdr_','bonf_']\n",
    "dims = ['pl','fam']\n",
    "rois = ['OFC_olf','pPirT']\n",
    "olf_regions = ['OFC_olf','pPirT']\n",
    "\n",
    "df_init = pd.read_csv(df_name)\n",
    "#print('Initial df shape', df_init.shape,df_init.columns)\n",
    "# combine Amg/pPirT together\n",
    "df_init['labels'] = [x if x != 'Amg' else 'pPirT' for x in df_init['labels']]\n",
    "\n",
    "for th, dim, corr in product(thrs,dims,corrections):\n",
    "    for roi in rois:\n",
    "        print('>>> processing', roi, dim, corr, th)\n",
    "        df_roi = df_init.loc[df_init['labels']==roi]\n",
    "        pvals = [p if not math.isnan(p) else 1 for p in df_roi['unc_'+dim].values]\n",
    "        df_roi['new_pvalues'] = fdr_correction(pvals)[1]\n",
    "        #print(df_roi[['subjects','labels','channels','R_'+dim]].mean())\n",
    "        #print(df_roi[['subjects','labels','channels','R_'+dim]].sem())\n",
    "        #             'unc_'+dim, 'fdr_'+dim, 'new_pvalues']].loc[df_roi['unc_'+dim]<th])\n",
    "        df_sel = df_roi.loc[df_roi['new_pvalues']<th]\n",
    "        print('sig results',df_sel)\n",
    "        df_sel['sign'] = ['similar' if t > 0 else 'different' for t in df_sel['R_'+dim]]\n",
    "        print('\\n stats at p < ',th, 'correction : ',corr, df_sel.shape, 'for dimension',dim)\n",
    "        print(Counter(df_sel['labels']))\n",
    "\n",
    "        df_dec = df_sel.loc[df_sel['sign']=='similar'].groupby(['subjects']).count()\n",
    "        if (df_dec.shape[0] >= 3) or (df_dec.shape[0] >=2 and roi in olf_regions):\n",
    "            print(roi, 'NB of subjects with SIMILAR',df_dec.shape[0],' subjects')\n",
    "            df_plot = df_sel.loc[df_sel['sign']=='similar']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "            df_plot[['subjects','labels','channels','x','y','z','R_'+dim,\n",
    "                         'unc_'+dim, 'fdr_'+dim,'new_pvalues']].to_csv(df_save.format(roi,corr+str(th),'late',dim))\n",
    "            print(df_plot[['subjects','labels','channels','x','y','z','R_'+dim,\n",
    "                         'unc_'+dim, 'fdr_'+dim,'new_pvalues']])\n",
    "            print(df_plot['R_'+dim].mean(), df_plot['R_'+dim].std())\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "//// PLEASANTNESS + FAMILIARITY ////\n",
    "Final OFC (2 patients 3 elecs)\n",
    "Final avg OFC (3 patients 5 elecs) + MFG (3 patients 4 elecs)\n",
    "\n",
    "//// FAMILIARITY ////\n",
    "Final OFC (2P,3elecs), MFG (3P, 5elecs)\n",
    "Final avg MFG (3P,6elecs), OFC (2P 2elecs 2 sens), aHC (3P,4elecs)\n",
    "\n",
    "//// PLEASANTNESS ////\n",
    "Final OFC (3P, 4elecs)\n",
    "Final avg OFC (3P, 4elecs)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from brainpipe.system import study\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "st = study('Olfacto')\n",
    "PATH = '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "filename = 'Recap_Odeurs_Evaluations.xlsx'\n",
    "PATH_SAVE = join(st.path, 'feature/TPSim_3groups_Enc/similarity_matrix_btw/')\n",
    "savename = 'dist_pl_fam_all_odors_pleas.npz'\n",
    "\n",
    "df = pd.read_excel(PATH+filename, sheet_name='Final')\n",
    "odors = df[['od_num']].values[:,0]\n",
    "#odors = [14,10,3,8,13,6,12,9,1,18,4,15,5,17,11,2,16,7] #ordered by Fam\n",
    "odors = [10,1,12,3,9,13,6,5,8,14,16,4,18,11,15,7,2,17] #ordered by Pleas\n",
    "#odors = [10,3,9,1,13,12,6,14,8,5,4,18,16,15,7,2,11,17] #fam * pleas\n",
    "#odors = [10,3,9,13,1,6,12,14,8,5,4,18,16,15,7,2,11,17] #fam + pleas\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "dist_f, dist_p, dist_fp = [], [], []\n",
    "for o1,o2 in combinations(odors,2):\n",
    "    f1 = df.loc[df['od_num']=='O'+str(o1)]['Familiarity'].values\n",
    "    f2 = df.loc[df['od_num']=='O'+str(o2)]['Familiarity'].values\n",
    "    p1 = df.loc[df['od_num']=='O'+str(o1)]['Pleasantness'].values\n",
    "    p2 = df.loc[df['od_num']=='O'+str(o2)]['Pleasantness'].values\n",
    "    fp1, fp2 = np.array([f1,p1]), np.array([f2,p2])\n",
    "    dist_f.append(np.round(np.linalg.norm(f1-f2),2))\n",
    "    dist_p.append(np.round(np.linalg.norm(p1-p2),2))\n",
    "    dist_fp.append(np.round(np.linalg.norm(fp1-fp2),2))\n",
    "print(len(dist_f))\n",
    "np.savez(PATH_SAVE+savename,d_f=np.array(dist_f),d_p=np.array(dist_p),\n",
    "        d_fp=np.array(dist_fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot odors RDM matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import cm\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.manifold import MDS\n",
    "\"\"\"\n",
    "Plot TPSim matrices (RDM) for all odors (Familiarity Pleasantness, both)\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_npz = join(st.path,'feature/TPSim_3groups_Enc/')\n",
    "path_pow = join(path_npz, 'similarity_matrix_btw/dist_pl_fam_all_odors_mult.npz')\n",
    "savename = join(path_npz, 'distance_graphs/Plot_distance_{}_all_odors_mult.png')\n",
    "###############################################################################\n",
    "exp = 'Enc' #Ret, Enc\n",
    "###############################################################################\n",
    "#new_order = [10,1,12,3,9,13,6,5,8,14,16,4,18,11,15,7,2,17] #Pleas order\n",
    "new_order = [10,3,9,1,13,12,6,14,8,5,4,18,16,15,7,2,11,17] #fam * pleas\n",
    "#new_order = [10,3,9,13,1,6,12,14,8,5,4,18,16,15,7,2,11,17] #fam + pleas\n",
    "#new_order = [14,10,3,8,13,6,12,9,1,18,4,15,5,17,11,2,16,7] #Fam order\n",
    "mat = np.load(path_pow)\n",
    "features = mat.files\n",
    "\n",
    "for feat in features:\n",
    "    combs = mat[feat]\n",
    "    n_od = 18\n",
    "    idx = list(np.arange(1,n_od+1))\n",
    "    tri = np.zeros((n_od, n_od))\n",
    "    tri[np.triu_indices(n_od,1)] = combs\n",
    "    tri[np.tril_indices(n_od, -1)] = tri.T[np.tril_indices(n_od, -1)]\n",
    "\n",
    "    model = MDS(n_components=2, dissimilarity='precomputed', random_state=None)\n",
    "    out = model.fit_transform(tri)\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(8,3))\n",
    "    colors = 'black'\n",
    "    markers = 'o'\n",
    "\n",
    "    for i, txt in enumerate(idx):\n",
    "        ax1.scatter(out[i,0], out[i,1], c=colors, marker=markers)\n",
    "        ax1.annotate('O'+str(txt), (out[i,0], out[i,1]))\n",
    "    ax1.set_xlabel('component 1')\n",
    "    ax1.set_ylabel('component 2')\n",
    "    #ax1.axis('equal')\n",
    "        \n",
    "    #subplot #1 Graph 2D \n",
    "    cmap = cm.get_cmap('viridis', 30)\n",
    "    mask =  np.tri(tri.shape[0], k=0) #mask upper triangle\n",
    "    A = np.ma.array(tri, mask=mask) # mask out the lower triangle\n",
    "    cax = ax2.imshow(A, vmin=0,vmax=3,interpolation=\"nearest\", cmap=cmap)\n",
    "    ax2.set_xticks(np.arange(n_od))\n",
    "    ax2.set_yticks(np.arange(n_od))\n",
    "    ax2.set_xticklabels(new_order,fontsize=11)\n",
    "    ax2.set_yticklabels(new_order,fontsize=11)\n",
    "    plt.colorbar(cax)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    title = 'Distance btw odors in {} domaine )'.format(feat)\n",
    "    fig.suptitle(title, fontsize=12)\n",
    "    \n",
    "    plt.savefig(savename.format(feat))\n",
    "    plt.savefig(savename.format(feat).replace('.png','.pdf'))\n",
    "    plt.clf()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute distance btw all odors (GoodSenseCompagny)\n",
    "- Structure (single, mixture)\n",
    "- Strength (medium, high)\n",
    "- Descriptors (type of odors: floral...)\n",
    "- Averaged ratings (pleasantness, familiarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, zscore\n",
    "from itertools import combinations\n",
    "#import nltk\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "PATH = '/media/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "filename = 'Recap_Odeurs_Evaluations.xlsx'\n",
    "df_save = 'distance_odors_all_pairs_meth=sum.csv'\n",
    "cols_sel = ['Od_ID','Pleasantness','Familiarity','intensity','struct','type']\n",
    "\n",
    "df = pd.read_excel(PATH+filename,sheet_name='Final')\n",
    "df['Od_ID'] = [x[1:] for x in df['od_num']]\n",
    "df['intensity'] = [0 if x == 'medium' else 1 for x  in df['strength']]\n",
    "df['struct'] = [0 if x == 'single' else 1 for x  in df['structure']]\n",
    "for col in np.setdiff1d(cols_sel,['Od_ID','type']):\n",
    "    df[col+'_z'] = [(x - min(df[col]))/(max(df[col]-min(df[col]))) \\\n",
    "                        for x in df[col]] \n",
    "    \n",
    "ncombs = len([c1 for c1,c2 in combinations(df['Od_ID'].values,2)])\n",
    "od_vec, dist_vec = [], np.zeros((ncombs,5))\n",
    "i=0\n",
    "for c1, c2 in combinations(df['Od_ID'],2):\n",
    "    r1 = df.loc[df['Od_ID']==c1]\n",
    "    r2 = df.loc[df['Od_ID']==c2]\n",
    "    r3 = []\n",
    "    for col in ['Od_ID','Pleasantness_z','Familiarity_z','intensity_z','struct_z','type']:\n",
    "        if col == 'Od_ID':\n",
    "            od_vec.append(r1[col].values[0]+'_'+r2[col].values[0])\n",
    "        elif col == 'type':\n",
    "            syn1 = wn.synsets(r1[col].values[0])[0]\n",
    "            syn2 = wn.synsets(r2[col].values[0])[0]\n",
    "            r3.append(np.round(syn1.wup_similarity(syn2),2))\n",
    "        else:\n",
    "            r3.append(np.round(np.linalg.norm(r1[col].values[0]-r2[col].values[0]),2))\n",
    "    dist_vec[i] += r3\n",
    "    i += 1\n",
    "\n",
    "data = np.concatenate((np.array(od_vec)[:,np.newaxis],dist_vec),axis=1)\n",
    "cols = ['Pl_d','Fam_d','Int_d','Stru_d','Type_d']\n",
    "df = pd.DataFrame(data,columns=['od_pairs','Pl_d','Fam_d','Int_d','Stru_d','Type_d'])\n",
    "for c in cols:\n",
    "    df[c] = df[c].astype(float)\n",
    "df['dist_sum'] = df[cols].sum(axis=1)\n",
    "df.to_csv(PATH+df_save,index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create distance file for every patient (different odor pairs)\n",
    "- olfactory distance\n",
    "- spatial distance between circles\n",
    "- temporal distance between explorations (Day2 = time + 24h)\n",
    "- respiration difference (volume of the first inspiration) only for Encoding analyses\n",
    "- memory distance (episodic memory perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(df,r1,r2,col0,col1):\n",
    "    xy1 = np.array([df[col0].iloc[r1].values[0],df[col1].iloc[r1].values[0]])\n",
    "    xy2 = np.array([df[col0].iloc[r2].values[0],df[col1].iloc[r2].values[0]])\n",
    "    dist = np.round(np.linalg.norm(xy1-xy2),2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from codes import num_odor_to_ref\n",
    "from utils import pos_cirles, odor_su_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "subjects = ['CHAF','FERJ','LEFC','PIRJ','SEMC','VACJ']\n",
    "PATH = '/media/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "df_perf = 'encoding_individual_results.xls'\n",
    "df_od_name = 'distance_odors_all_pairs_meth=sum.csv'\n",
    "df_save = 'distance_dims=all_odors=all_su={}_norm={}.csv'\n",
    "cols_s = ['trial_time','odor_num','encoding_day','0_insp_V','0_exp_V']\n",
    "\n",
    "for su in subjects:\n",
    "    df_E = pd.read_excel(PATH+df_perf,sheet_name=su)\n",
    "    df_E['0_insp_V'] = np.abs(df_E['total_encodage_0_insp_volume'])\n",
    "    df_E['0_exp_V'] = df_E['total_encodage_0_exp_volume']*-1\n",
    "    df_E = df_E[cols_s]\n",
    "    df_E = df_E.fillna(df_E.mean())\n",
    "    df_od = pd.read_csv(PATH+df_od_name)\n",
    "\n",
    "    od_pairs, od_dist, temp_dist, resp_dist = [], [], [], []\n",
    "    spa_dist, rich_dist = [], []\n",
    "    for r1, r2 in combinations(df_E.index,2):\n",
    "        o1 = str(df_E['odor_num'].iloc[r1])\n",
    "        o2 = str(df_E['odor_num'].iloc[r2])\n",
    "        p1 = 'P'+str(num_odor_to_ref[su][int(o1)][1])\n",
    "        p2 = 'P'+str(num_odor_to_ref[su][int(o2)][1])\n",
    "\n",
    "        if o1 != o2:\n",
    "            comb, comb_inv = o1+'_'+o2, o2+'_'+o1\n",
    "            od_pairs.append(comb)\n",
    "            od_dist.append(df_od['dist_sum'].loc[df_od['od_pairs'].isin([comb,comb_inv])].values[0])\n",
    "            temp_dist.append(compute_distance(df_E,r1,r2,\n",
    "                                              col0=['trial_time'],col1=['encoding_day']))\n",
    "            resp_dist.append(compute_distance(df_E,r1,r2,\n",
    "                                              col0=['0_insp_V'],col1=['0_exp_V']))\n",
    "            coord1, coord2 = np.array(pos_cirles[p1]), np.array(pos_cirles[p2])\n",
    "            spa_dist.append(np.round(np.linalg.norm(coord1-coord2),2))\n",
    "            score1 = np.array(odor_su_score[su][o1])\n",
    "            score2 = np.array(odor_su_score[su][o2])\n",
    "            rich_dist.append(np.round(np.linalg.norm(coord1-coord2),2))\n",
    "    data = np.concatenate((np.array(od_pairs)[:,np.newaxis], \n",
    "                           np.array(od_dist)[:,np.newaxis], \n",
    "                           np.array(temp_dist)[:,np.newaxis], \n",
    "                           np.array(resp_dist)[:,np.newaxis], \n",
    "                           np.array(spa_dist)[:,np.newaxis],\n",
    "                           np.array(rich_dist)[:,np.newaxis]),axis=1)\n",
    "    df_dist = pd.DataFrame(data, columns=['od_pairs','od_dist','temp_dist',\n",
    "                                         'resp_dist','spa_dist','rich_dist'])\n",
    "    df_dist.to_csv(PATH+df_save.format(su,'False',index=False))\n",
    "    #rescale all distances to be between 0 and 1\n",
    "    for c in ['od_dist','temp_dist','resp_dist','spa_dist','rich_dist']:\n",
    "        df_dist[c] = df_dist[c].astype(float)\n",
    "        df_dist[c] = [(x - min(df_dist[c]))/(max(df_dist[c]-min(df_dist[c]))) \\\n",
    "                        for x in df_dist[c]]\n",
    "    df_dist.to_csv(PATH+df_save.format(su,'True'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
