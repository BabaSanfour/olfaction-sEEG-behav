{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check files dimension in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from brainpipe.system import study\n",
    "from os import path\n",
    "import os\n",
    "\n",
    "st = study('Olfacto')\n",
    "path_data = path.join(st.path,'database/Encoding_By_Odor/try_PIRJ/') #Retrieval_EpiPerf_LowHigh\n",
    "files = os.listdir(path_data) #Retrieval_By_Odor\n",
    "\n",
    "for fi in files:\n",
    "    if fi.endswith('ok.npz') and fi.startswith('PIRJ'):\n",
    "        loadname = path_data+fi\n",
    "        mat = np.load(loadname, allow_pickle=True)\n",
    "        x = np.load(loadname)['x']\n",
    "        print (fi, x.shape,mat.files, mat['channel'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove bad electrodes after artefact detection\n",
    "### TF with artefacts or 50Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from brainpipe.system import study\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st = study('Olfacto')\n",
    "pathfiles = path.join(st.path, 'database/R_pre_stim_1s_By_Odor/')\n",
    "#conds = ['low', 'high']\n",
    "phases = ['odor']#'rest'\n",
    "rej_elec = {\n",
    "    'CHAF' : [98,102,103,104],\n",
    "    'VACJ' : [0,66,67,68,122,128], \n",
    "    'SEMC' : [36],\n",
    "    'PIRJ' : [10,14,15,25,26,41,47,48,53,54,55,57,58,63,64,71,72,79,80,81,82,83,],\n",
    "    'LEFC' : [47,48,49,50,140,141,],\n",
    "    'MICP' : [4,9,13,71,],\n",
    "    'FERJ': [],\n",
    "            }\n",
    "files = [k for k in st.search('_bipo.npz', folder=('database/R_pre_stim_1s_By_Odor/'))]\n",
    "for fi in files:\n",
    "    mat = np.load(pathfiles+fi)\n",
    "    x, sf, label, channel, xyz = mat['x'], mat['sf'], mat['label'], mat['channel'], mat['xyz']\n",
    "    print (fi, x.shape, label.shape, channel.shape, xyz.shape)\n",
    "\n",
    "    #Remove all bad electrodes from the database\n",
    "    new_x = np.delete(x,rej_elec[fi[:4]], axis=0)\n",
    "    new_label = np.delete(label,rej_elec[fi[:4]], axis=0)\n",
    "    new_channel = np.delete(channel,rej_elec[fi[:4]], axis=0)\n",
    "    new_xyz = np.delete(xyz,rej_elec[fi[:4]], axis=0)\n",
    "    print (fi, len(rej_elec[fi[:4]]),new_x.shape, new_label.shape, new_channel.shape, new_xyz.shape)\n",
    "\n",
    "    #Save all new information\n",
    "    mat_new = {'x':new_x, 'label':new_label, 'channel':new_channel, 'xyz':new_xyz, 'sf':sf}\n",
    "    file_source = fi.replace('bipo.npz','bipo2.npz')\n",
    "    np.savez(pathfiles+file_source,**mat_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Remove aHC electrodes in PIRJ (all but O6/O7)\"\"\"\n",
    "from utils import odor_su_score\n",
    "st = study('Olfacto')\n",
    "pathfiles = path.join(st.path, 'database/Encoding_By_Odor/try_PIRJ/')\n",
    "files = path.join(pathfiles, 'PIRJ_odor_{}_bipo.npz')\n",
    "\n",
    "ref = np.load(files.format('6'),allow_pickle=True)['channel']\n",
    "\n",
    "d_sel = {}\n",
    "for od in odor_su_score['PIRJ']:\n",
    "    mat = np.load(files.format(od),allow_pickle=True)\n",
    "    idx_ = [i for i,ch in enumerate(mat['channel']) if ch in ref]\n",
    "    \n",
    "    for f in mat.files:\n",
    "        d_sel[f] = mat[f][idx_] if f != 'sf' else mat[f]\n",
    "    np.savez(files.format(od).replace('.npz','_elecs_ok.npz'),**d_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove elecs with WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st = study('Olfacto')\n",
    "pathfiles = path.join(st.path, 'database/Encoding_By_Odor/try_PIRJ/')\n",
    "\n",
    "files = [k for k in st.search('elecs_ok.npz', folder=('database/Encoding_By_Odor/try_PIRJ/'))]\n",
    "for fi in files:\n",
    "    mat = np.load(pathfiles+fi)\n",
    "    print(mat.files)\n",
    "    data, label, channel, xyz,sf= mat['x'], mat['label'], mat['channel'], mat['xyz'],mat['sf']\n",
    "    print(fi, 'data shape: ', data.shape, label.shape, channel.shape, xyz.shape)\n",
    "\n",
    "    #create a list of all electrodes to remove\n",
    "    elecs = label.shape[0]\n",
    "    elecs_rej = []\n",
    "    for elec in range(elecs):\n",
    "        elec_rej_wm = np.where(label[elec].find('WM') != -1,int(elec),None)\n",
    "        elec_rej_lcr = np.where(label[elec].find('LCR') != -1,int(elec),None)\n",
    "        elec_rej_skull = np.where(label[elec].find('skull') != -1,int(elec),None)\n",
    "        elec_rej_out = np.where(label[elec].find('out') != -1,int(elec),None)\n",
    "        if elec_rej_wm != None:\n",
    "            elecs_rej = np.append(elecs_rej,elec_rej_wm)\n",
    "        if elec_rej_lcr != None and elec_rej_lcr != elec_rej_wm:\n",
    "            elecs_rej = np.append(elecs_rej,elec_rej_lcr)\n",
    "        if elec_rej_skull != None and elec_rej_skull != elec_rej_wm and elec_rej_skull != elec_rej_lcr:\n",
    "            elecs_rej = np.append(elecs_rej,elec_rej_skull)\n",
    "        if elec_rej_out != None and elec_rej_out != elec_rej_skull and elec_rej_out!= elec_rej_wm and elec_rej_out != elec_rej_lcr:\n",
    "            elecs_rej = np.append(elecs_rej, elec_rej_out)\n",
    "\n",
    "    #Remove all bad electrodes from the database\n",
    "    new_data, new_label = np.delete(data,elecs_rej, axis=0), np.delete(label,elecs_rej, axis=0)\n",
    "    new_channel, new_xyz = np.delete(channel,elecs_rej, axis=0), np.delete(xyz,elecs_rej, axis=0)\n",
    "    print (fi,'new data',new_data.shape, new_label.shape,new_channel.shape, new_xyz.shape)\n",
    "\n",
    "    #Save all new information\n",
    "    mat_new = {'x':new_data, 'label':new_label, 'channel':new_channel, 'xyz':new_xyz, 'sf':sf}\n",
    "    filename2 = fi.replace('elecs_ok.npz','all_noWM.npz')\n",
    "    print('CHECK', mat_new['x'].shape)\n",
    "    np.savez(pathfiles+filename2,**mat_new)\n",
    "    del elecs, elecs_rej, new_data, new_label, new_channel, new_xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add AAL & BA labels to subjects' matrices\n",
    "### Add also the Mai labels (Jane-AL) post fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK NUMBER OF ELECTRODES WITHOUT ARTEFACTS \n",
    "PATHS = [path.join(st.path,'database/R_pre_stim_1s/'),\n",
    "        path.join(st.path,'database/R_resting_3s/'),\n",
    "        path.join(st.path,'database/Retrieval_EpiPerf_LowHigh/')]\n",
    "subjects = ['CHAF','SEMC','PIRJ','FERJ','LEFC','VACJ']\n",
    "for su in subjects:\n",
    "    for p in PATHS:\n",
    "        filename = p+'_labels/Elecs_{}_labels_aal.csv'.format(su)\n",
    "        df = pd.read_csv(filename)\n",
    "        print(p, su, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############SANS LABELS DE MAI#######################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from brainpipe.system import study\n",
    "from os import path\n",
    "\n",
    "st = study('Olfacto')\n",
    "path_data = path.join(st.path,'database/Encoding_By_Odor/try_PIRJ/')\n",
    "path_labels = path.join(st.path,'database/Encoding_By_Odor/_labels/') #create with visbrain in 4_Visbrain new scripts\n",
    "\n",
    "files = [k for k in st.search('bipo_all_noWM.npz', folder=('database/Encoding_By_Odor/try_PIRJ/'))]\n",
    "for f in files:\n",
    "    mat = np.load(path_data+f, allow_pickle=True)\n",
    "    kwargs = {}\n",
    "    kwargs['x'], kwargs['channels'], kwargs['xyz'] = mat['x'], mat['channel'],mat['xyz']\n",
    "    kwargs['labels'], kwargs['sf']=mat['label'],mat['sf']\n",
    "    # Load the AAL labels\n",
    "    aal = 'Elecs_'+f[:4]+'_labels_aal.csv'\n",
    "    df = pd.read_csv(path_labels+aal, sep=',')\n",
    "    kwargs['aal'] = df['aal'].values\n",
    "    # Load the BA labels\n",
    "    BA = 'Elecs_'+f[:4]+'_labels_brodmann.csv'\n",
    "    df = pd.read_csv(path_labels+BA, sep=',')\n",
    "    kwargs['BA'] = df['brodmann'].values\n",
    "    # Update the datafile\n",
    "    filename = f.replace('noWM.npz','noWM_phys.npz')\n",
    "    np.savez(path_data+filename, **kwargs)\n",
    "    mat2 = np.load(path_data+filename, allow_pickle=True)\n",
    "    print(f[:4],mat2['x'].shape, mat2['xyz'].shape, mat2['aal'].shape, mat2['BA'].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from brainpipe.system import study\n",
    "from os import path\n",
    "\n",
    "st = study('Olfacto')\n",
    "path_data = path.join(st.path,'database/Encoding_By_Odor/try_PIRJ/')\n",
    "path_elecs = path.join(st.path,'database/Encoding_By_Odor/')\n",
    "path_labels = path.join(path_elecs,'All_elecs_infos_npz/') #create with visbrain in 4_Visbrain new scripts\n",
    "path_atlas = path.join(path_elecs, '_labels/')\n",
    "files = [k for k in st.search('bipo_all_noWM_phys.npz', \n",
    "                              folder=('database/Encoding_By_Odor/try_PIRJ'))]\n",
    "\n",
    "for fi in files:\n",
    "    mat = np.load(path_data+fi)\n",
    "    print(mat.files)\n",
    "    kwargs = {}\n",
    "    kwargs['x'], kwargs['channels'], kwargs['xyz'] = mat['x'], mat['channels'],mat['xyz']\n",
    "    kwargs['labels'], kwargs['sf']=mat['labels'],mat['sf']\n",
    "    # Load the AAL labels\n",
    "    aal = 'Elecs_'+fi[:4]+'_labels_aal.csv'\n",
    "    df = pd.read_csv(path_atlas+aal, sep=',')\n",
    "    kwargs['aal'] = df['aal'].values\n",
    "    # Load the BA labels\n",
    "    BA = 'Elecs_'+fi[:4]+'_labels_brodmann.csv'\n",
    "    df = pd.read_csv(path_atlas+BA, sep=',')\n",
    "    kwargs['BA'] = df['brodmann'].values\n",
    "    #Load the new_labels from Mai atlas\n",
    "    Mai_file = '0_all_subjects_info_elecs_mai_labels.csv'\n",
    "    df2 = pd.read_csv(path_labels+Mai_file, sep=',')\n",
    "    Mai_data = df2['Mai_RL'].loc[df2['su_names'] == fi[:4]].values\n",
    "    kwargs['Mai_RL'] = Mai_data\n",
    "    #Add  the new labels Mai RL\n",
    "    kwargs['Mai'] = Mai_data+'_'+['R' if x > 0 else 'L' for x in df2['x'].loc[df2['su_names'] == fi[:4]].values]\n",
    "    # Update the datafile\n",
    "    filename2 = fi.replace('bipo_all_noWM_phys.npz','bipo_all_noWM_phys.npz')\n",
    "    np.savez(path_data+filename2, **kwargs)\n",
    "    mat2 = np.load(path_data+filename2, allow_pickle=True)\n",
    "    print(mat2.files, mat2['Mai'][:5],mat2['Mai_RL'][:5])\n",
    "    print(fi[:4],mat2['x'].shape, mat2['xyz'].shape, mat2['aal'].shape, mat2['BA'].shape,\n",
    "          mat2['Mai'].shape, mat2['Mai_RL'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only regions present in at least 2 patients \n",
    "#### Remove all not memory related regions (motor, precentral, SMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = study('Olfacto')\n",
    "pathfiles = path.join(st.path, 'database/Encoding_EpiPerf_LowHigh/')\n",
    "subjects = ['CHAF','VACJ','SEMC','LEFC','MICP','PIRJ','FERJ']\n",
    "conds = ['bad','good']\n",
    "to_keep = ['Amygdala (R)', 'Cingulum Ant (R)','Cingulum Mid (R)', 'Frontal Inf Orb (R)', \n",
    "           'Frontal Inf Tri (R)', 'Frontal Mid (R)', 'Frontal Mid Orb (R)', 'Frontal Sup (R)',\n",
    "           'Frontal Sup Medial (R)', 'Frontal Sup Orb (R)', 'Hippocampus (R)', 'Insula (R)',\n",
    "           'ParaHippocampal (R)','Temporal Inf (R)', 'Temporal Mid (R)', 'Temporal Pole Mid (R)',\n",
    "           'Temporal Pole Sup (R)', 'Temporal Sup (R)','Amygdala (L)', 'Cingulum Ant (L)', \n",
    "           'Cingulum Mid (L)', 'Frontal Inf Orb (L)', 'Frontal Inf Tri (L)','Frontal Mid (L)', \n",
    "           'Frontal Mid Orb (L)', 'Frontal Sup (L)','Frontal Sup Medial (L)', 'Frontal Sup Orb (L)',\n",
    "           'Hippocampus (L)', 'Insula (L)','ParaHippocampal (L)','Temporal Inf (L)', \n",
    "           'Temporal Mid (L)','Temporal Pole Mid (L)','Temporal Pole Sup (L)', 'Temporal Sup (L)']\n",
    "\n",
    "for su in subjects:\n",
    "    for cond in conds:\n",
    "        mat = np.load(pathfiles+su+'_odor_'+cond+'_bipo_sel_phys.npz')\n",
    "        idx = np.where([mat['phys'][i] in to_keep for i in range(len(mat['phys']))])\n",
    "        kwargs = {}\n",
    "        kwargs['labels'], kwargs['x'], kwargs['phys'] = mat['labels'][idx], mat['x'][idx], mat['phys'][idx]\n",
    "        kwargs['xyz'], kwargs['channels'], kwargs['sf'] = mat['xyz'][idx], mat['channels'][idx], mat['sf']\n",
    "        np.savez(pathfiles+su+'_odor_'+cond+'_bipo_sel_phys2.npz',**kwargs)\n",
    "        del mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take same electrodes at retrieval than encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainpipe.system import study\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "st= study('Olfacto')\n",
    "PATH_E = join(st.path, 'database/Encoding_By_Odor/')\n",
    "PATH_R = join(st.path, 'database/Encoding_No_Odor/')\n",
    "\n",
    "filesE = st.search('all_noWM_physFT.npz',folder ='database/Encoding_By_Odor/' )\n",
    "\n",
    "for fi in filesE:\n",
    "    matE = np.load(PATH_E+fi,allow_pickle=True)\n",
    "    matR = np.load(PATH_R+fi.replace('_all_noWM_physFT',''),allow_pickle=True)\n",
    "    channelsE = matE['channels']\n",
    "    channelsR = matR['channel']\n",
    "    idx_sel_R = [i for i,chan in enumerate(channelsR) if chan in channelsE]\n",
    "    idx_sel_E = [i for i,chan in enumerate(channelsE) if chan in channelsR]\n",
    "    \n",
    "    dict_data = {}\n",
    "    for file in matE.files:\n",
    "        dict_data[file] = matE[file][idx_sel_E] if file != 'sf' else matE[file]\n",
    "    dict_data['x'] = matR['x'][idx_sel_R,...]\n",
    "    np.savez(PATH_R+fi,**dict_data)\n",
    "    dict_data['x'] = matE['x'][idx_sel_E,...]\n",
    "    np.savez(PATH_E+fi.replace('physFT','physFT_reinstatement'),**dict_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Low, Mid, High conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from brainpipe.system import study\n",
    "from utils import odor_groups_wgth as dict_ #odor_groups_wgth, odor_groups_3wgth\n",
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "from itertools import product\n",
    "\n",
    "st = study('Olfacto')\n",
    "PATH = join(st.path, 'database/Encoding_By_Odor/')\n",
    "od_name = join(PATH, '{}_odor_{}_bipo_all_noWM_physFT.npz')\n",
    "PATH_COND = join(st.path, 'database/Encoding_By_Cond_v=1_elecs=all/2conds/')\n",
    "save_name = join(PATH_COND, '{}_odor_{}_E.npz')\n",
    "subjects = ['PIRJ']\n",
    "    \n",
    "for su in subjects:\n",
    "    for cond in dict_[su]:\n",
    "        print('>>> processing:', su, cond)\n",
    "        glob_data = np.array([])\n",
    "        for od in dict_[su][cond]:\n",
    "            mat = np.load(od_name.format(su,od),allow_pickle=True)\n",
    "            glob_data = np.concatenate((glob_data, mat['x']),\n",
    "                               axis=-1) if np.size(glob_data) else mat['x']\n",
    "            print(su, od, cond,glob_data.shape)\n",
    "        dict_pow = {}\n",
    "        for file in mat.files:\n",
    "            dict_pow[file] = mat[file]\n",
    "        dict_pow['x'] = glob_data\n",
    "        np.savez(save_name.format(su,cond),**dict_pow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_early_late(data):\n",
    "    thr = int(data.shape[-1]/2)\n",
    "    if thr < 1:\n",
    "        early = data\n",
    "        late = np.array([])\n",
    "    else:\n",
    "        early = data[...,:thr]\n",
    "        late = data[...,thr:]\n",
    "    return early, late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      ">>> processing: CHAF 1\n",
      "CHAF 1 (61, 3584, 1) (0,)\n",
      ">>> processing: CHAF 2\n",
      "CHAF 2 (61, 3584, 2) (61, 3584, 2)\n",
      ">>> processing: CHAF 4\n",
      "CHAF 4 (61, 3584, 3) (61, 3584, 2)\n",
      ">>> processing: CHAF 5\n",
      "CHAF 5 (61, 3584, 4) (61, 3584, 2)\n",
      ">>> processing: CHAF 3\n",
      "CHAF 3 (61, 3584, 5) (61, 3584, 4)\n",
      ">>> processing: CHAF 8\n",
      "CHAF 8 (61, 3584, 6) (61, 3584, 6)\n",
      ">>> processing: CHAF 7\n",
      "CHAF 7 (61, 3584, 8) (61, 3584, 8)\n",
      ">>> processing: CHAF 9\n",
      "CHAF 9 (61, 3584, 10) (61, 3584, 11)\n",
      ">>> processing: VACJ 11\n",
      "VACJ 11 (39, 3584, 1) (39, 3584, 2)\n",
      ">>> processing: VACJ 14\n",
      "VACJ 14 (39, 3584, 2) (39, 3584, 4)\n",
      ">>> processing: VACJ 12\n",
      "VACJ 12 (39, 3584, 3) (39, 3584, 5)\n",
      ">>> processing: VACJ 10\n",
      "VACJ 10 (39, 3584, 4) (39, 3584, 7)\n",
      ">>> processing: VACJ 15\n",
      "VACJ 15 (39, 3584, 5) (39, 3584, 8)\n",
      ">>> processing: VACJ 17\n",
      "VACJ 17 (39, 3584, 6) (39, 3584, 9)\n",
      ">>> processing: VACJ 16\n",
      "VACJ 16 (39, 3584, 7) (39, 3584, 11)\n",
      ">>> processing: VACJ 13\n",
      "VACJ 13 (39, 3584, 9) (39, 3584, 13)\n",
      ">>> processing: SEMC 7\n",
      "SEMC 7 (53, 3584, 2) (53, 3584, 2)\n",
      ">>> processing: SEMC 10\n",
      "SEMC 10 (53, 3584, 5) (53, 3584, 6)\n",
      ">>> processing: SEMC 11\n",
      "SEMC 11 (53, 3584, 7) (53, 3584, 8)\n",
      ">>> processing: SEMC 12\n",
      "SEMC 12 (53, 3584, 10) (53, 3584, 11)\n",
      ">>> processing: SEMC 13\n",
      "SEMC 13 (53, 3584, 15) (53, 3584, 16)\n",
      ">>> processing: SEMC 5\n",
      "SEMC 5 (53, 3584, 16) (53, 3584, 18)\n",
      ">>> processing: SEMC 8\n",
      "SEMC 8 (53, 3584, 17) (53, 3584, 20)\n",
      ">>> processing: SEMC 9\n",
      "SEMC 9 (53, 3584, 18) (53, 3584, 22)\n",
      ">>> processing: PIRJ 1\n",
      "PIRJ 1 (18, 3584, 3) (18, 3584, 4)\n",
      ">>> processing: PIRJ 9\n",
      "PIRJ 9 (18, 3584, 6) (18, 3584, 7)\n",
      ">>> processing: PIRJ 5\n",
      "PIRJ 5 (18, 3584, 7) (18, 3584, 7)\n",
      ">>> processing: PIRJ 4\n",
      "PIRJ 4 (18, 3584, 9) (18, 3584, 9)\n",
      ">>> processing: PIRJ 6\n",
      "PIRJ 6 (18, 3584, 14) (18, 3584, 14)\n",
      ">>> processing: PIRJ 7\n",
      "PIRJ 7 (18, 3584, 19) (18, 3584, 19)\n",
      ">>> processing: PIRJ 18\n",
      "PIRJ 18 (18, 3584, 21) (18, 3584, 22)\n",
      ">>> processing: LEFC 15\n",
      "LEFC 15 (27, 3584, 5) (27, 3584, 6)\n",
      ">>> processing: LEFC 2\n",
      "LEFC 2 (27, 3584, 7) (27, 3584, 9)\n",
      ">>> processing: LEFC 1\n",
      "LEFC 1 (27, 3584, 8) (27, 3584, 10)\n",
      ">>> processing: LEFC 16\n",
      "LEFC 16 (27, 3584, 16) (27, 3584, 18)\n",
      ">>> processing: LEFC 14\n",
      "LEFC 14 (27, 3584, 19) (27, 3584, 21)\n",
      ">>> processing: LEFC 3\n",
      "LEFC 3 (27, 3584, 21) (27, 3584, 23)\n",
      ">>> processing: LEFC 4\n",
      "LEFC 4 (27, 3584, 23) (27, 3584, 25)\n",
      ">>> processing: LEFC 17\n",
      "LEFC 17 (27, 3584, 26) (27, 3584, 29)\n",
      ">>> processing: FERJ 7\n",
      "FERJ 7 (32, 3584, 1) (32, 3584, 2)\n",
      ">>> processing: FERJ 12\n",
      "FERJ 12 (32, 3584, 3) (32, 3584, 4)\n",
      ">>> processing: FERJ 16\n",
      "FERJ 16 (32, 3584, 4) (32, 3584, 6)\n",
      ">>> processing: FERJ 17\n",
      "FERJ 17 (32, 3584, 8) (32, 3584, 11)\n",
      ">>> processing: FERJ 13\n",
      "FERJ 13 (32, 3584, 9) (32, 3584, 13)\n",
      ">>> processing: FERJ 1\n",
      "FERJ 1 (32, 3584, 11) (32, 3584, 15)\n",
      ">>> processing: FERJ 5\n",
      "FERJ 5 (32, 3584, 12) (32, 3584, 17)\n",
      ">>> processing: FERJ 2\n",
      "FERJ 2 (32, 3584, 13) (32, 3584, 18)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Separate each odor in Early and Late parts \n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from brainpipe.system import study\n",
    "from utils import su_list_od #odor_groups_wgth, odor_groups_3wgth\n",
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "from itertools import product\n",
    "\n",
    "st = study('Olfacto')\n",
    "PATH = join(st.path, 'database/Encoding_By_Odor/')\n",
    "od_name = join(PATH, '{}_odor_{}_bipo_all_noWM_physFT.npz')\n",
    "PATH_COND = join(st.path, 'database/Encoding_By_Cond_v=1_elecs=all/')\n",
    "save_name = join(PATH_COND, '{}_odor_early_late.npz')\n",
    "    \n",
    "for su in su_list_od:\n",
    "    early_glob, late_glob = np.array([]), np.array([])\n",
    "    for od in su_list_od[su]:\n",
    "        print('>>> processing:', su, od)\n",
    "        mat = np.load(od_name.format(su,od),allow_pickle=True)\n",
    "        data = mat['x']\n",
    "        early,late = sep_early_late(data)\n",
    "        early_glob = np.concatenate((early_glob, early),\n",
    "                           axis=-1) if np.size(early_glob) else early\n",
    "        if np.size(late):\n",
    "            late_glob = np.concatenate((late_glob, late),\n",
    "                           axis=-1) if np.size(late_glob) else late\n",
    "        print(su, od,early_glob.shape,late_glob.shape)\n",
    "        \n",
    "        dict_pow = {}\n",
    "        for file in mat.files:\n",
    "            dict_pow[file] = mat[file]\n",
    "        dict_pow['x_E'] = early_glob\n",
    "        dict_pow['x_L'] = late_glob\n",
    "        np.savez(save_name.format(su),**dict_pow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      ">>> processing: CHAF 1 low\n",
      "CHAF 1 (61, 3584, 1) (0,)\n",
      ">>> processing: CHAF 2 low\n",
      "CHAF 2 (61, 3584, 2) (61, 3584, 2)\n",
      ">>> processing: CHAF 4 low\n",
      "CHAF 4 (61, 3584, 3) (61, 3584, 2)\n",
      ">>> processing: CHAF 5 low\n",
      "CHAF 5 (61, 3584, 4) (61, 3584, 2)\n",
      ">>> processing: CHAF 3 high\n",
      "CHAF 3 (61, 3584, 1) (61, 3584, 2)\n",
      ">>> processing: CHAF 8 high\n",
      "CHAF 8 (61, 3584, 2) (61, 3584, 4)\n",
      ">>> processing: CHAF 7 high\n",
      "CHAF 7 (61, 3584, 4) (61, 3584, 6)\n",
      ">>> processing: CHAF 9 high\n",
      "CHAF 9 (61, 3584, 6) (61, 3584, 9)\n",
      ">>> processing: VACJ 11 low\n",
      "VACJ 11 (39, 3584, 1) (39, 3584, 2)\n",
      ">>> processing: VACJ 14 low\n",
      "VACJ 14 (39, 3584, 2) (39, 3584, 4)\n",
      ">>> processing: VACJ 12 low\n",
      "VACJ 12 (39, 3584, 3) (39, 3584, 5)\n",
      ">>> processing: VACJ 10 low\n",
      "VACJ 10 (39, 3584, 4) (39, 3584, 7)\n",
      ">>> processing: VACJ 15 high\n",
      "VACJ 15 (39, 3584, 1) (39, 3584, 1)\n",
      ">>> processing: VACJ 17 high\n",
      "VACJ 17 (39, 3584, 2) (39, 3584, 2)\n",
      ">>> processing: VACJ 16 high\n",
      "VACJ 16 (39, 3584, 3) (39, 3584, 4)\n",
      ">>> processing: VACJ 13 high\n",
      "VACJ 13 (39, 3584, 5) (39, 3584, 6)\n",
      ">>> processing: SEMC 7 low\n",
      "SEMC 7 (53, 3584, 2) (53, 3584, 2)\n",
      ">>> processing: SEMC 10 low\n",
      "SEMC 10 (53, 3584, 5) (53, 3584, 6)\n",
      ">>> processing: SEMC 11 low\n",
      "SEMC 11 (53, 3584, 7) (53, 3584, 8)\n",
      ">>> processing: SEMC 12 low\n",
      "SEMC 12 (53, 3584, 10) (53, 3584, 11)\n",
      ">>> processing: SEMC 13 low\n",
      "SEMC 13 (53, 3584, 15) (53, 3584, 16)\n",
      ">>> processing: SEMC 5 high\n",
      "SEMC 5 (53, 3584, 1) (53, 3584, 2)\n",
      ">>> processing: SEMC 8 high\n",
      "SEMC 8 (53, 3584, 2) (53, 3584, 4)\n",
      ">>> processing: SEMC 9 high\n",
      "SEMC 9 (53, 3584, 3) (53, 3584, 6)\n",
      ">>> processing: PIRJ 1 low\n",
      "PIRJ 1 (18, 3584, 3) (18, 3584, 4)\n",
      ">>> processing: PIRJ 9 low\n",
      "PIRJ 9 (18, 3584, 6) (18, 3584, 7)\n",
      ">>> processing: PIRJ 5 low\n",
      "PIRJ 5 (18, 3584, 7) (18, 3584, 7)\n",
      ">>> processing: PIRJ 4 high\n",
      "PIRJ 4 (18, 3584, 2) (18, 3584, 2)\n",
      ">>> processing: PIRJ 6 high\n",
      "PIRJ 6 (18, 3584, 7) (18, 3584, 7)\n",
      ">>> processing: PIRJ 7 high\n",
      "PIRJ 7 (18, 3584, 12) (18, 3584, 12)\n",
      ">>> processing: PIRJ 18 high\n",
      "PIRJ 18 (18, 3584, 14) (18, 3584, 15)\n",
      ">>> processing: LEFC 15 low\n",
      "LEFC 15 (27, 3584, 5) (27, 3584, 6)\n",
      ">>> processing: LEFC 2 low\n",
      "LEFC 2 (27, 3584, 7) (27, 3584, 9)\n",
      ">>> processing: LEFC 1 low\n",
      "LEFC 1 (27, 3584, 8) (27, 3584, 10)\n",
      ">>> processing: LEFC 16 low\n",
      "LEFC 16 (27, 3584, 16) (27, 3584, 18)\n",
      ">>> processing: LEFC 14 high\n",
      "LEFC 14 (27, 3584, 3) (27, 3584, 3)\n",
      ">>> processing: LEFC 3 high\n",
      "LEFC 3 (27, 3584, 5) (27, 3584, 5)\n",
      ">>> processing: LEFC 4 high\n",
      "LEFC 4 (27, 3584, 7) (27, 3584, 7)\n",
      ">>> processing: LEFC 17 high\n",
      "LEFC 17 (27, 3584, 10) (27, 3584, 11)\n",
      ">>> processing: FERJ 7 low\n",
      "FERJ 7 (32, 3584, 1) (32, 3584, 2)\n",
      ">>> processing: FERJ 12 low\n",
      "FERJ 12 (32, 3584, 3) (32, 3584, 4)\n",
      ">>> processing: FERJ 16 low\n",
      "FERJ 16 (32, 3584, 4) (32, 3584, 6)\n",
      ">>> processing: FERJ 17 low\n",
      "FERJ 17 (32, 3584, 8) (32, 3584, 11)\n",
      ">>> processing: FERJ 13 high\n",
      "FERJ 13 (32, 3584, 1) (32, 3584, 2)\n",
      ">>> processing: FERJ 1 high\n",
      "FERJ 1 (32, 3584, 3) (32, 3584, 4)\n",
      ">>> processing: FERJ 5 high\n",
      "FERJ 5 (32, 3584, 4) (32, 3584, 6)\n",
      ">>> processing: FERJ 2 high\n",
      "FERJ 2 (32, 3584, 5) (32, 3584, 7)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Separate each odor in Early and Late parts + MEMORY COND\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from brainpipe.system import study\n",
    "from utils import su_list_od, odor_groups_wgth #odor_groups_wgth, odor_groups_3wgth\n",
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "from itertools import product\n",
    "\n",
    "st = study('Olfacto')\n",
    "PATH = join(st.path, 'database/Encoding_By_Odor/')\n",
    "od_name = join(PATH, '{}_odor_{}_bipo_all_noWM_physFT.npz')\n",
    "PATH_COND = join(st.path, 'database/Encoding_By_Cond_v=1_elecs=all/')\n",
    "save_name = join(PATH_COND, '{}_odor_cond={}_early_late.npz')\n",
    "    \n",
    "for su in odor_groups_wgth:\n",
    "    for cond in odor_groups_wgth[su]:\n",
    "        early_glob, late_glob = np.array([]), np.array([])\n",
    "        for od in odor_groups_wgth[su][cond]:\n",
    "            print('>>> processing:', su, od,cond)\n",
    "            mat = np.load(od_name.format(su,od),allow_pickle=True)\n",
    "            data = mat['x']\n",
    "            early,late = sep_early_late(data)\n",
    "            early_glob = np.concatenate((early_glob, early),\n",
    "                               axis=-1) if np.size(early_glob) else early\n",
    "            if np.size(late):\n",
    "                late_glob = np.concatenate((late_glob, late),\n",
    "                               axis=-1) if np.size(late_glob) else late\n",
    "            print(su, od,early_glob.shape,late_glob.shape)\n",
    "\n",
    "            dict_pow = {}\n",
    "            for file in mat.files:\n",
    "                dict_pow[file] = mat[file]\n",
    "            dict_pow['x_E'] = early_glob\n",
    "            dict_pow['x_L'] = late_glob\n",
    "            np.savez(save_name.format(su,cond),**dict_pow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take same electrodes and labels Odor and No Odor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "CHAF ['SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG'\n",
      " 'ACC' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'ACC'\n",
      " 'ACC' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG'\n",
      " 'MFG' 'MFG' 'MFG' 'MFG' 'MFG' 'MFG' 'MFG' 'MFG' 'MFG' 'MFG' 'OFC_olf'\n",
      " 'OFC_olf' 'OFC_olf' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'MFG'\n",
      " 'MFG' 'MFG' 'MFG']\n",
      "VACJ ['aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'Amg' 'Amg' 'Amg' 'IFG'\n",
      " 'IFG' 'IFG' 'IFG' 'IFG' 'MFG' 'MFG' 'pPirT' 'ACC' 'MFG' 'MFG' 'MFG' 'MFG'\n",
      " 'MFG' 'MFG' 'ACC' 'IFG' 'IFG' 'IFG' 'IFG' 'IFG' 'IFG' 'OFC_olf' 'OFC_olf'\n",
      " 'OFC_olf' 'OFC_olf' 'IFG' 'IFG']\n",
      "SEMC ['aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'IFG' 'IFG' 'IFG' 'IFG' 'IFG' 'IFG' 'MFG'\n",
      " 'MFG' 'MFG' 'IFG' 'IFG' 'ACC' 'MFG' 'MFG' 'MFG' 'MFG' 'ACC' 'OFC_olf'\n",
      " 'OFC_olf' 'OFC_olf' 'IFG' 'IFG' 'IFG' 'IFG' 'ACC' 'IFG' 'IFG' 'IFG' 'IFG'\n",
      " 'IFG' 'ACC' 'MFG' 'MFG' 'MFG' 'MFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'SFG'\n",
      " 'SFG' 'SFG' 'SFG' 'SFG' 'SFG' 'MFG' 'MFG']\n",
      "PIRJ ['aHC' 'PHG' 'PHG' 'PHG' 'PHG' 'PHG' 'OFC_olf' 'OFC_olf' 'OFC_olf'\n",
      " 'OFC_olf' 'IFG' 'IFG' 'IFG' 'IFG' 'Ins_olf' 'Ins_olf' 'Ins_olf' 'Ins_olf']\n",
      "LEFC ['pPirT' 'aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'SFG' 'SFG' 'SFG'\n",
      " 'MFG' 'MFG' 'MFG' 'MFG' 'MFG' 'OFC_olf' 'OFC_olf' 'OFC_olf' 'OFC_olf'\n",
      " 'OFC_olf' 'IFG' 'IFG' 'IFG' 'SFG' 'SFG']\n",
      "FERJ ['Amg' 'Amg' 'aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'aHC' 'aHC'\n",
      " 'aHC' 'aHC' 'aHC' 'aHC' 'Ins_olf' 'Ins_olf' 'Ins_olf' 'Ins_olf' 'pPirT'\n",
      " 'pPirT' 'pPirT' 'pPirT' 'IFG' 'IFG' 'IFG' 'IFG' 'Ins_olf' 'Ins_olf'\n",
      " 'Ins_olf' 'Ins_olf']\n"
     ]
    }
   ],
   "source": [
    "from brainpipe.system import study\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from utils import su_list_od\n",
    "\n",
    "st= study('Olfacto')\n",
    "filename = join(st.path,\n",
    "             'database/Encoding_By_Odor/{}_odor_{}_bipo_all_noWM_physFT.npz')\n",
    "file_no_od = join(st.path,\n",
    "             'database/Encoding_No_Odor/{}_odor_no_odor_bipo_sel_phys.npz')\n",
    "\n",
    "files_to_match = []\n",
    "for su in su_list_od:\n",
    "    for od in su_list_od[su][:1]:\n",
    "        files_to_match.append(filename.format(su,od))\n",
    "\n",
    "for fi in files_to_match:\n",
    "    match = np.load(fi,allow_pickle=True)\n",
    "    su = fi.split('/')[-1][:4]\n",
    "    mat_no_odor = np.load(file_no_od.format(su),allow_pickle=True)\n",
    "    channels_m = match['channels']\n",
    "    channels_no_od = mat_no_odor['channels']\n",
    "    idx_sel = [i for i,chan in enumerate(channels_no_od) if chan in channels_m]\n",
    "    \n",
    "    dict_data = {}\n",
    "    for file in match.files:\n",
    "        dict_data[file] = match[file] if file != 'sf' else match[file]\n",
    "    dict_data['x'] = mat_no_odor['x'][idx_sel,...]\n",
    "    print(su,match['Mai_RL'])\n",
    "    np.savez(file_no_od.format(su).replace('phys.npz','physFT.npz'),**dict_data)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
