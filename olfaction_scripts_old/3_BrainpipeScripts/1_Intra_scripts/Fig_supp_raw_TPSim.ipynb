{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenate RAW data as function of cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      ">>> processing: CHAF low\n",
      "CHAF 1 low (61,) (61, 3584, 1)\n",
      "CHAF 2 low (61,) (61, 3584, 4)\n",
      "CHAF 4 low (61,) (61, 3584, 5)\n",
      "CHAF 5 low (61,) (61, 3584, 6)\n",
      ">>> processing: CHAF high\n",
      "CHAF 3 high (61,) (61, 3584, 3)\n",
      "CHAF 8 high (61,) (61, 3584, 6)\n",
      "CHAF 7 high (61,) (61, 3584, 10)\n",
      "CHAF 9 high (61,) (61, 3584, 15)\n",
      ">>> processing: VACJ low\n",
      "VACJ 11 low (39,) (39, 3584, 3)\n",
      "VACJ 14 low (39,) (39, 3584, 6)\n",
      "VACJ 12 low (39,) (39, 3584, 8)\n",
      "VACJ 10 low (39,) (39, 3584, 11)\n",
      ">>> processing: VACJ high\n",
      "VACJ 15 high (39,) (39, 3584, 2)\n",
      "VACJ 17 high (39,) (39, 3584, 4)\n",
      "VACJ 16 high (39,) (39, 3584, 7)\n",
      "VACJ 13 high (39,) (39, 3584, 11)\n",
      ">>> processing: SEMC low\n",
      "SEMC 7 low (53,) (53, 3584, 4)\n",
      "SEMC 10 low (53,) (53, 3584, 11)\n",
      "SEMC 11 low (53,) (53, 3584, 15)\n",
      "SEMC 12 low (53,) (53, 3584, 21)\n",
      "SEMC 13 low (53,) (53, 3584, 31)\n",
      ">>> processing: SEMC high\n",
      "SEMC 5 high (53,) (53, 3584, 3)\n",
      "SEMC 8 high (53,) (53, 3584, 6)\n",
      "SEMC 9 high (53,) (53, 3584, 9)\n",
      ">>> processing: PIRJ low\n",
      "PIRJ 1 low (24,) (24, 3584, 7)\n",
      "PIRJ 9 low (24,) (24, 3584, 13)\n",
      "PIRJ 5 low (24,) (24, 3584, 14)\n",
      ">>> processing: PIRJ high\n",
      "PIRJ 4 high (24,) (24, 3584, 4)\n",
      "PIRJ 6 high (24,) (24, 3584, 5)\n",
      "PIRJ 7 high (24,) (24, 3584, 6)\n",
      "PIRJ 18 high (24,) (24, 3584, 11)\n",
      ">>> processing: LEFC low\n",
      "LEFC 15 low (27,) (27, 3584, 11)\n",
      "LEFC 2 low (27,) (27, 3584, 16)\n",
      "LEFC 1 low (27,) (27, 3584, 18)\n",
      "LEFC 16 low (27,) (27, 3584, 34)\n",
      ">>> processing: LEFC high\n",
      "LEFC 14 high (27,) (27, 3584, 6)\n",
      "LEFC 3 high (27,) (27, 3584, 10)\n",
      "LEFC 4 high (27,) (27, 3584, 14)\n",
      "LEFC 17 high (27,) (27, 3584, 21)\n",
      ">>> processing: FERJ low\n",
      "FERJ 7 low (32,) (32, 3584, 3)\n",
      "FERJ 12 low (32,) (32, 3584, 7)\n",
      "FERJ 16 low (32,) (32, 3584, 10)\n",
      "FERJ 17 low (32,) (32, 3584, 19)\n",
      ">>> processing: FERJ high\n",
      "FERJ 13 high (32,) (32, 3584, 3)\n",
      "FERJ 1 high (32,) (32, 3584, 7)\n",
      "FERJ 5 high (32,) (32, 3584, 10)\n",
      "FERJ 2 high (32,) (32, 3584, 12)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from brainpipe.system import study\n",
    "from utils import odor_groups_wgth as dict_ #odor_groups_3wgth\n",
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "from itertools import product\n",
    "\n",
    "st = study('Olfacto')\n",
    "phase = 'E'\n",
    "PATH = join(st.path, 'database/')\n",
    "PATH_OD = join(PATH, 'Encoding_By_Odor/')\n",
    "od_name = join(PATH_OD, '{}_odor_{}_bipo_all_noWM_physFT.npz')\n",
    "PATH_COND = join(PATH, 'Encoding_By_Cond_v=1_elecs=all/')\n",
    "save_name = join(PATH_COND, '{}_odor_{}_{}.npz')\n",
    "\n",
    "if not exists(PATH_COND):\n",
    "    makedirs(PATH_COND)\n",
    "    \n",
    "for su in dict_:\n",
    "    for cond in dict_[su]:\n",
    "        print('>>> processing:', su, cond)\n",
    "        data = np.array([])\n",
    "        for od in dict_[su][cond]:\n",
    "            mat = np.load(od_name.format(su,od),allow_pickle=True)\n",
    "            data = np.concatenate((data, mat['x']),axis=-1) if np.size(data) else mat['x']\n",
    "            print(su, od, cond, mat['channels'].shape,data.shape)\n",
    "        dict_pow = {}\n",
    "        for file in mat.files:\n",
    "            dict_pow[file] = mat[file]\n",
    "        dict_pow['x'] = data\n",
    "        np.savez(save_name.format(su,cond,phase),**dict_pow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute TPSim for RAW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "PIRJ low (24, 3584, 14)\n",
      "PIRJ low TPSim (24, 91) initial data (24, 1536, 14)\n",
      "PIRJ mid (24, 3584, 9)\n",
      "PIRJ mid TPSim (24, 36) initial data (24, 1536, 9)\n",
      "PIRJ high (24, 3584, 2)\n",
      "PIRJ high TPSim (24, 1) initial data (24, 1536, 2)\n",
      "CHAF low (61, 3584, 5)\n",
      "CHAF low TPSim (61, 10) initial data (61, 1536, 5)\n",
      "CHAF mid (61, 3584, 4)\n",
      "CHAF mid TPSim (61, 6) initial data (61, 1536, 4)\n",
      "CHAF high (61, 3584, 12)\n",
      "CHAF high TPSim (61, 66) initial data (61, 1536, 12)\n",
      "FERJ low (32, 3584, 16)\n",
      "FERJ low TPSim (32, 120) initial data (32, 1536, 16)\n",
      "FERJ mid (32, 3584, 6)\n",
      "FERJ mid TPSim (32, 15) initial data (32, 1536, 6)\n",
      "FERJ high (32, 3584, 9)\n",
      "FERJ high TPSim (32, 36) initial data (32, 1536, 9)\n",
      "VACJ low (39, 3584, 9)\n",
      "VACJ low TPSim (39, 36) initial data (39, 1536, 9)\n",
      "VACJ mid (39, 3584, 4)\n",
      "VACJ mid TPSim (39, 6) initial data (39, 1536, 4)\n",
      "VACJ high (39, 3584, 9)\n",
      "VACJ high TPSim (39, 36) initial data (39, 1536, 9)\n",
      "SEMC low (53, 3584, 21)\n",
      "SEMC low TPSim (53, 210) initial data (53, 1536, 21)\n",
      "SEMC mid (53, 3584, 10)\n",
      "SEMC mid TPSim (53, 45) initial data (53, 1536, 10)\n",
      "SEMC high (53, 3584, 9)\n",
      "SEMC high TPSim (53, 36) initial data (53, 1536, 9)\n",
      "LEFC low (27, 3584, 23)\n",
      "LEFC low TPSim (27, 253) initial data (27, 1536, 23)\n",
      "LEFC mid (27, 3584, 15)\n",
      "LEFC mid TPSim (27, 105) initial data (27, 1536, 15)\n",
      "LEFC high (27, 3584, 17)\n",
      "LEFC high TPSim (27, 136) initial data (27, 1536, 17)\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "\"\"\"\n",
    "Compute TPSim by combining all odors from each CONDITION\n",
    "\"\"\"\n",
    "exp = 'Enc'\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_data = join(st.path, 'database/Encoding_By_Cond_v=1_elecs=all/')\n",
    "pow_file = join(path_data, '{}_odor_{}_'+exp[0]+'.npz')\n",
    "pathsave = join(st.path,'feature/TPSim_3groups_{}/TPS_RAW_btw_v=1_elecs=all/')#_'+RT_type+'/')\n",
    "savename = join(pathsave,'TPS_pears_{}_{}_btw.npz')\n",
    "\n",
    "###############################################################################\n",
    "if not exists(pathsave.format(exp)):\n",
    "    makedirs(pathsave.format(exp))\n",
    "#############################################RT_type##################################\n",
    "subjects = ['PIRJ','CHAF','FERJ','VACJ','SEMC','LEFC']\n",
    "conds = ['low','mid','high']\n",
    "to_take = [1024,2560] #from -1s to +2s in frames\n",
    "\n",
    "def tpsim_by_cond(su,cond):\n",
    "    mat = np.load(pow_file.format(su,cond),allow_pickle=True)\n",
    "    print(su,cond,mat['x'].shape)\n",
    "    data = mat['x'][:,to_take[0]:to_take[1],:] #3584 points \n",
    "    nelecs,npts,ntrials = data.shape\n",
    "    ncomb = len([t0 for t0,_ in combinations(np.arange(ntrials), 2)])\n",
    "    tps_su = np.zeros((nelecs,ncomb))\n",
    "    for elec in range(nelecs):\n",
    "        x0 = data[elec,...]\n",
    "        i = 0\n",
    "        for t0, t1 in combinations(np.arange(ntrials), 2):\n",
    "            R, _ = stats.pearsonr(x0[:,t0],x0[:,t1])\n",
    "            D = 1 - R # <<<<<<< HERE TO CHANGE FOR DISTANCE COMPUTATIONS\n",
    "            tps_su[elec,i] += D\n",
    "            i += 1\n",
    "    print(su,cond,'TPSim',tps_su.shape,'initial data',data.shape)\n",
    "    dict_ = {'tps':tps_su, 'label':mat['Mai_RL'], 'channel':mat['channels'], 'xyz':mat['xyz']}\n",
    "    np.savez(savename.format(exp,su,cond),**dict_)\n",
    "\n",
    "for su,cond in product(subjects,conds):\n",
    "    tpsim_by_cond(su,cond)\n",
    "# Parallel(n_jobs=-1)(delayed(\n",
    "#     tpsim_by_cond)(su,cond) for su,cond in product(subjects,conds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Linear Regression analyses and summarize stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "(236, 14)\n"
     ]
    }
   ],
   "source": [
    "from utils import rename_elecs\n",
    "import statsmodels.api as sm\n",
    "from mne.stats import fdr_correction, bonferroni_correction\n",
    "import pandas as pd\n",
    "\"\"\"\n",
    "Correlate TPSim with behavioral variables // Memory group\n",
    "BY ELECTRODE and Plot summary (for all included electrodes)\n",
    "\"\"\"\n",
    "\n",
    "exps = ['Enc']\n",
    "meth, conds, stat = 'RAW_btw', ['low','mid','high'], 'LinReg'\n",
    "subjects = ['CHAF','VACJ','PIRJ','SEMC','FERJ','LEFC']\n",
    "rois_sel = ['aHC','MFG','ACC','IFG','Amg','pPirT','PHG','Ins_olf',\n",
    "            'OFC_olf','SFG']\n",
    "dict_perf = {'low':1, 'mid':2, 'high':3}\n",
    "st = study('Olfacto')\n",
    "\n",
    "for exp in exps:\n",
    "    ###############################################################################\n",
    "    path_tps = join(st.path, 'feature/TPSim_3groups_'+exp+'/')\n",
    "    tps_form = join(path_tps, 'TPS_'+meth+'_v=1_elecs=all/TPS_pears_{}_{}_btw.npz')\n",
    "    df_path = join(path_tps, 'LinReg_stats_RAW_v=1_elecs=all/')\n",
    "    df_name = join(df_path, '{}_ols_'+meth+'_RAW_{}.csv') #su, conds0, conds1, freq\n",
    "    ###############################################################################\n",
    "    if not exists(df_path):\n",
    "        makedirs(df_path)\n",
    "\n",
    "    subjects_c, elecs_c, labels_c = np.array([]), np.array([]), np.array([])\n",
    "    channels_c, x_c, y_c, z_c = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "    tps_scores, T_vals_c, p_vals_c = np.array([]), np.array([]), np.array([])\n",
    "    p_fdr_c, p_bf_c = np.array([]), np.array([])\n",
    "\n",
    "    for su in subjects:\n",
    "        #load all elec info,rename and select electrodes id\n",
    "        mat = np.load(tps_form.format(su,conds[0]),allow_pickle=True)\n",
    "        labels, channels = mat['label'], mat['channel']\n",
    "        x, y, z = mat['xyz'][:,0], mat['xyz'][:,1], mat['xyz'][:,2]\n",
    "        labels_new = rename_elecs(labels,x,y,z)\n",
    "        idx_sel = [i for i,lab in enumerate(labels_new) if lab in rois_sel]\n",
    "        labels, channels = labels_new[idx_sel], channels[idx_sel]\n",
    "        x, y, z = x[idx_sel], y[idx_sel], z[idx_sel]\n",
    "\n",
    "        if stat == 'LinReg':\n",
    "            tps_su = np.zeros((len(idx_sel),len(conds)))\n",
    "            all_tps, all_scores = [], []\n",
    "            for c,cond in enumerate(conds):\n",
    "                mat = np.load(tps_form.format(su,cond))\n",
    "                tps = mat['tps'][idx_sel]\n",
    "                nelecs, ntrials = tps.shape\n",
    "                score_ = np.array([dict_perf[cond]]*ntrials)\n",
    "                tps_su[:,c] += np.mean(tps,axis=1)\n",
    "                #fill tps and score vectors\n",
    "                all_tps.append(tps)\n",
    "                all_scores.append(score_)\n",
    "\n",
    "            #compute stats Ttests-unpaired\n",
    "            all_tps = np.concatenate(all_tps,axis=1)\n",
    "            all_scores = np.concatenate(all_scores,axis=0)\n",
    "            T, unc_p = [], []\n",
    "            for elec in range(nelecs):\n",
    "                #Tval,pval = stats.kendalltau(all_tps[elec],all_scores)\n",
    "                Y, X = np.array(all_tps[elec]), sm.add_constant(np.array(all_scores))\n",
    "                model_ols = sm.OLS(Y,X).fit()\n",
    "                Tval, pval = np.round(model_ols.tvalues[1],3),model_ols.pvalues[1]\n",
    "                T.append(Tval), unc_p.append(pval)\n",
    "        if stat == 'Ttest':\n",
    "            tps0 = np.load(tps_form.format(su,conds[0]))['tps'][idx_sel]\n",
    "            nelecs = len(idx_sel)\n",
    "            tps1 = np.load(tps_form.format(su,conds[1]))['tps'][idx_sel]\n",
    "            mean0, mean1 = np.mean(tps0,axis=1)[:,np.newaxis], np.mean(tps1,axis=1)[:,np.newaxis]\n",
    "            tps_su = np.concatenate((mean0,mean1),axis=1)\n",
    "            #compute stats Ttests-unpaired\n",
    "            tps0, tps1 = tps0.swapaxes(0,1), tps1.swapaxes(0,1) #ntrials x nelecs\n",
    "            T, unc_p = ttest_ind(tps0, tps1, equal_var=False)\n",
    "            print(T.shape, unc_p.shape)\n",
    "        _, p_fdr = fdr_correction(unc_p)\n",
    "        _, p_bf = bonferroni_correction(unc_p)\n",
    "\n",
    "        #fill all df data\n",
    "        subjects_c = np.hstack((subjects_c,np.array([su]*nelecs))) if np.size(subjects_c) else np.array([su]*nelecs)\n",
    "        elecs_c = np.hstack((elecs_c,np.arange(nelecs))) if np.size(elecs_c) else np.arange(nelecs)\n",
    "        labels_c = np.hstack((labels_c,labels)) if np.size(labels_c) else labels\n",
    "        channels_c = np.hstack((channels_c,channels)) if np.size(channels_c) else channels\n",
    "        tps_scores = np.concatenate((tps_scores,tps_su),axis=0) if np.size(tps_scores) else tps_su\n",
    "        x_c = np.hstack((x_c,x)) if np.size(x_c) else x\n",
    "        y_c = np.hstack((y_c,y)) if np.size(y_c) else y\n",
    "        z_c = np.hstack((z_c,z)) if np.size(z_c) else z\n",
    "        T_vals_c = np.hstack((T_vals_c,T)) if np.size(T_vals_c) else T\n",
    "        p_vals_c = np.hstack((p_vals_c,unc_p)) if np.size(p_vals_c) else unc_p\n",
    "        p_fdr_c = np.hstack((p_fdr_c,p_fdr)) if np.size(p_fdr_c) else p_fdr\n",
    "        p_bf_c = np.hstack((p_bf_c,p_bf)) if np.size(p_bf_c) else p_bf\n",
    "\n",
    "    data = np.concatenate((subjects_c[:,np.newaxis],labels_c[:,np.newaxis],\n",
    "                channels_c[:,np.newaxis],x_c[:,np.newaxis],y_c[:,np.newaxis],\n",
    "                z_c[:,np.newaxis],elecs_c[:,np.newaxis],tps_scores,T_vals_c[:,np.newaxis],\n",
    "                p_vals_c[:,np.newaxis],p_fdr_c[:,np.newaxis],p_bf_c[:,np.newaxis]),\n",
    "                axis=1)\n",
    "    df = pd.DataFrame(data, columns=['subjects','labels','channels','x','y','z',\n",
    "                            'elecs_num', 'tps_'+conds[0], 'tps_'+conds[1],'tps_'+conds[2],\n",
    "                                    'Tvals', 'unc_p','fdr_p', 'bonf_p'])\n",
    "    print(df.shape)\n",
    "    df.to_csv(df_name.format('All_subjects',stat),index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "Initial df shape (236, 14) btw Enc LinReg\n",
      "\n",
      " btw stats at p <  0.05 correction :  fdr_p (3, 15)\n",
      "    subjects   labels channels      x      y      z  elecs_num   tps_low  \\\n",
      "211     LEFC      aHC    b3-b2  34.55 -20.30 -10.85          2  1.003046   \n",
      "223     LEFC      MFG   k10-k9  40.35  46.55  12.60         14  1.013134   \n",
      "230     LEFC  OFC_olf    o7-o6  28.95  38.65 -13.55         21  1.022978   \n",
      "\n",
      "      tps_mid  tps_high  Tvals     unc_p    fdr_p    bonf_p        sign  \n",
      "211  0.974159  0.954550 -3.075  0.002219  0.02478  0.059924  completion  \n",
      "223  1.011890  0.917893 -4.376  0.000015  0.00040  0.000400  completion  \n",
      "230  0.967591  0.951690 -3.009  0.002753  0.02478  0.074339  completion  \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "st = study('Olfacto')\n",
    "exp, stat = 'Enc', 'LinReg'#'Enc'\n",
    "meth = 'btw'\n",
    "thrs = [0.05]\n",
    "corrections = ['fdr_p']\n",
    "\n",
    "##################################################################################\n",
    "path_pow = join(st.path, 'feature/TPSim_3groups_'+exp+'/LinReg_stats_RAW_v=1_elecs=all/')\n",
    "df_name = join(path_pow, 'All_subjects_ols_RAW_btw_RAW_LinReg.csv') #su, conds0, conds1, freq\n",
    "df_stat_save = join(path_pow, 'Bilan_{}_OLS_'+meth+'_{}_{}_{}_{}_{}_{}.csv')\n",
    "df_stat_all = join(path_pow, 'Bilan_{}_OLS_'+meth+'_{}_{}_{}_{}.csv')\n",
    "##################################################################################\n",
    "\n",
    "df = pd.read_csv(df_name)\n",
    "print('Initial df shape', df.shape, meth, exp, stat)\n",
    "\n",
    "for th, corr in product(thrs,corrections):\n",
    "    df_sel = df.loc[df[corr]<th]\n",
    "    df_sel['sign'] = ['separation' if t > 0 else 'completion' for t in df_sel['Tvals']]\n",
    "    print('\\n',meth,'stats at p < ',th, 'correction : ',corr, df_sel.shape)\n",
    "    print(df_sel)\n",
    "    rois = np.unique(df_sel['labels'])\n",
    "    for roi in rois:\n",
    "        df_roi = df_sel.loc[df_sel['labels']==roi]\n",
    "        df_inc = df_roi.loc[df_roi['sign']=='completion'].groupby(['subjects']).count()\n",
    "        df_dec = df_roi.loc[df_roi['sign']=='separation'].groupby(['subjects']).count()\n",
    "\n",
    "        if (df_inc.shape[0] >= 3):\n",
    "            print(roi, 'NB of subjects with completion',df_inc.shape[0],' subjects')\n",
    "            df_plot = df_roi.loc[df_roi['sign']=='completion']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "            df_plot.to_csv(df_stat_save.format('All_subjects','RAW','mem_groups',\n",
    "                                               'compl',roi,corr+str(th),stat))\n",
    "\n",
    "        if (df_dec.shape[0] >= 3):\n",
    "            print(roi, 'NB of subjects with separation',df_dec.shape[0],' subjects')\n",
    "            df_plot = df_roi.loc[df_roi['sign']=='separation']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "            df_plot.to_csv(df_stat_save.format('All_subjects','RAW','mem_groups',\n",
    "                                               'sep',roi,corr+str(th),stat))\n",
    "            #print(df_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
