{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from brainpipe.system import study\n",
    "from scipy.stats import ttest_ind\n",
    "from Ttests_perm_arthur import ttest_perm\n",
    "from mne.stats import fdr_correction, bonferroni_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "x0,y0,z0 = 20, 30,-16 #VOI for olf OFC\n",
    "x1,y1,z1 = -20, 32,-16 #VOI for olf OFC\n",
    "x0_ins,y0_ins,z0_ins = 42.0, -7.3, 0.3 #VOI for olf Ins\n",
    "x1_ins,y1_ins,z1_ins = -38, -4, 12 #VOI for olf Ins\n",
    "rad = 11 #radius of the VOI\n",
    "HC_lim = -26 #limit anterior/posterior part of the aHC\n",
    "\n",
    "def rename_elecs(names,x,y,z):\n",
    "    \n",
    "    labels = ['pPirT' if lab in ['Amg-PirT'] else lab for lab in names]\n",
    "\n",
    "    labels = ['aHC' if lab == 'HC' and y[i] > -26 else lab \\\n",
    "                                  for i,lab in enumerate(labels)]\n",
    "    \n",
    "    id_R_OFC = [1 if all([x0-rad<=round(x[i])<=x0+rad, y0-rad<=round(y[i])<=y0+rad,\n",
    "                    z0-rad<=round(z[i])<=z0+rad]) else 0 for i in range(len(labels))]\n",
    "    id_L_OFC = [1 if all([x1-rad<=round(x[i])<=x1+rad, y1-rad<=round(y[i])<=y1+rad,\n",
    "                    z1-rad<=round(z[i])<=z1+rad]) else 0 for i in range(len(labels))]\n",
    "    idx_OFC = id_R_OFC + id_L_OFC\n",
    "    labels = ['OFC_olf' if i == 1 else lab for i,lab in zip(idx_OFC,labels)]\n",
    "    \n",
    "    id_R_ins = [1 if all([x0_ins-rad<=round(x[i])<=x0_ins+rad, y0_ins-rad<=round(y[i])<=y0_ins+rad,\n",
    "                    z0_ins-rad<=round(z[i])<=z0_ins+rad]) else 0 for i in range(len(labels))]\n",
    "    id_L_ins = [1 if all([x1_ins-rad<=round(x[i])<=x1_ins+rad, y1_ins-rad<=round(y[i])<=y1_ins+rad,\n",
    "                    z1_ins-rad<=round(z[i])<=z1_ins+rad]) else 0 for i in range(len(labels))]\n",
    "    idx_ins = id_R_ins + id_L_ins\n",
    "    labels = ['Ins_olf' if i == 1 else lab for i,lab in zip(idx_ins,labels)]\n",
    "\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "0.025278227210930215 0.020477859799328094\n",
      "VACJ ['tps', 'pval', 'label', 'channel', 'xyz'] TPS shape:  (48, 132) (48, 132)\n",
      "0.027658502810104946 0.01785139923073272\n",
      "SEMC ['tps', 'pval', 'label', 'channel', 'xyz'] TPS shape:  (62, 81) (62, 465)\n",
      "0.00726556844465632 0.004365265448658761\n",
      "LEFC ['tps', 'pval', 'label', 'channel', 'xyz'] TPS shape:  (36, 252) (36, 408)\n",
      "0.8983979239555274 0.9036151860255727\n",
      "PIRJ ['tps', 'pval', 'label', 'channel', 'xyz'] TPS shape:  (30, 176) (30, 168)\n",
      "0.9146123164882075 0.9351694224007469\n",
      "FERJ ['tps', 'pval', 'label', 'channel', 'xyz'] TPS shape:  (45, 144) (45, 228)\n",
      "0.02214815248478383 -0.006229468740445851\n",
      "CHAF ['tps', 'pval', 'label', 'channel', 'xyz'] TPS shape:  (57, 180) (57, 72)\n",
      "(232, 14)\n"
     ]
    }
   ],
   "source": [
    "st = study('Olfacto')\n",
    "exp = 'Enc_Ret'#'Enc'\n",
    "fold = 'E_R'\n",
    "perf, meth = 'btw', 'BTW'\n",
    "conds, subjects = ['high','low'],['VACJ','SEMC','LEFC','PIRJ','FERJ','CHAF']\n",
    "freqs = ['theta']\n",
    "path_pow = path.join(st.path, 'feature/TPSim_'+exp+'_By_Odor_By_Cond/TPS_by_cond/6freqs/')\n",
    "filename = path.join(path_pow, 'TPS_spear_{}_cond_{}_{}_6freqs_3s_dissim.npz')\n",
    "#path_pow = path.join(st.path, 'feature/TPSim_'+exp+'_By_Odor_By_Cond/TPS_by_odor/')\n",
    "#filename = path.join(path_pow, 'TPS_pears_{}_{}_{}.npz')\n",
    "#filename = path.join(path_pow, 'TPS_pears_{}_{}_{}_{}_'+meth+'_med_split.npz')\n",
    "save_path = path.join(st.path, 'feature/TPSim_'+exp+'_By_Odor_By_Cond/TPS_by_odor/')\n",
    "df_name = path.join(save_path, '{}_Ttests_old_{}_{}_{}_{}.csv') #su, conds0, conds1, freq\n",
    "#df_name = path.join(path_pow, '{}_Ttests_'+meth+'_'+perf+'_{}_{}_{}.csv') #su, conds0, conds1, freq\n",
    "#df_name = path.join(path_pow, '{}_Ttests_'+perf+'_{}_{}_{}.csv') #su, conds0, conds1, freq\n",
    "nperm = 1000\n",
    "\n",
    "rois_sel = ['aHC','MFG','ACC','IFG','Amg','pPirT','PHG','Ins_olf','OFC_olf','SFG']\n",
    "\n",
    "for freq in freqs:\n",
    "    subjects_c, elecs_c, labels_c = np.array([]), np.array([]), np.array([])\n",
    "    channels_c, x_c, y_c, z_c = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "    tps0_c, tps1_c = np.array([]), np.array([])\n",
    "    T_vals_c, p_vals_c, p_max_c = np.array([]), np.array([]), np.array([])\n",
    "    p_fdr_c, p_bf_c = np.array([]), np.array([])\n",
    "    \n",
    "    for su in subjects:\n",
    "        if path.exists(filename.format(su,conds[0],freq)):\n",
    "            mat0 = np.load(filename.format(su,conds[0],freq),allow_pickle=True)\n",
    "            #mat0b = np.load(filename.format(su,conds[1],perf[0],freq))['tps']\n",
    "            #tps0 = np.concatenate((mat0['tps'],mat0b),axis=-1)\n",
    "            tps0 = mat0['tps']\n",
    "            labels, channels = mat0['label'], mat0['channel']\n",
    "            x, y, z = mat0['xyz'][:,0], mat0['xyz'][:,1], mat0['xyz'][:,2]\n",
    "            tps1 = np.load(filename.format(su,conds[1],freq))['tps']\n",
    "            #mat1b = np.load(filename.format(su,conds[1],perf[1],freq))['tps']\n",
    "            #tps1 = np.concatenate((mat1,mat1b),axis=-1)\n",
    "            print(np.mean(tps0),np.mean(tps1))\n",
    "            print (su,mat0.files, 'TPS shape: ', tps0.shape, tps1.shape)\n",
    "            \n",
    "            #rename electrodes labels and select only specific electrodes\n",
    "            labels_new = rename_elecs(labels,x,y,z)\n",
    "            idx_sel = [i for i,lab in enumerate(labels_new) if lab in rois_sel]\n",
    "            tps0, labels, channels = tps0[idx_sel,:], labels_new[idx_sel], channels[idx_sel]\n",
    "            x, y, z, tps1 = x[idx_sel], y[idx_sel], z[idx_sel], tps1[idx_sel,:]\n",
    "            nelecs = len(idx_sel)\n",
    "            \n",
    "            #compute stats Ttests-unpaired\n",
    "            tps0, tps1 = tps0.swapaxes(0,1), tps1.swapaxes(0,1) #ntrials x nelecs\n",
    "            Tvals, unc_p = ttest_ind(tps0, tps1, equal_var=False)\n",
    "            Tvals2, pvals = ttest_perm(tps0, tps1, n_perm=nperm, correction='maxstat',\n",
    "                                  two_tailed=False, paired=False, equal_var=False, n_jobs=-1)\n",
    "            _, p_fdr = fdr_correction(unc_p)\n",
    "            _, p_bf = bonferroni_correction(unc_p)\n",
    "            #print(Tvals,unc_p, p_fdr)\n",
    "            #print(Tvals2,pvals)\n",
    "\n",
    "            #Fill the csv file with elec infos and stats\n",
    "            subjects_c = np.hstack((subjects_c,np.array([su]*nelecs))) if np.size(subjects_c) else np.array([su]*nelecs)\n",
    "            elecs_c = np.hstack((elecs_c,np.arange(nelecs))) if np.size(elecs_c) else np.arange(nelecs)\n",
    "            labels_c = np.hstack((labels_c,labels)) if np.size(labels_c) else labels\n",
    "            channels_c = np.hstack((channels_c,channels)) if np.size(channels_c) else channels\n",
    "            x_c = np.hstack((x_c,x)) if np.size(x_c) else x\n",
    "            y_c = np.hstack((y_c,y)) if np.size(y_c) else y\n",
    "            z_c = np.hstack((z_c,z)) if np.size(z_c) else z\n",
    "            tps0_c = np.hstack((tps0_c,np.mean(tps0, axis=0))) if np.size(tps0_c) else np.mean(tps0, axis=0)\n",
    "            tps1_c = np.hstack((tps1_c,np.mean(tps1, axis=0))) if np.size(tps1_c) else np.mean(tps1, axis=0)\n",
    "            T_vals_c = np.hstack((T_vals_c,Tvals)) if np.size(T_vals_c) else Tvals\n",
    "            p_vals_c = np.hstack((p_vals_c,unc_p)) if np.size(p_vals_c) else unc_p\n",
    "            p_max_c = np.hstack((p_max_c,pvals)) if np.size(p_max_c) else pvals\n",
    "            p_fdr_c = np.hstack((p_fdr_c,p_fdr)) if np.size(p_fdr_c) else p_fdr\n",
    "            p_bf_c = np.hstack((p_bf_c,p_bf)) if np.size(p_bf_c) else p_bf\n",
    "        \n",
    "    data = np.concatenate((subjects_c[:,np.newaxis],labels_c[:,np.newaxis],channels_c[:,np.newaxis],x_c[:,np.newaxis],y_c[:,np.newaxis],z_c[:,np.newaxis],elecs_c[:,np.newaxis],\n",
    "                          tps0_c[:,np.newaxis], tps1_c[:,np.newaxis], T_vals_c[:,np.newaxis],\n",
    "                           p_vals_c[:,np.newaxis], p_max_c[:,np.newaxis], p_fdr_c[:,np.newaxis],\n",
    "                          p_bf_c[:,np.newaxis]), axis=1)\n",
    "    df = pd.DataFrame(data, columns=['subjects','labels','channels','x','y','z',\n",
    "                            'elecs_num', 'tps_'+conds[0], 'tps_'+conds[1], 'Tvals', 'unc_p', 'max_p', \n",
    "                            'fdr_p', 'bonf_p'])\n",
    "    print(df.shape)\n",
    "    df.to_csv(df_name.format('All_subjects',conds[0],perf,conds[1],freq),index=False)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial df shape (232, 14)\n",
      "\n",
      " stats at p <  0.05 correction :  fdr_p (51, 15)\n",
      "Counter({'SFG': 11, 'MFG': 10, 'aHC': 10, 'IFG': 6, 'OFC_olf': 4, 'Amg': 3, 'PHG': 3, 'pPirT': 2, 'ACC': 2})\n",
      "IFG NB of subjects with separation 3  subjects\n",
      "#electrodes in total >>>  4\n",
      "MFG NB of subjects with separation 3  subjects\n",
      "#electrodes in total >>>  6\n",
      "OFC_olf NB of subjects with completion 3  subjects\n",
      "#electrodes in total >>>  3\n",
      "aHC NB of subjects with completion 3  subjects\n",
      "#electrodes in total >>>  8\n",
      "pPirT NB of subjects with completion 2  subjects\n",
      "#electrodes in total >>>  2\n",
      "\n",
      " stats at p <  0.05 correction :  bonf_p (32, 15)\n",
      "Counter({'aHC': 7, 'MFG': 5, 'IFG': 4, 'SFG': 4, 'Amg': 3, 'PHG': 3, 'OFC_olf': 3, 'pPirT': 2, 'ACC': 1})\n",
      "MFG NB of subjects with separation 3  subjects\n",
      "#electrodes in total >>>  5\n",
      "OFC_olf NB of subjects with completion 2  subjects\n",
      "#electrodes in total >>>  2\n",
      "pPirT NB of subjects with completion 2  subjects\n",
      "#electrodes in total >>>  2\n",
      "\n",
      " stats at p <  0.01 correction :  fdr_p (32, 15)\n",
      "Counter({'aHC': 7, 'MFG': 5, 'IFG': 4, 'SFG': 4, 'Amg': 3, 'PHG': 3, 'OFC_olf': 3, 'pPirT': 2, 'ACC': 1})\n",
      "MFG NB of subjects with separation 3  subjects\n",
      "#electrodes in total >>>  5\n",
      "OFC_olf NB of subjects with completion 2  subjects\n",
      "#electrodes in total >>>  2\n",
      "pPirT NB of subjects with completion 2  subjects\n",
      "#electrodes in total >>>  2\n",
      "\n",
      " stats at p <  0.01 correction :  bonf_p (27, 15)\n",
      "Counter({'aHC': 7, 'Amg': 3, 'MFG': 3, 'IFG': 3, 'PHG': 3, 'OFC_olf': 3, 'SFG': 3, 'pPirT': 2})\n",
      "MFG NB of subjects with separation 3  subjects\n",
      "#electrodes in total >>>  3\n",
      "OFC_olf NB of subjects with completion 2  subjects\n",
      "#electrodes in total >>>  2\n",
      "pPirT NB of subjects with completion 2  subjects\n",
      "#electrodes in total >>>  2\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "fold = 'Enc_Ret'\n",
    "perf, meth = 'btw', 'BTW'\n",
    "conds = ['high','low']\n",
    "olf_regions = ['Amg','pPirT','OFC_olf','Ins_olf']\n",
    "\n",
    "save_path = path.join(st.path, 'feature/TPSim_'+fold+'_By_Odor_By_Cond/TPS_by_odor/')\n",
    "#save_path = path.join(st.path, 'feature/TPSim_'+fold+'_By_Odor_By_Cond/TPS_by_cond/6freqs/')\n",
    "#save_path = path.join(st.path, 'classified/TPSim_classif_'+fold+'_by_cond_dissim/')\n",
    "df_name = path.join(save_path, '{}_Ttests_old_{}_'+perf+'_{}_{}.csv') #su, conds0, conds1, freq\n",
    "df_stat_save = path.join(save_path, 'stats_df/','{}_Ttests_old_'+meth+'_{}_{}_{}_{}_{}.csv')\n",
    "#df_name = path.join(save_path, '{}_Ttests_{}_{}_{}.csv') #su, conds0, conds1, freq\n",
    "\n",
    "df = pd.read_csv(df_name.format('All_subjects',conds[0], conds[1],'theta'))\n",
    "print('Initial df shape', df.shape)\n",
    "\n",
    "thrs = [0.05, 0.01]\n",
    "corrections = ['fdr_p','bonf_p']\n",
    "\n",
    "for th, corr in product(thrs,corrections):\n",
    "    df_sel = df.loc[df[corr]<th]\n",
    "    df_sel['sign'] = ['separation' if t > 0 else 'completion' for t in df_sel['Tvals']]\n",
    "    print('\\n stats at p < ',th, 'correction : ',corr, df_sel.shape)\n",
    "    print(Counter(df_sel['labels']))\n",
    "\n",
    "    if fold == 'Enc_Ret' and meth == 'BTW':\n",
    "        df_sel['tps_high'] = 1-df_sel['tps_high']\n",
    "        df_sel['tps_low'] =  1-df_sel['tps_low']\n",
    "        \n",
    "    rois = np.unique(df_sel['labels'])\n",
    "    for roi in rois:\n",
    "        df_roi = df_sel.loc[df_sel['labels']==roi]\n",
    "        df_inc = df_roi.loc[df_roi['sign']=='completion'].groupby(['subjects']).count()\n",
    "        df_dec = df_roi.loc[df_roi['sign']=='separation'].groupby(['subjects']).count()\n",
    "            \n",
    "        if (df_inc.shape[0] >= 3) or (df_inc.shape[0] >=2 and roi in olf_regions):\n",
    "            print(roi, 'NB of subjects with completion',df_inc.shape[0],' subjects')\n",
    "            df_plot = df_roi.loc[df_roi['sign']=='completion']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "            df_plot.to_csv(df_stat_save.format('All_subjects',conds[0],\n",
    "                                conds[1],'theta',roi,corr+str(th)))\n",
    "            \n",
    "        if (df_dec.shape[0] >= 3) or (df_dec.shape[0] >=2 and roi in olf_regions):\n",
    "            print(roi, 'NB of subjects with separation',df_dec.shape[0],' subjects')\n",
    "            df_plot = df_roi.loc[df_roi['sign']=='separation']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "            df_plot.to_csv(df_stat_save.format('All_subjects',conds[0],\n",
    "                                conds[1],'theta',roi,corr+str(th)))\n",
    "            #print(df_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9)\n",
      "1.022779643814247\n"
     ]
    }
   ],
   "source": [
    "path = '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_Enc_By_Odor_By_Cond/TPS_by_odor/'\n",
    "\n",
    "mat = np.load(path+'TPS_pears_SEMC_high_wth_theta.npz')\n",
    "chan = [i for i,elec in enumerate(mat['channel']) if elec == 'b5-b4']\n",
    "tpsim = mat['tps'][chan,...]\n",
    "print(tpsim.shape)\n",
    "print(np.mean(tpsim))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
