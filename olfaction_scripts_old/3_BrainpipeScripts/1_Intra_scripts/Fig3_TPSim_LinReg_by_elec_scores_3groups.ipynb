{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from os.path import join, exists\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from brainpipe.system import study\n",
    "from mne.stats import fdr_correction, bonferroni_correction\n",
    "from utils import rename_elecs, odors_su_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Correlate TPSim with behavioral variables // Memory group\n",
    "BY ELECTRODE and Plot summary (for all included electrodes)\n",
    "\"\"\"\n",
    "\n",
    "exps, RT_type = ['Enc'], 'mem_groups' #RT_rec_first, RT_rec_wght, RT_epi_wght, RT_epi_first\n",
    "freqs = ['theta'] #'1_alpha', '2_beta','3_gamma', high_gamma\n",
    "meth, conds, stat = 'btw', ['low','mid','high'], 'LinReg'\n",
    "subjects = ['CHAF','VACJ','PIRJ','SEMC','FERJ','LEFC']\n",
    "rois_sel = ['aHC','MFG','ACC','IFG','Amg','pPirT','PHG','Ins_olf',\n",
    "            'OFC_olf','SFG','HC']\n",
    "width, step = 'None', 'None'\n",
    "st = study('Olfacto')\n",
    "\n",
    "for exp in exps:\n",
    "    ###############################################################################\n",
    "    path_tps = join(st.path, 'feature/TPSim_3groups_'+exp+'/')\n",
    "    tps_form = join(path_tps, 'TPS_'+meth+'_v=1_elecs=all_hilbert=ok/'+\\\n",
    "                        'TPS_pears_{}_{}_'+meth+'_{}_width={}_step={}_ds.npz')\n",
    "    df_path = join(path_tps, 'LinReg_stats_{}_v=1_elecs=all_hilbert=ok/')\n",
    "    df_name = join(df_path, '{}_ols_'+meth+'_{}_{}_{}_width={}_step={}_ds.csv') #su, conds0, conds1, freq\n",
    "    ###############################################################################\n",
    "    \n",
    "    dict_perf = {'low':1, 'mid':2, 'high':3}\n",
    "    #dict_perf = {'low':1, 'high':2}\n",
    "\n",
    "    for freq in freqs:\n",
    "        if not exists(df_path.format(freq)):\n",
    "            makedirs(df_path.format(freq))\n",
    "        subjects_c, elecs_c, labels_c = np.array([]), np.array([]), np.array([])\n",
    "        channels_c, x_c, y_c, z_c = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "        tps_scores, T_vals_c, p_vals_c = np.array([]), np.array([]), np.array([])\n",
    "        p_fdr_c, p_bf_c = np.array([]), np.array([])\n",
    "        \n",
    "        for su in subjects:\n",
    "            #load all elec info,rename and select electrodes id\n",
    "            mat = np.load(tps_form.format(su,conds[0],freq,width,step),allow_pickle=True)\n",
    "            labels, channels = mat['label'], mat['channel']\n",
    "            print(su,labels.shape, mat['tps'].shape,np.unique(labels))\n",
    "            x, y, z = mat['xyz'][:,0], mat['xyz'][:,1], mat['xyz'][:,2]\n",
    "            labels_new = rename_elecs(labels,x,y,z)\n",
    "            idx_sel = [i for i,lab in enumerate(labels_new) if lab in rois_sel]\n",
    "            labels, channels = labels_new[idx_sel], channels[idx_sel]\n",
    "            x, y, z = x[idx_sel], y[idx_sel], z[idx_sel]\n",
    "            \n",
    "            if stat == 'LinReg':\n",
    "                tps_su = np.zeros((len(idx_sel),len(conds)))\n",
    "                all_tps, all_scores = [], []\n",
    "                for c,cond in enumerate(conds):\n",
    "                    mat = np.load(tps_form.format(su,cond,freq,width,step))\n",
    "                    tps = mat['tps'][idx_sel]\n",
    "                    nelecs, ntrials = tps.shape\n",
    "                    score_ = np.array([dict_perf[cond]]*ntrials)\n",
    "                    tps_su[:,c] += np.mean(tps,axis=1)\n",
    "                    #fill tps and score vectors\n",
    "                    all_tps.append(tps)\n",
    "                    all_scores.append(score_)\n",
    "\n",
    "                #compute stats Ttests-unpaired\n",
    "                all_tps = np.concatenate(all_tps,axis=1)\n",
    "                all_scores = np.concatenate(all_scores,axis=0)\n",
    "                T, unc_p = [], []\n",
    "                for elec in range(nelecs):\n",
    "                    #Tval,pval = stats.kendalltau(all_tps[elec],all_scores)\n",
    "                    Y, X = np.array(all_tps[elec]), sm.add_constant(np.array(all_scores))\n",
    "                    model_ols = sm.OLS(Y,X).fit()\n",
    "                    Tval, pval = np.round(model_ols.tvalues[1],3),model_ols.pvalues[1]\n",
    "                    T.append(Tval), unc_p.append(pval)\n",
    "            if stat == 'Ttest':\n",
    "                tps0 = np.load(tps_form.format(su,conds[0],freq,width,step))['tps'][idx_sel]\n",
    "                nelecs = len(idx_sel)\n",
    "                tps1 = np.load(tps_form.format(su,conds[1],freq,width,step))['tps'][idx_sel]\n",
    "                mean0, mean1 = np.mean(tps0,axis=1)[:,np.newaxis], np.mean(tps1,axis=1)[:,np.newaxis]\n",
    "                tps_su = np.concatenate((mean0,mean1),axis=1)\n",
    "                #compute stats Ttests-unpaired\n",
    "                tps0, tps1 = tps0.swapaxes(0,1), tps1.swapaxes(0,1) #ntrials x nelecs\n",
    "                T, unc_p = ttest_ind(tps0, tps1, equal_var=False)\n",
    "                print(T.shape, unc_p.shape)\n",
    "            _, p_fdr = fdr_correction(unc_p)\n",
    "            _, p_bf = bonferroni_correction(unc_p)\n",
    "\n",
    "            #fill all df data\n",
    "            subjects_c = np.hstack((subjects_c,np.array([su]*nelecs))) if np.size(subjects_c) else np.array([su]*nelecs)\n",
    "            elecs_c = np.hstack((elecs_c,np.arange(nelecs))) if np.size(elecs_c) else np.arange(nelecs)\n",
    "            labels_c = np.hstack((labels_c,labels)) if np.size(labels_c) else labels\n",
    "            channels_c = np.hstack((channels_c,channels)) if np.size(channels_c) else channels\n",
    "            tps_scores = np.concatenate((tps_scores,tps_su),axis=0) if np.size(tps_scores) else tps_su\n",
    "            x_c = np.hstack((x_c,x)) if np.size(x_c) else x\n",
    "            y_c = np.hstack((y_c,y)) if np.size(y_c) else y\n",
    "            z_c = np.hstack((z_c,z)) if np.size(z_c) else z\n",
    "            T_vals_c = np.hstack((T_vals_c,T)) if np.size(T_vals_c) else T\n",
    "            p_vals_c = np.hstack((p_vals_c,unc_p)) if np.size(p_vals_c) else unc_p\n",
    "            p_fdr_c = np.hstack((p_fdr_c,p_fdr)) if np.size(p_fdr_c) else p_fdr\n",
    "            p_bf_c = np.hstack((p_bf_c,p_bf)) if np.size(p_bf_c) else p_bf\n",
    "\n",
    "        data = np.concatenate((subjects_c[:,np.newaxis],labels_c[:,np.newaxis],\n",
    "                    channels_c[:,np.newaxis],x_c[:,np.newaxis],y_c[:,np.newaxis],\n",
    "                    z_c[:,np.newaxis],elecs_c[:,np.newaxis],tps_scores,T_vals_c[:,np.newaxis],\n",
    "                    p_vals_c[:,np.newaxis],p_fdr_c[:,np.newaxis],p_bf_c[:,np.newaxis]),\n",
    "                    axis=1)\n",
    "        df = pd.DataFrame(data, columns=['subjects','labels','channels','x','y','z',\n",
    "                                'elecs_num', 'tps_'+conds[0], 'tps_'+conds[1],'tps_'+conds[2],\n",
    "                                        'Tvals', 'unc_p','fdr_p', 'bonf_p'])\n",
    "        print(df.shape)\n",
    "        df.to_csv(df_name.format(freq,'All_subjects',freq,RT_type,stat,width,step),index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Create a big csv file with all Freesurfer labels\"\"\"\n",
    "\n",
    "PATH = '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Implantation_Patients_MNI/db_slicer_labels/'\n",
    "file_name = '/{}_radius-5.0_hip-hires.xlsx'\n",
    "PATH_SAVE = join(st.path, 'feature/')\n",
    "subjects = ['S04_FERJ','S02_SEMC','S03_LEFC','S01_VACJ','S05_PIRJ','S06_MICP','S00_CHAF']\n",
    "savename = 'All_subjects_Fressurfer_labels.csv'\n",
    "\n",
    "#concat all labels together\n",
    "df_tot = pd.DataFrame()\n",
    "for su in subjects:\n",
    "    df = pd.read_excel(PATH+su+file_name.format(su), sheet_name='bipolar')\n",
    "    nelecs = df.shape[0]\n",
    "    df_sel = df[['contact','Freesurfer']]\n",
    "    df_sel['subjects'] = [su[4:]]*nelecs\n",
    "    df_sel['hip_CA'] = [lab0 if lab0 != 'none' else lab1 for lab0,lab1 in \\\n",
    "                                zip(df['lh.hippoAmygLabels-T1.v21.CA.FSvoxelSpace'],\n",
    "                                    df['rh.hippoAmygLabels-T1.v21.CA.FSvoxelSpace'])]\n",
    "    df_sel['hip_FS60'] = [lab0 if lab0 != 'none' else lab1 for lab0,lab1 in \\\n",
    "                                zip(df['lh.hippoAmygLabels-T1.v21.FS60.FSvoxelSpace'],\n",
    "                                    df['rh.hippoAmygLabels-T1.v21.FS60.FSvoxelSpace'])]\n",
    "    columnsTitles = ['subjects', 'contact', 'Freesurfer','hip_CA','hip_FS60']\n",
    "    df_sel = df_sel.reindex(columns=columnsTitles)\n",
    "    df_tot = df_tot.append(df_sel)\n",
    "df_tot.to_csv(PATH_SAVE+savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Add freesurfer labels to the results df\"\"\"\n",
    "\n",
    "###############################################################################\n",
    "path_tps = join(st.path, 'feature/')\n",
    "df_path = join(path_tps, 'TPSim_3groups_'+exp+'/LinReg_stats_{}_v=1_elecs=all_hilbert=ok/')\n",
    "# df_path = join(path_tps, 'TPSim_3groups_'+exp+'/Ttest_odor_identity_v=1_elecs=all/')\n",
    "df_name = join(df_path, '{}_ols_'+meth+'_{}_{}_{}.csv') #su, conds0, conds1, freq\n",
    "# df_name = join(df_path, 'Bilan_All_subjects_Ttests_Low_High_all_roi_aHC_fdr_0.05_theta.csv') #su, conds0, conds1, freq\n",
    "df_f_name = join(path_tps, 'All_subjects_Fressurfer_labels.csv')\n",
    "###############################################################################\n",
    "exp, freq, meth, stat = 'Enc', 'theta', 'btw', 'LinReg'\n",
    "\n",
    "df = pd.read_csv(df_name.format(freq,'All_subjects',freq, 'mem_groups',stat))\n",
    "# df = pd.read_csv(df_name)\n",
    "_, su_idx = np.unique(df['subjects'].values, return_index=True)\n",
    "subjects = df['subjects'].values[np.sort(su_idx)]\n",
    "df_f = pd.read_csv(df_f_name)\n",
    "\n",
    "free_labs, hip_CA, hip_fs60 = [], [], []\n",
    "for su in subjects:\n",
    "    #select one subject's df and select only good contacts labels\n",
    "    df_su = df.loc[df['subjects']==su]\n",
    "    df_f_su = df_f.loc[df_f['subjects']==su]\n",
    "    list_chans = [lab.replace(\"'\",\"\") for lab in df_su['channels'].str.upper()] \\\n",
    "                                if su == 'CHAF' else df_su['channels'].str.upper().values\n",
    "    idx = [i for i,lab in enumerate(df_f_su['contact'].values) if lab in list_chans]\n",
    "    \n",
    "    #due to contact type 3x5 some are missing in Freesurfer data\n",
    "    missing = [elec for elec in list_chans if elec not in df_f_su['contact'].values[idx]]\n",
    "    idx_miss = [i for i,elec in enumerate(list_chans) if elec in missing]\n",
    "    idx_miss = [ind -i for i, ind in enumerate(idx_miss)]\n",
    "    print(su, 'missing contacts', missing, idx_miss)\n",
    "    \n",
    "    #select all subject's labels\n",
    "    fr_l = df_f_su['Freesurfer'].values[idx]\n",
    "    ca_l = df_f_su['hip_CA'].values[idx]\n",
    "    fs_l = df_f_su['hip_FS60'].values[idx]\n",
    "    \n",
    "    #add None labels at the good index location in subject's df\n",
    "    fr_l = np.insert(fr_l, idx_miss, 'not_fs')\n",
    "    ca_l = np.insert(ca_l, idx_miss, 'not_fs')\n",
    "    fs_l = np.insert(fs_l, idx_miss, 'not_fs')\n",
    "    free_labs.extend(fr_l), hip_CA.extend(ca_l), hip_fs60.extend(fs_l)\n",
    "\n",
    "df['fsf'], df['hip_CA'], df['hip_FS60'] = free_labs, hip_CA, hip_fs60\n",
    "#save new files with all labels\n",
    "df_save = df_name.format(freq,'All_subjects',freq, 'mem_groups',stat).replace('.csv','_fsf.csv')\n",
    "df.to_csv(df_save,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "st = study('Olfacto')\n",
    "exp, stat = 'Enc', 'LinReg'#'Enc'\n",
    "meth, RT_types = 'btw', ['mem_groups']#['RT_epi_first','RT_epi_wght','RT_rec_first','RT_rec_wght']\n",
    "olf_regions = ['Amg','pPirT','OFC_olf']\n",
    "freq, width, step = 'theta', 'None', 'None'\n",
    "thrs = [0.05]\n",
    "corrections = ['fdr_p']#['fdr_p'] unc_p\n",
    "\n",
    "##################################################################################\n",
    "path_pow = join(st.path, 'feature/TPSim_3groups_'+exp+'/LinReg_stats_{}_v=1_elecs=all_hilbert=ok/')\n",
    "df_name = join(path_pow, '{}_ols_'+meth+'_{}_{}_{}_width={}_step={}_ds.csv') #su, conds0, conds1, freq\n",
    "df_stat_save = join(path_pow, 'Bilan_{}_OLS_'+meth+'_{}_{}_{}_{}_{}_{}_width={}_step={}_ds.csv')\n",
    "df_stat_all = join(path_pow, 'Bilan_{}_OLS_'+meth+'_{}_{}_{}_width={}_step={}_ds.csv')\n",
    "##################################################################################\n",
    "\n",
    "for RT_type in RT_types:\n",
    "    df = pd.read_csv(df_name.format(freq,'All_subjects',freq,RT_type,stat,width,step))\n",
    "    df['labels'] = ['pPirT' if lab == 'Amg' else lab for lab in df['labels']]\n",
    "    print('Initial df shape', df.shape, meth, exp, RT_type, stat)\n",
    "    for th, corr in product(thrs,corrections):\n",
    "        df_sel = df.loc[df[corr]<th] #\n",
    "        print(df.loc[df['fdr_p']<th])\n",
    "        df_sel['sign'] = ['separation' if t > 0 else 'completion' for t in df_sel['Tvals']]\n",
    "        print('\\n',meth,'stats at p < ',th, 'correction : ',corr, df_sel.shape)\n",
    "        df_sel.to_csv(df_stat_all.format(freq,'All_subjects',freq,RT_type,\n",
    "                                                 corr+str(th),width,step))\n",
    "        #print(df_sel.groupby(['fsf','subjects','sign']).count())\n",
    "        rois = np.unique(df_sel['labels'])\n",
    "        for roi in rois:\n",
    "            df_roi = df_sel.loc[df_sel['labels']==roi]\n",
    "            df_inc = df_roi.loc[df_roi['sign']=='completion'].groupby(['subjects']).count()\n",
    "            df_dec = df_roi.loc[df_roi['sign']=='separation'].groupby(['subjects']).count()\n",
    "            #print(roi, 'integration', df_inc.shape, 'segregation',df_dec.shape)\n",
    "            \n",
    "            if (df_inc.shape[0] >= 3) or (df_inc.shape[0] >=2 and roi in olf_regions):\n",
    "                print(roi, 'NB of subjects with completion',df_inc.shape[0],' subjects')\n",
    "                df_plot = df_roi.loc[df_roi['sign']=='completion']\n",
    "                print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "                df_plot.to_csv(df_stat_save.format(freq,'All_subjects',freq,'mem_groups',\n",
    "                                                   'compl',roi,corr+str(th),stat,width,step))\n",
    "\n",
    "            if (df_dec.shape[0] >= 3) or (df_dec.shape[0] >=2 and roi in olf_regions):\n",
    "                print(roi, 'NB of subjects with separation',df_dec.shape[0],' subjects')\n",
    "                df_plot = df_roi.loc[df_roi['sign']=='separation']\n",
    "                print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "                df_plot.to_csv(df_stat_save.format(freq,'All_subjects','theta','mem_groups',\n",
    "                                                   'sep',roi,corr+str(th),stat,width,step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plots for sig electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "st = study('Olfacto')\n",
    "PATH = join(st.path, 'feature/TPSim_3groups_{}/LinReg_stats_{}_v=1_elecs=all/')\n",
    "# PATH = join(st.path, 'feature/TPSim_3groups_{}/Ttest_odor_identity_v=1_elecs=all/')\n",
    "SAVE_PATH = join(PATH, 'Nb_elecs_{}_by_subject.png')\n",
    "meth, exp, freq= 'btw', 'Enc_Ret', 'theta'\n",
    "\n",
    "files = st.search('Bilan_All_subjects_',folder=PATH.format(exp,freq))\n",
    "#files = st.search('0.05_'+freq,folder=PATH.format(exp,freq))\n",
    "\n",
    "for f in files:\n",
    "    splits = f.split('_')[-5:]\n",
    "    f_name = splits[0]+'_'+splits[1]+'_'+splits[2]+'_'+splits[3]\n",
    "    df = pd.read_csv(PATH.format(exp,freq)+f)\n",
    "    \n",
    "    #Plot nb of significant electrodes by win and subjects\n",
    "    colors = {'CHAF':'darkblue', 'FERJ':'royalblue', 'LEFC':'deepskyblue', \n",
    "            'PIRJ':'yellow','SEMC':'darkorange', 'VACJ':'red'}\n",
    "    df1 = df[['subjects','labels']].groupby(['subjects']).count()\n",
    "    xticks, w = np.arange(0,1,0.2), 0.5\n",
    "    fig = plt.figure()\n",
    "    bottom = np.zeros(1)\n",
    "    for i,su in enumerate(df1.index):\n",
    "        count = df1.iloc[[i]].values[0]\n",
    "        xpts = range(len(count))\n",
    "        print('shape to plot',count.shape, xticks.shape)\n",
    "        plt.bar(xpts, count, color=colors[su], label=su, bottom=bottom)\n",
    "        bottom += count\n",
    "    plt.title('Significant electrodes for '+freq)\n",
    "    plt.ylabel('Nb of electrodes')\n",
    "    plt.xticks(xticks,freq)\n",
    "    plt.ylim(0,15)\n",
    "    plt.legend(loc=0,handletextpad=0.1, frameon=False)\n",
    "    plt.savefig(SAVE_PATH.format(exp,freq,f_name))\n",
    "    plt.savefig(SAVE_PATH.format(exp,freq,f_name).replace('.png','.pdf'))\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot average sig data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PATH = join(st.path, 'feature/TPSim_3groups_{}/LinReg_stats_{}_v=1_elecs=all_hilbert=ok/')\n",
    "#PATH = join(st.path, 'feature/TPSim_3groups_{}/TPS_btw_thgh_time_v=1_elecs=all/')\n",
    "# PATH = join(st.path, 'feature/TPSim_3groups_{}/Ttest_odor_identity_v=1_elecs=all/')\n",
    "SAVE_PATH = join(PATH, 'Mean_{}_{}_tps_by_subject.png')\n",
    "meth, exp, freq= 'btw', 'Enc', 'theta'\n",
    "width, step = '256', '51'\n",
    "conds = ['low','mid','high']\n",
    "#conds = ['early','late']\n",
    "# conds = ['tps_wth','tps_btw','wth-btw','tps_diff']\n",
    "features = ['Tvals','tps']\n",
    "\n",
    "files = st.search('Bilan_All_subjects_OLS_',folder=PATH.format(exp,freq))\n",
    "#files = st.search('0.05_'+freq,folder=PATH.format(exp,freq))\n",
    "\n",
    "for f in files:\n",
    "    splits = f.split('_')[-5:]\n",
    "    f_name = splits[0]+'_'+splits[1]+'_'+splits[2]+'_'+splits[3]\n",
    "    df = pd.read_csv(PATH.format(exp,freq)+f)\n",
    "    df_gr = df #df.groupby(['subjects']).mean()\n",
    "    \n",
    "    for feat in features:\n",
    "        df_f = df_gr.filter(like=feat)\n",
    "        mean, sem = df_f.mean(), df_f.sem()\n",
    "        print(f_name, feat, mean,sem)\n",
    "        #Plot Mean AUC Score\n",
    "        fig = plt.figure()\n",
    "        plt.title('Mean {} Score by region for {}'.format(feat,freq))\n",
    "        plt.ylabel('Mean '+feat)\n",
    "        xticks, w = np.arange(0,df_f.shape[1]), 0.8\n",
    "        plt.xticks(xticks,df_f.columns)\n",
    "        plt.bar(xticks,mean,yerr=sem,color='darkorange')\n",
    "        \n",
    "        plt.savefig(SAVE_PATH.format(exp,freq,feat,f_name))\n",
    "        plt.savefig(SAVE_PATH.format(exp,freq,feat,f_name).replace('.png','.pdf'))\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot individual data with patient name and electrode number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from brainpipe.system import study\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "st = study('Olfacto')\n",
    "#PATH = join(st.path, 'feature/TPSim_3groups_{}/LinReg_stats_{}_v=1_elecs=all/')\n",
    "PATH = join(st.path, 'feature/TPSim_3groups_{}/Ttest_odor_identity_v=1_elecs=all/')\n",
    "SAVE_PATH = join(PATH, 'Ind_elecs_{}_{}_avg_subject_3gr_LinReg.png')\n",
    "meth, exp, freq= 'btw', 'Enc', 'theta'\n",
    "features = ['tps_low','tps_mid','tps_high']\n",
    "features_sd = ['sem_low','sem_mid','sem_high']\n",
    "\n",
    "files = st.search('Bilan_All_subjects_LinReg_',folder=PATH.format(exp,freq))\n",
    "\n",
    "for f in files:\n",
    "    splits = f.split('_')[-6:]\n",
    "    if '3gr' in splits:\n",
    "        print('selected',f)\n",
    "        f_name = splits[1]+'_'+splits[2]+'_'+splits[3]+'_'+splits[4]\n",
    "        df = pd.read_csv(PATH.format(exp,freq)+f)\n",
    "        df_m = df.groupby(['subjects']).agg(['mean','sem'])\n",
    "        nelecs = df_m.shape[0]\n",
    "\n",
    "        fig, axs = plt.subplots(2,4, figsize=(15, 6), facecolor='w', edgecolor='k')\n",
    "        fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "\n",
    "        axs = axs.ravel()\n",
    "\n",
    "        for i in range(nelecs):\n",
    "            df_sel = df_m.iloc[i,:].unstack().T\n",
    "            #print(df_sel)\n",
    "\n",
    "            su, roi =  df_m.index[i], splits[1]\n",
    "            data = df_sel[features].iloc[0,:].values\n",
    "    #         yerr = df_sd.iloc[i,:][features].values\n",
    "            yerr = df_sel[features].iloc[1,:].values\n",
    "            #print(data,yerr)\n",
    "\n",
    "            xticks, w = np.arange((len(features))), 0.8\n",
    "            axs[i].set_xticks(xticks,features)\n",
    "            axs[i].bar(xticks,data,yerr=yerr,color='blue')\n",
    "            axs[i].set_title('{} in {}'.format(su,roi))\n",
    "        plt.setp(axs, ylim=(0,1))\n",
    "        plt.savefig(SAVE_PATH.format(exp,'tps',f_name))\n",
    "        plt.savefig(SAVE_PATH.format(exp,'tps',f_name).replace('.png','.pdf'))\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot regression plots for sig elecs with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from scipy.stats import sem\n",
    "\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_tps = join(st.path, 'feature/TPSim_3groups_{}/')\n",
    "tps_form = join(path_tps, 'TPS_btw_v=1_elecs=all/TPS_pears_{}_{}_btw_{}.npz')\n",
    "df_path = join(path_tps, 'LinReg_stats_{}_v=1_elecs=all/')\n",
    "SAVE_PATH = join(df_path, 'LinReg_{}_{}_avg_subject.png')\n",
    "###############################################################################\n",
    "freq = 'theta' #'1_alpha', '2_beta','3_gamma', high_gamma\n",
    "meth, exp, conds = 'btw', 'Enc_Ret', ['low','mid','high']\n",
    "subjects = ['CHAF','VACJ','PIRJ','SEMC','FERJ','LEFC']\n",
    "dict_perf = {'low':1, 'mid':2, 'high':3}\n",
    "\n",
    "files = st.search('Bilan_All_subjects_OLS_btw_'+freq,folder=df_path.format(exp,freq))\n",
    "\n",
    "for fi in files:\n",
    "    splits = f.split('_')[-5:]\n",
    "    f_name = splits[0]+'_'+splits[1]+'_'+splits[2]+'_'+splits[3]\n",
    "    df = pd.read_csv(df_path.format(exp,freq)+fi)\n",
    "    subjects = np.unique(df[['subjects']])\n",
    "    \n",
    "    tps_su = np.zeros((len(subjects),len(conds)))\n",
    "    for s,su in enumerate(subjects):\n",
    "        df_su = df.loc[df['subjects']==su]\n",
    "        chans_sig = df_su[['channels']].values\n",
    "        \n",
    "        mat = np.load(tps_form.format(exp,su,conds[0],freq),allow_pickle=True)\n",
    "        channels = mat['channel']\n",
    "        id_chans = [i for i,chan in enumerate(channels) if chan in chans_sig]\n",
    "            \n",
    "        all_tps, all_scores = [], []\n",
    "        tps_cds, sem_cds = [], []\n",
    "        for c,cond in enumerate(conds):\n",
    "            mat = np.load(tps_form.format(exp,su,cond,freq))\n",
    "            tps = mat['tps'][id_chans]\n",
    "            nelecs, ntrials = tps.shape\n",
    "            score_ = np.array([dict_perf[cond]]*ntrials)\n",
    "            all_tps.append(tps)\n",
    "            all_scores.append(score_)\n",
    "            tps_cds.append(np.mean(tps))\n",
    "            sem_cds.append(sem(np.mean(tps,axis=0)))\n",
    "        \n",
    "        #compute stats Ttests-unpaired\n",
    "        tps_su[s] += tps_cds\n",
    "        all_tps = np.concatenate(all_tps,axis=1)\n",
    "        all_scores = np.concatenate(all_scores,axis=0)\n",
    "        all_T, all_p = [], []\n",
    "        for elec in range(nelecs):\n",
    "            Y, X = np.array(all_tps[elec]), sm.add_constant(np.array(all_scores))\n",
    "            model_ols = sm.OLS(Y,X).fit()\n",
    "            #print(model_ols.summary())\n",
    "            Tval, pval = np.round(model_ols.tvalues[1],2),np.round(model_ols.pvalues[1],3)\n",
    "            all_T.append(Tval), all_p.append(pval)\n",
    "        #Plot all values by subject\n",
    "        tps_plot = np.mean(all_tps,axis=0)\n",
    "        T, p = all_T[np.argmin(abs(np.array(all_T)))],np.max(np.array(all_p))\n",
    "        fig, ax = plt.subplots(figsize=(3,3))\n",
    "        #ax = sns.stripplot(x=all_scores, y=tps_plot, alpha=.25, zorder=1)\n",
    "        ax = sns.violinplot(x=all_scores, y=tps_plot, alpha=.25, zorder=1, bw=0.5,scale='width')\n",
    "        ax = sns.pointplot(x=all_scores, y =tps_plot, markers=\"d\", scale=.75,\n",
    "                          estimator=np.median, ci=None)\n",
    "        #plt.errorbar([0,1,2],tps_cds,yerr=sem_cds,fmt='o')\n",
    "        #m, b = np.polyfit(all_scores, tps_plot, 1)\n",
    "        #plt.plot(all_scores-1, (m*all_scores)+b)\n",
    "        if len(id_chans) == 1:\n",
    "            anchored_text = AnchoredText('t = %s \\np = %s' % (T, p),loc=2)\n",
    "        elif len(id_chans) > 1 and T > 0:\n",
    "            anchored_text = AnchoredText('t > %s \\np < %s' % (T, p),loc=2)\n",
    "        elif len(id_chans) > 1 and T < 0:\n",
    "            anchored_text = AnchoredText('t < %s \\np < %s' % (T, p),loc=2)\n",
    "        ax.add_artist(anchored_text)\n",
    "        plt.savefig(SAVE_PATH.format(exp,freq,su,f_name))\n",
    "        plt.savefig(SAVE_PATH.format(exp,freq,su,f_name).replace('png','pdf'))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression analyses for electrodes significant at encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Linear Regression of TPD with memory richness\n",
    "Only subjects and ROIs with significant results at Encoding\n",
    "Take SIGNIFICANT electrodes within ROI and FDR correct across subjects\n",
    "\"\"\"\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from os import path\n",
    "import pingouin as pg\n",
    "from utils import odor_groups_3wgth\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "############################################################################################\n",
    "st = study('Olfacto')\n",
    "fold, fold2, freq, suffix = 'Enc','Enc_Ret','theta',  'E=E_R=all'\n",
    "path_df = path.join(st.path, 'feature/TPSim_3groups_{}/LinReg_stats_theta_v=1_elecs=all/')\n",
    "path_data = path.join(st.path, 'feature/TPSim_3groups_'+fold2+'/TPS_btw_v=1_elecs=all/')\n",
    "filename = path.join(path_data, 'TPS_pears_{}_{}_btw_theta_'+suffix+'.npz')\n",
    "############################################################################################\n",
    "corr = 'fdr'\n",
    "conds = ['low','mid','high']\n",
    "files = st.search('Bilan_All_subjects_OLS',\n",
    "              folder='feature/TPSim_3groups_'+fold+'/LinReg_stats_theta_v=1_elecs=all/')\n",
    "dict_score = {'low':0, 'mid':1, 'high':2}\n",
    "\n",
    "for fi in files:\n",
    "    if corr in fi.split('_'):\n",
    "        roi = fi.split('_')[9]\n",
    "        roi = 'OFC_olf' if roi == 'OFC' else roi\n",
    "        #if roi in ['OFC','aHC','Amg']:\n",
    "        print('>>>> processing ',fi, roi)\n",
    "        df = pd.read_csv(path_df.format(fold)+fi)\n",
    "        _, idx = np.unique(df['subjects'], return_index=True)\n",
    "        subjects = df['subjects'][np.sort(idx)]\n",
    "        print('>>>> {} subjects significant'.format(len(subjects)))\n",
    "        print(subjects)\n",
    "        pvals, Tvals, subj, chans = [], [], [], []\n",
    "        tps_low, tps_high, sem_low, sem_high = [], [], [], []\n",
    "        tps_mid, sem_mid = [], []\n",
    "        for su in subjects:\n",
    "            df_su = df.loc[df['subjects']==su]\n",
    "            chans_df = df_su['channels'].values\n",
    "\n",
    "            all_su_tps, all_scores = [], []\n",
    "            for cond in conds:\n",
    "                mat = np.load(filename.format(su,cond),allow_pickle=True)\n",
    "                idx_elecs = [i for i,chan in enumerate(mat['channel']) if chan in chans_df]\n",
    "                \n",
    "                #if roi != 'Amg':\n",
    "                #    idx_elecs = [i for i,lab in enumerate(mat['label']) if lab == roi]\n",
    "                #if roi == 'Amg':\n",
    "                #    idx_elecs = [i for i,lab in enumerate(mat['label']) if lab in ['Amg','pPirT']]\n",
    "                channels = mat['channel'][idx_elecs]\n",
    "                data = mat['tps'][idx_elecs,:]\n",
    "                nelecs, ntrials = data.shape\n",
    "                all_su_tps.append(data)\n",
    "                score_ = np.array([dict_score[cond]]*ntrials)\n",
    "                all_scores.append(score_)\n",
    "            \n",
    "            print([x.shape for x in all_su_tps])\n",
    "            if all_su_tps[-1].shape[-1] > 1: #pass subjects without enough trials\n",
    "                all_tps_concat = np.concatenate(all_su_tps,axis=1)\n",
    "                all_scores_concat = np.concatenate(all_scores,axis=0)\n",
    "                T, unc_p = [], []\n",
    "                for elec in range(nelecs):\n",
    "                    Y = np.array(all_tps_concat[elec])\n",
    "                    X = sm.add_constant(np.array(all_scores_concat))\n",
    "                    model_ols = sm.OLS(Y,X).fit()\n",
    "                    Tval, pval = np.round(model_ols.tvalues[1],3),model_ols.pvalues[1]\n",
    "                    Tvals.append(Tval), pvals.append(pval)\n",
    "    \n",
    "                    subj.append(su), chans.append(channels[elec])\n",
    "                    tps_low.append(np.mean(all_su_tps[0][elec]))\n",
    "                    tps_mid.append(np.mean(all_su_tps[1][elec]))\n",
    "                    tps_high.append(np.mean(all_su_tps[2][elec]))\n",
    "                    sem_low.append(stats.sem(all_su_tps[0][elec]))\n",
    "                    sem_mid.append(stats.sem(all_su_tps[1][elec]))\n",
    "                    sem_high.append(stats.sem(all_su_tps[2][elec]))\n",
    "\n",
    "        _, pvals_fdr = fdr_correction(pvals)\n",
    "        _, pvals_bonf = bonferroni_correction(pvals)\n",
    "        \n",
    "        subj, chans = np.array(subj),np.array(chans)\n",
    "        tps_low, tps_high, Tvals = np.array(tps_low),np.array(tps_high), np.array(Tvals)\n",
    "        sem_low, sem_high, pvals = np.array(sem_low),np.array(sem_high),np.array(pvals)\n",
    "        sem_mid, tps_mid = np.array(sem_mid),np.array(tps_mid)\n",
    "        #print(pvals.shape, pvals_fdr.shape,pvals_bonf.shape, Tvals.shape)\n",
    "        data_final = np.concatenate([subj[:,np.newaxis],chans[:,np.newaxis],\n",
    "                tps_low[:,np.newaxis], sem_low[:,np.newaxis],\n",
    "                tps_mid[:,np.newaxis], sem_mid[:,np.newaxis],\n",
    "                tps_high[:,np.newaxis],sem_high[:,np.newaxis],\n",
    "                Tvals[:,np.newaxis],pvals[:,np.newaxis],\n",
    "                pvals_fdr[:,np.newaxis],pvals_bonf[:,np.newaxis]],axis=1)\n",
    "        \n",
    "        df = pd.DataFrame(data_final, columns=['subjects','channels',\n",
    "                    'tps_low', 'sem_low', 'tps_mid', 'sem_mid','tps_high', 'sem_high', \n",
    "                    'Tvals_diff','unc_diff','fdr_diff','bonf_diff'])\n",
    "        \n",
    "        df['fdr_diff'] = df['fdr_diff'].astype(float)\n",
    "        df['Tvals_diff'] = df['Tvals_diff'].astype(float)\n",
    "        df_sig = df.loc[(df['fdr_diff']<0.05)&(df['Tvals_diff']<0)]\n",
    "        if df_sig.shape[0] > 0:\n",
    "            print(df_sig)\n",
    "        df.to_csv(path_df.format(fold2)+fi.replace('mem_groups',\n",
    "                                        'elecsE_3gr').replace('.csv',suffix+'.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAME analysis but with 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LOW vs HIGH TPD at Retrieval and Reinstatement\n",
    "Only subjects and ROIs with significant results at Encoding\n",
    "Take SIGNIFICANT electrodes within ROI and FDR correct across subjects\n",
    "\"\"\"\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from os import path\n",
    "import pingouin as pg\n",
    "from utils import odor_groups_3wgth\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "############################################################################################\n",
    "st = study('Olfacto')\n",
    "fold, fold2, freq = 'Enc','Enc_Ret','theta'\n",
    "path_df = path.join(st.path, 'feature/TPSim_3groups_{}/LinReg_stats_theta_v=1_elecs=all/')\n",
    "path_data = path.join(st.path, 'feature/TPSim_3groups_'+fold2+'/TPS_btw_v=1_elecs=all/')\n",
    "filename = path.join(path_data, 'TPS_pears_{}_{}_btw_theta.npz')\n",
    "############################################################################################\n",
    "corr = 'fdr'\n",
    "conds = ['low','mid','high']\n",
    "files = st.search('Bilan_All_subjects_OLS',\n",
    "              folder='feature/TPSim_3groups_'+fold+'/LinReg_stats_theta_v=1_elecs=all/')\n",
    "dict_score = {'low':0, 'mid':1, 'high':2}\n",
    "\n",
    "for fi in files:\n",
    "    if corr in fi.split('_'):\n",
    "        roi = fi.split('_')[9]\n",
    "        roi = 'OFC_olf' if roi == 'OFC' else roi\n",
    "        print('>>>> processing ',fi, roi)\n",
    "        df = pd.read_csv(path_df.format(fold)+fi)\n",
    "        _, idx = np.unique(df['subjects'], return_index=True)\n",
    "        subjects = df['subjects'][np.sort(idx)]\n",
    "        print('>>>> {} subjects significant'.format(len(subjects)))\n",
    "        print(subjects)\n",
    "        pvals, Tvals, subj, chans = [], [], [], []\n",
    "        tps_low, tps_high, sem_low, sem_high = [], [], [], []\n",
    "        tps_mid, sem_mid = [], []\n",
    "        for su in subjects:\n",
    "            df_su = df.loc[df['subjects']==su]\n",
    "            chans_df = df_su['channels'].values\n",
    "            all_su_tps = []\n",
    "            for cond in conds:\n",
    "                mat = np.load(filename.format(su,cond),allow_pickle=True)\n",
    "                idx_elecs = [i for i,chan in enumerate(mat['channel']) if chan in chans_df]\n",
    "                \n",
    "                #if roi != 'Amg':\n",
    "                #    idx = [i for i,lab in enumerate(mat['label']) if lab == roi]\n",
    "                #if roi == 'Amg':\n",
    "                #    idx = [i for i,lab in enumerate(mat['label']) if lab in ['Amg','pPirT']]\n",
    "                channels = mat['channel'][idx_elecs]\n",
    "                data = mat['tps'][idx_elecs,:]\n",
    "                nelecs = data.shape[0]\n",
    "                all_su_tps.append(data)\n",
    "\n",
    "            if all_su_tps[-1].shape[-1] > 1: #pass subjects without enough trials\n",
    "                print(su, [x.shape for x in all_su_tps])    \n",
    "                for elec in range(nelecs):\n",
    "                    df_ = pd.DataFrame()\n",
    "                    df_['tps'] = np.concatenate([x[elec] for x in all_su_tps])\n",
    "                    df_['mem_score'] = np.concatenate([[cond]*x.shape[1] for cond,x in zip(conds,all_su_tps)])\n",
    "                    df_['mem_val'] = df_['mem_score'].map(dict_score)\n",
    "                    df_ = df_.loc[df_['mem_score']!='mid']\n",
    "\n",
    "                    ttests = pg.pairwise_gameshowell(data=df_, dv='tps',\n",
    "                                                    tail='one-sided',between='mem_score') \n",
    "                    stats_ = np.round(ttests['T'].values,3),np.round(ttests['pval'].values,3)\n",
    "                    pvals.append(stats_[1]), Tvals.append(stats_[0])\n",
    "                    subj.append(su), chans.append(channels[elec])\n",
    "                    tps_low.append(np.mean(all_su_tps[0][elec]))\n",
    "                    tps_mid.append(np.mean(all_su_tps[1][elec]))\n",
    "                    tps_high.append(np.mean(all_su_tps[2][elec]))\n",
    "                    sem_low.append(stats.sem(all_su_tps[0][elec]))\n",
    "                    sem_mid.append(stats.sem(all_su_tps[1][elec]))\n",
    "                    sem_high.append(stats.sem(all_su_tps[2][elec]))\n",
    "                    \n",
    "        pvals = [p if not math.isnan(p) else 1 for p in pvals]\n",
    "        _, pvals_fdr = fdr_correction(pvals)\n",
    "        _, pvals_bonf = bonferroni_correction(pvals)\n",
    "        \n",
    "        subj, chans = np.array(subj),np.array(chans)\n",
    "        tps_low, tps_high, Tvals = np.array(tps_low),np.array(tps_high), np.array(Tvals)\n",
    "        sem_low, sem_high, pvals = np.array(sem_low),np.array(sem_high),np.array(pvals)\n",
    "        sem_mid, tps_mid = np.array(sem_mid),np.array(tps_mid)\n",
    "        \n",
    "        data_final = np.concatenate([subj[:,np.newaxis],chans[:,np.newaxis],\n",
    "                tps_low[:,np.newaxis], sem_low[:,np.newaxis],\n",
    "                tps_mid[:,np.newaxis], sem_mid[:,np.newaxis],\n",
    "                tps_high[:,np.newaxis],sem_high[:,np.newaxis],\n",
    "                Tvals,pvals,pvals_fdr,pvals_bonf],axis=1)\n",
    "        \n",
    "        df = pd.DataFrame(data_final, columns=['subjects','channels',\n",
    "                    'tps_low', 'sem_low', 'tps_mid', 'sem_mid','tps_high', 'sem_high', \n",
    "                    'Tvals_diff','unc_diff','fdr_diff','bonf_diff'])\n",
    "        \n",
    "        df['fdr_diff'] = df['fdr_diff'].astype(float)\n",
    "        df['Tvals_diff'] = df['Tvals_diff'].astype(float)\n",
    "        df.to_csv(path_df.format(fold2)+fi.replace('mem_groups','elecsE_2gr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot individual violin plots for NON significant electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from scipy.stats import sem\n",
    "\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_tps = join(st.path, 'feature/TPSim_3groups_{}/')\n",
    "tps_form = join(path_tps, 'TPS_btw_v=1_elecs=all/TPS_pears_{}_{}_btw_{}.npz')\n",
    "df_path = join(path_tps, 'LinReg_stats_{}_v=1_elecs=all/')\n",
    "SAVE_PATH = join(df_path, 'LinReg_{}_{}_NOT_sig.png')\n",
    "###############################################################################\n",
    "freq = 'theta' #'1_alpha', '2_beta','3_gamma', high_gamma\n",
    "meth, exp, conds = 'btw', 'Enc', ['low','mid','high']\n",
    "subjects = ['CHAF','VACJ','PIRJ','SEMC','FERJ','LEFC']\n",
    "dict_perf = {'low':1, 'mid':2, 'high':3}\n",
    "rois = ['aHC','OFC_olf']\n",
    "\n",
    "for roi in rois:\n",
    "    for s,su in enumerate(subjects):\n",
    "        mat = np.load(tps_form.format(exp,su,conds[0],freq),allow_pickle=True)\n",
    "        labels = mat['label']\n",
    "        id_labs = [i for i,lab in enumerate(labels) if lab == roi]\n",
    "        \n",
    "        if len(id_labs) > 0:\n",
    "            all_tps, all_scores = [], []\n",
    "            tps_cds, sem_cds = [], []\n",
    "            for c,cond in enumerate(conds):\n",
    "                mat = np.load(tps_form.format(exp,su,cond,freq))\n",
    "                tps = mat['tps'][id_labs]\n",
    "                nelecs, ntrials = tps.shape\n",
    "                score_ = np.array([dict_perf[cond]]*ntrials)\n",
    "                all_tps.append(tps)\n",
    "                all_scores.append(score_)\n",
    "                tps_cds.append(np.mean(tps))\n",
    "                sem_cds.append(sem(np.mean(tps,axis=0)))\n",
    "\n",
    "            #compute stats Ttests-unpaired\n",
    "            all_tps = np.concatenate(all_tps,axis=1)\n",
    "            all_scores = np.concatenate(all_scores,axis=0)\n",
    "            all_T, all_p = [], []\n",
    "            for elec in range(nelecs):\n",
    "                Y, X = np.array(all_tps[elec]), sm.add_constant(np.array(all_scores))\n",
    "                model_ols = sm.OLS(Y,X).fit()\n",
    "                #print(model_ols.summary())\n",
    "                Tval, pval = np.round(model_ols.tvalues[1],2),np.round(model_ols.pvalues[1],3)\n",
    "                all_T.append(Tval), all_p.append(pval)\n",
    "            #Plot all values by subject\n",
    "            tps_plot = np.mean(all_tps,axis=0)\n",
    "            T, p = all_T[np.argmin(abs(np.array(all_T)))],np.max(np.array(all_p))\n",
    "            fig, ax = plt.subplots(figsize=(3,3))\n",
    "            #ax = sns.stripplot(x=all_scores, y=tps_plot, alpha=.25, zorder=1)\n",
    "            ax = sns.violinplot(x=all_scores, y=tps_plot, alpha=.25, zorder=1, bw=0.5,scale='width')\n",
    "            ax = sns.pointplot(x=all_scores, y =tps_plot, markers=\"d\", scale=.75,\n",
    "                              estimator=np.median, ci=None)\n",
    "            #plt.errorbar([0,1,2],tps_cds,yerr=sem_cds,fmt='o')\n",
    "            #m, b = np.polyfit(all_scores, tps_plot, 1)\n",
    "            #plt.plot(all_scores-1, (m*all_scores)+b)\n",
    "            if len(id_labs) == 1:\n",
    "                anchored_text = AnchoredText('t = %s \\np = %s' % (T, p),loc=2)\n",
    "            elif len(id_labs) > 1 and T > 0:\n",
    "                anchored_text = AnchoredText('t > %s \\np < %s' % (T, p),loc=2)\n",
    "            elif len(id_labs) > 1 and T < 0:\n",
    "                anchored_text = AnchoredText('t < %s \\np < %s' % (T, p),loc=2)\n",
    "            ax.add_artist(anchored_text)\n",
    "            plt.savefig(SAVE_PATH.format(exp,freq,su,roi))\n",
    "            plt.savefig(SAVE_PATH.format(exp,freq,su,roi).replace('png','pdf'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics by electrode or by patient\n",
    "(not single-trial analysis) - Group analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "from os.path import join\n",
    "from utils import subjects\n",
    "import pandas as pd\n",
    "from brainpipe.system import study\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "rep_study = join(st.path, 'feature/TPSim_3groups_Enc/')\n",
    "data_rep = join(rep_study, 'LinReg_stats_theta_v=1_elecs=all_hilbert=ok/')\n",
    "csv_file = join(data_rep, 'All_subjects_ols_btw_theta_mem_groups_LinReg_width=None_step=None_ds.csv')\n",
    "###############################################################################\n",
    "conds = ['low','mid','high']\n",
    "var_con = {'low':1,'mid':2,'high':3}\n",
    "#rois = ['aHC_R','aHC_L','OFC_olf_R', 'OFC_olf_L', 'pPirT_L', 'pPirT_R']\n",
    "rois = ['OFC_olf','aHC','pPirT','IFG']\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df['labels'] = ['pPirT' if lab =='Amg' else lab for lab in df['labels']]\n",
    "df['labels_RL'] = [x+'_R' if df['x'][i] > 0 else x+'_L' for i,x in enumerate(df['labels'])]\n",
    "#rois = np.unique(df['labels'])\n",
    "\n",
    "pvals, rois_sel = [], []\n",
    "for roi in rois:\n",
    "    df_roi = df.loc[df['labels']==roi]\n",
    "    #df_roi2 = df_roi.loc[df_roi['channels'] != 'o2-o1'] #outlier\n",
    "    #if (df_roi.groupby(['subjects']).mean().shape[0])>=4:\n",
    "    rois_sel.append(roi)\n",
    "    #print(df_roi[['subjects','channels','tps_low','tps_mid','tps_high']])\n",
    "\n",
    "    df_take = df_roi\n",
    "    #print(df_take)\n",
    "    data = np.concatenate([df_take['tps_'+cond] for cond in conds])\n",
    "    richness = np.concatenate([[var_con[cond]]*len(df_take['tps_'+cond]) for cond in conds])\n",
    "    subjs = np.concatenate([df_take['subjects']]*len(conds))\n",
    "    all_df = np.concatenate((subjs[:,np.newaxis],richness[:,np.newaxis],\n",
    "                             data[:,np.newaxis]),axis=-1)\n",
    "    df_stats = pd.DataFrame(all_df, columns=['subjs','richness','tps'])\n",
    "    df_stats['richness'] = df_stats['richness'].astype('float')\n",
    "    df_stats['tps'] = df_stats['tps'].astype('float')\n",
    "\n",
    "    print(\">>> processing \", roi)\n",
    "    print(df_take[['tps_low','tps_mid','tps_high']].mean())\n",
    "    #print(df_take[['tps_low','tps_mid','tps_high']].sem())\n",
    "\n",
    "    md = smf.mixedlm(\"tps ~ richness\", df_stats, groups = df_stats['subjs'])\n",
    "    mdf = md.fit()\n",
    "    pvals.append(mdf.pvalues[1])\n",
    "    print(mdf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            all_tps = np.concatenate(all_tps,axis=1)\n",
    "            all_scores = np.concatenate(all_scores,axis=0)\n",
    "            all_T, all_p = [], []\n",
    "            for elec in range(nelecs):\n",
    "                Y, X = np.array(all_tps[elec]), sm.add_constant(np.array(all_scores))\n",
    "                model_ols = sm.OLS(Y,X).fit()\n",
    "                #print(model_ols.summary())\n",
    "                Tval, pval = np.round(model_ols.tvalues[1],2),np.round(model_ols.pvalues[1],3)\n",
    "                all_T.append(Tval), all_p.append(pval)\n",
    "            #Plot all values by subject\n",
    "            tps_plot = np.mean(all_tps,axis=0)\n",
    "            T, p = all_T[np.argmin(abs(np.array(all_T)))],np.max(np.array(all_p))\n",
    "            fig, ax = plt.subplots(figsize=(3,3))\n",
    "            #ax = sns.stripplot(x=all_scores, y=tps_plot, alpha=.25, zorder=1)\n",
    "            ax = sns.violinplot(x=all_scores, y=tps_plot, alpha=.25, zorder=1, bw=0.5,scale='width')\n",
    "            ax = sns.pointplot(x=all_scores, y =tps_plot, markers=\"d\", scale=.75,\n",
    "                              estimator=np.median, ci=None)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
