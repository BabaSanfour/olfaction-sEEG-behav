{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from itertools import combinations, product\n",
    "\n",
    "from brainpipe.system import study\n",
    "from utils import subjects, context_su, odor_groups_wgth, odor_groups_3wgth\n",
    "from similarity_funcs import compute_tps_btw, compute_tps_wth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "CHAF\n",
      "CHAF 2 (10, 1024, 3)\n",
      "CHAF 3 (10, 1024, 3)\n",
      "CHAF 7 (10, 1024, 4)\n",
      "CHAF 8 (10, 1024, 3)\n",
      "CHAF 9 (10, 1024, 5)\n",
      "tps_wth xpow_E l_theta (10, 25)\n",
      "CHAF 2 (10, 1024, 3)\n",
      "CHAF 3 (10, 1024, 3)\n",
      "CHAF 7 (10, 1024, 4)\n",
      "CHAF 8 (10, 1024, 3)\n",
      "CHAF 9 (10, 1024, 5)\n",
      "tps_wth xpow_L l_theta (10, 25)\n",
      "CHAF\n",
      "CHAF 2 (14, 1024, 3)\n",
      "CHAF 3 (14, 1024, 3)\n",
      "CHAF 7 (14, 1024, 4)\n",
      "CHAF 8 (14, 1024, 3)\n",
      "CHAF 9 (14, 1024, 5)\n",
      "tps_wth xpow_E h_theta (14, 25)\n",
      "CHAF 2 (14, 1024, 3)\n",
      "CHAF 3 (14, 1024, 3)\n",
      "CHAF 7 (14, 1024, 4)\n",
      "CHAF 8 (14, 1024, 3)\n",
      "CHAF 9 (14, 1024, 5)\n",
      "tps_wth xpow_L h_theta (14, 25)\n",
      "LEFC\n",
      "LEFC 1 (31, 1024, 42)\n",
      "LEFC 2 (31, 1024, 5)\n",
      "LEFC 3 (31, 1024, 4)\n",
      "LEFC 4 (31, 1024, 10)\n",
      "LEFC 5 (31, 1024, 11)\n",
      "LEFC 6 (31, 1024, 16)\n",
      "LEFC 7 (31, 1024, 7)\n",
      "tps_wth xpow_E l_theta (31, 1118)\n",
      "LEFC 1 (31, 1024, 42)\n",
      "LEFC 2 (31, 1024, 5)\n",
      "LEFC 3 (31, 1024, 4)\n",
      "LEFC 4 (31, 1024, 10)\n",
      "LEFC 5 (31, 1024, 11)\n",
      "LEFC 6 (31, 1024, 16)\n",
      "LEFC 7 (31, 1024, 7)\n",
      "tps_wth xpow_L l_theta (31, 1118)\n",
      "LEFC\n",
      "LEFC 1 (26, 1024, 42)\n",
      "LEFC 2 (26, 1024, 5)\n",
      "LEFC 3 (26, 1024, 4)\n",
      "LEFC 4 (26, 1024, 10)\n",
      "LEFC 5 (26, 1024, 11)\n",
      "LEFC 6 (26, 1024, 16)\n",
      "LEFC 7 (26, 1024, 7)\n",
      "tps_wth xpow_E h_theta (26, 1118)\n",
      "LEFC 1 (26, 1024, 42)\n",
      "LEFC 2 (26, 1024, 5)\n",
      "LEFC 3 (26, 1024, 4)\n",
      "LEFC 4 (26, 1024, 10)\n",
      "LEFC 5 (26, 1024, 11)\n",
      "LEFC 6 (26, 1024, 16)\n",
      "LEFC 7 (26, 1024, 7)\n",
      "tps_wth xpow_L h_theta (26, 1118)\n",
      "FERJ\n",
      "FERJ 1 (76, 1024, 23)\n",
      "FERJ 2 (76, 1024, 6)\n",
      "FERJ 3 (76, 1024, 3)\n",
      "FERJ 5 (76, 1024, 3)\n",
      "FERJ 6 (76, 1024, 3)\n",
      "FERJ 7 (76, 1024, 12)\n",
      "tps_wth xpow_E l_theta (76, 343)\n",
      "FERJ 1 (76, 1024, 23)\n",
      "FERJ 2 (76, 1024, 6)\n",
      "FERJ 3 (76, 1024, 3)\n",
      "FERJ 5 (76, 1024, 3)\n",
      "FERJ 6 (76, 1024, 3)\n",
      "FERJ 7 (76, 1024, 12)\n",
      "tps_wth xpow_L l_theta (76, 343)\n",
      "FERJ\n",
      "FERJ 1 (66, 1024, 23)\n",
      "FERJ 2 (66, 1024, 6)\n",
      "FERJ 3 (66, 1024, 3)\n",
      "FERJ 5 (66, 1024, 3)\n",
      "FERJ 6 (66, 1024, 3)\n",
      "FERJ 7 (66, 1024, 12)\n",
      "tps_wth xpow_E h_theta (66, 343)\n",
      "FERJ 1 (66, 1024, 23)\n",
      "FERJ 2 (66, 1024, 6)\n",
      "FERJ 3 (66, 1024, 3)\n",
      "FERJ 5 (66, 1024, 3)\n",
      "FERJ 6 (66, 1024, 3)\n",
      "FERJ 7 (66, 1024, 12)\n",
      "tps_wth xpow_L h_theta (66, 343)\n",
      "SEMC\n",
      "SEMC 0 (15, 1024, 7)\n",
      "SEMC 1 (15, 1024, 31)\n",
      "SEMC 2 (15, 1024, 6)\n",
      "SEMC 3 (15, 1024, 10)\n",
      "SEMC 5 (15, 1024, 3)\n",
      "SEMC 7 (15, 1024, 4)\n",
      "SEMC 8 (15, 1024, 3)\n",
      "SEMC 9 (15, 1024, 3)\n",
      "tps_wth xpow_E l_theta (15, 561)\n",
      "SEMC 0 (15, 1024, 7)\n",
      "SEMC 1 (15, 1024, 31)\n",
      "SEMC 2 (15, 1024, 6)\n",
      "SEMC 3 (15, 1024, 10)\n",
      "SEMC 5 (15, 1024, 3)\n",
      "SEMC 7 (15, 1024, 4)\n",
      "SEMC 8 (15, 1024, 3)\n",
      "SEMC 9 (15, 1024, 3)\n",
      "tps_wth xpow_L l_theta (15, 561)\n",
      "SEMC\n",
      "SEMC 0 (15, 1024, 7)\n",
      "SEMC 1 (15, 1024, 31)\n",
      "SEMC 2 (15, 1024, 6)\n",
      "SEMC 3 (15, 1024, 10)\n",
      "SEMC 5 (15, 1024, 3)\n",
      "SEMC 7 (15, 1024, 4)\n",
      "SEMC 8 (15, 1024, 3)\n",
      "SEMC 9 (15, 1024, 3)\n",
      "tps_wth xpow_E h_theta (15, 561)\n",
      "SEMC 0 (15, 1024, 7)\n",
      "SEMC 1 (15, 1024, 31)\n",
      "SEMC 2 (15, 1024, 6)\n",
      "SEMC 3 (15, 1024, 10)\n",
      "SEMC 5 (15, 1024, 3)\n",
      "SEMC 7 (15, 1024, 4)\n",
      "SEMC 8 (15, 1024, 3)\n",
      "SEMC 9 (15, 1024, 3)\n",
      "tps_wth xpow_L h_theta (15, 561)\n",
      "VACJ\n",
      "VACJ 0 (38, 1024, 3)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 26 is out of bounds for axis 3 with size 26",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-61edccb9a075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_trials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mx_od\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mid_trials\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_od\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mtps_od\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_od\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_tps_wth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_od\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#nelecs x ncombs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 26 is out of bounds for axis 3 with size 26"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compute TPSim wth ODOR BY ODOR\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_pow = join(st.path, 'feature_new/TPSim_power_data/')\n",
    "pow_file = join(path_pow, '{}_odors=all_elecs=psd_freq={}_pow_EL.npz')\n",
    "path2save = join(st.path, 'feature_new/TPSim_by_odor_wth/')\n",
    "savename = join(path2save, '{}_odors=all_tps=wth_elecs=psd_freq={}_{}.npz')\n",
    "###############################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "\n",
    "freqs = ['l_theta','h_theta']\n",
    "dims = ['xpow_E','xpow_L']\n",
    "t0, t1 = 0, 2\n",
    "\n",
    "for su, freq in product(subjects,freqs):\n",
    "    print(su)\n",
    "    pow_mat = np.load(pow_file.format(su,freq),allow_pickle=True)\n",
    "    time = pow_mat['time']-3\n",
    "    t_sel = [i for i,t in enumerate(time) if t0<=t<t1]\n",
    "    \n",
    "    for dim in dims:\n",
    "        step = dim.split('_')[-1]\n",
    "        x = pow_mat[dim][:,:,t_sel,:]\n",
    "\n",
    "        od_wth, tps_all_od, p_all_od, tr_list = [], [], [], []\n",
    "        for od in np.unique(pow_mat['od_'+step]):\n",
    "            id_trials = np.where([pow_mat['od_'+step]==od])[1]\n",
    "\n",
    "            if len(id_trials) > 1:\n",
    "                x_od = np.squeeze(x[:,:,:,id_trials])\n",
    "                print(su,od,x_od.shape)\n",
    "                tps_od, p_od, tr_l = compute_tps_wth(x_od) #nelecs x ncombs\n",
    "                tps_all_od.append(tps_od), p_all_od.append(p_od)\n",
    "                od_wth.extend([od]*tps_od.shape[-1])\n",
    "                tr_list.extend(tr_l)\n",
    "        tps_all_od = np.concatenate((tps_all_od),axis=-1)\n",
    "        print('tps_wth',dim,freq,tps_all_od.shape)\n",
    "        p_all_od = np.concatenate((p_all_od),axis=-1)\n",
    "\n",
    "        dico_tps = {}\n",
    "        for fi in pow_mat.files:\n",
    "            dico_tps[fi] = pow_mat[fi]\n",
    "        dico_tps['tps'], dico_tps['pvals'] = tps_all_od, p_all_od\n",
    "        dico_tps['odor'] = od_wth\n",
    "        dico_tps['trials_combs'] = tr_list\n",
    "        #print(freq, 'mean tps wth by elec', np.mean(tps_all_od,axis=1))\n",
    "        np.savez(savename.format(su,freq,dim),**dico_tps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute TPSim BTW ODORS\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_pow = join(st.path, 'feature_new/TPSim_power_data/')\n",
    "pow_file = join(path_pow, '{}_odors=all_elecs=psd_freq={}_pow_EL.npz')\n",
    "path2save = join(st.path, 'feature_new/TPSim_by_odor_btw/')\n",
    "savename = join(path2save, '{}_odors=all_tps=btw_elecs=psd_freq={}.npz')\n",
    "###############################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "\n",
    "freqs = ['l_theta','h_theta']\n",
    "subjects = ['LEFC']\n",
    "\n",
    "t0, t1 = 0, 2\n",
    "\n",
    "for su, freq in product(subjects,freqs):\n",
    "    print(su)\n",
    "    pow_mat = np.load(pow_file.format(su,freq),allow_pickle=True)\n",
    "    time = pow_mat['time']-3\n",
    "    t_sel = [i for i,t in enumerate(time) if t0<=t<t1]\n",
    "    \n",
    "    od_btw, tps_all_od, p_all_od, combs_ods = [], [], [], []\n",
    "    for od in np.unique(pow_mat['odor']):\n",
    "        x = pow_mat['xpow'][:,:,t_sel,:]\n",
    "        id_trials = np.where([pow_mat['odor']==od])[1]\n",
    "        id_others = [i for i in range(pow_mat['xpow'].shape[-1]) if i not in id_trials]\n",
    "        od_target, od_others = pow_mat['odor'][id_trials], pow_mat['odor'][id_others]\n",
    "\n",
    "        if len(id_trials) > 1:\n",
    "            x_od = np.squeeze(x[:,:,:,id_trials])\n",
    "            x_od2 = np.squeeze(x[:,:,:,id_others])\n",
    "            tps_od, p_od = compute_tps_btw(x_od,x_od2) #nelecs x ncombs\n",
    "            tps_all_od.append(tps_od), p_all_od.append(p_od)\n",
    "            od_btw.extend([od]*tps_od.shape[-1])\n",
    "            combs_ods.extend([o1+'_'+o2 for o1, o2 in product(od_target,od_others)])\n",
    "    tps_all_od = np.concatenate((tps_all_od),axis=-1)\n",
    "    print('tps_btw',tps_all_od.shape)\n",
    "    p_all_od = np.concatenate((p_all_od),axis=-1)\n",
    "    \n",
    "    dico_tps = {}\n",
    "    for fi in pow_mat.files:\n",
    "        dico_tps[fi] = pow_mat[fi]\n",
    "    dico_tps['tps'], dico_tps['pvals'] = tps_all_od, p_all_od\n",
    "    dico_tps['odor'] = od_btw\n",
    "    dico_tps['combs'] = combs_ods\n",
    "    print(freq, 'combs', len(combs_ods), 'od', len(od_btw))\n",
    "    np.savez(savename.format(su,freq),**dico_tps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute TPSim WTH multiple Odors (by Richness, Context)\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_pow = join(st.path, 'feature_new/TPSim_power_data/')\n",
    "pow_file = join(path_pow, '{}_odors=all_elecs=psd_freq={}_bsl=400ms_pow.npz')\n",
    "path2save = join(st.path, 'feature_new/TPSim_by_{}_wth/')\n",
    "savename = join(path2save, '{}_odors=all_tps=wth_elecs=psd_freq={}_bsl=400ms.npz')\n",
    "###############################################################################\n",
    "cond = 'context' #'mem2', 'mem3', 'context'\n",
    "freqs = ['l_theta','h_theta']\n",
    "t0, t1 = 0,2\n",
    "dict_gr = (context_su if cond == 'context' else \\\n",
    "            (odor_groups_wgth if cond == 'mem2' else odor_groups_3wgth))\n",
    "\n",
    "if not exists(path2save.format(cond)):\n",
    "    makedirs(path2save.format(cond))\n",
    "###############################################################################\n",
    "\n",
    "for su, freq in product(dict_gr,freqs):\n",
    "    print('>> processing',su,freq,cond)\n",
    "    pow_mat = np.load(pow_file.format(su,freq),allow_pickle=True)\n",
    "    time = pow_mat['time']-3\n",
    "    t_sel = [i for i,t in enumerate(time) if t0<=t<t1]\n",
    "    x = pow_mat['xpow'][:,:,t_sel,:]\n",
    "    \n",
    "    keys_list = list(dict_gr[su].keys())\n",
    "    od_lists = list(dict_gr[su].values())\n",
    "    cond_wth, tps_all_od, p_all_od = [], [], []\n",
    "    for num,l in enumerate(od_lists):\n",
    "        id_trials = [i for i,od in enumerate(pow_mat['odor']) if od in l]\n",
    "        if len(id_trials) > 1:\n",
    "            x_od = np.squeeze(x[:,:,:,id_trials])\n",
    "            tps_od, p_od = compute_tps_wth(x_od) #nelecs x ncombs\n",
    "            tps_all_od.append(tps_od), p_all_od.append(p_od)\n",
    "            cond_wth.extend([keys_list[num]]*tps_od.shape[-1])\n",
    "    tps_all_od = np.concatenate((tps_all_od),axis=-1)\n",
    "    #print('tps_wth',tps_all_od.shape,cond_wth)\n",
    "    p_all_od = np.concatenate((p_all_od),axis=-1)\n",
    "    \n",
    "    dico_tps = {}\n",
    "    for fi in pow_mat.files:\n",
    "        dico_tps[fi] = pow_mat[fi]\n",
    "    dico_tps['tps'], dico_tps['pvals'] = tps_all_od, p_all_od\n",
    "    dico_tps[cond] = cond_wth\n",
    "    #print(freq, 'mean tps wth by elec', np.mean(tps_all_od,axis=1))\n",
    "    np.savez(savename.format(cond,su,freq),**dico_tps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute TPSim BTW multiple Odors (by Richness, Context)\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_pow = join(st.path, 'feature_new/TPSim_power_data/')\n",
    "pow_file = join(path_pow, '{}_odors=all_elecs=psd_freq={}_bsl=400ms_pow.npz')\n",
    "path2save = join(st.path, 'feature_new/TPSim_by_{}_btw/')\n",
    "savename = join(path2save, '{}_odors=all_tps=btw_elecs=psd_freq={}_bsl=400ms.npz')\n",
    "###############################################################################\n",
    "cond = 'context' #'mem2', 'mem3', 'context'\n",
    "freqs = ['l_theta','h_theta']\n",
    "t0, t1 = 0, 2\n",
    "dict_gr = (context_su if cond == 'context' else \\\n",
    "            (odor_groups_wgth if cond == 'mem2' else odor_groups_3wgth))\n",
    "\n",
    "if not exists(path2save.format(cond)):\n",
    "    makedirs(path2save.format(cond))\n",
    "###############################################################################\n",
    "\n",
    "for su, freq in product(dict_gr,freqs):\n",
    "    print('>> processing',su,freq,cond)\n",
    "    pow_mat = np.load(pow_file.format(su,freq),allow_pickle=True)\n",
    "    time = pow_mat['time']-3\n",
    "    t_sel = [i for i,t in enumerate(time) if t0<=t<t1]\n",
    "    x = pow_mat['xpow'][:,:,t_sel,:]\n",
    "    \n",
    "    keys_list = list(dict_gr[su].keys())\n",
    "    od_lists = list(dict_gr[su].values())\n",
    "\n",
    "    cond_btw, tps_all_od, p_all_od = [], [], []\n",
    "    for cond1,cond2 in combinations(range(len(keys_list)),2):\n",
    "        id_trials0 = [i for i,od in enumerate(pow_mat['odor'])\\\n",
    "                                          if od in od_lists[cond1]]\n",
    "        id_trials1 = [i for i,od in enumerate(pow_mat['odor'])\\\n",
    "                                          if od in od_lists[cond2]]\n",
    "        x_od = np.squeeze(x[:,:,:,id_trials0])\n",
    "        x_od2 = np.squeeze(x[:,:,:,id_trials1])\n",
    "        tps_od, p_od = compute_tps_btw(x_od,x_od2) #nelecs x ncombs\n",
    "        tps_all_od.append(tps_od), p_all_od.append(p_od)\n",
    "        cond_btw.extend([keys_list[cond1]+'_'+keys_list[cond2]]*tps_od.shape[-1])\n",
    "    \n",
    "    tps_all_od = np.concatenate((tps_all_od),axis=-1)\n",
    "    print('tps_btw',tps_all_od.shape)\n",
    "    p_all_od = np.concatenate((p_all_od),axis=-1)\n",
    "    \n",
    "    dico_tps = {}\n",
    "    for fi in pow_mat.files:\n",
    "        dico_tps[fi] = pow_mat[fi]\n",
    "    dico_tps['tps'], dico_tps['pvals'] = tps_all_od, p_all_od\n",
    "    dico_tps[cond] = cond_btw\n",
    "    #print(freq, 'mean tps wth by elec', np.mean(tps_all_od,axis=1))\n",
    "    np.savez(savename.format(cond,su,freq),**dico_tps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early/Late conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute TPSim by combining all odors from each CONDITION for Early/Late\n",
    "\"\"\"\n",
    "exp = 'Enc' #Ret, Enc\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_data = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_cond_3groups_v=1_elecs=all/')\n",
    "pow_file = join(path_data, '{}_odor_{}_'+exp[0]+'_6freqs_EL.npz')\n",
    "pathsave = join(st.path,'feature/TPSim_3groups_{}/TPS_btw_v=1_elecs=all/')#_'+RT_type+'/')\n",
    "savename = join(pathsave,'TPS_pears_{}_{}_btw_{}_{}.npz')\n",
    "###############################################################################\n",
    "if not exists(pathsave.format(exp)):\n",
    "    makedirs(pathsave.format(exp))\n",
    "#print('save path',path2save.format(exp))\n",
    "#print('pow files',pow_file)\n",
    "#############################################RT_type##################################\n",
    "# freqs = ['delta','theta', 'alpha', 'beta','low_gamma','high_gamma']\n",
    "freqs = ['theta']\n",
    "subjects = ['PIRJ','CHAF','FERJ','VACJ','SEMC','LEFC']\n",
    "conds,step = ['low','mid','high'], 'Early'\n",
    "to_take = [17,47]\n",
    "\n",
    "def tpsim_by_cond(su,cond):\n",
    "    mat = np.load(pow_file.format(su,cond),allow_pickle=True)\n",
    "    print(su,cond,mat['xpow_'+step[0]].shape,np.unique(mat['labels']))\n",
    "    pow_data = mat['xpow_'+step[0]][:,:,to_take[0]:to_take[1],:] #3584 points \n",
    "    _,nelecs,npts,ntrials = pow_data.shape\n",
    "    for f,freq in enumerate(freqs):\n",
    "        data_freq = pow_data[f]\n",
    "        R_freq, p_freq = np.array([]), np.array([])\n",
    "        for elec in range(nelecs):\n",
    "            pow0 = data_freq[elec,...]\n",
    "            R_trials, p_trials = np.array([]), np.array([])\n",
    "            for t0, t1 in combinations(np.arange(ntrials), 2):\n",
    "                R, p = stats.pearsonr(pow0[:,t0],pow0[:,t1])\n",
    "                D = 1 - R # <<<<<<< HERE TO CHANGE FOR DISTANCE COMPUTATIONS\n",
    "                R_trials = np.vstack((R_trials,D)) if np.size(R_trials) else D\n",
    "                p_trials = np.vstack((p_trials,p)) if np.size(p_trials) else p\n",
    "            R_freq = np.vstack((R_freq,R_trials.T)) if np.size(R_freq) else R_trials.T\n",
    "            p_freq = np.vstack((p_freq,p_trials.T)) if np.size(p_freq) else p_trials.T\n",
    "        #R_freq = np.arctanh(R_freq)\n",
    "        print(su,cond,freq,'TPSim',R_freq.shape, p_freq.shape,'initial data',pow_data.shape)\n",
    "        dict_ = {'tps':R_freq, 'pval':p_freq,'label':mat['labels'],\n",
    "                           'channel':mat['channels'], 'xyz':mat['xyz']}\n",
    "        np.savez(savename.format(exp,su,cond,freq,step),**dict_)\n",
    "\n",
    "for su,cond in product(subjects,conds):\n",
    "    tpsim_by_cond(su,cond)\n",
    "# Parallel(n_jobs=-1)(delayed(\n",
    "#     tpsim_by_cond)(su,cond) for su,cond in product(subjects,conds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute similarity BTW odors through learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import odor_list_su, odor_groups_3wgth\n",
    "\"\"\"\n",
    "LEARNING effect\n",
    "Compute TPSim for all ODORS whatever the memory perf group\n",
    "ALL ODORS TOGETHER // EARLY MID LATE GROUPS OF TRIALS\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_data = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_odor_all_elecsFT/')\n",
    "pow_file = join(path_data, '{}_odor_{}_bipo_all_E_6freqs.npz')\n",
    "pathsave = join(st.path,'feature/TPSim_3groups_Enc/TPS_btw_thgh_time_v=1_elecs=all/')\n",
    "savename = join(pathsave,'TPS_pears_learn_{}_btw_{}_{}.npz')\n",
    "###############################################################################\n",
    "if not exists(pathsave.format(exp)):\n",
    "    makedirs(pathsave.format(exp))\n",
    "###############################################################################\n",
    "freq = 'theta'\n",
    "to_take = [17,47]\n",
    "\n",
    "def tpsim_by_cond_learn(data):\n",
    "    nelecs, npts, ntrials = data.shape\n",
    "    ncomb = len([a for a,_ in combinations(np.arange(ntrials), 2)])\n",
    "    tps_trials = np.empty((nelecs,ncomb))\n",
    "    for e,elec in enumerate(range(nelecs)):\n",
    "        pow0 = data[elec,...]\n",
    "        c = 0\n",
    "        for t0, t1 in combinations(np.arange(ntrials), 2):\n",
    "            tps_trials[e,c], _ = stats.pearsonr(pow0[:,t0],pow0[:,t1])\n",
    "            c += 1\n",
    "    tps_trials = 1 - np.arctanh(tps_trials)\n",
    "    return tps_trials\n",
    "\n",
    "for su in odor_list_su('Enc'):\n",
    "    early_t, mid_t, late_t = [], [], []\n",
    "    for od in odor_list_su('Enc')[su]:\n",
    "        mat = np.load(pow_file.format(su,od),allow_pickle=True)\n",
    "        pow_ = mat['xpow'][1,:,to_take[0]:to_take[1],:]\n",
    "        thr = int(pow_.shape[-1]/3)\n",
    "        print(pow_.shape,thr)\n",
    "        if thr == 0:\n",
    "            if pow_.shape[-1] >= 1:\n",
    "                early_t.append(pow_[...,:thr+1])\n",
    "            if pow_.shape[-1] == 2:\n",
    "                mid_t.append(pow_[...,thr+1:])\n",
    "        if thr >= 1:\n",
    "            #if pow_.shape[-1] == 4:\n",
    "            #    early_t.append(pow_[...,:thr])\n",
    "            #    mid_t.append(pow_[...,thr:3])\n",
    "            #    late_t.append(pow_[...,3:])\n",
    "            #if pow_.shape[-1] == 5:\n",
    "            #    early_t.append(pow_[...,:2])\n",
    "            #    mid_t.append(pow_[...,2:4])\n",
    "            #    late_t.append(pow_[...,4:])\n",
    "            #if (pow_.shape[-1] >= 6) or (pow_.shape[-1]==3):\n",
    "            early_t.append(pow_[...,:thr])\n",
    "            mid_t.append(pow_[...,thr:(2*thr)])\n",
    "            late_t.append(pow_[...,(2*thr):])\n",
    "    print('early odors list', [x.shape for x in early_t])\n",
    "    print('mid odors list', [x.shape for x in mid_t])\n",
    "    print('late odors list', [x.shape for x in late_t])\n",
    "\n",
    "    concat_E = np.concatenate(early_t, axis=-1)\n",
    "    concat_M = np.concatenate(mid_t, axis=-1)\n",
    "    concat_L = np.concatenate(late_t, axis=-1)\n",
    "    tps_E = tpsim_by_cond_learn(concat_E)\n",
    "    tps_M = tpsim_by_cond_learn(concat_M)\n",
    "    tps_L = tpsim_by_cond_learn(concat_L)\n",
    "    \n",
    "    dict_t = {}\n",
    "    dict_t['tps_0'], dict_t['tps_1'], dict_t['tps_2'] = tps_E, tps_M, tps_L\n",
    "    dict_t['label'], dict_t['channel'], dict_t['xyz'] = mat['labels'],mat['channels'], mat['xyz']\n",
    "    np.savez(savename.format(su,freq,'3gr'),**dict_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import odor_list_su, odor_groups_3wgth\n",
    "\"\"\"\n",
    "LEARNING effect\n",
    "Compute TPSim for all ODORS whatever the memory perf group\n",
    "ALL ODORS TOGETHER // EARLY AND LATE GROUPS OF TRIALS\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "conds = ['low','mid','high']\n",
    "path_data = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_odor_all_elecsFT/')\n",
    "pow_file = join(path_data, '{}_odor_{}_bipo_all_E_6freqs.npz')\n",
    "pathsave = join(st.path,'feature/TPSim_3groups_Enc/TPS_btw_thgh_time_v=1_elecs=all/')\n",
    "savename = join(pathsave,'TPS_pears_learn_{}_btw_{}_{}.npz')\n",
    "###############################################################################\n",
    "if not exists(pathsave.format(exp)):\n",
    "    makedirs(pathsave.format(exp))\n",
    "###############################################################################\n",
    "freq = 'theta'\n",
    "to_take = [17,47]\n",
    "\n",
    "def tpsim_by_cond_learn(data):\n",
    "    nelecs, npts, ntrials = data.shape\n",
    "    ncomb = len([a for a,_ in combinations(np.arange(ntrials), 2)])\n",
    "    tps_trials = np.empty((nelecs,ncomb))\n",
    "    for e,elec in enumerate(range(nelecs)):\n",
    "        pow0 = data[elec,...]\n",
    "        c = 0\n",
    "        for t0, t1 in combinations(np.arange(ntrials), 2):\n",
    "            tps_trials[e,c], _ = stats.pearsonr(pow0[:,t0],pow0[:,t1])\n",
    "            c += 1\n",
    "    tps_trials = 1 - np.arctanh(tps_trials)\n",
    "    return tps_trials\n",
    "\n",
    "for su in odor_list_su('Enc'):\n",
    "    early_t, late_t = [], []\n",
    "    for od in odor_list_su('Enc')[su]:\n",
    "        mat = np.load(pow_file.format(su,od),allow_pickle=True)\n",
    "        pow_ = mat['xpow'][1,:,to_take[0]:to_take[1],:]\n",
    "        thr = int(pow_.shape[-1]/2)\n",
    "        if thr == 0:\n",
    "            early_t.append(pow_[...,:thr+1])\n",
    "        else:\n",
    "            early_t.append(pow_[...,:thr]), late_t.append(pow_[...,thr:])\n",
    "    print('early odors list', [x.shape for x in early_t])\n",
    "    print('late odors list', [x.shape for x in late_t])\n",
    "\n",
    "    concat_E = np.concatenate(early_t, axis=-1)\n",
    "    concat_L = np.concatenate(late_t, axis=-1)\n",
    "    tps_E = tpsim_by_cond_learn(concat_E)\n",
    "    tps_L = tpsim_by_cond_learn(concat_L)\n",
    "    \n",
    "    dict_t = {}\n",
    "    dict_t['tps_0'], dict_t['tps_1'] = tps_E, tps_L\n",
    "    dict_t['label'], dict_t['channel'], dict_t['xyz'] = mat['labels'],mat['channels'], mat['xyz']\n",
    "    np.savez(savename.format(su,freq,'2gr'),**dict_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import odor_list_su, odor_groups_3wgth\n",
    "\"\"\"\n",
    "LEARNING effect for WITHIN COMPARISONS\n",
    "Compute TPSim for all ODORS whatever the memory perf group \n",
    "ALL ODORS TOGETHER // EARLY AND LATE GROUPS OF TRIALS\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_data = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_odor_all_elecsFT/')\n",
    "pow_file = join(path_data, '{}_odor_{}_bipo_all_E_6freqs.npz')\n",
    "pathsave = join(st.path,'feature/TPSim_3groups_Enc/by_odor_wth_thgh_time_v=1_elecs=all/')\n",
    "savename = join(pathsave,'TPS_pears_learn_{}_wth_{}_{}_2gr.npz')\n",
    "###############################################################################\n",
    "f,freq = 1,'theta'\n",
    "to_take = [17,47]\n",
    "reps = ['Enc'] #Ret, Enc\n",
    "for rep in reps:\n",
    "    if not exists(pathsave.format(rep)):\n",
    "        makedirs(pathsave.format(rep))\n",
    "\n",
    "odors_su = {'CHAF': {5:12,7:68,8:36,9:96,1:6,2:2,3:68,4:8},\n",
    "            'LEFC': {1:4,2:0,3:6,4:12,14:96,15:2,16:4,17:68},\n",
    "            'PIRJ': {4:36,9:2,1:4,18:32,6:34,5:4,7:68}, #missing odor 15\n",
    "            'VACJ': {14:6,15:64,16:68,17:8,10:6,11:4,12:4,13:40},\n",
    "            'SEMC': {10:2,11:6,12:6,13:6,5:8,7:4,8:8,9:10},\n",
    "            'FERJ': {16:6,17:6,5:8,7:6,12:8,13:8,2:6,1:10}}\n",
    "\n",
    "def tpsim_by_odor(data):\n",
    "    nelecs,npts,ntrials = data.shape\n",
    "    tps_wth = np.array([])\n",
    "    for elec in range(nelecs):\n",
    "        pow0 = data[elec,:]\n",
    "        tps_trials = np.array([])\n",
    "        for t0, t1 in combinations(np.arange(ntrials), 2):\n",
    "            R, _ = stats.pearsonr(pow0[:,t0],pow0[:,t1])\n",
    "            tps_trials = np.vstack((tps_trials,R)) if np.size(tps_trials) else R\n",
    "        tps_wth = np.vstack((tps_wth,tps_trials.T)) if np.size(tps_wth) else tps_trials.T\n",
    "    #tps_wth = np.arctanh(tps_wth)\n",
    "    print(su,odor,freq,'R',tps_wth.shape, 'initial data',data.shape)\n",
    "    return tps_wth\n",
    "\n",
    "def compute_save_tpsim_wth_step(exp,su,odor,f,freq):\n",
    "    mat = np.load(pow_path.format(su,odor,rep[0]),allow_pickle=True)\n",
    "    pow_data = mat['xpow'][f,:,to_take[0]:to_take[1],:]\n",
    "    print(su,odor,pow_data.shape)\n",
    "    \n",
    "    #separate data in two groups\n",
    "    thr = int(pow_data.shape[-1]/2)\n",
    "    if thr != 0:\n",
    "        tps_E = tpsim_by_odor(pow_data[...,:thr])\n",
    "        tps_L = tpsim_by_odor(pow_data[...,thr:])\n",
    "    \n",
    "        dict_t = {}\n",
    "        dict_t['tps_0'], dict_t['tps_1'] = tps_E, tps_L\n",
    "        dict_t['label'], dict_t['channel'], dict_t['xyz'] = mat['labels'],mat['channels'], mat['xyz']\n",
    "        np.savez(savename.format(su,freq,odor),**dict_t)\n",
    "\n",
    "for rep in reps:\n",
    "    for su in odors_su:\n",
    "        for odor in odors_su[su]:\n",
    "            compute_save_tpsim_wth_step(rep,su,odor,f,freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import odor_list_su, odor_groups_3wgth\n",
    "\"\"\"\n",
    "LEARNING effect for BETWEEN COMPARISONS\n",
    "Compute TPSim for all ODORS whatever the memory perf group \n",
    "ALL ODORS TOGETHER // EARLY AND LATE GROUPS OF TRIALS\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_data = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_odor_all_elecsFT/')\n",
    "pow_file = join(path_data, '{}_odor_{}_bipo_all_E_6freqs.npz')\n",
    "pathsave = join(st.path,'feature/TPSim_3groups_Enc/by_odor_btw_thgh_time_v=1_elecs=all/')\n",
    "savename = join(pathsave,'TPS_pears_learn_{}_btw_{}_{}_2gr.npz')\n",
    "###############################################################################\n",
    "f,freq = 1,'theta'\n",
    "to_take = [17,47]\n",
    "reps = ['Enc'] #Ret, Enc\n",
    "for rep in reps:\n",
    "    if not exists(pathsave.format(rep)):\n",
    "        makedirs(pathsave.format(rep))\n",
    "\n",
    "odors_su = {'CHAF': {5:12,7:68,8:36,9:96,1:6,2:2,3:68,4:8},\n",
    "            'LEFC': {1:4,2:0,3:6,4:12,14:96,15:2,16:4,17:68},\n",
    "            'PIRJ': {4:36,9:2,1:4,18:32,6:34,5:4,7:68}, #missing odor 15\n",
    "            'VACJ': {14:6,15:64,16:68,17:8,10:6,11:4,12:4,13:40},\n",
    "            'SEMC': {10:2,11:6,12:6,13:6,5:8,7:4,8:8,9:10},\n",
    "            'FERJ': {16:6,17:6,5:8,7:6,12:8,13:8,2:6,1:10}}\n",
    "\n",
    "def tpsim_by_odor(data):\n",
    "    nelecs,npts,ntrials = data.shape\n",
    "    tps_wth = np.array([])\n",
    "    for elec in range(nelecs):\n",
    "        pow0 = data[elec,:]\n",
    "        tps_trials = np.array([])\n",
    "        for t0, t1 in combinations(np.arange(ntrials), 2):\n",
    "            R, _ = stats.pearsonr(pow0[:,t0],pow0[:,t1])\n",
    "            tps_trials = np.vstack((tps_trials,R)) if np.size(tps_trials) else R\n",
    "        tps_wth = np.vstack((tps_wth,tps_trials.T)) if np.size(tps_wth) else tps_trials.T\n",
    "    #tps_wth = np.arctanh(tps_wth)\n",
    "    print(su,odor,freq,'R',tps_wth.shape, 'initial data',data.shape)\n",
    "    return tps_wth\n",
    "\n",
    "def separate_2gr(pow_data):\n",
    "    thr = int(pow_data.shape[-1]/2)\n",
    "    all_files = []\n",
    "    if thr != 0:\n",
    "        all_files.append(pow_data[...,:thr])\n",
    "        all_files.append(pow_data[...,thr:])\n",
    "    return all_files\n",
    "\n",
    "for rep in reps:\n",
    "    for su in odors_su:\n",
    "        for o1 in odors_su[su]:\n",
    "            o2 = [o for o in odors_su[su] if o != o1]\n",
    "            mat_o1 = np.load(pow_file.format(su,o1,exp[0]),allow_pickle=True)\n",
    "            list_o1 = separate_2gr(mat_o1['xpow'][f,:,17:47,:]) #nelecs,npts,ntrials\n",
    "            if len(list_o1) > 0: #at least 2 repetitions of o1\n",
    "                list_o2 = []\n",
    "                for o in o2:\n",
    "                    pow_ = np.load(pow_file.format(su,o,exp[0],freq))['xpow'][f,:,17:47,:]\n",
    "                    pow_sep = separate_2gr(pow_)\n",
    "                    if len(pow_sep) > 0:\n",
    "                        list_o2.append(separate_2gr(pow_))\n",
    "                o2_E = np.concatenate([x[0] for x in list_o2],axis=-1)\n",
    "                o2_L = np.concatenate([x[1] for x in list_o2],axis=-1)\n",
    "                tpsE = tpsim_btw_odors_by_odor(list_o1[0], o2_E)\n",
    "                tpsL = tpsim_btw_odors_by_odor(list_o1[1], o2_L)\n",
    "                mat = {'tps_0':tpsE, 'tps_1':tpsL,'label':mat_o1['labels'],\n",
    "                               'channel':mat_o1['channels'], 'xyz':mat_o1['xyz']}\n",
    "                np.savez(savename.format(su,str(o1),freq),**mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpsim_btw_odors_by_odor(pow_o1,pow_o2):\n",
    "    \"\"\"\n",
    "    Compute tpsim for one odor with all other odors in list od 2\n",
    "    Parameters\n",
    "    ----------\n",
    "    od1, od2 : list\n",
    "        o1 of length 1 and o2 of length (n_odors - 1)\n",
    "    freq : string\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tpsim : array\n",
    "        The Temporal Pattern Similarity between all odors BY odor\n",
    "        (n_combinations of trials btw o1 and o2)\n",
    "    \"\"\"\n",
    "    \n",
    "    R_freq, p_freq = np.array([]), np.array([])\n",
    "    for elec in range(pow_o2.shape[0]):\n",
    "        pow1, pow2 = pow_o1[elec], pow_o2[elec]\n",
    "        R_trials, p_trials = np.array([]), np.array([])\n",
    "        for t0, t1 in product(range(pow1.shape[-1]),range(pow2.shape[-1])):\n",
    "            R, p = stats.pearsonr(pow1[:,t0],pow2[:,t1])\n",
    "            R_trials = np.vstack((R_trials,R)) if np.size(R_trials) else R\n",
    "            p_trials = np.vstack((p_trials,p)) if np.size(p_trials) else p\n",
    "        R_freq = np.vstack((R_freq,R_trials.T)) if np.size(R_freq) else R_trials.T\n",
    "        p_freq = np.vstack((p_freq,p_trials.T)) if np.size(p_freq) else p_trials.T\n",
    "        #print(R_freq.shape, p_freq.shape)\n",
    "    R_freq = np.arctanh(R_freq)\n",
    "    return R_freq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import odor_list_su, odor_groups_3wgth\n",
    "\"\"\"\n",
    "LEARNING effect\n",
    "Compute TPSim for all ODORS BY memory perf group\n",
    "EARLY AND LATE GROUPS OF TRIALS\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "conds,exp = ['low','mid','high'],'Enc'\n",
    "path_data = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_cond_3groups_v=1_elecs=all/')\n",
    "pow_file = join(path_data, '{}_odor_{}_E_6freqs.npz')\n",
    "pathsave = join(st.path,'feature/TPSim_3groups_Enc/TPS_btw_thgh_time_v=1_elecs=all/')\n",
    "savename = join(pathsave,'TPS_pears_learn_{}_btw_{}_{}_{}.npz')\n",
    "###############################################################################\n",
    "if not exists(pathsave.format(exp)):\n",
    "    makedirs(pathsave.format(exp))\n",
    "###############################################################################\n",
    "freq, meth = 'theta', '2gr' #groups here refer to time groups early late\n",
    "to_take = [17,47]\n",
    "\n",
    "def tpsim_by_cond_learn(data):\n",
    "    nelecs, npts, ntrials = data.shape\n",
    "    ncomb = len([a for a,_ in combinations(np.arange(ntrials), 2)])\n",
    "    tps_trials = np.empty((nelecs,ncomb))\n",
    "    for e,elec in enumerate(range(nelecs)):\n",
    "        pow0 = data[elec,...]\n",
    "        c = 0\n",
    "        for t0, t1 in combinations(np.arange(ntrials), 2):\n",
    "            tps_trials[e,c], _ = stats.pearsonr(pow0[:,t0],pow0[:,t1])\n",
    "            c += 1\n",
    "    tps_trials = 1 - tps_trials\n",
    "    return tps_trials\n",
    "\n",
    "for su in odor_list_su('Enc'):\n",
    "    for cond in conds:\n",
    "        mat = np.load(pow_file.format(su,cond),allow_pickle=True)\n",
    "        pow_ = mat['xpow'][1,:,to_take[0]:to_take[1],:]\n",
    "        if meth == '2gr':\n",
    "            thr = int(pow_.shape[-1]/2)\n",
    "            early_c, late_c = pow_[...,:thr], pow_[...,thr:]\n",
    "            print('early ', early_c.shape)\n",
    "            print('late ', late_c.shape)\n",
    "\n",
    "            tps_E = tpsim_by_cond_learn(early_c)\n",
    "            tps_L = tpsim_by_cond_learn(late_c)\n",
    "\n",
    "            dict_t = {}\n",
    "            dict_t['tps_0'], dict_t['tps_1'] = tps_E, tps_L\n",
    "            dict_t['label'], dict_t['channel'], dict_t['xyz'] = mat['labels'],mat['channels'], mat['xyz']\n",
    "            np.savez(savename.format(su,freq,cond,'2gr'),**dict_t)\n",
    "        \n",
    "        elif meth =='3gr':\n",
    "            thr = int(pow_.shape[-1]/3)\n",
    "            print(pow_.shape,thr)\n",
    "            if thr == 0:\n",
    "                if pow_.shape[-1] >= 1:\n",
    "                    early_c = pow_[...,:thr+1]\n",
    "                if pow_.shape[-1] == 2:\n",
    "                    mid_c = pow_[...,thr+1:]\n",
    "            if thr >= 1:\n",
    "                early_c = pow_[...,:thr]\n",
    "                mid_c = pow_[...,thr:(2*thr)]\n",
    "                late_c = pow_[...,(2*thr):]\n",
    "            print('early odors list', [x.shape for x in early_c])\n",
    "            print('mid odors list', [x.shape for x in mid_c])\n",
    "            print('late odors list', [x.shape for x in late_c])\n",
    "\n",
    "            tps_E = tpsim_by_cond_learn(early_c)\n",
    "            tps_M = tpsim_by_cond_learn(mid_c)\n",
    "            tps_L = tpsim_by_cond_learn(late_c)\n",
    "    \n",
    "            dict_t = {}\n",
    "            dict_t['tps_0'], dict_t['tps_1'], dict_t['tps_2'] = tps_E, tps_M, tps_L\n",
    "            dict_t['label'], dict_t['channel'], dict_t['xyz'] = mat['labels'],mat['channels'], mat['xyz']\n",
    "            np.savez(savename.format(su,freq,cond,'3gr'),**dict_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import odor_list_su, odor_groups_3wgth\n",
    "\"\"\"\n",
    "LEARNING effect\n",
    "Compute TPSim for all ODORS whatever the memory perf group\n",
    "ALL ODORS TOGETHER // ALL trials INDIVIDUALLY no groups\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_data = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_cond_3groups_v=1_elecs=all/')\n",
    "pow_file = join(path_data, '{}_odor_{}_E_6freqs.npz')\n",
    "pathsave = join(st.path,'feature/TPSim_3groups_Enc/TPS_btw_thgh_time_v=1_elecs=all/')\n",
    "savename = join(pathsave,'TPS_pears_learn_{}_btw_{}_{}.npz')\n",
    "###############################################################################\n",
    "if not exists(pathsave.format(exp)):\n",
    "    makedirs(pathsave.format(exp))\n",
    "###############################################################################\n",
    "freq = 'theta'\n",
    "to_take = [17,47]\n",
    "\n",
    "def tpsim_by_cond_learn(data):\n",
    "    nelecs, npts, ntrials = data.shape\n",
    "    ncomb = len([a for a,_ in combinations(np.arange(ntrials), 2)])\n",
    "    tps_trials = np.empty((nelecs,ncomb))\n",
    "    for e,elec in enumerate(range(nelecs)):\n",
    "        pow0 = data[elec,...]\n",
    "        c = 0\n",
    "        for t0, t1 in combinations(np.arange(ntrials), 2):\n",
    "            tps_trials[e,c], _ = stats.pearsonr(pow0[:,t0],pow0[:,t1])\n",
    "            c += 1\n",
    "    tps_trials = 1 - np.arctanh(tps_trials)\n",
    "    return tps_trials\n",
    "\n",
    "for su in odor_list_su('Ret'):\n",
    "    all_odors = []\n",
    "    for od in odor_list_su('Ret')[su]:\n",
    "        mat = np.load(pow_file.format(su,od))\n",
    "        pow_ = mat['xpow'][1,:,to_take[0]:to_take[1],:]\n",
    "        all_odors.append(pow_)\n",
    "        \n",
    "    max_trials = np.max([x.shape[-1] for x in all_odors])\n",
    "    list_tpsim = []\n",
    "    for t in range(max_trials):\n",
    "        list_t = [x[:,:,t][np.newaxis] for x in all_odors if x.shape[-1] > t]\n",
    "        if len(list_t) > 1 :\n",
    "            concat_od = np.concatenate(list_t, axis=0).swapaxes(0,-1).swapaxes(0,1)\n",
    "            tps_t = tpsim_by_cond_learn(concat_od)\n",
    "            list_tpsim.append(tps_t)\n",
    "\n",
    "    print(su,freq,max_trials,[x.shape for x in list_tpsim])\n",
    "    dict_t = {}\n",
    "    for n in range(len(list_tpsim)):\n",
    "        dict_t['tps_'+str(n)] = list_tpsim[n]\n",
    "    dict_t['label'], dict_t['channel'], dict_t['xyz'] = mat['labels'],mat['channels'], mat['xyz']\n",
    "    np.savez(savename.format(su,freq,cond),**dict_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpsim_btw_odors(array1,array2):\n",
    "    \"\"\"\n",
    "    Compute tpsim for one odor with all other odors in list od 2\n",
    "    Parameters\n",
    "    ----------\n",
    "    array1, array2 : array\n",
    "        shape nelecs, npts, ntrials (same shape of elecs and npts)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tpsim : array\n",
    "        The Temporal Pattern Similarity between 2 two arrays\n",
    "        (n_combinations of trials btw array1 and array2)\n",
    "    \"\"\"\n",
    "    tpsim_btw = np.array([])\n",
    "    for elec in range(array1.shape[0]):\n",
    "        pow1, pow2 = array1[elec], array2[elec]\n",
    "        R_trials = np.array([])\n",
    "        for t0, t1 in product(range(pow1.shape[-1]),range(pow2.shape[-1])):\n",
    "            R, p = stats.pearsonr(pow1[:,t0],pow2[:,t1])\n",
    "            R_trials = np.vstack((R_trials,R)) if np.size(R_trials) else R\n",
    "        tpsim_btw = np.vstack((tpsim_btw,R_trials.T)) if np.size(tpsim_btw) else R_trials.T\n",
    "    tpsim_btw = 1 - np.arctanh(tpsim_btw)\n",
    "    return tpsim_btw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import odor_list_su, odor_groups_3wgth\n",
    "\"\"\"\n",
    "LEARNING effect\n",
    "Compute TPSim for all ODORS whatever the memory perf group\n",
    "SIMILARITY BTW ALL ODORS across trials\n",
    "trial1 with trial2 / trial2 with trial3 / trial 3 with rest of trials\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_data = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_odor_all_elecsFT/')\n",
    "pow_file = join(path_data, '{}_odor_{}_bipo_all_E_6freqs.npz')\n",
    "pathsave = join(st.path,'feature/TPSim_3groups_Enc/TPS_btw_thgh_time_v=1_elecs=all/')\n",
    "savename = join(pathsave,'TPS_pears_learn_{}_btw_{}_{}.npz')\n",
    "###############################################################################\n",
    "if not exists(pathsave.format(exp)):\n",
    "    makedirs(pathsave.format(exp))\n",
    "###############################################################################\n",
    "freq = 'theta'\n",
    "to_take = [17,47]\n",
    "\n",
    "for su in odor_list_su('Ret'):\n",
    "    all_odors = []\n",
    "    for od in odor_list_su('Ret')[su]:\n",
    "        mat = np.load(pow_file.format(su,od),allow_pickle=True)\n",
    "        pow_ = mat['xpow'][1,:,to_take[0]:to_take[1],:]\n",
    "        all_odors.append(pow_)\n",
    "    print([x.shape for x in all_odors])\n",
    "    \n",
    "    list_tpsim = []\n",
    "    for t in range(3):\n",
    "        list0 = [x[:,:,t][...,np.newaxis] for x in all_odors if x.shape[-1] > t]\n",
    "        if t == 2 :\n",
    "            list1 = [x[:,:,t+1:] for x in all_odors if x.shape[-1] > t+1]\n",
    "        else :\n",
    "            list1 = [x[:,:,t+1][...,np.newaxis] for x in all_odors if x.shape[-1] > t+1]\n",
    "        concat_1 = np.concatenate(list0, axis=-1)\n",
    "        concat_2 = np.concatenate(list1, axis=-1)\n",
    "        tps_t = tpsim_btw_odors(concat_1,concat_2)\n",
    "        list_tpsim.append(tps_t)\n",
    "        \n",
    "    print(su,freq,[x.shape for x in list_tpsim])\n",
    "    dict_t = {}\n",
    "    for n in range(len(list_tpsim)):\n",
    "        dict_t['tps_'+str(n)] = list_tpsim[n]\n",
    "    dict_t['label'], dict_t['channel'], dict_t['xyz'] = mat['labels'],mat['channels'], mat['xyz']\n",
    "    np.savez(savename.format(su,freq,'btw_trials'),**dict_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
