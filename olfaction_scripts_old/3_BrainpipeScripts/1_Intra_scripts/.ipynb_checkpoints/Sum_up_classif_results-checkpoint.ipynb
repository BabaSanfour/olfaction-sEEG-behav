{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "theta ['ACC' 'Amg' 'IFG' 'Ins_olf' 'MFG' 'OFC_olf' 'PHG' 'SFG' 'aHC']\n",
      "\n",
      ">>> for Amg in theta, 2 subjects have sig elecs\n",
      "AUC decoding score is 0.67 in average +/- 0.01\n",
      "1 electrodes showed completion TPSim, while 1 showed separation out of 2 elecs\n",
      "NB of subjects with completion 1\n",
      "NB of subjects with separation 1\n",
      "\n",
      ">>> for IFG in theta, 3 subjects have sig elecs\n",
      "AUC decoding score is 0.63 in average +/- 0.03\n",
      "1 electrodes showed completion TPSim, while 2 showed separation out of 3 elecs\n",
      "NB of subjects with completion 1\n",
      "NB of subjects with separation 2\n",
      "\n",
      ">>> for MFG in theta, 3 subjects have sig elecs\n",
      "AUC decoding score is 0.61 in average +/- 0.02\n",
      "3 electrodes showed completion TPSim, while 2 showed separation out of 5 elecs\n",
      "NB of subjects with completion 3\n",
      "NB of subjects with separation 1\n",
      "    subjects s_Mai_RL channels      x      y      z  elecs_num  theta_AUC  \\\n",
      "40      CHAF      MFG  h'4-h'3 -32.30  10.65  44.50         40   0.612139   \n",
      "155     SEMC      MFG    f8-f7  37.45  63.85  -0.95          9   0.576829   \n",
      "216     VACJ      MFG   k10-k9  36.15  39.30  16.30         21   0.606987   \n",
      "\n",
      "     theta_Pow0  theta_Pow1  sig_1levtheta  side        sign  \n",
      "40     0.939889    0.892564              1  -1.0  completion  \n",
      "155    1.009062    0.668236              1  -1.0  completion  \n",
      "216    0.782259    0.768765              1  -1.0  completion  \n",
      "\n",
      ">>> for OFC_olf in theta, 3 subjects have sig elecs\n",
      "AUC decoding score is 0.62 in average +/- 0.1\n",
      "2 electrodes showed completion TPSim, while 6 showed separation out of 8 elecs\n",
      "NB of subjects with completion 1\n",
      "NB of subjects with separation 3\n",
      "    subjects s_Mai_RL channels      x      y      z  elecs_num  theta_AUC  \\\n",
      "113     LEFC  OFC_olf    o4-o3  17.15  37.30 -13.45         19   0.538704   \n",
      "138     PIRJ  OFC_olf    o5-o4  21.45  38.35 -11.95         12   0.742212   \n",
      "139     PIRJ  OFC_olf    o6-o5  25.25  38.40 -12.05         13   0.677087   \n",
      "140     PIRJ  OFC_olf    o7-o6  29.05  38.50 -12.25         14   0.800053   \n",
      "165     SEMC  OFC_olf    o5-o4  21.25  32.25  -7.90         19   0.558816   \n",
      "166     SEMC  OFC_olf    o6-o5  25.30  32.35  -7.65         20   0.559305   \n",
      "\n",
      "     theta_Pow0  theta_Pow1  sig_1levtheta  side        sign  \n",
      "113    0.781405    0.993883              1   1.0  separation  \n",
      "138    0.418795    0.851467              1   1.0  separation  \n",
      "139    0.511294    0.829561              1   1.0  separation  \n",
      "140    0.371604    0.963847              1   1.0  separation  \n",
      "165    0.810696    1.022358              1   1.0  separation  \n",
      "166    0.945801    1.007737              1   1.0  separation  \n",
      "\n",
      ">>> for aHC in theta, 3 subjects have sig elecs\n",
      "AUC decoding score is 0.6 in average +/- 0.08\n",
      "7 electrodes showed completion TPSim, while 0 showed separation out of 7 elecs\n",
      "NB of subjects with completion 3\n",
      "NB of subjects with separation 0\n",
      "    subjects s_Mai_RL channels      x      y      z  elecs_num  theta_AUC  \\\n",
      "95      LEFC      aHC    b2-b1  30.65 -20.50 -10.75          1   0.556983   \n",
      "97      LEFC      aHC    b4-b3  38.45 -20.10 -10.95          3   0.541399   \n",
      "100     LEFC      aHC    d4-d3  32.95 -13.05 -26.45          6   0.547628   \n",
      "101     LEFC      aHC    d5-d4  36.80 -12.75 -26.35          7   0.569798   \n",
      "127     PIRJ      aHC    b3-b2  31.20 -16.45 -15.25          1   0.717119   \n",
      "129     PIRJ      aHC  b'2-b'1 -25.80 -16.20 -12.80          3   0.735566   \n",
      "146     SEMC      aHC    b2-b1  18.30  -9.10 -18.50          0   0.557163   \n",
      "\n",
      "     theta_Pow0  theta_Pow1  sig_1levtheta  side        sign  \n",
      "95     0.970025    0.722462              1  -1.0  completion  \n",
      "97     0.958233    0.820552              1  -1.0  completion  \n",
      "100    0.958839    0.805255              1  -1.0  completion  \n",
      "101    0.957785    0.677981              1  -1.0  completion  \n",
      "127    0.936828    0.422859              1  -1.0  completion  \n",
      "129    1.033291    0.579233              1  -1.0  completion  \n",
      "146    0.884481    0.645347              1  -1.0  completion  \n"
     ]
    }
   ],
   "source": [
    "from brainpipe.system import study\n",
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem\n",
    "import seaborn as sns\n",
    "\n",
    "st = study('Olfacto')\n",
    "exp, pval, meth, skf = 'E', '0.01', 'BETWEEN', '5'\n",
    "pathdata = join(st.path, 'classified/TPSim_clf_all_theta/')\n",
    "\n",
    "leg = ['Poor', 'Rich']\n",
    "freqs = ['theta']\n",
    "\n",
    "dfname = '2_all_subjects_signif_rad=11_{}_{}_p={}_k={}_not_corr_freqs.csv'\n",
    "df_sel = pd.read_csv(pathdata+dfname.format(exp,meth,pval,skf))\n",
    "df_ = df_sel[['subjects','s_Mai_RL','channels','x','y','z','elecs_num']]\n",
    "olf_regions = ['Amg','pPirT','OFC_olf','Ins_olf','Amg-PirT']\n",
    "\n",
    "#Select results significant for each frequency band and ROIs\n",
    "for freq in freqs:\n",
    "    df_freq = pd.concat([df_,df_sel.filter(like=freq[:])], axis=1)\n",
    "    \n",
    "    ## JUST FOR REINSTATEMENT BETWEN\n",
    "    if exp == 'E_R' and meth == 'BETWEEN':\n",
    "        df_freq['theta_Pow0'] = [1-x if df_freq['subjects'][i] not in ['PIRJ','FERJ'] else x \\\n",
    "                                     for i,x in enumerate(df_freq['theta_Pow0'])]\n",
    "        df_freq['theta_Pow1'] =  [1-x if df_freq['subjects'][i] not in ['PIRJ','FERJ'] else x \\\n",
    "                                     for i,x in enumerate(df_freq['theta_Pow1'])]\n",
    "    \n",
    "    df_sig = df_freq.loc[df_freq['sig_1lev'+freq[:]]>0]\n",
    "    sig_rois = np.unique(df_sig['s_Mai_RL'])\n",
    "    print(freq, sig_rois)\n",
    "    for roi in sig_rois:\n",
    "        df_plot = None\n",
    "        df_roi_f = df_sig.loc[df_sig['s_Mai_RL'] == roi]\n",
    "        nb_su = len(np.unique(df_roi_f['subjects']))\n",
    "        #if roi == roi_sel and freq == freq_sel:\n",
    "        nb_elec_su = Counter(df_roi_f['subjects'])\n",
    "        if (nb_su >= 3) or (nb_su >=2 and roi in olf_regions):\n",
    "            print('\\n>>> for %s in %s, %s subjects have sig elecs' % (roi,freq[:],nb_su))\n",
    "#             print('organized as follow', nb_elec_su)\n",
    "            auc = df_roi_f[freq+'_AUC'].values\n",
    "            auc_mean, std_auc = np.mean(auc), np.std(auc)\n",
    "            print('AUC decoding score is %s in average +/- %s' %(round(auc_mean,2),\n",
    "                                round(std_auc,2)))\n",
    "            #create a value of 1 for increase, -1 for decrease and 0 for no change\n",
    "            df_roi_f['side'] = np.sign(df_freq[freq+'_Pow1'] - df_freq[freq+'_Pow0'])\n",
    "            df_roi_f['sign'] = ['separation' if t > 0 else 'completion' for t in df_roi_f['side']]\n",
    "            inc = (df_roi_f.loc[df_roi_f.sign == 'completion']).shape[0]\n",
    "            dec = (df_roi_f.loc[df_roi_f.sign == 'separation']).shape[0]\n",
    "            print('%s electrodes showed completion TPSim, while %s showed separation out of %s elecs' \n",
    "                  % (inc,dec,inc+dec))\n",
    "            df_inc = df_roi_f.loc[df_roi_f.sign == 'completion'].groupby(['subjects']).count()\n",
    "            df_dec = df_roi_f.loc[df_roi_f.sign == 'separation'].groupby(['subjects']).count()\n",
    "            print('NB of subjects with completion',df_inc.shape[0])\n",
    "            print('NB of subjects with separation',df_dec.shape[0])\n",
    "            \n",
    "            if (df_inc.shape[0] >= 3) or (df_inc.shape[0] >=2 and roi in olf_regions):\n",
    "                df_plot = df_roi_f.loc[df_roi_f.sign == 'completion']\n",
    "                n_subj = df_inc.shape[0]\n",
    "                print(df_plot)\n",
    "            if (df_dec.shape[0] >= 3) or (df_dec.shape[0] >=2 and roi in olf_regions):\n",
    "                df_plot = df_roi_f.loc[df_roi_f.sign == 'separation']\n",
    "                n_subj = df_dec.shape[0]\n",
    "                print(df_plot)\n",
    "            \n",
    "            #if df_plot is not None:\n",
    "                #if not exists(pathdata+'npy_figs/'):\n",
    "                #    makedirs(pathdata+'npy_figs/')\n",
    "                    \n",
    "                #x = [np.mean(df_plot[freq+'_Pow0']),np.mean(df_plot[freq+'_Pow1'])]  \n",
    "                #print('mean', x)\n",
    "                #sd = [np.std(df_plot[freq+'_Pow0']),np.std(df_plot[freq+'_Pow1'])]        \n",
    "                #title = '{} in {} at {} (p={}) \\n {} elecs in {} patients'.format(\n",
    "                #                roi,freq,exp,pval,df_plot.shape[0],n_subj)\n",
    "                #plt.title(title)\n",
    "                #plt.bar(np.arange(len(leg)), x, width=0.5, yerr=sd)\n",
    "                #plt.ylabel('Similarity (r)')\n",
    "                #plt.xticks(np.arange(len(leg)), labels=leg)\n",
    "                #plt.savefig(pathdata+'npy_figs/{}_{}_{}_{}__mean_tps.png'.format(freq,roi,exp,pval))\n",
    "                #plt.savefig(pathdata+'npy_figs/{}_{}_{}_{}__mean_tps.pdf'.format(freq,roi,exp,pval))\n",
    "                #df_plot.to_csv(pathdata+'npy_figs/{}_{}_{}_{}_tps.csv'.format(freq,roi,exp,pval))\n",
    "                #plt.clf()\n",
    "                #plt.cloe()\n",
    "                #del df_plot\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = ['0_theta', '1_alpha', '2_beta', '3_gamma']\n",
    "su_odor_groups = {'CHAF' : {'low':['1','2','4','5'],\n",
    "                              'high':['3','8','7','9']},\n",
    "                    'VACJ' : {'low':['11','14','12','10'],\n",
    "                              'high':['15','17','16','13']},\n",
    "                    'SEMC' : {'low':['7','10','11','12','13'],\n",
    "                              'high':['5','8','9']},\n",
    "                    'PIRJ' : {'low':['1','9','5'],\n",
    "                              'high':['4','6','7','18']},\n",
    "                    'LEFC' : {'low':['15','2','1','16'],\n",
    "                              'high':['14','3','4','17']},\n",
    "                    'FERJ' : {'low':['7','2','16','17'],\n",
    "                              'high':['12','1','5','13']},}\n",
    "context_su = {'CHAF': {'M':[5,7,8,9],'F':[1,2,3,4]},\n",
    "              'LEFC': {'M':[1,2,3,4],'F':[14,15,16,17]},\n",
    "              'PIRJ': {'M':[4,9,1,18],'F':[6,5,7]}, #missing odor 15\n",
    "              'VACJ': {'M':[14,15,16,17],'F':[10,11,12,13]},\n",
    "              'SEMC': {'M':[10,11,12,13],'F':[5,7,8,9]},\n",
    "              'FERJ': {'M':[16,17,5,7],'F':[12,13,2,1]},}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot TPSim matrices (RDM) for all odors by subject \n",
    "Plot Graph 2D representations of RDM matrices\n",
    "\"\"\"\n",
    "from brainpipe.system import study\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import cm\n",
    "import seaborn as sns \n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.manifold import MDS\n",
    "import glob\n",
    "\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/TPSim_LDA_{}_by_cond_6freqs_3s_dissim/npy_figs/')\n",
    "path_npz = join(st.path,'feature/TPSim_{}_By_Odor_By_Cond/')\n",
    "path_pow = join(path_npz, 'similarity_matrix_btw/TPS_pearson_{}_{}_btw_odors_mean.npz')\n",
    "savename = join(pathdata, 'rdm_{}/{}_{}_{}_{}_({})_p={}_rdm.png')\n",
    "savename2 = join(pathdata, 'rdm_{}/{}_{}_{}_{}_({})_p={}_rdm.pdf')\n",
    "###############################################################################\n",
    "exp, pval = 'Ret', '0.01' #Ret, Enc\n",
    "freqs = ['0_theta']#, '1_alpha', '2_beta', '3_gamma']\n",
    "###############################################################################\n",
    "\n",
    "files = glob.glob(pathdata.format(exp[0])+freqs[0][2:]+'*'+pval+'_tps.csv')\n",
    "\n",
    "for fi in files:\n",
    "    roi = fi.split('_')[13]\n",
    "    df = pd.read_csv(fi)\n",
    "    subjects, chans = df['subjects'], df['channels']\n",
    "    \n",
    "    for su, chan in zip(subjects,chans):\n",
    "        mat = np.load(path_pow.format(exp,su,freqs[0]),allow_pickle=True)\n",
    "        mat_chans = mat['channels']\n",
    "        idx_elec = [i for i,c in enumerate(mat_chans) if c == chan]\n",
    "        combs, tps = mat['comb'], mat['tps'][idx_elec,:]\n",
    "        n_od = len(np.unique(combs))\n",
    "        idx = list([o for o in combs[:n_od,1]])\n",
    "        tps_resh = tps.reshape(n_od,n_od)\n",
    "        tri = tps_resh\n",
    "        #tri = np.zeros((n_od, n_od))\n",
    "        #tri[np.triu_indices(n_od, 1)] = tps\n",
    "        #tri[np.tril_indices(n_od, -1)] = tri.T[np.tril_indices(n_od, -1)]\n",
    "        model = MDS(n_components=2, dissimilarity='precomputed', random_state=1)\n",
    "        out = model.fit_transform(tri)\n",
    "        \n",
    "        #plot and save RDM matrices\n",
    "        fig, (ax1,ax2) = plt.subplots(1,2,figsize=(8,3))\n",
    "        title = 'Distance btw odors for {} in {} at {} (p={}) - Patient {} elec({})'.format(\n",
    "            roi, freq[2:], exp[0], pval, su, str(elec))\n",
    "        fig.suptitle(title)\n",
    "        \n",
    "        #subplot #1 Graph 2D \n",
    "        colors = ['red' if str(c) in su_odor_groups[su]['high'] else 'blue' for c in idx]\n",
    "        markers = ['o' if c in context_su[su]['M'] else '*' for c in idx]\n",
    "        for i, txt in enumerate(idx):\n",
    "            ax1.scatter(out[i,0], out[i,1], c=colors[i], marker=markers[i],\n",
    "                       label=['Rich' if colors[i]=='red' else 'Poor'])\n",
    "            ax1.annotate('O'+str(txt), (out[i,0], out[i,1]))\n",
    "        ax1.set_xlabel('component 1')\n",
    "        ax1.set_ylabel('component 2')\n",
    "        ax1.axis('equal')\n",
    "        legend_elements = [Line2D([0], [0], marker='o', color='b', label='Poor_M'),\n",
    "                           Line2D([0], [0], marker='*', color='b', label='Poor_C'),\n",
    "                           Line2D([0], [0], marker='o', color='r', label='Rich_M'),\n",
    "                           Line2D([0], [0], marker='*', color='r', label='Rich_C')]\n",
    "        ax1.legend(handles=legend_elements, loc='best')\n",
    "        \n",
    "        #subplot #1 Graph 2D \n",
    "        cmap = cm.get_cmap('jet', 30)\n",
    "        cax = ax2.imshow(tri, vmin=0,interpolation=\"none\", cmap=cmap)\n",
    "        ax2.set_xticks(np.arange(n_od))\n",
    "        ax2.set_yticks(np.arange(n_od))\n",
    "        ax2.set_xticklabels(idx,fontsize=11)\n",
    "        ax2.set_yticklabels(idx,fontsize=11)\n",
    "        plt.colorbar(cax)\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "#         plt.tight_layout()\n",
    "\n",
    "        if not exists(join(pathdata,'rdm_{}').format(exp[0],pval)):\n",
    "            makedirs(join(pathdata,'rdm_{}').format(exp[0],pval))\n",
    "                      \n",
    "        plt.savefig(savename.format(exp[0],pval,freqs[0][2:],roi,exp[0],su,chan,pval))\n",
    "        plt.savefig(savename2.format(exp[0],pval,freqs[0][2:],roi,exp[0],su,chan,pval))\n",
    "        plt.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot TPSim matrices (RDM) for all odors by subject // AVERAGE BY ROI and SUBJECT\n",
    "Plot Graph 2D representations of RDM matrices\n",
    "\"\"\"\n",
    "from brainpipe.system import study\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import cm\n",
    "import seaborn as sns \n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.manifold import MDS\n",
    "import glob\n",
    "\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/TPSim_LDA_{}_by_cond_6freqs_3s_dissim/npy_figs/')\n",
    "path_npz = join(st.path,'feature/TPSim_{}_By_Odor_By_Cond/')\n",
    "path_pow = join(path_npz, 'similarity_matrix_btw/TPS_pearson_{}_{}_btw_odors_mean.npz')\n",
    "savename = join(pathdata, 'rdm_{}/{}_{}_{}_{}_p={}_avg_by_group__rdm.png')\n",
    "savename2 = join(pathdata, 'rdm_{}/{}_{}_{}_{}_p={}_avg_by_group__rdm.pdf')\n",
    "###############################################################################\n",
    "exp, pval = 'Enc', '0.01' #Ret, Enc\n",
    "freqs = ['0_theta']#, '1_alpha', '2_beta', '3_gamma']\n",
    "###############################################################################\n",
    "\n",
    "files = glob.glob(pathdata.format(exp[0])+freqs[0][2:]+'*'+pval+'_tps.csv')\n",
    "\n",
    "for fi in files:\n",
    "    roi = fi.split('_')[13]\n",
    "    df = pd.read_csv(fi)\n",
    "    subjects = df['subjects']\n",
    "    \n",
    "    for su in subjects:\n",
    "        elec_su = df['elecs_num'].loc[df['subjects']==su]\n",
    "        OUT_all, TRI_all = np.array([]), np.array([])\n",
    "        for elec in elec_su:\n",
    "            mat = np.load(path_pow.format(exp,su,freqs[0]),allow_pickle=True)\n",
    "            combs, tps = mat['comb'], mat['tps'][elec,:]\n",
    "            n_od = len(np.unique(combs))\n",
    "            idx = list([combs[0,0]])+list([o for o in combs[:n_od-1,1]])\n",
    "            tri = np.zeros((n_od, n_od))\n",
    "            tri[np.triu_indices(n_od, 1)] = tps\n",
    "            tri[np.tril_indices(n_od, -1)] = tri.T[np.tril_indices(n_od, -1)]\n",
    "            model = MDS(n_components=2, dissimilarity='precomputed', random_state=1)\n",
    "            out = model.fit_transform(tri)[np.newaxis]\n",
    "            tri = tri[np.newaxis]\n",
    "            TRI_all = np.concatenate((TRI_all,tri),axis=0) if np.size(TRI_all) else tri\n",
    "            OUT_all = np.concatenate((OUT_all,out),axis=0) if np.size(OUT_all) else out\n",
    "        out_m = np.mean(OUT_all,axis=0)\n",
    "        tri_m = np.mean(TRI_all, axis=0)\n",
    "\n",
    "        #plot and save RDM matrices\n",
    "        fig, (ax1,ax2) = plt.subplots(1,2,figsize=(8,3))\n",
    "        title = 'Distance btw odors for {} in {} at {} (p={}) - Patient {}'.format(\n",
    "            roi, freq[2:], exp[0], pval, su)\n",
    "        fig.suptitle(title)\n",
    "\n",
    "        #subplot #1 Graph 2D \n",
    "        colors = ['red' if str(c) in su_odor_groups[su]['high'] else 'blue' for c in idx]\n",
    "        markers = ['o' if c in context_su[su]['M'] else '*' for c in idx]\n",
    "        for i, txt in enumerate(idx):\n",
    "            ax1.scatter(out_m[i,0], out_m[i,1], c=colors[i], marker=markers[i],\n",
    "                       label=['Rich' if colors[i]=='red' else 'Poor'])\n",
    "            ax1.annotate('O'+str(txt), (out_m[i,0], out_m[i,1]))\n",
    "        ax1.set_xlabel('component 1')\n",
    "        ax1.set_ylabel('component 2')\n",
    "        ax1.axis('equal')\n",
    "        legend_elements = [Line2D([0], [0], marker='o', color='b', label='Poor_M'),\n",
    "                           Line2D([0], [0], marker='*', color='b', label='Poor_C'),\n",
    "                           Line2D([0], [0], marker='o', color='r', label='Rich_M'),\n",
    "                           Line2D([0], [0], marker='*', color='r', label='Rich_C')]\n",
    "        ax1.legend(handles=legend_elements, loc='best')\n",
    "\n",
    "        #subplot #1 Graph 2D \n",
    "        cmap = cm.get_cmap('jet', 30)\n",
    "        cax = ax2.imshow(tri_m, interpolation=\"none\", cmap=cmap)\n",
    "        ax2.set_xticks(np.arange(n_od))\n",
    "        ax2.set_yticks(np.arange(n_od))\n",
    "        ax2.set_xticklabels(idx,fontsize=11)\n",
    "        ax2.set_yticklabels(idx,fontsize=11)\n",
    "        plt.colorbar(cax)\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "    #         plt.tight_layout()\n",
    "\n",
    "        if not exists(join(pathdata,'rdm_{}').format(exp[0],pval)):\n",
    "            makedirs(join(pathdata,'rdm_{}').format(exp[0],pval))\n",
    "\n",
    "        plt.savefig(savename.format(exp[0],pval,freqs[0][2:],roi,exp[0],su,pval))\n",
    "        plt.savefig(savename2.format(exp[0],pval,freqs[0][2:],roi,exp[0],su,pval))\n",
    "        plt.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot TPSim matrices (RDM) BY GROUP and for all Sig ELECS // AVERAGE BY ROI\n",
    "Plot Graph 2D representations of RDM matrices\n",
    "\"\"\"\n",
    "from brainpipe.system import study\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import cm\n",
    "import seaborn as sns \n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.manifold import MDS\n",
    "import glob\n",
    "\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/TPSim_LDA_{}_by_cond_6freqs_3s_dissim/npy_figs/')\n",
    "path_npz = join(st.path,'feature/TPSim_{}_By_Odor_By_Cond/')\n",
    "path_pow = join(path_npz, 'similarity_matrix_btw/TPS_pearson_{}_{}_btw_odors_mean.npz')\n",
    "savename = join(pathdata, 'rdm_{}/{}_{}_{}_{}_p={}_avg_by_group__rdm.png')\n",
    "savename2 = join(pathdata, 'rdm_{}/{}_{}_{}_{}_p={}_avg_by_group__rdm.pdf')\n",
    "###############################################################################\n",
    "exp, pval = 'Enc', '0.01' #Ret, Enc\n",
    "freqs = ['0_theta']#, '1_alpha', '2_beta', '3_gamma']\n",
    "###############################################################################\n",
    "\n",
    "files = glob.glob(pathdata.format(exp[0])+freqs[0][2:]+'*'+pval+'_tps.csv')\n",
    "\n",
    "for fi in files:\n",
    "    roi = fi.split('_')[13]\n",
    "    df = pd.read_csv(fi)\n",
    "    subjects = df['subjects']\n",
    "    \n",
    "    for su in subjects:\n",
    "        elec_su = df['elecs_num'].loc[df['subjects']==su]\n",
    "        OUT_all, TRI_all = np.array([]), np.array([])\n",
    "        for elec in elec_su:\n",
    "            mat = np.load(path_pow.format(exp,su,freqs[0]),allow_pickle=True)\n",
    "            combs, tps = mat['comb'], mat['tps'][elec,:]\n",
    "            n_od = len(np.unique(combs))\n",
    "            idx = list([combs[0,0]])+list([o for o in combs[:n_od-1,1]])\n",
    "            tri = np.zeros((n_od, n_od))\n",
    "            tri[np.triu_indices(n_od, 1)] = tps\n",
    "            tri[np.tril_indices(n_od, -1)] = tri.T[np.tril_indices(n_od, -1)]\n",
    "            model = MDS(n_components=2, dissimilarity='precomputed', random_state=1)\n",
    "            out = model.fit_transform(tri)[np.newaxis]\n",
    "            tri = tri[np.newaxis]\n",
    "            TRI_all = np.concatenate((TRI_all,tri),axis=0) if np.size(TRI_all) else tri\n",
    "            OUT_all = np.concatenate((OUT_all,out),axis=0) if np.size(OUT_all) else out\n",
    "        out_m = np.mean(OUT_all,axis=0)\n",
    "        tri_m = np.mean(TRI_all, axis=0)\n",
    "\n",
    "        #plot and save RDM matrices\n",
    "        fig, (ax1,ax2) = plt.subplots(1,2,figsize=(8,3))\n",
    "        title = 'Distance btw odors for {} in {} at {} (p={}) - Patient {}'.format(\n",
    "            roi, freq[2:], exp[0], pval, su)\n",
    "        fig.suptitle(title)\n",
    "\n",
    "        #subplot #1 Graph 2D \n",
    "        colors = ['red' if str(c) in su_odor_groups[su]['high'] else 'blue' for c in idx]\n",
    "        markers = ['o' if c in context_su[su]['M'] else '*' for c in idx]\n",
    "        for i, txt in enumerate(idx):\n",
    "            ax1.scatter(out_m[i,0], out_m[i,1], c=colors[i], marker=markers[i],\n",
    "                       label=['Rich' if colors[i]=='red' else 'Poor'])\n",
    "            ax1.annotate('O'+str(txt), (out_m[i,0], out_m[i,1]))\n",
    "        ax1.set_xlabel('component 1')\n",
    "        ax1.set_ylabel('component 2')\n",
    "        ax1.axis('equal')\n",
    "        legend_elements = [Line2D([0], [0], marker='o', color='b', label='Poor_M'),\n",
    "                           Line2D([0], [0], marker='*', color='b', label='Poor_C'),\n",
    "                           Line2D([0], [0], marker='o', color='r', label='Rich_M'),\n",
    "                           Line2D([0], [0], marker='*', color='r', label='Rich_C')]\n",
    "        ax1.legend(handles=legend_elements, loc='best')\n",
    "\n",
    "        #subplot #1 Graph 2D \n",
    "        cmap = cm.get_cmap('jet', 30)\n",
    "        cax = ax2.imshow(tri_m, interpolation=\"none\", cmap=cmap)\n",
    "        ax2.set_xticks(np.arange(n_od))\n",
    "        ax2.set_yticks(np.arange(n_od))\n",
    "        ax2.set_xticklabels(idx,fontsize=11)\n",
    "        ax2.set_yticklabels(idx,fontsize=11)\n",
    "        plt.colorbar(cax)\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "    #         plt.tight_layout()\n",
    "\n",
    "        if not exists(join(pathdata,'rdm_{}').format(exp[0],pval)):\n",
    "            makedirs(join(pathdata,'rdm_{}').format(exp[0],pval))\n",
    "\n",
    "        plt.savefig(savename.format(exp[0],pval,freqs[0][2:],roi,exp[0],su,pval))\n",
    "        plt.savefig(savename2.format(exp[0],pval,freqs[0][2:],roi,exp[0],su,pval))\n",
    "        plt.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check whether there is difference btw EARLY and LATE similarities during E and R\n",
    "for High and Low conditions independantly\n",
    "\"\"\"\n",
    "from brainpipe.system import study\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import bonferroni_correction, fdr_correction\n",
    "import glob\n",
    "\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/TPSim_LDA_{}_by_cond_6freqs_3s_dissim/npy_figs/')\n",
    "path_npz = join(st.path,'feature/TPSim_{}_By_Odor_By_Cond/')\n",
    "path_pow = join(path_npz, 'rdm_thgh_time/TPS_spear_{}_{}_{}_{}_wth_cond_med_split.npz')\n",
    "\n",
    "savename = join(pathdata, '{}_{}_{}_p={}_time.png')\n",
    "savename2 = join(pathdata, '{}_{}_{}_p={}_time.pdf')\n",
    "###############################################################################\n",
    "exp, pval = 'Enc', '0.01' #Ret, Enc\n",
    "freqs = ['theta']#, 'alpha', 'beta', 'gamma']\n",
    "conds, wins = ['low','high'], ['early','late']\n",
    "###############################################################################\n",
    "\n",
    "files = glob.glob(pathdata.format(exp[0])+freqs[0]+'*'+pval+'_tps.csv')\n",
    "\n",
    "for fi in files:\n",
    "    freq, roi =freqs[0], fi.split('_')[-4]\n",
    "    df = pd.read_csv(fi)\n",
    "    subjects, elecs = df['subjects'], df['elecs_num']\n",
    "    \n",
    "    Tvals_l, pvals_l, Tvals_h, pvals_h = [],[],[],[]\n",
    "    Tvals_0, pvals_0, Tvals_1, pvals_1 = [],[],[],[]\n",
    "    early_l, early_h, late_l, late_h = [],[],[],[]\n",
    "    for su, elec in zip(subjects,elecs):\n",
    "        \n",
    "        rdm0 = np.load(path_pow.format(exp,su,'low',freq,'early'))['rdm'][elec,:]\n",
    "        rdm1 = np.load(path_pow.format(exp,su,'low',freq,'late'))['rdm'][elec,:]\n",
    "        rdm2 = np.load(path_pow.format(exp,su,'high',freq,'early'))['rdm'][elec,:]\n",
    "        rdm3 = np.load(path_pow.format(exp,su,'high',freq,'late'))['rdm'][elec,:]\n",
    "        \n",
    "        T0, p0 = stats.ttest_ind(rdm0,rdm1)\n",
    "        T_e, p_e = stats.ttest_ind(rdm0, rdm2)\n",
    "        T_l, p_l = stats.ttest_ind(rdm1, rdm3)\n",
    "        T1, p1 = stats.ttest_ind(rdm2,rdm3)\n",
    "        Tvals_l.append(T0), pvals_l.append(p0)\n",
    "        Tvals_h.append(T1), pvals_h.append(p1)\n",
    "        Tvals_0.append(T_e), pvals_0.append(p_e)\n",
    "        Tvals_1.append(T_l), pvals_1.append(p_l)\n",
    "        early_l.append(np.mean(rdm0)), early_h.append(np.mean(rdm2))\n",
    "        late_l.append(np.mean(rdm1)), late_h.append(np.mean(rdm3))\n",
    "    \n",
    "    T_low, p_low = stats.ttest_rel(early_l,late_l)\n",
    "    T_high, p_high = stats.ttest_rel(early_h,late_h)\n",
    "    T_hl_e, p_hl_e = stats.ttest_rel(early_l, early_h)\n",
    "    T_hl_l, p_hl_l = stats.ttest_rel(late_l, late_h)\n",
    "    df['tps_early_low'], df['tps_late_low'] = early_l, late_l\n",
    "    df['Tvals_low'], df['pvals_low'] = Tvals_l, pvals_l\n",
    "    df['pvals_low_b'], df['pvals_low_fdr'] = bonferroni_correction(pvals_l)[1], fdr_correction(pvals_l)[1]\n",
    "    df['tps_early_high'], df['tps_late_high'] = early_h, late_h\n",
    "    df['Tvals_high'], df['pvals_high'] = Tvals_h, pvals_h\n",
    "    df['pvals_high_b'], df['pvals_high_fdr'] = bonferroni_correction(pvals_h)[1], fdr_correction(pvals_h)[1]\n",
    "    df.to_csv(fi, index=False)\n",
    "    \n",
    "    nsig_l = np.sum(np.array(pvals_l) < 0.05)\n",
    "    nsig_h = np.sum(np.array(pvals_h) < 0.05)\n",
    "    print('High/Low - early', T_hl_e, p_hl_e)\n",
    "    print('High/Low - late', T_hl_l, p_hl_l)\n",
    "    n_subj = len(np.unique(subjects))\n",
    "    print(freq,roi,'For Low : {}/{} elecs sig in {} subjects'.format(nsig_l,len(df),n_subj))\n",
    "    print('Group level stat : T={}, p={}'.format(round(T_low,2),round(p_low,3)))\n",
    "    #print(df[['tps_early_low','tps_late_low','Tvals_low','pvals_low_b']])\n",
    "    df_print2 = df[['subjects','elecs_num','tps_early_low','tps_late_low','Tvals_low','pvals_low']]\n",
    "    df_print2 = df_print2.loc[(df_print2['pvals_low']<0.05)]\n",
    "    print(df_print2)\n",
    "    print(freq,roi,'For High : {}/{} elecs sig in {} subjects'.format(nsig_h,len(df),n_subj))\n",
    "    print('Group level stat : T={}, p={}'.format(round(T_high,2),round(p_high,3)))\n",
    "    df_print = df[['subjects','elecs_num','tps_early_high','tps_late_high','Tvals_high','pvals_high']]\n",
    "    df_print = df_print.loc[(df_print['pvals_high']<0.05)]\n",
    "    print(df_print)\n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(8,3))\n",
    "    title = 'Distance btw odors from LOW and HIGH in {} in {} at {} (p={})'.format(\n",
    "        roi, freq, exp[0], pval, su, str(elec))\n",
    "    fig.suptitle(title)\n",
    "     \n",
    "    x0, x1 = [np.mean(early_l),np.mean(late_l)], [np.mean(early_h), np.mean(late_h)]\n",
    "    sd0, sd1 = [np.std(early_l),np.std(late_l)], [np.std(early_h), np.std(late_h)] \n",
    "    \n",
    "    ax1.bar(np.arange(len(wins)), x0, width=0.5, yerr=sd0)\n",
    "    ax1.set_ylabel('Similarity (r)')\n",
    "    ax1.set_xticks(np.arange(len(wins)))\n",
    "    ax1.set_xticklabels(wins)\n",
    "    \n",
    "    ax2.bar(np.arange(len(wins)), x1, width=0.5, yerr=sd1)\n",
    "    ax2.set_ylabel('Similarity (r)')\n",
    "    ax2.set_xticks(np.arange(len(wins)))\n",
    "    ax2.set_xticklabels(wins)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    plt.savefig(savename.format(exp[0],freq,roi,exp,pval))\n",
    "    plt.savefig(savename2.format(exp[0],freq,roi,exp,pval))\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check distance btw High and Low odors at EARLY and LATE E and R\n",
    "\"\"\"\n",
    "from brainpipe.system import study\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import bonferroni_correction, fdr_correction\n",
    "import glob\n",
    "\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/TPSim_LDA_{}_by_cond_6freqs_3s_dissim/npy_figs/')\n",
    "path_npz = join(st.path,'feature/TPSim_{}_By_Odor_By_Cond/')\n",
    "path_pow = join(path_npz, 'rdm_thgh_time/TPS_pearson_{}_{}_{}_Low_High_med_split.npy')\n",
    "\n",
    "savename = join(pathdata, '{}_{}_{}_p={}_high_low_time_med_split.png')\n",
    "savename2 = join(pathdata, '{}_{}_{}_p={}_high_low_time_med_split.pdf')\n",
    "###############################################################################\n",
    "exp, pval = 'Enc', '0.01' #Ret, Enc\n",
    "freqs = ['theta']#, 'alpha', 'beta', 'gamma']\n",
    "wins = ['early','late']\n",
    "###############################################################################\n",
    "\n",
    "files = glob.glob(pathdata.format(exp[0])+freqs[0]+'*'+pval+'_tps.csv')\n",
    "\n",
    "for fi in files:\n",
    "    freq, roi = freqs[0],fi.split('_')[-4]\n",
    "    df = pd.read_csv(fi)\n",
    "    subjects, elecs = df['subjects'], df['elecs_num']\n",
    "    \n",
    "    Tvals, pvals, early, late = [],[],[],[]\n",
    "    for su, elec in zip(subjects,elecs):\n",
    "        \n",
    "        rdm0 = np.load(path_pow.format(exp,su,freq,'early'))[elec,:]\n",
    "        rdm1 = np.load(path_pow.format(exp,su,freq,'late'))[elec,:]\n",
    "        T0, p0 = stats.ttest_ind(rdm0,rdm1)\n",
    "        Tvals.append(T0), pvals.append(p0)\n",
    "        early.append(np.mean(rdm0)), late.append(np.mean(rdm1))\n",
    "    \n",
    "    T_tot, p_tot = stats.ttest_rel(early,late)\n",
    "    df['tps_early_btw'], df['tps_late_btw'] = early, late\n",
    "    df['Tvals_btw'], df['pvals_btw'] = Tvals, pvals\n",
    "    df['pvals_btw_b'], df['pvals_btw_fdr'] = bonferroni_correction(pvals)[1], fdr_correction(pvals)[1]\n",
    "    df_print = df[['subjects','elecs_num','tps_early_btw','tps_late_btw','Tvals_btw','pvals_btw']]\n",
    "    df_print = df_print.loc[(df_print['pvals_btw']<0.05)]\n",
    "    print(df_print)\n",
    "    df.to_csv(fi, index=False)\n",
    "    \n",
    "    nsig = np.sum(bonferroni_correction(pvals)[1]<0.05)\n",
    "    n_subj = len(np.unique(subjects))\n",
    "    print(freq,roi,'Sig early/late : {}/{} elecs sig in {} subjects'.format(nsig,len(df),n_subj))\n",
    "    print('Group level stat : T={}, p={}'.format(round(T_tot,2),round(p_tot,3)))\n",
    "       \n",
    "    plt.figure()\n",
    "    title = 'Distance btw LOW and HIGH odors in {} in {} at {} (p={})'.format(\n",
    "        roi, freq, exp[0], pval, su, str(elec))\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    x0 = [np.mean(early),np.mean(late)]\n",
    "    sd0 = [stats.sem(early),stats.sem(late)]\n",
    "    \n",
    "    plt.bar(np.arange(len(wins)), x0, width=0.5, yerr=sd0)\n",
    "    plt.ylabel('Similarity (r)')\n",
    "    plt.xticks(np.arange(len(wins)), labels=wins)\n",
    "    \n",
    "    plt.savefig(savename.format(exp[0],freq,roi,exp,pval))\n",
    "    plt.savefig(savename2.format(exp[0],freq,roi,exp,pval))\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check whether reinstatement (TPSim between E and R) is significant\n",
    "in olfactory regions showing discriminant richness effets at E and R\n",
    "\"\"\"\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "###############################################################################\n",
    "dict_ = {'FERJ':[\"b2-b1\",\"b6-b5\"], 'PIRJ':[\"b'4-b'3\"], 'VACJ':[\"b3-b2\"]} #aHC\n",
    "#dict_ = {'FERJ':[\"b2-b1\",\"b6-b5\",\"b3-b2\",\"b'5-b'4\"],\n",
    "#         'PIRJ':[\"b'4-b'3\"], 'VACJ':[\"b3-b2\",\"b'2-b'1\"], 'SEMC':[\"b5-b4\"]} #aHC 10e-2\n",
    "#dict_ = {'FERJ':[\"o9-o8\",\"o10-o9\"], 'SEMC':[\"j2-j1\"], 'VACJ':[\"k'13-k'12\"]} #IFG\n",
    "#dict_ = {'FERJ':[\"o9-o8\",\"o10-o9\",\"o8-o7\"], 'SEMC':[\"j2-j1\"], 'VACJ':[\"k'13-k'12\"]} #IFG 10e-2\n",
    "#dict_ = {'LEFC':[\"o4-o3\"], 'SEMC':[\"o5-o4\",\"o6-o5\"], 'PIRJ':[\"o5-o4\"]} #OFC\n",
    "#dict_ = {'LEFC':[\"o4-o3\",\"o6-o5\"], 'SEMC':[\"o5-o4\",\"o6-o5\",\"o7-o6\"], 'PIRJ':[\"o5-o4\"]} #OFC 10e-2\n",
    "#dict_ = {'FERJ':[\"a3-a2\",\"j2-j1\"], 'VACJ':[\"d'2-d'1\"]} #PirC 10e-2\n",
    "###############################################################################\n",
    "freq = 'beta' #'1_alpha', '2_beta','3_gamma', high_gamma\n",
    "conds = ['low','high']\n",
    "tps_path = join(st.path, 'feature/TPSim_Enc_Ret_By_Odor_By_Cond/TPS_by_cond/6freqs/')\n",
    "tps_name = join(tps_path,'TPS_spear_{}_cond_{}_{}_3s_zFisher.npz')\n",
    "\n",
    "tps_h_all, tps_l_all = [], []\n",
    "for su in dict_:\n",
    "    for chan in dict_[su]:\n",
    "        mat = np.load(tps_name.format(su,conds[0],freq),allow_pickle=True)\n",
    "        idx_chan = [i for i,c in enumerate(mat['channel']) if c == chan][0]\n",
    "        lab = mat['label'][idx_chan]\n",
    "        \n",
    "        tps_l = mat['tps'][idx_chan]\n",
    "        tps_h = np.load(tps_name.format(su,conds[1],freq))['tps'][idx_chan]\n",
    "        \n",
    "        tps_h_all.extend([tps_h])\n",
    "        tps_l_all.extend([tps_l])\n",
    "        print('low', np.mean(tps_l), np.min(tps_l), np.max(tps_l))\n",
    "        print('high', np.mean(tps_h), np.min(tps_h), np.max(tps_h))\n",
    "        Tl, pl = ttest_1samp(tps_l, 0)\n",
    "        Th, ph = ttest_1samp(tps_h, 0)\n",
    "        \n",
    "        print('Tests for {} in {}'.format(su,chan,freq,lab))\n",
    "        print('Tests Low, T={}, p={}'.format(round(Tl,2),round(pl,3)))\n",
    "        print('Tests High, T={}, p={}'.format(round(Th,2),round(ph,3)))\n",
    "tps_h_all = np.concatenate(tps_h_all,axis=0)\n",
    "tps_l_all = np.concatenate(tps_l_all,axis=0)\n",
    "\n",
    "T_all_h, p_all_h = ttest_1samp(tps_h_all, 0)\n",
    "T_all_l, p_all_l = ttest_1samp(tps_l_all, 0)\n",
    "print('ALL Tests Low, T={}, p={}'.format(round(T_all_l,2),round(p_all_l,3)))\n",
    "print('ALL Tests High, T={}, p={}'.format(round(T_all_h,2),round(p_all_h,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "from itertools import product\n",
    "\n",
    "def tpsim_btw_cond(dataE, dataR, pow_data=None, stat='spearmanr'):\n",
    "    \"\"\"compute the Temporal Pattern Similarity (tpsim) for all combinations of\n",
    "    single-trial power in 2 different conditions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data1, data2 : arrays\n",
    "        Must be of shape (n_pts, n_trials)\n",
    "    stat : string\n",
    "        The stat correlation method to use. 'pearson' or 'spearman'\n",
    "    Returns\n",
    "    -------\n",
    "    tpsim : value\n",
    "        The mean TPSim value \n",
    "    \"\"\"\n",
    "    corr = pearsonr if stat == 'pearson' else spearmanr\n",
    "    assert (\n",
    "        dataE.shape[0] == dataR.shape[0]\n",
    "    ), \"Error: shape of trial1 and trial2 must have the same npts\"\n",
    "    n_trials0, n_trials1 = dataE.shape[1],dataR.shape[1]\n",
    "    \n",
    "    pow_data = dataE if pow_data is None else pow_data\n",
    "    list_tpsim = np.zeros((n_trials0*n_trials1))\n",
    "    list_pow = np.zeros((n_trials0*n_trials1))\n",
    "    i = 0\n",
    "    for trial0, trial1 in product(range(n_trials0),range(n_trials1)):\n",
    "        list_tpsim[i] += 1 -(corr(dataE[:,trial0],dataR[:,trial1])[0])\n",
    "        list_pow[i] += np.mean(pow_data[:,trial0])\n",
    "        i += 1\n",
    "    return list_tpsim, list_pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test if reinstatement is linked to power at encoding in same OR different brain regions\n",
    "\"\"\"\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from brainpipe.system import study\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "st = study('Olfacto')\n",
    "###############################################################################\n",
    "#dict_ = {'FERJ':[\"b2-b1\",\"b6-b5\"], 'PIRJ':[\"b'4-b'3\"], 'VACJ':[\"b3-b2\"]} #aHC\n",
    "#dict_ = {'FERJ':[\"b2-b1\",\"b6-b5\",\"b3-b2\",\"b'5-b'4\"],\n",
    "#         'PIRJ':[\"b'4-b'3\"], 'VACJ':[\"b3-b2\",\"b'2-b'1\"], 'SEMC':[\"b5-b4\"]} #aHC 10e-2\n",
    "#dict_ = {'FERJ':[\"o9-o8\",\"o10-o9\"], 'SEMC':[\"j2-j1\"], 'VACJ':[\"k'13-k'12\"]} #IFG\n",
    "#dict_ = {'FERJ':[\"o9-o8\",\"o10-o9\",\"o8-o7\"], 'SEMC':[\"j2-j1\"], 'VACJ':[\"k'13-k'12\"]} #IFG 10e-2\n",
    "#dict_ = {'LEFC':[\"o4-o3\"], 'SEMC':[\"o5-o4\",\"o6-o5\"], 'PIRJ':[\"o5-o4\"]} #OFC\n",
    "#dict_ = {'LEFC':[\"o4-o3\",\"o6-o5\"], 'SEMC':[\"o5-o4\",\"o6-o5\",\"o7-o6\"], 'PIRJ':[\"o5-o4\"]} #OFC 10e-2\n",
    "dict_ = {'FERJ':[\"a3-a2\",\"j2-j1\"], 'VACJ':[\"d'2-d'1\"]} #PirC 10e-2\n",
    "###############################################################################\n",
    "exp, roi_sel, freq = 'E_R', 'IFG', 'high_gamma'\n",
    "fnames = ['delta', 'theta', 'alpha', 'beta', 'low_gamma', 'high_gamma']\n",
    "i_freq = [i for i,f in enumerate(fnames) if f == freq]\n",
    "conds = ['low','high']\n",
    "pow_path = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_cond/')\n",
    "path_df = join(st.path, 'figure/TPSim_LDA_E_R_by_cond_6freqs_3s_zFisher/')\n",
    "dfname = join(path_df, '2_all_subjects_info_elecs_AUC_by_roi_0.001_corr.csv')\n",
    "pow_name = join(pow_path,'Pow_{}_{}_{}_allfreqs.npz')\n",
    "rois = ['aHC','OFC_olf']\n",
    "\n",
    "for su in elecs_d:\n",
    "    for elec in elecs_d[su]:\n",
    "        dataE_l = np.load(pow_name.format(su,'E','low'))['xpow'][i_freq,elec,17:47,:]       \n",
    "        dataE_h = np.load(pow_name.format(su,'E','high'))['xpow'][i_freq,elec,17:47,:]\n",
    "        data_E = np.concatenate((dataE_l,dataE_h),axis=-1)\n",
    "        #print(dataE_l.shape, dataE_h.shape, data_E.shape)\n",
    "        dataR_l = np.load(pow_name.format(su,'R','low'))['xpow'][i_freq,elec,17:47,:]       \n",
    "        dataR_h = np.load(pow_name.format(su,'R','high'))['xpow'][i_freq,elec,17:47,:]\n",
    "        data_R = np.concatenate((dataR_l,dataR_h),axis=-1)\n",
    "        #print(dataR_l.shape, dataR_h.shape, data_R.shape)\n",
    "        \n",
    "        for roi in rois:\n",
    "            df = pd.read_csv(dfname)\n",
    "            labels = df.loc[df['subjects'] == su]['s_Mai_RL'].values\n",
    "            idx = np.where(labels == roi)[0]\n",
    "            if len(idx) > 0 :\n",
    "                pow_roi_datal = np.load(pow_name.format(su,'E','low'))['xpow'][freq,idx,17:47,:]    \n",
    "                pow_roi_datah = np.load(pow_name.format(su,'E','high'))['xpow'][freq,idx,17:47,:]    \n",
    "                #pow_roi_datal = np.concatenate(pow_roi_datal,axis=-1)\n",
    "                #pow_roi_datah = np.concatenate(pow_roi_datah,axis=-1)\n",
    "                pow_roi_data_all = np.concatenate((pow_roi_datal, pow_roi_datah),axis=-1)    \n",
    "\n",
    "                for e in range(pow_roi_datal.shape[0]):\n",
    "                    tpsER_l, powE_l = tpsim_btw_cond(dataE_l,dataR_l,\n",
    "                                                     pow_data=pow_roi_datal[e,...])        \n",
    "                    tpsER_h, powE_h = tpsim_btw_cond(dataE_h,dataR_h,\n",
    "                                                     pow_data=pow_roi_datah[e,...])        \n",
    "                    tpsER_all = np.concatenate((tpsER_l,tpsER_h))\n",
    "                    powE_all = np.concatenate((powE_l, powE_h))\n",
    "\n",
    "                    R_l, p_l = spearmanr(tpsER_l,powE_l)      \n",
    "                    R_h, p_h = spearmanr(tpsER_h,powE_h)\n",
    "                    R_all, p_all = spearmanr(tpsER_all,powE_all)\n",
    "                    print('\\n correlation for {} in {} roi {}'.format(su,elec,roi))\n",
    "                    print('elec {} out of {}'.format(e,pow_roi_datal.shape[0]))\n",
    "                    print('Tests Low, R={}, p={}'.format(round(R_l,2),round(p_l,3)))\n",
    "                    print('Tests High, R={}, p={}'.format(round(R_h,2),round(p_h,3)))\n",
    "                    print('Tests ALL, R={}, p={}'.format(round(R_all,2),round(p_all,3))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test whether Temporal patterns are correlated btw E and R\n",
    "in frontal and olf/HC regions during encoding\n",
    "\"\"\"\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from brainpipe.system import study\n",
    "from scipy.stats import spearmanr, ttest_1samp\n",
    "\n",
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/TPSim_LDA_{}_by_cond_6freqs_3s_dissim/npy_figs/')\n",
    "pow_path = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_cond/')\n",
    "pow_name = join(pow_path,'Pow_{}_{}_{}_allfreqs.npz')\n",
    "conds = ['low','high']\n",
    "rois = ['aHC','OFC_olf','pPirT']\n",
    "freqs, id_f = ['theta'], 0\n",
    "\n",
    "files = glob.glob(pathdata.format(exp[0])+freqs[0]+'*'+pval+'_tps.csv')\n",
    "\n",
    "for fi in files:\n",
    "    freq, roi = freqs[0],fi.split('_')[-4]\n",
    "    df = pd.read_csv(fi)\n",
    "    subjects, elecs = df['subjects'], df['elecs_num']\n",
    "    for su,elec in zip(subjects,elecs):\n",
    "        data1_l = np.load(pow_name.format(su,'R','low'))['xpow'][id_f,elec,17:47,:]       \n",
    "        data1_h = np.load(pow_name.format(su,'R','high'))['xpow'][id_f,elec,17:47,:]\n",
    "        data1 = np.concatenate((data1_l,data1_h),axis=-1)\n",
    "        #print(dataR_l.shape, dataR_h.shape, data_R.shape)\n",
    "        \n",
    "        for roi in rois:\n",
    "            df = pd.read_csv(dfname)\n",
    "            labels = df.loc[df['subjects'] == su]['s_Mai_RL'].values\n",
    "            idx = np.where(labels == roi)[0]\n",
    "            data0_l = np.load(pow_name.format(su,'E','low'))['xpow'][freq,idx,17:47,:]       \n",
    "            data0_h = np.load(pow_name.format(su,'E','high'))['xpow'][freq,idx,17:47,:]\n",
    "            data0 = np.concatenate((data0_l,data0_h),axis=-1)\n",
    "            #print(dataE_l.shape, dataE_h.shape, data_E.shape)  \n",
    "\n",
    "            for e in range(data0_l.shape[0]):\n",
    "                tpsER_l, _ = tpsim_btw_cond(data0_l[e,...],data1_l)        \n",
    "                tpsER_h, _ = tpsim_btw_cond(data0_h[e,...],data1_h)     \n",
    "                tpsER_all = np.concatenate((tpsER_l,tpsER_h))\n",
    "\n",
    "                T_l, p_l = ttest_1samp(tpsER_l,1)      \n",
    "                T_h, p_h = ttest_1samp(tpsER_h,1)\n",
    "                T_all, p_all = ttest_1samp(tpsER_all,1)\n",
    "                if p_h < 0.05:\n",
    "                    print('\\ncorrelation for {} in {} roi {}'.format(su,idx[e],roi))\n",
    "                    print('elec {} out of {}'.format(e,data0_l.shape[0]))\n",
    "                    #print('Tests Low, R={}, p={}'.format(round(T_l,2),round(p_l,3)))\n",
    "                    print('Tests High, R={}, p={}'.format(round(T_h,2),round(p_h,3)))\n",
    "                    #print('Tests ALL, R={}, p={}'.format(round(T_all,2),round(p_all,3))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test whether Temporal patterns are correlated btw regions during E or R\n",
    "\"\"\"\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from brainpipe.system import study\n",
    "from scipy.stats import spearmanr, ttest_1samp\n",
    "from itertools import combinations\n",
    "\n",
    "st = study('Olfacto')\n",
    "elecs_d = ['PIRJ','SEMC','VACJ','FERJ','LEFC']\n",
    "freq = 0\n",
    "conds = ['low','high']\n",
    "pow_path = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_cond/')\n",
    "pow_name = join(pow_path,'Pow_{}_{}_{}_allfreqs.npz')\n",
    "path_df = join(st.path, 'figure/TPSim_LDA_E_by_cond_3s/')\n",
    "dfname = join(path_df, '2_all_subjects_info_elecs_AUC_Signif_th_0.001_mean_corr_all_11.csv')\n",
    "rois = ['aHC','OFC_olf','pPirT']\n",
    "\n",
    "for su in elecs_d:\n",
    "    for roi0, roi1 in combinations(rois,2):\n",
    "        print(su, roi0, roi1)\n",
    "        df = pd.read_csv(dfname)\n",
    "        labels = df.loc[df['subjects'] == su]['s_Mai_RL'].values\n",
    "        idx0 = np.where(labels == roi0)[0]\n",
    "        idx1 = np.where(labels == roi1)[0]\n",
    "\n",
    "        if (len(idx0) > 0 and len(idx1) > 0):\n",
    "            data0_l = np.load(pow_name.format(su,'E','low'))['xpow'][freq,idx0,17:47,:]       \n",
    "            data0_h = np.load(pow_name.format(su,'E','high'))['xpow'][freq,idx0,17:47,:]\n",
    "            data0_l = np.concatenate(data0_l,axis=-1)\n",
    "            data0_h = np.concatenate(data0_h,axis=-1)\n",
    "\n",
    "            data1_l = np.load(pow_name.format(su,'E','low'))['xpow'][freq,idx1,17:47,:]       \n",
    "            data1_h = np.load(pow_name.format(su,'E','high'))['xpow'][freq,idx1,17:47,:]\n",
    "            data1_l = np.concatenate(data1_h,axis=-1)\n",
    "            data1_h = np.concatenate(data1_h,axis=-1)\n",
    "\n",
    "            tpsER_l, _ = tpsim_btw_cond(data0_l,data1_l)\n",
    "            print('low',np.mean(tpsER_l)) \n",
    "            tpsER_h, _ = tpsim_btw_cond(data0_h,data1_h)    \n",
    "            print('high',np.mean(tpsER_h))\n",
    "            tpsER_all = np.concatenate((tpsER_l,tpsER_h))\n",
    "\n",
    "            T_l, p_l = ttest_1samp(tpsER_l,1)      \n",
    "            T_h, p_h = ttest_1samp(tpsER_h,1)\n",
    "            T_all, p_all = ttest_1samp(tpsER_all,1)\n",
    "            print('correlation for {} in {} and {}'.format(su,roi0,roi1))\n",
    "            print('Tests Low, T={}, p={}'.format(round(T_l,2),round(p_l,3)))\n",
    "            print('Tests High, T={}, p={}\\n'.format(round(T_h,2),round(p_h,3)))\n",
    "            #print('Tests ALL, R={}, p={}'.format(round(T_all,2),round(p_all,3)))\n",
    "        else:\n",
    "            print('roi missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test whether Temporal patterns are correlated btw regions during E or R\n",
    "ADD DELAY TO CHECK FOR TIME DIFFERENCE IN PATTERNS\n",
    "\"\"\"\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from brainpipe.system import study\n",
    "from scipy.stats import spearmanr, ttest_1samp\n",
    "from itertools import combinations\n",
    "\n",
    "st = study('Olfacto')\n",
    "elecs_d = ['PIRJ','SEMC','VACJ','FERJ','LEFC']\n",
    "freq = 0\n",
    "conds = ['low','high']\n",
    "pow_path = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_cond/')\n",
    "pow_name = join(pow_path,'Pow_{}_{}_{}_allfreqs.npz')\n",
    "path_df = join(st.path, 'figure/TPSim_LDA_E_by_cond_3s/')\n",
    "dfname = join(path_df, '2_all_subjects_info_elecs_AUC_Signif_th_0.001_mean_corr_all_11.csv')\n",
    "rois = ['aHC','pPirT']\n",
    "\n",
    "for su in elecs_d:\n",
    "    for roi0, roi1 in product(rois,rois):\n",
    "        if roi0 != roi1:\n",
    "            df = pd.read_csv(dfname)\n",
    "            labels = df.loc[df['subjects'] == su]['s_Mai_RL'].values\n",
    "            idx0 = np.where(labels == roi0)[0]\n",
    "            idx1 = np.where(labels == roi1)[0]\n",
    "            print(su, roi0, roi1)\n",
    "\n",
    "            if (len(idx0) > 0 and len(idx1) > 0):\n",
    "                for d in range(5):\n",
    "                    print(roi0, \"being delayed of {} win\".format(d))\n",
    "                    data0_l = np.load(pow_name.format(su,'E','low'))['xpow'][freq,idx0,17+d:47+d,:]       \n",
    "                    data0_h = np.load(pow_name.format(su,'E','high'))['xpow'][freq,idx0,17+d:47+d,:]\n",
    "                    data0_l = np.concatenate(data0_l,axis=-1)\n",
    "                    data0_h = np.concatenate(data0_h, axis=-1)\n",
    "\n",
    "                    data1_l = np.load(pow_name.format(su,'E','low'))['xpow'][freq,idx1,17:47,:]       \n",
    "                    data1_h = np.load(pow_name.format(su,'E','high'))['xpow'][freq,idx1,17:47,:]\n",
    "                    data1_l = np.concatenate(data1_l,axis=-1)\n",
    "                    data1_h = np.concatenate(data1_h,axis=-1)\n",
    "\n",
    "                    tpsER_l, _ = tpsim_btw_cond(data0_l,data1_l)\n",
    "                    print('low',np.mean(tpsER_l)) \n",
    "                    tpsER_h, _ = tpsim_btw_cond(data0_h,data1_h)    \n",
    "                    print('high',np.mean(tpsER_h))\n",
    "                    tpsER_all = np.concatenate((tpsER_l,tpsER_h))\n",
    "\n",
    "                    T_l, p_l = ttest_1samp(tpsER_l,1)      \n",
    "                    T_h, p_h = ttest_1samp(tpsER_h,1)\n",
    "                    T_all, p_all = ttest_1samp(tpsER_all,1)\n",
    "                    print('correlation for {} in {} and {}'.format(su,roi0,roi1))\n",
    "                    print('Tests Low, T={}, p={}'.format(round(T_l,2),round(p_l,3)))\n",
    "                    print('Tests High, T={}, p={}\\n'.format(round(T_h,2),round(p_h,3)))\n",
    "                    #print('Tests ALL, R={}, p={}'.format(round(T_all,2),round(p_all,3))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpsim_by_cond(pow1, pow_data, average=False):\n",
    "    \"\"\"\n",
    "    Compute tpsim within one condition for all combinations\n",
    "    Parameters\n",
    "    ----------\n",
    "    pow1 : array (npts x ntrials)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tpsim : array\n",
    "    \"\"\"\n",
    "    \n",
    "    pow_data = dataE if pow_data is None else pow_data\n",
    "    sim_trials = np.array([])\n",
    "    pow_trials = np.array([])\n",
    "    for t0, t1 in combinations(np.arange(pow1.shape[-1]),2):\n",
    "        R, _ = stats.spearmanr(pow1[:,t0],pow1[:,t1])\n",
    "        sim_trials = np.vstack((sim_trials,1-R)) if np.size(sim_trials) else 1-R\n",
    "        pow_trials = np.vstack((pow_trials,pow_data[:,t0])) if np.size(pow_trials) else pow_data[:,t0]\n",
    "    if np.size(sim_trials) == 1:\n",
    "        sim_trials = np.array([[sim_trials]])\n",
    "        pow_trials = np.array([[pow_trials]])\n",
    "    else:\n",
    "        sim_trials = sim_trials.swapaxes(0,1)\n",
    "        pow_trials = pow_trials.swapaxes(0,1)\n",
    "    if average == True:\n",
    "        sim_trials = np.mean(sim_trials)\n",
    "        pow_trials = np.mean(pow_trials)\n",
    "    return sim_trials, pow_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check whether the strength of TPSim values (reinstatement or retrieval) is related to \n",
    "power values during encoding in aHC\n",
    "Correlations by electrode and patient for 2 sig patients (LEFC & PIRJ)\n",
    "We take average values by odor\n",
    "\"\"\"\n",
    "\n",
    "from os import listdir\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns \n",
    "\n",
    "st = study('Olfacto')\n",
    "exp, freq = 'E', 'theta'\n",
    "fnames = ['delta', 'theta', 'alpha', 'beta', 'low_gamma', 'high_gamma']\n",
    "i_freq = [i for i,f in enumerate(fnames) if f == freq]\n",
    "path_tps = join(st.path, 'feature/TPSim_Ret_By_Odor_By_Cond/TPS_by_odor/')\n",
    "path_df = join(st.path, 'figure/TPSim_LDA_E_by_cond_3s/')\n",
    "dfname = join(path_df, '2_all_subjects_info_elecs_AUC_Signif_th_0.001_mean_corr_all_11.csv')\n",
    "path_pow = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_odor/')\n",
    "pow_name = join(path_pow, '{}_odor{}_{}_pow{}.npz')\n",
    "###############################################################################\n",
    "#dict_ = {'FERJ':[\"b2-b1\",\"b6-b5\"], 'PIRJ':[\"b'4-b'3\"], 'VACJ':[\"b3-b2\"]} #aHC\n",
    "#dict_ = {'FERJ':[\"b2-b1\",\"b6-b5\",\"b3-b2\",\"b'5-b'4\"],\n",
    "#         'PIRJ':[\"b'4-b'3\"], 'VACJ':[\"b3-b2\",\"b'2-b'1\"], 'SEMC':[\"b5-b4\"]} #aHC 10e-2\n",
    "#dict_ = {'FERJ':[\"o9-o8\",\"o10-o9\"], 'SEMC':[\"j2-j1\"], 'VACJ':[\"k'13-k'12\"]} #IFG\n",
    "#dict_ = {'FERJ':[\"o9-o8\",\"o10-o9\",\"o8-o7\"], 'SEMC':[\"j2-j1\"], 'VACJ':[\"k'13-k'12\"]} #IFG 10e-2\n",
    "#dict_ = {'LEFC':[\"o4-o3\"], 'SEMC':[\"o5-o4\",\"o6-o5\"], 'PIRJ':[\"o5-o4\"]} #OFC\n",
    "#dict_ = {'LEFC':[\"o4-o3\",\"o6-o5\"], 'SEMC':[\"o5-o4\",\"o6-o5\",\"o7-o6\"], 'PIRJ':[\"o5-o4\"]} #OFC 10e-2\n",
    "dict_ = {'FERJ':[\"a3-a2\",\"j2-j1\"], 'VACJ':[\"d'2-d'1\"]} #PirC 10e-2\n",
    "###############################################################################\n",
    "rois = ['aHC']\n",
    "odors_su = {'CHAF': {5:12,7:68,8:36,9:96,1:6,2:2,3:68,4:8},\n",
    "            'LEFC': {1:4,2:0,3:6,4:12,14:96,15:2,16:4,17:68},\n",
    "            'PIRJ': {4:36,9:2,1:4,18:32,6:34,5:4,7:68}, #missing odor 15\n",
    "            'VACJ': {14:6,15:64,16:68,17:8,10:6,11:4,12:4,13:40},\n",
    "            'SEMC': {10:2,11:6,12:6,13:6,5:8,7:4,8:8,9:10},\n",
    "            'FERJ': {16:6,17:6,5:8,7:6,12:8,13:8,2:6,1:10}}\n",
    "\n",
    "ALL_TPS, ALL_POW = [], []\n",
    "for su in elecs_tps:\n",
    "    for elec in elecs_tps[su]:\n",
    "        all_pow, all_tps = [], []\n",
    "        for od in odors_su[su]:\n",
    "            tps_od = np.load(path_tps+'TPS_spear_{}_odor_{}_{}_3s.npz'.format(su,\n",
    "                                                                od,freq))['tps'][elec,:]\n",
    "            mean_tps = np.mean(tps_od)\n",
    "            \n",
    "            for roi in rois:\n",
    "                df = pd.read_csv(dfname)\n",
    "                labels = df.loc[df['subjects'] == su]['s_Mai_RL'].values\n",
    "                idx = np.where(labels == roi)[0]\n",
    "                pow_roi = np.load(pow_name.format(su,od,'E',freq))['xpow'][idx,17:47,:]    \n",
    "                \n",
    "                mean_pow = np.mean(pow_roi)\n",
    "#                 mean_pow = np.mean(pow_roi,axis=(1,2))\n",
    "                all_tps.append(mean_tps)\n",
    "#                 all_tps.append(np.repeat(mean_tps,len(idx)))\n",
    "                all_pow.append(mean_pow)\n",
    "#                 ALL_TPS.append(np.repeat(mean_tps,len(idx)))\n",
    "#                 ALL_POW.append(mean_pow)\n",
    "#         R,p = spearmanr(np.concatenate(all_pow),np.concatenate(all_tps))\n",
    "        R,p = pea(all_pow,all_tps)\n",
    "        print(su, R, p)\n",
    "#         sns.regplot(x=np.concatenate(all_pow), y=np.concatenate(all_tps));\n",
    "        sns.regplot(x=all_pow, y=all_tps);\n",
    "# R_all, p_all = spearmanr(np.concatenate(ALL_POW),np.concatenate(ALL_TPS))\n",
    "# print('ALL', R_all, p_all)\n",
    "# sns.regplot(x=np.concatenate(ALL_POW),y=np.concatenate(ALL_TPS));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
