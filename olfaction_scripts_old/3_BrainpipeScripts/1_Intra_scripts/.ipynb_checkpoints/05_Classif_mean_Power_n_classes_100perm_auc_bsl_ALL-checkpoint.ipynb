{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, MaxNLocator\n",
    "import scipy.io as sio\n",
    "\n",
    "from brainpipe.classification import *\n",
    "from brainpipe.system import study\n",
    "from brainpipe.feature import power, amplitude, sigfilt\n",
    "from brainpipe.visual import *\n",
    "from brainpipe.statistics import *\n",
    "from scipy.stats import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Decoding - Partial//Detailed Encoding\n",
    "### For ALL time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_freqname(freq):\n",
    "    freqnames = ['0_theta', '1_alpha', '2_beta', '3_gamma']\n",
    "    freqname = freqnames[freq]\n",
    "    return freqname\n",
    "\n",
    "def odor_su_dict(phase):\n",
    "    if phase == 'Encoding':\n",
    "        odors_su = {'CHAF': {5:12,7:68,8:36,9:96,1:6,2:2,3:68,4:8},\n",
    "                'LEFC': {1:4,2:0,3:6,4:12,14:96,15:2,16:4,17:68},\n",
    "                'PIRJ': {4:36,9:2,1:4,18:32,6:34,5:4,7:68}, #missing odor 15\n",
    "                'VACJ': {14:6,15:64,16:68,17:8,10:6,11:4,12:4,13:40},\n",
    "                'SEMC': {10:2,11:6,12:6,13:6,5:8,7:4,8:8,9:10},\n",
    "                'MICP': {2:6,12:8,6:96,8:8,3:12,18:4,9:6,14:10},\n",
    "                'FERJ': {16:6,17:6,5:8,7:6,12:8,13:8,2:6,1:10}}\n",
    "    else:\n",
    "        odors_su = {'CHAF': {5:12,7:68,8:36,9:96,1:6,2:2,3:68,4:8},\n",
    "                'LEFC': {1:4,2:0,3:6,4:12,14:96,15:2,16:4,17:68},\n",
    "                'PIRJ': {4:36,9:2,1:4,18:32,6:34,5:4,7:68},#15:4 #remove for TPSim 15:4\n",
    "                'VACJ': {14:6,15:64,16:68,17:8,10:6,11:4,12:4,13:40},\n",
    "                'SEMC': {10:2,11:6,12:6,13:6,5:8,7:4,8:8,9:10},\n",
    "                'FERJ': {16:6,17:6,5:8,7:6,12:8,13:8,2:6,1:10}}\n",
    "    return odors_su\n",
    "\n",
    "def concat_power_by_roi(phase,su,roi,freq,time=False):\n",
    "    path_pow = path.join(st.path, 'feature/0_Power_'+phase+'_By_Odor/')\n",
    "    mat_file = path_pow+'{}_odor_{}_bipo_sel_physFT_pow.npz'\n",
    "    all_odor_pow, all_bsl_pow, scores = np.array([]),np.array([]), []\n",
    "    odors_su = odor_su_dict(phase)\n",
    "    fname = def_freqname(freq)\n",
    "    for odor in odors_su[su]:\n",
    "        mat = np.load(mat_file.format(su,odor))\n",
    "        xpow, Mai_RL, channels = mat[val][freq,...], mat['Mai_RL'], mat['channels']      \n",
    "        if roi == 'pPirT':\n",
    "            id_rois = [r in ['pPirT','Amg','Amg-PirT'] for r in Mai_RL]\n",
    "        else:\n",
    "            id_rois = [r == roi for r in Mai_RL]\n",
    "        if time == False:\n",
    "            m_pow = np.mean(xpow[id_rois,27:47,:],axis=-2) if val == 'xpow' else xpow[id_rois,...]\n",
    "            bsl = np.mean(xpow[id_rois,:23,:],axis=1) #last point in the baseline including no odor time\n",
    "        elif time == True:\n",
    "            m_pow = xpow[id_rois,27:47,:]\n",
    "            print('no sel',xpow.shape)\n",
    "            bsl_mean = xpow[id_rois,:23,:]\n",
    "            print('rois',bsl_mean)\n",
    "            bsl_no_rep = np.mean(xpow[id_rois,:23,:],axis=1)\n",
    "            print('bsl no rep',bsl_no_rep.shape)\n",
    "            bsl = np.tile(bsl_no_rep,(1,m_pow.shape[1],1))\n",
    "            print('bsl rep',bsl_no_rep.shape)\n",
    "            0/0\n",
    "        score_roi = [odors_su[su][odor]]*m_pow.shape[-1]\n",
    "        scores.append(score_roi)\n",
    "        all_odor_pow = np.concatenate((all_odor_pow,m_pow),axis=-1) if np.size(all_odor_pow) else m_pow\n",
    "        all_bsl_pow = np.concatenate((all_bsl_pow,bsl),axis=-1) if np.size(all_bsl_pow) else bsl\n",
    "    scores = np.concatenate(scores,axis=0)\n",
    "    kwargs = {}\n",
    "    kwargs['label'], kwargs['channels']= Mai_RL[id_rois], channels[id_rois]\n",
    "    kwargs['xyz'], kwargs['xpow'], kwargs['bsl'] = mat['xyz'][id_rois], all_odor_pow, all_bsl_pow\n",
    "    kwargs['fname'], kwargs['nelecs'] = fname, all_odor_pow.shape[0]\n",
    "    kwargs['scores'], kwargs['time'] = np.array(scores), (mat['time'][27:47])-3\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold as SKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from numpy.random import permutation\n",
    "from scipy import stats\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "st = study('Olfacto')\n",
    "save_path = path.join(st.path, 'classified/_multi_classes/LDA_Power_mean_bsl_TIME_2classes_BBG_k10_auc/')\n",
    "subjects = ['LEFC','VACJ','SEMC','FERJ','PIRJ','CHAF']\n",
    "rois = ['ACC','HC','IFG','Ins','MFG','OFC','PHG','SFG','pPirT']\n",
    "phase = 'Encoding'\n",
    "freqs = 4\n",
    "nperm = 1000\n",
    "val = 'xpow'\n",
    "\n",
    "def classif_n_classes_by_subj(su):\n",
    "    for freq in range(freqs):\n",
    "        for roi in rois:\n",
    "            dict_ = concat_power_by_roi(phase,su,roi,freq)\n",
    "            freq_name, nelecs = dict_['fname'], dict_['nelecs']\n",
    "            if nelecs > 0:\n",
    "                for elec_num in range(nelecs): \n",
    "                    elec, elec_label = dict_['channels'][elec_num], dict_['label'][elec_num]\n",
    "                    xyz = dict_['xyz'][elec_num]\n",
    "#                     print ('elec ', elec, 'elec_label ', elec_label)\n",
    "\n",
    "                    #Filenames to save\n",
    "                    name_auc = (save_path+freq_name+'/auc/'+su +'_auc_2classes_'+roi+'_('+str(elec)+').npy')\n",
    "                    name_perm = (save_path+freq_name+'/auc/'+su +'_perm_2classes_'+roi+'_('+str(elec)+').npy')\n",
    "                    plot_name = (save_path+freq_name+'/fig/'+su +'_Power_2classes_'+roi+'_('+str(elec)+').png')    \n",
    "                    \n",
    "                    if path.exists(name_auc):\n",
    "                        print(su,phase,elec_num,freq,'already computed')\n",
    "                    else:\n",
    "                        print('--Â» processing',roi, su, 'elec', elec_num,'/',nelecs, 'freq',freq)\n",
    "                        \n",
    "                        pow_odor, pow_bsl = dict_['xpow'][elec_num], dict_['bsl'][elec_num]\n",
    "                        print('shape pow',pow_odor.shape, pow_bsl.shape)\n",
    "\n",
    "                # =============================  Classification Computation ============================================================           \n",
    "                        # create a data matrix, concatenate along the trial dimension\n",
    "                        x = np.concatenate((pow_odor,pow_bsl),axis=0)[:,np.newaxis]\n",
    "                        print ('Size of the concatenated data: ', x.shape)\n",
    "                        y = np.array([0]*pow_odor.shape[0] + [1]*pow_bsl.shape[0])\n",
    "                        print ('Size of label for classif: ', len(y))\n",
    "\n",
    "                        auc = np.array([])\n",
    "                        for t in range(x.shape[1]):\n",
    "                            X = x[:,t]\n",
    "                            X = X.reshape(-1, 1)\n",
    "                            score_rep = []\n",
    "                            for i in range(10):\n",
    "                                k = 10\n",
    "                                skf = SKFold(n_splits=k, random_state=None, shuffle=True)\n",
    "                                skf.get_n_splits(X, y)\n",
    "                                score_cv = []\n",
    "                                for train_index, test_index in skf.split(X, y):\n",
    "                                    clf = LDA()\n",
    "                                    X_train, X_test = X[train_index], X[test_index]\n",
    "                                    y_train, y_test = y[train_index], y[test_index]\n",
    "                                    clf.fit(X=X_train, y=y_train)\n",
    "                                    y_pred = clf.predict(X_test)\n",
    "                                    score_cv.append(roc_auc_score(y_test,y_pred))\n",
    "                                score_rep.append(np.mean(score_cv))\n",
    "                            score_rep = np.asarray(score_rep).reshape(1,len(score_rep))\n",
    "                            auc = np.vstack((auc, score_rep)) if np.size(auc) else score_rep\n",
    "                        auc = np.swapaxes(auc,0,1)\n",
    "                        DA = np.mean(auc)\n",
    "\n",
    "                        perm_scores = np.array([])\n",
    "                        for t in range(x.shape[1]):\n",
    "                            X = x[:,t]\n",
    "                            X = X.reshape(-1, 1)\n",
    "                            perm_rep = []\n",
    "                            for perm in range(nperm):\n",
    "                                y_perm = y[permutation(len(y))]\n",
    "                                score_cv = []\n",
    "                                for train_index, test_index in skf.split(X, y_perm):\n",
    "                                    clf = LDA()\n",
    "                                    X_train, X_test = X[train_index], X[test_index]\n",
    "                                    y_train, y_test = y_perm[train_index], y_perm[test_index]\n",
    "                                    clf.fit(X=X_train, y=y_train)\n",
    "                                    y_pred = clf.predict(X_test)\n",
    "                                    score_cv.append(roc_auc_score(y_test,y_pred))\n",
    "                                perm_rep.append(np.mean(score_cv))\n",
    "                            perm_rep = np.asarray(perm_rep).reshape(1,len(perm_rep))\n",
    "                            perm_scores = np.vstack((perm_scores, perm_rep)) if np.size(perm_scores) else perm_rep\n",
    "                        perm_scores = np.swapaxes(perm_scores,0,1)           \n",
    "                        th_0_05_perm = perm_pvalue2level(perm_scores, p=0.05, maxst=True)\n",
    "                        th_0_01_perm = perm_pvalue2level(perm_scores, p=0.01, maxst=True)\n",
    "                        print('th_perm 005: ', th_0_05_perm[0], '001',th_0_01_perm[0], \n",
    "                              'auc_max', np.max(auc), 'auc_mean', np.mean(auc))\n",
    "\n",
    "                # ============================== PLOT POWER ANALYSIS + STATS & DECODING ACCURACY ===================================================\n",
    "                        #if DA >= th_0_05_perm[0]:\n",
    "                        # plot and figure parameters\n",
    "                        xfmt = ScalarFormatter(useMathText=True)\n",
    "                        xfmt.set_powerlimits((0,3))\n",
    "                        fig, ax = plt.subplots(figsize=(7,7))\n",
    "                        title = freq_name+' for '+su+' 4 classes '+str(elec)+' '+str(elec_label)+' coord '+str(xyz)\n",
    "                        fig.suptitle(title, fontsize=12)\n",
    "\n",
    "                        # Plot the POW + STATS\n",
    "                        plt.ylabel(freq_name)\n",
    "                        anchored_text = AnchoredText('DA = %s, th = %s' % (np.round(DA,2), round(th_0_05_perm[0],2)), loc=2)\n",
    "                        ax.add_artist(anchored_text)\n",
    "                        xticks, w = np.arange(0,2), 0.8\n",
    "                        plt.xticks(xticks, ['odor','bsl'])\n",
    "                        means = np.append(pow_odor.mean(),pow_bsl.mean())\n",
    "                        stds = np.append(stats.sem(pow_odor),stats.sem(pow_bsl))\n",
    "                        plt.bar(xticks,means,color='blue',yerr=stds)\n",
    "                        plt.savefig(plot_name, dpi=300, bbox_inches='tight')\n",
    "                        plt.clf()\n",
    "                        plt.close()\n",
    "\n",
    "                        #Save plots\n",
    "                        np.save(name_auc, auc)\n",
    "                        np.save(name_perm, perm_scores)\n",
    "                        del X, auc, pow_odor, pow_bsl\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Parallel(n_jobs=-1)(delayed(classif_n_classes_by_subj)(su) for su in subjects)\n",
    "    #classif_n_classes_by_subj('LEFC') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/karim/anaconda3/envs/mne_coreg/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/home/karim/anaconda3/envs/mne_coreg/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/karim/anaconda3/envs/mne_coreg/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/karim/anaconda3/envs/mne_coreg/lib/python3.6/site-packages/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/karim/anaconda3/envs/mne_coreg/lib/python3.6/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"<ipython-input-14-feb9b3392f41>\", line 24, in classif_n_classes_by_subj\n  File \"<ipython-input-13-5bfb76be7ada>\", line 43, in concat_power_by_roi\nIndexError: too many indices for array\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-feb9b3392f41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassif_n_classes_by_subj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubjects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;31m#classif_n_classes_by_subj('LEFC')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne_coreg/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne_coreg/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne_coreg/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne_coreg/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne_coreg/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold as SKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from numpy.random import permutation\n",
    "from scipy import stats\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "st = study('Olfacto')\n",
    "save_path = path.join(st.path, 'classified/_multi_classes/LDA_Power_mean_bsl_TIME_2classes_BBG_k10_auc/')\n",
    "subjects = ['LEFC','VACJ','SEMC','FERJ','PIRJ','CHAF']\n",
    "# rois = ['ACC','HC','IFG','Ins','MFG','OFC','PHG','SFG','pPirT']\n",
    "rois = ['pPirT']\n",
    "phase = 'Encoding'\n",
    "freqs = 4\n",
    "color_codes = ['darkorange','grey']\n",
    "nperm = 1000\n",
    "val = 'xpow'\n",
    "conds = ['odor','bsl']\n",
    "\n",
    "def classif_n_classes_by_subj(su):\n",
    "    for freq in range(freqs):\n",
    "        for roi in rois:\n",
    "            dict_ = concat_power_by_roi(phase,su,roi,freq,time=True)\n",
    "            freq_name, nelecs = dict_['fname'], dict_['nelecs']\n",
    "            if nelecs > 0:\n",
    "                for elec_num in range(nelecs): \n",
    "                    elec, elec_label = dict_['channels'][elec_num], dict_['label'][elec_num]\n",
    "                    xyz, time = dict_['xyz'][elec_num], dict_['time']\n",
    "#                     print ('elec ', elec, 'elec_label ', elec_label)\n",
    "\n",
    "                    #Filenames to save\n",
    "                    name_auc = (save_path+freq_name+'/auc/'+su +'_auc_2classes_'+roi+'_('+str(elec)+').npy')\n",
    "                    name_perm = (save_path+freq_name+'/auc/'+su +'_perm_2classes_'+roi+'_('+str(elec)+').npy')\n",
    "                    plot_name = (save_path+freq_name+'/fig/'+su +'_Power_2classes_'+roi+'_('+str(elec)+').png')    \n",
    "                    \n",
    "                    if path.exists(name_auc):\n",
    "                        print(su,phase,elec_num,freq,'already computed')\n",
    "                    else:\n",
    "                        print('--Â» processing',roi, su, 'elec', elec_num,'/',nelecs, 'freq',freq)\n",
    "                        \n",
    "                        pow_odor, pow_bsl = dict_['xpow'][elec_num], dict_['bsl'][elec_num]\n",
    "                        print('shape pow',pow_odor.shape, pow_bsl.shape)\n",
    "\n",
    "                # =============================  Classification Computation ============================================================           \n",
    "                        # create a data matrix, concatenate along the trial dimension\n",
    "                        x = np.concatenate((pow_odor,pow_bsl),axis=1).swapaxes(0,1)\n",
    "                        print ('Size of the concatenated data: ', x.shape)\n",
    "                        y = np.array([0]*pow_odor.shape[1] + [1]*pow_bsl.shape[1])\n",
    "                        print ('Size of label for classif: ', len(y))\n",
    "                        \n",
    "                        auc = np.array([])\n",
    "                        for t in range(x.shape[1]):\n",
    "                            X = x[:,t]\n",
    "                            X = X.reshape(-1, 1)\n",
    "                            score_rep = []\n",
    "                            for i in range(10):\n",
    "                                k = 10\n",
    "                                skf = SKFold(n_splits=k, random_state=None, shuffle=True)\n",
    "                                skf.get_n_splits(X, y)\n",
    "                                score_cv = []\n",
    "                                for train_index, test_index in skf.split(X, y):\n",
    "                                    clf = LDA()\n",
    "                                    X_train, X_test = X[train_index], X[test_index]\n",
    "                                    y_train, y_test = y[train_index], y[test_index]\n",
    "                                    clf.fit(X=X_train, y=y_train)\n",
    "                                    y_pred = clf.predict(X_test)\n",
    "                                    score_cv.append(roc_auc_score(y_test,y_pred))\n",
    "                                score_rep.append(np.mean(score_cv))\n",
    "                            score_rep = np.asarray(score_rep).reshape(1,len(score_rep))\n",
    "                            auc = np.vstack((auc, score_rep)) if np.size(auc) else score_rep\n",
    "                        auc = np.swapaxes(auc,0,1)\n",
    "                        DA = np.mean(auc)\n",
    "\n",
    "                        perm_scores = np.array([])\n",
    "                        for t in range(x.shape[1]):\n",
    "                            print('permutation for time ',t)\n",
    "                            X = x[:,t]\n",
    "                            X = X.reshape(-1, 1)\n",
    "                            perm_rep = []\n",
    "                            for perm in range(nperm):\n",
    "                                y_perm = y[permutation(len(y))]\n",
    "                                score_cv = []\n",
    "                                for train_index, test_index in skf.split(X, y_perm):\n",
    "                                    clf = LDA()\n",
    "                                    X_train, X_test = X[train_index], X[test_index]\n",
    "                                    y_train, y_test = y_perm[train_index], y_perm[test_index]\n",
    "                                    clf.fit(X=X_train, y=y_train)\n",
    "                                    y_pred = clf.predict(X_test)\n",
    "                                    score_cv.append(roc_auc_score(y_test,y_pred))\n",
    "                                perm_rep.append(np.mean(score_cv))\n",
    "                            perm_rep = np.asarray(perm_rep).reshape(1,len(perm_rep))\n",
    "                            perm_scores = np.vstack((perm_scores, perm_rep)) if np.size(perm_scores) else perm_rep\n",
    "                        perm_scores = np.swapaxes(perm_scores,0,1)           \n",
    "                        th_0_05_perm = perm_pvalue2level(perm_scores, p=0.05, maxst=True)\n",
    "                        th_0_01_perm = perm_pvalue2level(perm_scores, p=0.01, maxst=True)\n",
    "                        print('th_perm 005: ', th_0_05_perm[0], '001',th_0_01_perm[0], \n",
    "                              'auc_max', np.max(auc), 'auc_mean', np.mean(auc))\n",
    "\n",
    "                # ============================== PLOT POWER ANALYSIS + STATS & DECODING ACCURACY ===================================================\n",
    "                        #if DA >= th_0_05_perm[0]:\n",
    "                        xfmt = ScalarFormatter(useMathText=True)\n",
    "                        xfmt.set_powerlimits((0,3))\n",
    "                        fig = plt.figure(1,figsize=(7,7))\n",
    "                        title = 'Power-Stats-DA for '+su+' '+conds[0]+' vs '+conds[1]+' '+str(elec)+' '+str(elec_label)+' ('+str(elec_num)+')'\n",
    "                        fig.suptitle(title, fontsize=12)\n",
    "\n",
    "                        # Plot the POW + STATS\n",
    "                        plt.subplot(211)        \n",
    "                        BorderPlot(time, x, y=y, kind='sem', alpha=0.2, color=color_codes,linewidth=2, \n",
    "                                   ncol=1, xlabel='Time (s)',ylabel = r'Power', legend=conds)\n",
    "                        rmaxis(plt.gca(), ['right', 'top'])\n",
    "                        addLines(plt.gca(), vLines=[0], vColor=['darkgray'], vWidth=[2])\n",
    "                        plt.legend(loc=0, handletextpad=0.1, frameon=False)\n",
    "                        plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "\n",
    "                        # Plot DA for the POW\n",
    "                        plt.subplot(212)\n",
    "                        BorderPlot(time, auc, color='b', kind='sd',xlabel='Time (s)', ylim=[0.4,1.], ylabel='Decoding accuracy (%)',linewidth=2, alpha=0.3)\n",
    "                        rmaxis(plt.gca(), ['right', 'top'])\n",
    "                        addLines(plt.gca(), vLines=[0], vColor=['darkgray'], vWidth=[2])\n",
    "                        plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "                        plt.plot(time, th_0_05_perm*np.ones(len(time)), '--', color='r', linewidth=2)\n",
    "                        plt.plot(time, th_0_01_perm*np.ones(len(time)), '--', color='orange', linewidth=2)\n",
    "                        plt.savefig(plot_name, dpi=300, bbox_inches='tight')\n",
    "                        plt.clf()\n",
    "                        plt.close()\n",
    "\n",
    "                        #Save plots\n",
    "                        np.save(name_auc, auc)\n",
    "                        np.save(name_perm, perm_scores)\n",
    "                        del X, auc, pow_odor, pow_bsl\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Parallel(n_jobs=-1)(delayed(classif_n_classes_by_subj)(su) for su in subjects)\n",
    "    #classif_n_classes_by_subj('LEFC') "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
