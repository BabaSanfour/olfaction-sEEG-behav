{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainpipe.system import study\n",
    "from os.path import isfile, join, exists\n",
    "from os import makedirs\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the region information to the big mama csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/figure/LDA_TPSim_E_R_all_BBG/2_all_subjects_info_elecs_AUC_Signif_th_0.01_region.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5a0b56ec7e27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2_all_subjects_info_elecs_AUC_Signif_th_0.01_region.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathdata\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#print(df.columns,df['aal'][:10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/figure/LDA_TPSim_E_R_all_BBG/2_all_subjects_info_elecs_AUC_Signif_th_0.01_region.csv' does not exist"
     ]
    }
   ],
   "source": [
    "conds = ['low','high']\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/LDA_TPSim_E_R_all_BBG/')\n",
    "###############################################################################\n",
    "\n",
    "dfname = '2_all_subjects_info_elecs_AUC_Signif_th_0.01_region.csv'\n",
    "df = pd.read_csv(pathdata+dfname)\n",
    "#print(df.columns,df['aal'][:10]\n",
    "\n",
    "df['region_RL']= np.where(df['aal'].str.contains(\"(L)\") == True,\n",
    "                           df['region']+'_L', df['region']+'_R')\n",
    "#print(df['region_RL'])\n",
    "# Add information about the lobe of elecs\n",
    "#dict_regions ={ 'ACC':'Frontal','IFG':'Frontal','MFG':'Frontal','SFG':'Frontal',\n",
    "#                'Amg':'Olf','pPirT':'Olf','Amg-PirT':'Olf','Ins':'Olf','OFC':'Olf',\n",
    "#                'HC':'MTL','PHG':'MTL','FuG':'Temporal','ITG':'Temporal',\n",
    "#                'MTG':'Temporal','STG':'Temporal'}\n",
    "#df['region'] = df['labels'].map(dict_regions)\n",
    "\n",
    "df.to_csv(pathdata+dfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-tests to compare AUC and Time btw ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "Frontal\n",
      "[ 1.          0.6962299   1.          0.32950311  0.6962299   1.          0.6962299\n",
      "  0.16051033  1.          0.6962299   1.          0.32950311  0.32950311\n",
      "  0.16051033  0.32950311  1.        ]\n",
      "Olf\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "MTL\n",
      "[  1.00000000e+00   1.77923746e-01   1.18757343e-02   1.77923746e-01\n",
      "   1.77923746e-01   1.00000000e+00   3.75858308e-01   1.01564458e-02\n",
      "   1.18757343e-02   3.75858308e-01   1.00000000e+00   1.64881122e-04\n",
      "   1.77923746e-01   1.01564458e-02   1.64881122e-04   1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from mne.stats import fdr_correction\n",
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/LDA_TPSim_E_R_all_BBG/')\n",
    "path2save = join(pathdata, 'AUC_Time_By_freq_region/' )\n",
    "###############################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "###############################################################################\n",
    "\n",
    "#freqs = ['2_theta', '3_alpha', '4_beta','5_gamma1','6_gamma2']\n",
    "freqs = ['0_theta', '1_alpha','2_beta','3_gamma']\n",
    "freqnames = [freq[2:] for freq in freqs]\n",
    "rois = ['Frontal','Olf','MTL']\n",
    "dfname = '2_all_subjects_info_elecs_AUC_Signif_th_0.01_region.csv'\n",
    "df = pd.read_csv(pathdata+dfname)\n",
    "\n",
    "# auc = np.array([])\n",
    "# for freq in freqs:\n",
    "#     #keep only significant electrodes (boolean col keep only 1 value)\n",
    "#     df_freq = pd.concat([df[['subjects','region']],df.filter(like=freq)], axis=1)\n",
    "#     df_freq = df_freq.loc[df_freq.iloc[:,-1] > 0]\n",
    "#     print(df_freq.columns)\n",
    "#     #df_freq = df_freq.loc[df_freq['s_Mai_RL'].isin(['Amg','Amg-PirT','OFC','Ins','pPirT','HC','PHG'])]\n",
    "#     #df_freq.loc[df_freq['s_Mai_RL'] == 'Amg-PirT', 's_Mai_RL'] = 'pPirT'\n",
    "    \n",
    "#     AUC_0 = df_freq[freq+'_AUC'].loc[df_freq['region']=='Frontal']\n",
    "#     AUC_1 = df_freq[freq+'_AUC'].loc[df_freq['region']=='Olf']\n",
    "#     AUC_2 = df_freq[freq+'_AUC'].loc[df_freq['region']=='MTL']\n",
    "#     T0, p0 = ttest_ind(AUC_0,AUC_1,equal_var=False)\n",
    "#     T1, p1 = ttest_ind(AUC_0,AUC_2,equal_var=False)\n",
    "#     T2, p2 = ttest_ind(AUC_2,AUC_1,equal_var=False)\n",
    "#     _,pvals = fdr_correction([p0,p1,p2],alpha=0.01)\n",
    "#     print(freq,'AUC',T0,p0,T1,p1,T2,p2)\n",
    "#     print(pvals)\n",
    "#     print('AUC scores', np.mean(AUC_0), np.std(AUC_0))\n",
    "    \n",
    "    #AUC_0 = df_freq[freq+'_AUC'].loc[df_freq['s_Mai_RL']=='Amg']\n",
    "    #AUC_1 = df_freq[freq+'_AUC'].loc[df_freq['s_Mai_RL']=='pPirT']\n",
    "    #AUC_2 = df_freq[freq+'_AUC'].loc[df_freq['s_Mai_RL']=='OFC']\n",
    "    #AUC_3 = df_freq[freq+'_AUC'].loc[df_freq['s_Mai_RL']=='Ins']\n",
    "    #AUC_4 = df_freq[freq+'_AUC'].loc[df_freq['s_Mai_RL']=='PHG']\n",
    "    #AUC_5 = df_freq[freq+'_AUC'].loc[df_freq['s_Mai_RL']=='HC']\n",
    "    #T0, p0 = ttest_ind(AUC_0,AUC_1,equal_var=False)\n",
    "    #T1, p1 = ttest_ind(AUC_0,AUC_2,equal_var=False)\n",
    "    #T2, p2 = ttest_ind(AUC_0,AUC_3,equal_var=False)\n",
    "    #T3, p3 = ttest_ind(AUC_0,AUC_4,equal_var=False)\n",
    "    #T4, p4 = ttest_ind(AUC_0,AUC_5,equal_var=False)\n",
    "    #_,pvals = fdr_correction([p0,p1,p2,p3,p4],alpha=0.05)\n",
    "    #print(freq,'AUC',p0,p1,p2,p3,p4)\n",
    "    #print(pvals)\n",
    "    \n",
    "df_freq = df.filter(like='AUC')\n",
    "for roi in rois:\n",
    "    AUC_freqs = []\n",
    "    for freq in freqs:\n",
    "        df2 = pd.concat([df[['subjects','region']],df_freq.filter(like=freq)], axis=1)\n",
    "        df2 = df2.loc[df_freq.iloc[:,-1] > 0]\n",
    "        AUC = df2[freq+'_AUC'].loc[df2['region']==roi]\n",
    "        AUC_freqs.append(AUC)\n",
    "    pvals, Tvals = [],[]\n",
    "    for i,j in product(range(4),range(4)):\n",
    "        T0, p0 = ttest_ind(AUC_freqs[i],AUC_freqs[j],equal_var=False)\n",
    "        pvals.append(p0)\n",
    "        Tvals.append(T0)\n",
    "    _,pvals_c = fdr_correction(pvals,alpha=0.01) \n",
    "    print(roi)\n",
    "    print(pvals_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "0_theta 1\n",
      "0_theta 2\n",
      "0_theta 3\n",
      "[(144,), (77,), (58,)]\n",
      "MTL AUC [ 0.97340009  0.25808687  0.25808687]\n",
      "1_alpha 1\n",
      "1_alpha 2\n",
      "1_alpha 3\n",
      "[(144,), (77,), (58,)]\n",
      "MTL AUC [ 0.77848638  0.77848638  0.77848638]\n",
      "2_beta 1\n",
      "2_beta 2\n",
      "2_beta 3\n",
      "[(144,), (77,), (58,)]\n",
      "MTL AUC [ 0.95370247  0.22496399  0.22496399]\n",
      "3_gamma 1\n",
      "3_gamma 2\n",
      "3_gamma 3\n",
      "[(144,), (77,), (58,)]\n",
      "MTL AUC [ 0.46849172  0.09369847  0.06169556]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from mne.stats import fdr_correction\n",
    "from itertools import combinations\n",
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/LDA_Power_R_pre_stim_1s_BBG/')\n",
    "path2save = join(pathdata, 'AUC_Time_By_freq_region/' )\n",
    "###############################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "###############################################################################\n",
    "\n",
    "freqs = ['0_theta', '1_alpha','2_beta','3_gamma']\n",
    "#freqs = ['2_theta', '3_alpha', '4_beta','5_gamma1','6_gamma2']\n",
    "freqnames = [freq[2:] for freq in freqs]\n",
    "rois = ['Frontal','Olf','MTL']\n",
    "dfname = '2_all_subjects_info_elecs_AUC_Signif_th_0.01_region.csv'\n",
    "df = pd.read_csv(pathdata+dfname)\n",
    "\n",
    "for freq in freqs:\n",
    "    auc , pow_f = [], []\n",
    "    for roi in rois:\n",
    "        #keep only significant electrodes (boolean col keep only 1 value)\n",
    "        df_freq = pd.concat([df[['subjects','region']],df.filter(like=freq)], axis=1)\n",
    "        df_freq = df_freq.loc[df_freq.iloc[:,-1] > 0]\n",
    "        AUC_0 = df_freq[freq+'_AUC'].loc[df_freq['region']==roi].values\n",
    "        POW = df_freq[freq+'_AUC'].loc[df_freq['region']==roi].values\n",
    "        auc.append(AUC_0)\n",
    "        print(freq,len(auc))\n",
    "    print([s.shape for s in auc])\n",
    "\n",
    "    T, p, comb = [], [], []\n",
    "    for a,b in combinations(auc,2):\n",
    "        T0, p0 = ttest_ind(a,b,equal_var=False)\n",
    "        T.append(T0),p.append(p0) \n",
    "\n",
    "    _,pvals = fdr_correction(p,alpha=0.05)\n",
    "    print(roi,'AUC',pvals)\n",
    "    \n",
    "    #AUC_0 = df_freq[freq+'_AUC'].loc[df_freq['s_Mai_RL']=='Amg']\n",
    "    #AUC_1 = df_freq[freq+'_AUC'].loc[df_freq['s_Mai_RL']=='pPirT']\n",
    "    #AUC_2 = df_freq[freq+'_AUC'].loc[df_freq['s_Mai_RL']=='OFC']\n",
    "    #AUC_3 = df_freq[freq+'_AUC'].loc[df_freq['s_Mai_RL']=='Ins']\n",
    "    #AUC_4 = df_freq[freq+'_AUC'].loc[df_freq['s_Mai_RL']=='PHG']\n",
    "    #AUC_5 = df_freq[freq+'_AUC'].loc[df_freq['s_Mai_RL']=='HC']\n",
    "    #T0, p0 = ttest_ind(AUC_0,AUC_1,equal_var=False)\n",
    "    #T1, p1 = ttest_ind(AUC_0,AUC_2,equal_var=False)\n",
    "    #T2, p2 = ttest_ind(AUC_0,AUC_3,equal_var=False)\n",
    "    #T3, p3 = ttest_ind(AUC_0,AUC_4,equal_var=False)\n",
    "    #T4, p4 = ttest_ind(AUC_0,AUC_5,equal_var=False)\n",
    "    #_,pvals = fdr_correction(p0+p1+p2+p3+p4,alpha=0.05)\n",
    "    #print(freq,'AUC',p0,p1,p2,p3,p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot AUC and Time by region for each frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "         0_theta_AUC                              \n",
      "               count      mean       std       sem\n",
      "s_Mai_RL                                          \n",
      "HC                15  0.770885  0.083452  0.021547\n",
      "IFG                8  0.829033  0.076690  0.027114\n",
      "Ins                7  0.863401  0.077757  0.029389\n",
      "MFG                5  0.789676  0.082733  0.037000\n",
      "OFC               16  0.815190  0.052471  0.013118\n",
      "SFG               19  0.847243  0.093511  0.021453\n",
      "pPirT              4  0.767435  0.041543  0.020771\n",
      "         1_alpha_AUC                              \n",
      "               count      mean       std       sem\n",
      "s_Mai_RL                                          \n",
      "HC                 9  0.818556  0.081328  0.027109\n",
      "IFG               13  0.794145  0.056827  0.015761\n",
      "Ins                8  0.796410  0.093447  0.033038\n",
      "MFG               12  0.825974  0.079678  0.023001\n",
      "OFC               12  0.798945  0.072425  0.020907\n",
      "SFG                7  0.865952  0.017529  0.006625\n",
      "pPirT              3  0.783232  0.155298  0.089661\n",
      "         2_beta_AUC                              \n",
      "              count      mean       std       sem\n",
      "s_Mai_RL                                         \n",
      "HC               22  0.785851  0.080550  0.017173\n",
      "IFG              13  0.815256  0.080865  0.022428\n",
      "Ins               7  0.845922  0.111508  0.042146\n",
      "MFG               9  0.790733  0.103748  0.034583\n",
      "OFC              19  0.801326  0.068490  0.015713\n",
      "SFG              15  0.910857  0.062619  0.016168\n",
      "pPirT             3  0.788762  0.092036  0.053137\n",
      "         3_gamma_AUC                              \n",
      "               count      mean       std       sem\n",
      "s_Mai_RL                                          \n",
      "HC                15  0.792557  0.084457  0.021807\n",
      "IFG               18  0.818753  0.070349  0.016581\n",
      "Ins               10  0.817652  0.096710  0.030582\n",
      "MFG               26  0.852635  0.104080  0.020412\n",
      "OFC               28  0.805254  0.075538  0.014275\n",
      "SFG               39  0.891868  0.083122  0.013310\n",
      "pPirT              6  0.832725  0.063085  0.025754\n"
     ]
    }
   ],
   "source": [
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/0_Classif_Power_E_EpiPerf_LowHigh_1000perm_BBG/')\n",
    "path2save = join(pathdata, 'AUC_Time_By_freq_region/' )\n",
    "###############################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "###############################################################################\n",
    "\n",
    "#freqs = ['2_theta', '3_alpha', '4_beta','5_gamma1','6_gamma2']\n",
    "freqs = ['0_theta', '1_alpha','2_beta','3_gamma']\n",
    "freqnames = [freq[2:] for freq in freqs]\n",
    "\n",
    "dfname = '2_all_subjects_info_elecs_AUC_Signif_th_0.01_region.csv'\n",
    "df = pd.read_csv(pathdata+dfname)\n",
    "#print(df.columns)\n",
    "#df.drop(['Unnamed: 0'],inplace=True, axis=1)\n",
    "\n",
    "for f,freq in enumerate(freqs):\n",
    "    #keep only significant electrodes (boolean col keep only 1 value)\n",
    "    df_freq = pd.concat([df[['subjects','s_Mai_RL']],df.filter(like=freqnames[f])], axis=1)\n",
    "    df_freq = df_freq.loc[df_freq.iloc[:,-1] > 0]\n",
    "    df_freq.loc[df_freq['s_Mai_RL'] == 'Amg-PirT', 's_Mai_RL'] = 'pPirT'\n",
    "    df_freq = df_freq.loc[df_freq['s_Mai_RL'].isin(['HC','IFG','MFG','SFG','Ins','pPirT','OFC'])]\n",
    "    #df_freq = df_freq.loc[df_freq[freq+'_Pow1'] > df_freq[freq+'_Pow0']]\n",
    "    #print(df_freq)\n",
    "    \n",
    "    #group result by region\n",
    "    df_gr = df_freq.groupby(['s_Mai_RL']).agg(('count','mean','std','sem'))\n",
    "    df_gr.to_csv(pathdata+'AUC_Time_by_roi_{}.csv'.format(freq))\n",
    "    #print(df_gr.filter(like='AUC'))\n",
    "    \n",
    "#     #Plot Mean Time \n",
    "#     fig = plt.figure()\n",
    "#     plt.title('Mean Decoding Time by region for '+freqnames[f])\n",
    "#     plt.ylabel('Mean Time (ms)')\n",
    "#     xticks, w = np.arange(0,df_gr.shape[0]), 0.8\n",
    "#     time = df_gr.filter(like=('Time'))\n",
    "#     plt.xticks(xticks,time.index.get_level_values(0).values)\n",
    "#     plt.ylim(0,2000)\n",
    "#     plt.bar(xticks,time.iloc[:,1]*100,yerr=time.iloc[:,3]*100, color='b')\n",
    "#     plt.savefig(path2save+'Time_'+freq+'_signif_th_01.png')\n",
    "#     plt.savefig(path2save+'Time_'+freq+'_signif_th_01.pdf')\n",
    "#     plt.clf()\n",
    "#     plt.close()\n",
    "    \n",
    "    #Plot Mean AUC Score\n",
    "    fig = plt.figure()\n",
    "    plt.title('Mean AUC Score by region for '+freqnames[f])\n",
    "    plt.ylabel('Mean AUC')\n",
    "    xticks, w = np.arange(0,df_gr.shape[0]), 0.8\n",
    "    auc = df_gr.filter(like=('AUC'))\n",
    "    print(auc)\n",
    "    plt.xticks(xticks,auc.index.get_level_values(0).values)\n",
    "    plt.ylim(0.7,0.95)\n",
    "    plt.bar(xticks,auc.iloc[:,1],yerr=auc.iloc[:,3],color='darkorange')\n",
    "    plt.savefig(path2save+'AUC_'+freq+'_signif_th_01.png')\n",
    "    plt.savefig(path2save+'AUC_'+freq+'_signif_th_01.pdf')\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot AUC and Time by region for all freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "0_theta         0_theta_Pow0             0_theta_Pow1           \n",
      "                mean         sem         mean        sem\n",
      "region                                                  \n",
      "Frontal   361.548618  186.017564   221.959741  52.599580\n",
      "MTL       493.421447   96.497967   251.683089  41.199100\n",
      "Olf       675.058635  249.354741   262.846551  84.203072\n",
      "1_alpha         1_alpha_Pow0            1_alpha_Pow1           \n",
      "                mean        sem         mean        sem\n",
      "region                                                 \n",
      "Frontal   173.379340  67.321110    72.515302  14.561844\n",
      "MTL       178.788329  43.350013    90.339014  21.770753\n",
      "Olf       207.736271  83.666639    55.199648  13.129317\n",
      "2_beta         2_beta_Pow0            2_beta_Pow1           \n",
      "               mean        sem        mean        sem\n",
      "region                                               \n",
      "Frontal  145.340448  27.936286  101.281497  17.130438\n",
      "MTL      197.992621  42.700612  131.870923  35.977945\n",
      "Olf      148.377779  61.665365   73.767352  14.379678\n",
      "3_gamma         3_gamma_Pow0             3_gamma_Pow1             \n",
      "                mean         sem         mean          sem\n",
      "region                                                    \n",
      "Frontal     7.702928    0.775612     8.249300     0.813610\n",
      "MTL        12.192686    4.473585    12.561685     5.338938\n",
      "Olf       843.995897  584.254565  2264.986303  1578.440179\n",
      "        0_theta_AUC           1_alpha_AUC           2_beta_AUC            \\\n",
      "               mean       sem        mean       sem       mean       sem   \n",
      "region                                                                     \n",
      "Frontal    0.835603  0.014595    0.819345  0.011516   0.843877  0.015702   \n",
      "MTL        0.779164  0.015787    0.813048  0.015585   0.792497  0.013788   \n",
      "Olf        0.824768  0.011932    0.803966  0.017600   0.816368  0.014196   \n",
      "\n",
      "        3_gamma_AUC            \n",
      "               mean       sem  \n",
      "region                         \n",
      "Frontal    0.867181  0.009578  \n",
      "MTL        0.808371  0.016040  \n",
      "Olf        0.818043  0.012080           0_theta_Time           1_alpha_Time           2_beta_Time            \\\n",
      "                mean       sem         mean       sem        mean       sem   \n",
      "region                                                                        \n",
      "Frontal     6.540541  0.861762     6.342857  0.960517    7.684211  0.921611   \n",
      "MTL         9.333333  1.056349     7.888889  1.430044   10.862069  0.880445   \n",
      "Olf        10.862069  0.925453     7.080000  0.879242   10.312500  1.016435   \n",
      "\n",
      "        3_gamma_Time            \n",
      "                mean       sem  \n",
      "region                          \n",
      "Frontal     8.438202  0.621983  \n",
      "MTL        10.086957  1.192720  \n",
      "Olf         9.804348  0.865674  \n",
      "Frontal\n",
      "MTL\n",
      "Olf\n"
     ]
    }
   ],
   "source": [
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/0_Classif_Power_E_EpiPerf_LowHigh_1000perm_BBG/')\n",
    "path2save = join(pathdata, 'AUC_Time_By_freq_region/' )\n",
    "###############################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "###############################################################################\n",
    "\n",
    "#freqs = ['2_theta', '3_alpha', '4_beta','5_gamma1','6_gamma2']\n",
    "freqs = ['0_theta', '1_alpha','2_beta','3_gamma']\n",
    "\n",
    "rois = ['Frontal','MTL','Olf']\n",
    "freqnames = [freq[2:] for freq in freqs]\n",
    "\n",
    "dfname = '2_all_subjects_info_elecs_AUC_Signif_th_0.01_region.csv'\n",
    "df = pd.read_csv(pathdata+dfname)\n",
    "#df.drop(['Unnamed: 0'],inplace=True, axis=1)\n",
    "\n",
    "result_auc = pd.DataFrame()\n",
    "result_time = pd.DataFrame()\n",
    "for freq in freqs:\n",
    "    df2 = pd.concat([df[['subjects','region']],df.filter(like=freq[2:])], axis=1)\n",
    "    df2 = df2.loc[df2.iloc[:,-1] > 0]\n",
    "    #df2 = df2.loc[df2['s_Mai_RL'].isin(['Amg','Amg-PirT','OFC','Ins','pPirT','HC','PHG'])]\n",
    "    #df2.loc[df2['s_Mai_RL'] == 'Amg-PirT', 's_Mai_RL'] = 'pPirT'\n",
    "    df2 = df2.groupby(['region']).agg(('mean','sem'))\n",
    "    auc = df2.filter(like='AUC')\n",
    "    time = df2.filter(like='Time')\n",
    "    pow_ = df2.filter(like='Pow')\n",
    "    result_auc = pd.concat([result_auc, auc], axis=1)\n",
    "    result_time = pd.concat([result_time, time], axis=1)\n",
    "    print(freq, pow_)\n",
    "print(result_auc, result_time)\n",
    "dfsave = pd.concat([result_auc,result_time],ignore_index=False)\n",
    "dfsave.to_csv(path2save+'AUC_Time_by_roi.csv')\n",
    "\n",
    "for i,roi in enumerate(result_auc.index):\n",
    "    print(roi)\n",
    "    #Plot Mean AUC Score\n",
    "    fig = plt.figure()\n",
    "    plt.title('Mean AUC Score for '+roi)\n",
    "    plt.ylabel('Mean AUC')\n",
    "    xticks, w = np.arange(0,len(freqnames)), 0.8\n",
    "    plt.xticks(xticks,freqnames)\n",
    "    if roi == 'Amg':\n",
    "        plt.ylim(0.6,0.75)\n",
    "    elif roi == 'Olf':\n",
    "        plt.ylim(0.6,0.75)\n",
    "    else:\n",
    "        plt.ylim(0.6,0.75)\n",
    "    data = result_auc.iloc[i,np.arange(0,result_auc.shape[1],2)]\n",
    "    plt.bar(xticks,data,yerr=result_auc.iloc[i,np.arange(1,result_auc.shape[1],2)],\n",
    "            color='darkorange')\n",
    "    #print(roi,'auc',data)\n",
    "    plt.savefig(path2save+'AUC_'+roi+'_signif_th_01.png')\n",
    "    plt.savefig(path2save+'AUC_'+roi+'_signif_th_01.pdf')\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "#     #Plot Mean Time Score\n",
    "#     fig = plt.figure()\n",
    "#     plt.title('Mean Time Score for '+roi)\n",
    "#     plt.ylabel('Mean Time (ms)')\n",
    "#     xticks, w = np.arange(0,len(freqnames)), 0.8\n",
    "#     plt.xticks(xticks,freqnames)\n",
    "#     plt.ylim(0,1300)\n",
    "#     data = (result_time.iloc[i,np.arange(0,result_time.shape[1],2)])*100\n",
    "#     plt.bar(xticks,data, yerr=(result_time.iloc[i,np.arange(1,result_time.shape[1],2)])*100,\n",
    "#             color='blue')\n",
    "#     #print(roi,'time',data)\n",
    "#     plt.savefig(path2save+'Time_'+roi+'_signif_th_01.png')\n",
    "#     plt.savefig(path2save+'Time_'+roi+'_signif_th_01.pdf')\n",
    "#     plt.clf()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "         ('theta', 'min_win1.0')  ('alpha', 'min_win1.0')  \\\n",
      "region                                                      \n",
      "Frontal                       11                        6   \n",
      "MTL                            7                        6   \n",
      "Olf                            5                        7   \n",
      "\n",
      "         ('beta', 'min_win1.0')  ('gamma', 'min_win1.0')  \n",
      "region                                                    \n",
      "Frontal                      14                       12  \n",
      "MTL                          10                       10  \n",
      "Olf                           8                        9   ['Frontal' 'MTL' 'Olf']\n",
      "Frontal ('theta', 'min_win1.0')    7.638889\n",
      "('alpha', 'min_win1.0')    4.166667\n",
      "('beta', 'min_win1.0')     9.722222\n",
      "('gamma', 'min_win1.0')    8.333333\n",
      "Name: Frontal, dtype: float64\n",
      "MTL ('theta', 'min_win1.0')    11.290323\n",
      "('alpha', 'min_win1.0')     9.677419\n",
      "('beta', 'min_win1.0')     16.129032\n",
      "('gamma', 'min_win1.0')    16.129032\n",
      "Name: MTL, dtype: float64\n",
      "Olf ('theta', 'min_win1.0')     6.666667\n",
      "('alpha', 'min_win1.0')     9.333333\n",
      "('beta', 'min_win1.0')     10.666667\n",
      "('gamma', 'min_win1.0')    12.000000\n",
      "Name: Olf, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/LDA_TPSim_E_R_all_BBG/')\n",
    "path2save = join(pathdata, 'AUC_Time_By_freq_region/' )\n",
    "###############################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "###############################################################################\n",
    "\n",
    "freqs = ['0_theta', '1_alpha','2_beta','3_gamma']\n",
    "#freqs = ['2_theta', '3_alpha', '4_beta','5_gamma1','6_gamma2']\n",
    "#nb_elecs = [143, 77, 92] #encoding\n",
    "nb_elecs = [144, 62, 75] #retrieval\n",
    "freqnames = [freq[2:] for freq in freqs]\n",
    "\n",
    "dfname = '2_all_subjects_info_elecs_AUC_Signif_th_0.01_region.csv'\n",
    "df = pd.read_csv(pathdata+dfname)\n",
    "#df.drop(['Unnamed: 0'],inplace=True, axis=1)\n",
    " \n",
    "df_roi = pd.concat([df[['subjects','region']],df.filter(like=('min_win'))],axis=1)\n",
    "df_roi = df_roi.groupby(['region']).agg('sum')\n",
    "rois = df_roi.index.get_level_values(0).values\n",
    "print(df_roi, rois)\n",
    "\n",
    "#Plot number of signif electrodes\n",
    "for i,roi in enumerate(rois):\n",
    "    fig = plt.figure()\n",
    "    plt.title('Signif electrodes in '+roi+' region')\n",
    "    plt.ylabel('#electrodes (%)')\n",
    "    xticks, w = np.arange(0,len(freqnames)), 0.8\n",
    "    plt.xticks(xticks,freqnames)\n",
    "    #plt.ylim(0,30) if roi == 'Frontal' else plt.ylim(0,12)\n",
    "    plt.ylim(0,70)\n",
    "    data = (df_roi.iloc[i,:]/nb_elecs[i])*100\n",
    "    print(roi,data)\n",
    "    plt.bar(xticks,data,color='grey')\n",
    "    plt.savefig(path2save+'Nb_elecs_'+roi+'_signif_th_01.png')\n",
    "    plt.savefig(path2save+'Nb_elecs_'+roi+'_signif_th_01.pdf')\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of electrodes that decode in both encoding and retrieval by freq and region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent [20.833333333333336, 29.032258064516132, 33.333333333333329] [144, 62, 75]\n",
      "percent [18.055555555555554, 9.67741935483871, 9.3333333333333339] [144, 62, 75]\n",
      "percent [4.8611111111111116, 4.838709677419355, 5.3333333333333339] [144, 62, 75]\n",
      "percent [20.833333333333336, 20.967741935483872, 25.333333333333336] [144, 62, 75]\n",
      "percent [16.666666666666664, 8.064516129032258, 12.0] [144, 62, 75]\n",
      "percent [3.4722222222222223, 8.064516129032258, 8.0] [144, 62, 75]\n",
      "percent [22.222222222222221, 41.935483870967744, 30.666666666666664] [144, 62, 75]\n",
      "percent [16.666666666666664, 9.67741935483871, 8.0] [144, 62, 75]\n",
      "percent [4.1666666666666661, 4.838709677419355, 12.0] [144, 62, 75]\n",
      "percent [47.916666666666671, 30.64516129032258, 50.666666666666671] [144, 62, 75]\n",
      "percent [5.5555555555555554, 8.064516129032258, 6.666666666666667] [144, 62, 75]\n",
      "percent [13.888888888888889, 6.4516129032258061, 10.666666666666668] [144, 62, 75]\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "th = '0.01'\n",
    "freqs = ['0_theta', '1_alpha','2_beta','3_gamma']\n",
    "#freqs = ['2_theta', '3_alpha', '4_beta','5_gamma1','6_gamma2']\n",
    "rois_to_keep = ['ACC','Amg','Amg-PirT','HC','IFG','Ins','MFG','OFC','PHG',\n",
    "            'SFG','pPirT']\n",
    "nb_elecs = [144, 62, 75] #retrieval\n",
    "###############################################################################\n",
    "path = r'/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/figure/'\n",
    "path_npz_enc = join(path, '0_Classif_Power_E_EpiPerf_LowHigh_1000perm_BBG/')\n",
    "path_npz_ret = join(path, '0_Classif_Power_R_EpiPerf_LowHigh_1000perm_BBG/')\n",
    "npz_form = 'All_subjects_sources_{}_odor_low_high_sel_physFT.npz'\n",
    "mask_form = 'All_subjects_mask_stat_{}_minwin1.0_th'+th+'.npy'\n",
    "path2save = join(path, 'Conjonction/')\n",
    "###############################################################################\n",
    "\n",
    "for freq in freqs:\n",
    "    mat_enc = np.load(path_npz_enc+npz_form.format(freq))\n",
    "    idx_E = np.where([roi in rois_to_keep for roi in mat_enc['s_labels']])\n",
    "    xyz0, labels0 = mat_enc['s_xyz'][idx_E], mat_enc['s_labels'][idx_E]\n",
    "    mask0 = np.load(path_npz_enc+'masks_stat/'+mask_form.format(freq))\n",
    "    \n",
    "    mat_ret = np.load(path_npz_ret+npz_form.format(freq))\n",
    "    idx_R = np.where([roi in rois_to_keep for roi in mat_ret['s_labels']])\n",
    "    xyz1, labels1 = mat_ret['s_xyz'][idx_R], mat_ret['s_labels'][idx_R]\n",
    "    mask1 = np.load(path_npz_ret+'masks_stat/'+mask_form.format(freq))\n",
    "    \n",
    "    xyz_all = np.unique(np.concatenate((xyz0,xyz1),axis=0),axis=0)\n",
    "    #print(xyz0.shape,xyz1.shape,xyz_all.shape)\n",
    "    \n",
    "    #create an array of region labels for encoding and retrieval\n",
    "    dict_regions ={ 'ACC':'Frontal','IFG':'Frontal','MFG':'Frontal','SFG':'Frontal',\n",
    "                'Amg':'Olf','pPirT':'Olf','Amg-PirT':'Olf','Ins':'Olf','OFC':'Olf',\n",
    "                'HC':'MTL','PHG':'MTL'}\n",
    "    regions0 = np.vectorize(dict_regions.get)(labels0)\n",
    "    regions1 = np.vectorize(dict_regions.get)(labels1)\n",
    "\n",
    "    #loop on all elecs and create a code indicating when it decodes\n",
    "    codes_elecs, region_elecs = [], []\n",
    "    for i, elec in enumerate(xyz_all):\n",
    "        in_1 = np.where(np.all(elec == xyz0, 1))[0] #encoding\n",
    "        in_2 = np.where(np.all(elec == xyz1, 1))[0] #retrieval\n",
    "\n",
    "        if in_1.size and in_2.size: #decode in both\n",
    "            sig0,sig1 = mask0[in_1], mask1[in_2]\n",
    "            if sig0 == False and sig1 == False:\n",
    "                codes_elecs.append(2)\n",
    "                region_elecs.append(regions0[in_1][0])\n",
    "            if sig0 == False and sig1 == True:\n",
    "                codes_elecs.append(0)\n",
    "                region_elecs.append(regions0[in_1][0])\n",
    "            if sig0 == True and sig1 == False:\n",
    "                codes_elecs.append(1)\n",
    "                region_elecs.append(regions1[in_2][0])\n",
    "        if in_1.size and not in_2.size: #decode only in encoding\n",
    "            if mask0[in_1] == False:\n",
    "                codes_elecs.append(0)\n",
    "                region_elecs.append(regions0[in_1][0])\n",
    "        if not in_1.size and in_2.size: #decode only in retrieval\n",
    "            if mask1[in_2] == False:\n",
    "                codes_elecs.append(1)\n",
    "                region_elecs.append(regions1[in_2][0])\n",
    "    \n",
    "    codes_elecs = np.asarray(codes_elecs)[np.newaxis]\n",
    "    region_elecs = np.asarray(region_elecs)[np.newaxis]\n",
    "    count = np.ones(shape=region_elecs.shape)\n",
    "    #print(freq,'regions',region_elecs.shape,codes_elecs.shape, count.shape)\n",
    "    concat = np.concatenate((codes_elecs,region_elecs,count),axis=0).swapaxes(0,1)\n",
    "    df = pd.DataFrame(concat,columns=['codes_elecs','region_elecs','count'])\n",
    "    df_gr = df.groupby(['codes_elecs','region_elecs']).count()\n",
    "    df_gr = df_gr.unstack(level=0).T\n",
    "    codes = df_gr.index.get_level_values(1).values\n",
    "    rois = df_gr.columns.get_level_values(0).values\n",
    "    #print(df_gr, codes, rois)\n",
    "    \n",
    "    #Plot number of signif electrodes\n",
    "    fig = plt.figure()\n",
    "    plt.title('Signif electrodes for '+freq)\n",
    "    plt.ylabel('#electrodes')\n",
    "    xticks, w = np.arange(0,len(rois)), 0.8\n",
    "    plt.xticks(xticks,rois)\n",
    "    plt.ylim(0,100)\n",
    "    #colors = [\"#114693\", \"#DA0615\", \"#30169A\"]\n",
    "    colors = [\"indigo\",\"yellow\",\"teal\"]\n",
    "    legends = ['Encoding','Retrieval','Both']\n",
    "    bottom = np.zeros(len(df_gr.columns))\n",
    "    for i,code in enumerate(codes):\n",
    "        nb = df_gr.iloc[i,:]\n",
    "        percent = [(nb[i]/nb_elecs[i])*100 for i in range(3)]\n",
    "        print('percent',percent, [nb_elecs[i] for i in range(3)])\n",
    "        plt.bar(xticks,percent,color=colors[i],bottom=bottom,label=legends[i])\n",
    "        bottom += percent\n",
    "    #print('count',freq,(df_gr.iloc[i,:]/nb_elecs[i])*100)\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(path2save+'Nb_elecs_'+freq+'_signif_th_01.png')\n",
    "    plt.savefig(path2save+'Nb_elecs_'+freq+'_signif_th_01.pdf')\n",
    "    plt.clf()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### % of electrode decreases & increases across frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC [5, 3, 1, 6] [100.0, array([ 66.66666667]), 100.0, array([ 50.])] [0, array([ 33.33333333]), 0, array([ 50.])]\n",
      "Amg [2, 2, 3, 2] [0, 0, 0, 0] [100.0, 100.0, 100.0, 100.0]\n",
      "Amg-PirT [1, 1, 1, 1] [0, 0, 100.0, 100.0] [100.0, 100.0, 0, 0]\n",
      "HC [15, 9, 22, 15] [array([ 13.33333333]), array([ 11.11111111]), array([ 31.81818182]), array([ 66.66666667])] [array([ 86.66666667]), array([ 88.88888889]), array([ 68.18181818]), array([ 33.33333333])]\n",
      "IFG [8, 13, 13, 18] [array([ 37.5]), array([ 23.07692308]), 0, array([ 27.77777778])] [array([ 62.5]), array([ 76.92307692]), 100.0, array([ 72.22222222])]\n",
      "Ins [7, 8, 7, 10] [array([ 14.28571429]), 0, array([ 14.28571429]), array([ 40.])] [array([ 85.71428571]), 100.0, array([ 85.71428571]), array([ 60.])]\n",
      "MFG [5, 12, 9, 26] [array([ 40.]), array([ 41.66666667]), array([ 22.22222222]), array([ 53.84615385])] [array([ 60.]), array([ 58.33333333]), array([ 77.77777778]), array([ 46.15384615])]\n",
      "OFC [16, 12, 19, 28] [array([ 37.5]), array([ 16.66666667]), array([ 26.31578947]), array([ 53.57142857])] [array([ 62.5]), array([ 83.33333333]), array([ 73.68421053]), array([ 46.42857143])]\n",
      "PHG [6, 9, 7, 8] [array([ 16.66666667]), 0, 0, array([ 37.5])] [array([ 83.33333333]), 100.0, 100.0, array([ 62.5])]\n",
      "SFG [19, 7, 15, 39] [100.0, 100.0, array([ 80.]), array([ 71.79487179])] [0, 0, array([ 20.]), array([ 28.20512821])]\n",
      "pPirT [3, 2, 2, 5] [0, 0, array([ 50.]), array([ 60.])] [100.0, 100.0, array([ 50.]), array([ 40.])]\n"
     ]
    }
   ],
   "source": [
    "# st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/0_Classif_Power_E_EpiPerf_LowHigh_1000perm_BBG/')\n",
    "path2save = join(pathdata, 'Power_By_freq_region/' )\n",
    "###############################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "###############################################################################\n",
    "#freqs = ['2_theta', '3_alpha', '4_beta','5_gamma1','6_gamma2']\n",
    "freqs = ['0_theta', '1_alpha','2_beta','3_gamma']\n",
    "conds = ['low','high']\n",
    "freqnames = [freq[2:] for freq in freqs]\n",
    "###############################################################################\n",
    "groups_roi = 's_Mai_RL'#'region'\n",
    "\n",
    "dfname = '2_all_subjects_info_elecs_AUC_Signif_th_0.01_region.csv'\n",
    "df = pd.read_csv(pathdata+dfname)\n",
    "#df.drop(['Unnamed: 0','aal', 'aal_RL', 'BA',\n",
    "#       '2_theta_AUC', '3_alpha_AUC', '4_beta_AUC', '5_gamma1_AUC',\n",
    "#       '6_gamma2_AUC','2_theta_Time', '3_alpha_Time', '4_beta_Time', '5_gamma1_Time',\n",
    "#       '6_gamma2_Time'],inplace=True, axis=1)\n",
    "#df.drop(['2_theta_AUC', '3_alpha_AUC', '4_beta_AUC', '5_gamma1_AUC',\n",
    "#       '6_gamma2_AUC'],inplace=True, axis=1)\n",
    "df.drop(['0_theta_AUC', '1_alpha_AUC', '2_beta_AUC', '3_gamma_AUC'],inplace=True, axis=1)\n",
    "regions = np.unique(df[[groups_roi]]) #'region'\n",
    "#print(regions)\n",
    "\n",
    "for roi in regions:\n",
    "    elecs_inc, elecs_dec, elecs_ratio = [],[],[]\n",
    "    for f,freq in enumerate(freqs):\n",
    "        #keep only significant electrodes (boolean col keep only 1 value)\n",
    "        df_freq = pd.concat([df[['subjects','elecs',groups_roi]],df.filter(like=freqnames[f])], axis=1)\n",
    "        df_freq = df_freq.loc[df_freq.iloc[:,-1] > 0]\n",
    "        df_freq = df_freq.loc[df_freq.s_Mai_RL == roi]\n",
    "        #print(df_freq)\n",
    "        df_freq['modulation'] = np.sign(df_freq[freq+'_Pow1'] - df_freq[freq+'_Pow0'])\n",
    "        #create a value of 1 for increase, -1 for decrease and 0 for no change\n",
    "        \n",
    "        #compute signif elecs, increasing and decreasing elecs\n",
    "        df_mod = df_freq[['elecs',groups_roi,'modulation']].groupby([groups_roi,'modulation']).count()\n",
    "        #print(df_mod)\n",
    "        if df_mod.size == 0:\n",
    "            pass\n",
    "        else:\n",
    "            mod = df_mod.values[:]\n",
    "            index0 = df_mod.index.get_level_values(1)[0]\n",
    "            #print(mod,len(mod),index0)\n",
    "\n",
    "            tot = [mod[0][0]+mod[1][0] if len(mod)==2 else mod[0][0]]\n",
    "            inc = [(mod[1][0]/tot)*100 if len(mod)==2 else 0]\n",
    "            inc = [(mod[0][0]/tot)*100 if len(mod)==1 and index0==1 else inc ]\n",
    "            dec = [(mod[0][0]/tot)*100 if len(mod)==2 else 0]\n",
    "            dec = [(mod[0][0]/tot)*100 if len(mod)==1 and index0==-1 else dec]\n",
    "            #print('inc',inc,'dec',dec)\n",
    "            elecs_ratio.append(tot[0]), elecs_inc.append(inc[0][0]), elecs_dec.append(dec[0][0])\n",
    "    print(roi, elecs_ratio, elecs_inc, elecs_dec)\n",
    "    #print('shapes inc dec', len(elecs_inc), len(elecs_dec))\n",
    "    \n",
    "    #Plot Mean Z-scored power\n",
    "    fig = plt.figure()\n",
    "    plt.title('Mean Power (SME) by freq for '+roi)\n",
    "    plt.ylabel('% of signif elecs')\n",
    "    xticks = np.arange(0,len(elecs_inc))\n",
    "    \n",
    "    plt.plot(xticks, elecs_inc, 'r-')\n",
    "    plt.plot(xticks, elecs_dec, 'b-')\n",
    "    plt.xticks(xticks,freqnames)\n",
    "    plt.ylim(0,100)\n",
    "    plt.savefig(path2save+'Percent_'+roi+'_signif_th_01.png')\n",
    "    plt.savefig(path2save+'Percent_'+roi+'_signif_th_01.pdf')\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "Index(['subjects', 'elecs', 's_Mai_RL', '0_theta_AUC', '1_alpha_AUC',\n",
      "       '2_beta_AUC', '3_gamma_AUC', '0_theta_Pow0', '1_alpha_Pow0',\n",
      "       '2_beta_Pow0', '3_gamma_Pow0', '0_theta_Pow1', '1_alpha_Pow1',\n",
      "       '2_beta_Pow1', '3_gamma_Pow1', '('theta', 'min_win1.0')',\n",
      "       '('alpha', 'min_win1.0')', '('beta', 'min_win1.0')',\n",
      "       '('gamma', 'min_win1.0')', 'region'],\n",
      "      dtype='object')\n",
      "ACC 0_theta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "ACC 1_alpha Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "ACC 2_beta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "ACC 3_gamma Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Amg 0_theta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Amg 1_alpha Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Amg 2_beta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Amg 3_gamma Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Amg-PirT 0_theta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Amg-PirT 1_alpha Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Amg-PirT 2_beta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Amg-PirT 3_gamma Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "HC 0_theta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "HC 1_alpha Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "HC 2_beta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "HC 3_gamma Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "IFG 0_theta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "IFG 1_alpha Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "IFG 2_beta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "IFG 3_gamma Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Ins 0_theta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Ins 1_alpha Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Ins 2_beta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Ins 3_gamma Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "MFG 0_theta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "MFG 1_alpha Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "MFG 2_beta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "MFG 3_gamma Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "OFC 0_theta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "OFC 1_alpha Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "OFC 2_beta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "OFC 3_gamma Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "PHG 0_theta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "PHG 1_alpha Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "PHG 2_beta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "PHG 3_gamma Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "SFG 0_theta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "SFG 1_alpha Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "SFG 2_beta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "SFG 3_gamma Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "pPirT 0_theta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "pPirT 1_alpha Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "pPirT 2_beta Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "pPirT 3_gamma Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/LDA_TPSim_E_R_all_BBG/')\n",
    "path2save = join(pathdata, 'Power_By_freq_region/' )\n",
    "###############################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "###############################################################################\n",
    "freqs = ['0_theta', '1_alpha','2_beta','3_gamma']\n",
    "#freqs = ['2_theta','3_alpha','4_beta','5_gamma1','6_gamma2']\n",
    "conds = ['low','high']\n",
    "freqnames = [freq[2:] for freq in freqs]\n",
    "###############################################################################\n",
    "groups_roi = 's_Mai_RL'#'region'\n",
    "\n",
    "dfname = '2_all_subjects_info_elecs_AUC_Signif_th_0.01_region.csv'\n",
    "df = pd.read_csv(pathdata+dfname)\n",
    "print(df.columns)\n",
    "#df.drop(['aal', 'aal_RL', 'BA',\n",
    "#       '2_theta_AUC', '3_alpha_AUC', '4_beta_AUC', '5_gamma1_AUC',\n",
    "#       '6_gamma2_AUC','2_theta_Time', '3_alpha_Time', '4_beta_Time', '5_gamma1_Time',\n",
    "#      '6_gamma2_Time'],inplace=True, axis=1)\n",
    "df.drop(['0_theta_AUC', '1_alpha_AUC', '2_beta_AUC', '3_gamma_AUC'],inplace=True, axis=1)\n",
    "\n",
    "regions = np.unique(df[[groups_roi]]) #'region'\n",
    "\n",
    "for roi in regions:\n",
    "    for f,freq in enumerate(freqs):\n",
    "    #keep only significant electrodes (boolean col keep only 1 value)\n",
    "        df_freq = pd.concat([df[['subjects','s_Mai_RL','region']],df.filter(like=freqnames[f])], axis=1)\n",
    "        df_freq = df_freq.loc[df_freq.iloc[:,-1] > 0]\n",
    "        df_freq = df_freq.loc[df_freq.region == roi]\n",
    "        df_freq['modulation'] = np.sign(df_freq[freq+'_Pow1'] - df_freq[freq+'_Pow0'])\n",
    "        df2 = df_freq[['modulation','s_Mai_RL']].groupby(['modulation','s_Mai_RL']).count()\n",
    "        print(roi,freq,df2)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
