{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import isfile, join, exists\n",
    "from os import listdir, makedirs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from brainpipe.system import study\n",
    "from scipy import stats\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean correlation by patient for all significant electrodes // By freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "original shape (405, 35) (405, 35) (25,)\n",
      "max AUC shape (405,) (405,) (405,)\n",
      "[ 0.90666667  0.94416667         nan  0.91833333         nan         nan\n",
      "         nan] [-56.6469241  -16.5599145           nan -67.28298651          nan\n",
      "          nan          nan] [  100.   150.    nan  1800.    nan    nan    nan]\n",
      "[ 20.    0.8   1.3] [ 12.3   2.4   2.1]\n",
      "(3,) (3,) (3,)\n",
      "original shape (405, 35) (405, 35) (25,)\n",
      "max AUC shape (405,) (405,) (405,)\n",
      "[ 0.91333333         nan  0.92083333  0.92833333         nan         nan\n",
      "         nan] [ 75.07143949          nan  47.54707865  54.86875843          nan\n",
      "          nan          nan] [-500.   nan  550.  950.   nan   nan   nan]\n",
      "[ 20.   14.4   1.3] [ 12.3   8.    2.1]\n",
      "(3,) (3,) (3,)\n",
      "original shape (405, 35) (405, 35) (25,)\n",
      "max AUC shape (405,) (405,) (405,)\n",
      "[ 0.93416667  0.90833333         nan  0.95083333         nan  0.91555556\n",
      "         nan] [ 12.30474415   3.96357677          nan -24.26086481          nan\n",
      "  40.76939355          nan] [  750.  1000.    nan   700.    nan  1000.    nan]\n",
      "[ 20.    0.8   1.3   7.1] [ 12.3   2.4   2.1   6.3]\n",
      "(4,) (4,) (4,)\n",
      "original shape (405, 35) (405, 35) (25,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karim/anaconda3/lib/python3.5/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/karim/anaconda3/lib/python3.5/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max AUC shape (405,) (405,) (405,)\n",
      "[        nan  0.965       0.91444444  0.90333333         nan  0.94916667\n",
      "         nan] [         nan  -5.18268993  18.4099494   -2.49117317          nan\n",
      "   3.66723145          nan] [           nan  1000.            33.33333333   100.                    nan\n",
      "   300.                    nan]\n",
      "[  0.8  14.4   1.3   7.1] [ 2.4  8.   2.1  6.3]\n",
      "(4,) (4,) (4,)\n",
      "stats for 3_alpha diff_EM pow_by_su 0.99 0.01\n",
      "original shape (405, 35) (405, 35) (25,)\n",
      "max AUC shape (405,) (405,) (405,)\n",
      "[ 0.9175             nan  0.9525      0.91        0.90166667  0.91583333\n",
      "         nan] [  59.13032839           nan    7.88333921   15.98757886  120.70845853\n",
      "   -7.69405999           nan] [    0.    nan   450.  1900.  -200.  1400.    nan]\n",
      "[ 20.   14.4   1.3  13.    7.1] [ 12.3   8.    2.1   7.7   6.3]\n",
      "(5,) (5,) (5,)\n",
      "stats for 4_beta diff_EM time_by_su -0.9 0.039\n",
      "original shape (405, 35) (405, 35) (25,)\n",
      "max AUC shape (405,) (405,) (405,)\n",
      "[ 1.                 nan         nan  0.94208333         nan  0.905\n",
      "         nan] [ 3.94134532         nan         nan -1.7500075          nan  0.91162857\n",
      "         nan] [ 900.   nan   nan  750.   nan  200.   nan]\n",
      "[ 20.    1.3   7.1] [ 12.3   2.1   6.3]\n",
      "(3,) (3,) (3,)\n",
      "original shape (405, 35) (405, 35) (25,)\n",
      "max AUC shape (405,) (405,) (405,)\n",
      "[        nan  0.915       0.91611111  0.91416667  0.9075      0.90166667\n",
      "         nan] [         nan  -9.02778666   9.34319799  12.31270618   5.17511151\n",
      "  12.51725567          nan] [           nan  1200.           966.66666667   500.          1300.          1600.\n",
      "            nan]\n",
      "[  0.8  14.4   1.3  13.    7.1] [ 2.4  8.   2.1  7.7  6.3]\n",
      "(5,) (5,) (5,)\n"
     ]
    }
   ],
   "source": [
    "th, feat, corr = '0.01', 'pow', False\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_npz = join(st.path, 'figure/0_Classif_Power_R_EpiPerf_LowHigh_200perm/')\n",
    "path_mask = join(path_npz, 'masks_stat/')\n",
    "path2save = join(path_npz, 'Correlations'+th+'/')\n",
    "npz_form = join(path_npz, '{}_sources_{}_{}_low_high_sel_physFT.npz')\n",
    "masks_vis_form = join(path_mask, '{}_mask_stat_{}_minwin{}_th{}.npy')\n",
    "###############################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "############################################################################### \n",
    "subjects = ['CHAF','FERJ','LEFC','SEMC','PIRJ','MICP','VACJ']\n",
    "su_codes = ['S0','S1','S2','S3','S4','S5','S6']\n",
    "\n",
    "# Load mean results by subjects\n",
    "freqs = ['0_VLFC', '1_delta', '2_theta', '3_alpha', '4_beta','5_gamma1','6_gamma2']\n",
    "method, win = ['s_Mail_RL'], 1\n",
    "\n",
    "for freq in freqs:\n",
    "    # Behavioral Performance\n",
    "    scores_tot = [12.3,2.4,8.0,2.1,7.7,6.3,8.3]\n",
    "    scores_low = [2.3,2.0,0.8,1.6,1.2,1.8,1.7]\n",
    "    scores_high = [22.3,2.8,15.2,2.9,14.2,8.9,15.5]\n",
    "    scores_diff = [scores_high[i]-scores_low[i] for i in range(len(scores_high))]\n",
    "    \n",
    "    arch_sig = np.load(npz_form.format('All_subjects',freq, 'odor'))\n",
    "    if exists(masks_vis_form.format('All_subjects',freq,str(win),th)):\n",
    "        mask = np.load(masks_vis_form.format('All_subjects',freq,str(win),th))\n",
    "        mask = np.logical_not(mask) #inverse True False\n",
    "        su_codes = arch_sig['su_codes'][mask]\n",
    "        s_da, s_power = arch_sig['s_da'], ((arch_sig['s_elec_pow1']-arch_sig['s_elec_pow0'])/arch_sig['s_elec_pow0'])*100\n",
    "        s_time = np.arange(-500,2000,100)\n",
    "        print('original shape',s_da.shape, s_power.shape,s_time.shape)\n",
    "        #Select the max AUC and corresponding power change for all electrodes\n",
    "        da_all, pow_all,time_all = np.array([]), np.array([]),np.array([])\n",
    "        for elec in range(s_da.shape[0]):\n",
    "            da_elec = s_da[elec][5:30]\n",
    "            idx = [i for i,j in enumerate(da_elec) if j ==max(da_elec)][0]\n",
    "            pow = s_power[elec][idx]\n",
    "            da = da_elec[idx]\n",
    "            time = s_time[idx]\n",
    "            pow_all = np.hstack((pow_all,pow)) if np.size(pow_all) else pow\n",
    "            da_all = np.hstack((da_all, da)) if np.size(da_all) else da\n",
    "            time_all = np.hstack((time_all,time)) if np.size(time_all) else time\n",
    "        print('max AUC shape',da_all.shape, pow_all.shape,time_all.shape)\n",
    "        #Mask non-significant electrodes\n",
    "        da_all,pow_all,time_all = da_all[mask], pow_all[mask], time_all[mask]\n",
    "        #Create an array of scores by patient and electrodes and masked it\n",
    "        #scores_elecs = [scores_tot[int(k[1])] for k in sorted(subjects)]\n",
    "        \n",
    "        #Create an array of mean values by subject\n",
    "        da_by_su, pow_by_su, time_by_su = np.array([]), np.array([]),np.array([])\n",
    "        for s,su in enumerate(subjects):\n",
    "            da_su = np.mean(da_all[np.where(su_codes=='S'+str(s))])\n",
    "            pow_su = np.mean(pow_all[np.where(su_codes=='S'+str(s))])\n",
    "            time_su = np.mean(time_all[np.where(su_codes=='S'+str(s))])\n",
    "            da_by_su = np.hstack((da_by_su,da_su)) if np.size(da_by_su) else da_su\n",
    "            pow_by_su = np.hstack((pow_by_su,pow_su)) if np.size(pow_by_su) else pow_su\n",
    "            time_by_su = np.hstack((time_by_su,time_su)) if np.size(time_by_su) else time_su\n",
    "        print(da_by_su,pow_by_su,time_by_su)\n",
    "        #remove scores values when patient not included\n",
    "        scores_diff = np.array(scores_diff)[np.where(~np.isnan(da_by_su))]\n",
    "        scores_tot = np.array(scores_tot)[np.where(~np.isnan(da_by_su))]\n",
    "        print(scores_diff, scores_tot)\n",
    "        #remove nan values\n",
    "        da_by_su = da_by_su[np.logical_not(np.isnan(da_by_su))] \n",
    "        pow_by_su = pow_by_su[np.logical_not(np.isnan(pow_by_su))] \n",
    "        time_by_su = time_by_su[np.logical_not(np.isnan(time_by_su))]\n",
    "        print(da_by_su.shape,pow_by_su.shape,time_by_su.shape)\n",
    "\n",
    "        if da_by_su.shape[0] >=4:\n",
    "            #Plot all correlations\n",
    "            scores, features = [scores_tot,scores_diff], [da_by_su,pow_by_su,time_by_su]\n",
    "            scores_names, feats_names= ['tot_EM','diff_EM',],['da_by_su','pow_by_su','time_by_su']\n",
    "            for i,score in enumerate(scores):\n",
    "                for j,feat in enumerate(features):\n",
    "                    R, p = stats.pearsonr(score,feat)\n",
    "                    R, p = round(R,2), round(p,3)\n",
    "                    if p < 0.05:\n",
    "                        print('stats for',freq,scores_names[i],feats_names[j],R,p)\n",
    "                        fig, ax = plt.subplots()\n",
    "                        plt.title('Correlation btw '+scores_names[i]+' and '+feats_names[j]+' for '+freq)\n",
    "                        plt.xlabel(scores_names[i]), plt.ylabel(feats_names[j])\n",
    "                        anchored_text = AnchoredText('R coeff = %s, pval = %s' % (R, p), loc=2)\n",
    "                        ax.add_artist(anchored_text)\n",
    "                        fit = np.polyfit(score, feat, deg=1)\n",
    "                        ax.plot(sorted(score), fit[0] * np.array(sorted(score)) + fit[1], color='red')\n",
    "                        ax.scatter(score, feat, color = 'dodgerblue')\n",
    "                        plt.savefig(path2save+'Correlation_'+freq+'_'+scores_names[i]+'_'+feats_names[j]+'.png')\n",
    "                        plt.clf()\n",
    "                        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations btw significant electrodes and memory score // By freq (no mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "(4,) [-56.6469241   20.52513301 -53.64496201 -67.28298651]\n",
      "score 0_VLFC -0.595 0.404994\n",
      "score 0_VLFC -0.271 0.729209\n",
      "score 0_VLFC -0.386 0.614371\n",
      "(5,) [  75.07143949   75.23015948   19.86399782  -28.93050193  138.66801878]\n",
      "score 1_delta -0.752 0.142261\n",
      "score 1_delta 0.086 0.891111\n",
      "score 1_delta -0.57 0.315874\n",
      "(10,) [-24.89427471  68.63924217 -13.02973147  18.50374063   3.96357677\n",
      "  24.43514896 -72.95687858  58.624426    92.23840888 -28.55465423]\n",
      "score 2_theta 0.017 0.963578\n",
      "score 2_theta 0.165 0.649562\n",
      "score 2_theta -0.09 0.804626\n",
      "(7,) [ -5.18268993   1.66402481  57.34182226  -3.77599888  -2.49117317\n",
      "  15.33866697  -8.00420407]\n",
      "score 3_alpha -0.268 0.561326\n",
      "score 3_alpha 0.412 0.358049\n",
      "score 3_alpha -0.421 0.346314\n",
      "(8,) [  41.8212289    76.43942788  -23.69818788   39.4648663    15.98757886\n",
      "  120.70845853  -30.24390037   14.85578039]\n",
      "score 4_beta 0.131 0.757022\n",
      "score 4_beta 0.374 0.361256\n",
      "score 4_beta -0.672 0.068112\n",
      "(6,) [  3.94134532  -5.16396595 -17.24034877  -9.12534365  24.52962836\n",
      "   0.91162857]\n",
      "score 5_gamma1 0.558 0.25019\n",
      "score 5_gamma1 0.165 0.755285\n",
      "score 5_gamma1 0.019 0.970906\n",
      "(10,) [ -4.2613968  -14.60559463  -8.21636854  15.53105773  20.75657062\n",
      "  -8.25803437  20.2410334    4.38437896   5.17511151  12.51725567]\n",
      "score 6_gamma2 -0.159 0.661809\n",
      "score 6_gamma2 0.354 0.314902\n",
      "score 6_gamma2 0.165 0.648823\n"
     ]
    }
   ],
   "source": [
    "th, feat, corr = '0.01', 'pow', False\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_npz = join(st.path, 'figure/0_Classif_Power_R_EpiPerf_LowHigh_200perm/')\n",
    "path_mask = join(path_npz, 'masks_stat/')\n",
    "path2save = join(path_npz, 'Correlations'+th+'/')\n",
    "npz_form = join(path_npz, '{}_sources_{}_{}_low_high_sel_physFT.npz')\n",
    "masks_vis_form = join(path_mask, '{}_mask_stat_{}_minwin{}_th{}.npy')\n",
    "###############################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "############################################################################### \n",
    "subjects = ['CHAF','FERJ','LEFC','SEMC','PIRJ','VACJ']\n",
    "su_codes = ['S0','S1','S2','S3','S4','S5','S6']\n",
    "\n",
    "# Load mean results by subjects\n",
    "freqs = ['0_VLFC', '1_delta', '2_theta', '3_alpha', '4_beta','5_gamma1','6_gamma2']\n",
    "method, win = ['s_Mail_RL'], 1\n",
    "\n",
    "for freq in freqs:\n",
    "    # Behavioral Performance\n",
    "    scores_tot = [12.3,2.4,8.0,2.1,7.7,6.3,8.3]\n",
    "    scores_low = [2.3,2.0,0.8,1.6,1.2,1.8,1.7]\n",
    "    scores_high = [22.3,2.8,15.2,2.9,14.2,8.9,15.5]\n",
    "    scores_diff = [scores_high[i]-scores_low[i] for i in range(len(scores_high))]\n",
    "    \n",
    "    arch_sig = np.load(npz_form.format('All_subjects',freq, 'odor'))\n",
    "    mask = np.load(masks_vis_form.format('All_subjects',freq,str(win),th))\n",
    "    mask = np.logical_not(mask) #inverse True False\n",
    "    su_codes = arch_sig['su_codes'][mask]\n",
    "    s_da, s_power = arch_sig['s_da'], ((arch_sig['s_elec_pow1']-arch_sig['s_elec_pow0'])/arch_sig['s_elec_pow0'])*100\n",
    "    s_time = np.arange(-500,2000,100)\n",
    "    #print('original shape',s_da.shape, s_power.shape,s_time.shape)\n",
    "    #Select the max AUC and corresponding power change for all electrodes\n",
    "    da_all, pow_all,time_all = np.array([]), np.array([]),np.array([])\n",
    "    for elec in range(s_da.shape[0]):\n",
    "        da_elec = s_da[elec][5:30]\n",
    "        idx = [i for i,j in enumerate(da_elec) if j ==max(da_elec)][0]\n",
    "        pow = s_power[elec][idx]\n",
    "        da = da_elec[idx]\n",
    "        time = s_time[idx]\n",
    "        pow_all = np.hstack((pow_all,pow)) if np.size(pow_all) else pow\n",
    "        da_all = np.hstack((da_all, da)) if np.size(da_all) else da\n",
    "        time_all = np.hstack((time_all,time)) if np.size(time_all) else time\n",
    "    #print('max AUC shape',da_all.shape, pow_all.shape,time_all.shape)\n",
    "    #Mask non-significant electrodes\n",
    "    da_all,pow_all,time_all = da_all[mask], pow_all[mask], time_all[mask]\n",
    "    print(pow_all.shape, pow_all)\n",
    "    \n",
    "    scores, features = [scores_tot], [da_all,pow_all,time_all]\n",
    "    scores_names, feats_names= ['tot_EM'],['da','pow','time']\n",
    "    for i,score in enumerate(scores):\n",
    "        #Create an array of scores by patient and electrodes and masked it\n",
    "        scores_elecs = [score[int(k[1])] for k in sorted(su_codes)]\n",
    "        for j,feat in enumerate(features):\n",
    "            R, p = stats.pearsonr(scores_elecs,feat)\n",
    "            R, p = round(R,3), round(p,6)\n",
    "            print('score',freq,R,p)\n",
    "            if p <= 0.05:\n",
    "                print('score',freq,'mask',len(np.where(mask==1)[0]),scores_names[i], feat.shape, feats_names[j],R,p)\n",
    "                fig, ax = plt.subplots()\n",
    "                plt.title('Correlation all // '+scores_names[i]+' & '+feats_names[j]+'-'+freq+' n_points = '+str(len(np.where(mask==1)[0])))\n",
    "                plt.xlabel(scores_names[i]), plt.ylabel(feats_names[j])\n",
    "                anchored_text = AnchoredText('R coeff = %s, pval = %s' % (R, p), loc=2)\n",
    "                ax.add_artist(anchored_text)\n",
    "                fit = np.polyfit(scores_elecs, feat, deg=1)\n",
    "                ax.plot(sorted(scores_elecs), fit[0] * np.array(sorted(scores_elecs)) + fit[1], color='red')\n",
    "                ax.scatter(scores_elecs, feat, color = 'dodgerblue')\n",
    "                plt.savefig(path2save+'Correlation_'+freq+'_'+scores_names[i]+'_'+feats_names[j]+'.png')\n",
    "                plt.clf()\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation btw memory score and classif in specific regions\n",
    "    Frontal vs Temporal regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "[12.3, 2.4, 2.4, 2.1] 4\n",
      "features by roi 0_VLFC Olf (3,)\n",
      "Olf score 0_VLFC mask 4 tot_EM (3,) time -0.999 0.033383\n",
      "3\n",
      "features by roi 0_VLFC MTL (0,)\n",
      "features by roi 0_VLFC Temporal (1,)\n",
      "features by roi 0_VLFC Frontal (3,)\n",
      "features by roi 0_VLFC all (4,)\n",
      "[12.3, 8.0, 8.0, 2.1, 2.1] 5\n",
      "features by roi 1_delta Olf (1,)\n",
      "features by roi 1_delta MTL (0,)\n",
      "features by roi 1_delta Temporal (2,)\n",
      "features by roi 1_delta Frontal (3,)\n",
      "features by roi 1_delta all (5,)\n",
      "[12.3, 12.3, 12.3, 12.3, 2.4, 2.1, 2.1, 6.3, 6.3, 6.3] 10\n",
      "features by roi 2_theta Olf (1,)\n",
      "features by roi 2_theta MTL (2,)\n",
      "MTL score 2_theta mask 10 tot_EM (2,) pow -1.0 0.0\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karim/anaconda3/lib/python3.5/site-packages/scipy/stats/stats.py:2998: RuntimeWarning: Mean of empty slice.\n",
      "  mx = x.mean()\n",
      "/home/karim/anaconda3/lib/python3.5/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/karim/anaconda3/lib/python3.5/site-packages/scipy/stats/stats.py:2999: RuntimeWarning: Mean of empty slice.\n",
      "  my = y.mean()\n",
      "/home/karim/anaconda3/lib/python3.5/site-packages/scipy/stats/stats.py:3003: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n",
      "/home/karim/anaconda3/lib/python3.5/site-packages/scipy/stats/stats.py:3013: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob = _betai(0.5*df, 0.5, df/(df+t_squared))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTL score 2_theta mask 10 tot_EM (2,) time 1.0 0.0\n",
      "2\n",
      "features by roi 2_theta Temporal (3,)\n",
      "features by roi 2_theta Frontal (7,)\n",
      "features by roi 2_theta all (10,)\n",
      "[2.4, 8.0, 8.0, 8.0, 2.1, 6.3, 6.3] 7\n",
      "features by roi 3_alpha Olf (2,)\n",
      "Olf score 3_alpha mask 7 tot_EM (2,) da -1.0 0.0\n",
      "2\n",
      "Olf score 3_alpha mask 7 tot_EM (2,) pow 1.0 0.0\n",
      "2\n",
      "Olf score 3_alpha mask 7 tot_EM (2,) time -1.0 0.0\n",
      "2\n",
      "features by roi 3_alpha MTL (0,)\n",
      "features by roi 3_alpha Temporal (2,)\n",
      "Temporal score 3_alpha mask 7 tot_EM (2,) da -1.0 0.0\n",
      "2\n",
      "Temporal score 3_alpha mask 7 tot_EM (2,) pow 1.0 0.0\n",
      "2\n",
      "Temporal score 3_alpha mask 7 tot_EM (2,) time -1.0 0.0\n",
      "2\n",
      "features by roi 3_alpha Frontal (5,)\n",
      "features by roi 3_alpha all (7,)\n",
      "[12.3, 12.3, 8.0, 8.0, 2.1, 7.7, 6.3, 6.3] 8\n",
      "features by roi 4_beta Olf (3,)\n",
      "Olf score 4_beta mask 8 tot_EM (3,) time -0.998 0.044441\n",
      "3\n",
      "features by roi 4_beta MTL (1,)\n",
      "features by roi 4_beta Temporal (3,)\n",
      "features by roi 4_beta Frontal (5,)\n",
      "features by roi 4_beta all (8,)\n",
      "[12.3, 2.1, 2.1, 2.1, 2.1, 6.3] 6\n",
      "features by roi 5_gamma1 Olf (2,)\n",
      "Olf score 5_gamma1 mask 6 tot_EM (2,) da -1.0 0.0\n",
      "2\n",
      "Olf score 5_gamma1 mask 6 tot_EM (2,) pow 1.0 0.0\n",
      "2\n",
      "features by roi 5_gamma1 MTL (0,)\n",
      "features by roi 5_gamma1 Temporal (0,)\n",
      "features by roi 5_gamma1 Frontal (6,)\n",
      "features by roi 5_gamma1 all (6,)\n",
      "[2.4, 2.4, 2.4, 8.0, 8.0, 8.0, 2.1, 2.1, 7.7, 6.3] 10\n",
      "features by roi 6_gamma2 Olf (0,)\n",
      "features by roi 6_gamma2 MTL (2,)\n",
      "MTL score 6_gamma2 mask 10 tot_EM (2,) da -1.0 0.0\n",
      "2\n",
      "MTL score 6_gamma2 mask 10 tot_EM (2,) pow 1.0 0.0\n",
      "2\n",
      "MTL score 6_gamma2 mask 10 tot_EM (2,) time 1.0 0.0\n",
      "2\n",
      "features by roi 6_gamma2 Temporal (7,)\n",
      "features by roi 6_gamma2 Frontal (3,)\n",
      "features by roi 6_gamma2 all (10,)\n"
     ]
    }
   ],
   "source": [
    "th, feat, corr = '0.01', 'pow', False\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_npz = join(st.path, 'figure/0_Classif_Power_R_EpiPerf_LowHigh_200perm/')\n",
    "path_mask = join(path_npz, 'masks_stat/')\n",
    "path2save = join(path_npz, 'Correlations'+th+'/')\n",
    "npz_form = join(path_npz, '{}_sources_{}_{}_low_high_sel_physFT.npz')\n",
    "masks_vis_form = join(path_mask, '{}_mask_stat_{}_minwin{}_th{}.npy')\n",
    "###############################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "############################################################################### \n",
    "subjects = ['CHAF','FERJ','LEFC','SEMC','PIRJ','MICP','VACJ']\n",
    "su_codes = ['S0','S1','S2','S3','S4','S5','S6']\n",
    "\n",
    "# Load mean results by subjects\n",
    "freqs = ['0_VLFC', '1_delta', '2_theta', '3_alpha', '4_beta','5_gamma1','6_gamma2']\n",
    "method, win = ['s_Mail_RL'], 1\n",
    "\n",
    "# List of rois to test\n",
    "rois_list = {'Frontal':['ACC','IFG','MFG','OFC','SFG','Ins'],\n",
    "            'Olf':['Amg','pPirT','Amg-PirT','Ins','OFC'],\n",
    "            'MTL':['HC','PHG'],\n",
    "            'Temporal':['FuG','HC','PHG','ITG','MTG','STG','Amg','pPirT','Amg-PirT'],\n",
    "            'all':['ACC','IFG','MFG','OFC','SFG','Ins','FuG','HC','PHG','ITG','MTG','STG','Amg','pPirT','Amg-PirT']}\n",
    "\n",
    "for freq in freqs:\n",
    "    # Behavioral Performance\n",
    "    scores_tot = [12.3,2.4,8.0,2.1,7.7,6.3,8.3]\n",
    "    scores_low = [2.3,2.0,0.8,1.6,1.2,1.8,1.7]\n",
    "    scores_high = [22.3,2.8,15.2,2.9,14.2,8.9,15.5]\n",
    "    scores_diff = [scores_high[i]-scores_low[i] for i in range(len(scores_high))]\n",
    "    \n",
    "    arch_sig = np.load(npz_form.format('All_subjects',freq, 'odor'))\n",
    "    mask = np.load(masks_vis_form.format('All_subjects',freq,str(win),th))\n",
    "    mask = np.logical_not(mask) #inverse True False\n",
    "    s_da, s_power = arch_sig['s_da'], ((arch_sig['s_elec_pow1']-arch_sig['s_elec_pow0'])/arch_sig['s_elec_pow0'])*100\n",
    "    s_time = np.arange(-500,2000,100)\n",
    "    su_codes = arch_sig['su_codes'][mask]\n",
    "    s_scores = [scores_tot[int(k[1])] for k in sorted(su_codes)]\n",
    "    print(s_scores,len(s_scores))\n",
    "    #print('original shape',s_da.shape, s_power.shape,s_time.shape)\n",
    "    \n",
    "    #Select the max AUC and corresponding power change for all electrodes\n",
    "    da_all, pow_all,time_all = np.array([]), np.array([]),np.array([])\n",
    "    for elec in range(s_da.shape[0]):\n",
    "        da_elec = s_da[elec][5:30]\n",
    "        idx = [i for i,j in enumerate(da_elec) if j ==max(da_elec)][0]\n",
    "        pow = s_power[elec][idx]\n",
    "        da = da_elec[idx]\n",
    "        time = s_time[idx]\n",
    "        pow_all = np.hstack((pow_all,pow)) if np.size(pow_all) else pow\n",
    "        da_all = np.hstack((da_all, da)) if np.size(da_all) else da\n",
    "        time_all = np.hstack((time_all,time)) if np.size(time_all) else time\n",
    "    #print('max AUC shape',da_all.shape, pow_all.shape,time_all.shape)\n",
    "    #Mask non-significant electrodes\n",
    "    da_all,pow_all,time_all = da_all[mask], pow_all[mask], time_all[mask]\n",
    "    \n",
    "    # Select only elecs in specific rois\n",
    "    for region in rois_list:\n",
    "        s_Mai_RL = arch_sig['s_MAI_RL'][mask]\n",
    "        da_rois, pow_rois, time_rois, scores_elecs = np.array([]), np.array([]),np.array([]),np.array([])\n",
    "        for roi in rois_list[region]:\n",
    "            #Create an array of mean values by subject\n",
    "            da_roi = da_all[np.where(s_Mai_RL==roi)]\n",
    "            pow_roi = pow_all[np.where(s_Mai_RL==roi)]\n",
    "            time_roi = time_all[np.where(s_Mai_RL==roi)]\n",
    "            score_elec = [s_scores[i] for i in range(len(s_scores)) if s_Mai_RL[i]==roi]\n",
    "            da_rois = np.hstack((da_rois,da_roi)) if np.size(da_rois) else da_roi\n",
    "            pow_rois = np.hstack((pow_rois,pow_roi)) if np.size(pow_rois) else pow_roi\n",
    "            time_rois = np.hstack((time_rois,time_roi)) if np.size(time_rois) else time_roi\n",
    "            scores_elecs = np.hstack((scores_elecs,score_elec)) if np.size(scores_elecs) else score_elec\n",
    "        print('features by roi',freq, region, pow_rois.shape)\n",
    "        \n",
    "        features = [da_rois,pow_rois,time_rois]\n",
    "        score_name, feats_names= 'tot_EM',['da','pow','time']\n",
    "        for j,feat in enumerate(features):\n",
    "            R, p = stats.pearsonr(scores_elecs,feat)\n",
    "            R, p = round(R,3), round(p,6)\n",
    "            if p <= 0.05 and feat.shape[0] >=10:\n",
    "                print(region,'score',freq,'mask',len(np.where(mask==1)[0]),scores_names[i], feat.shape, feats_names[j],R,p)\n",
    "                print(len(scores_elecs))\n",
    "                fig, ax = plt.subplots()\n",
    "                plt.title('Correlation '+region+' // '+scores_names[i]+' & '+feats_names[j]+'-'+freq+' n_points = '+str(feat.shape[0]))\n",
    "                plt.xlabel(scores_names[i]), plt.ylabel(feats_names[j])\n",
    "                anchored_text = AnchoredText('R coeff = %s, pval = %s' % (R, p), loc=2)\n",
    "                ax.add_artist(anchored_text)\n",
    "                fit = np.polyfit(scores_elecs, feat, deg=1)\n",
    "                ax.plot(sorted(scores_elecs), fit[0] * np.array(sorted(scores_elecs)) + fit[1], color='red')\n",
    "                ax.scatter(scores_elecs, feat, color = 'dodgerblue')\n",
    "                plt.savefig(path2save+'Correlation_'+freq+'_'+scores_names[i]+'_'+feats_names[j]+'_'+region+'.png')\n",
    "                plt.clf()\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation btw power change and memory perf in specific regions\n",
    "    Where at least 5 patients have significant electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "th, feat, corr = '0.01', 'pow', False\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_npz = join(st.path, 'figure/0_Classif_Power_E_EpiPerf_LowHigh_1000perm/')\n",
    "path_mask = join(path_npz, 'masks_visbrain'+th+'/')\n",
    "path2save = join(path_npz, 'Correlations'+th+'/')\n",
    "npz_form = join(path_npz, '{}_sources_{}_{}_low_high_sel_physFT.npz')\n",
    "masks_vis_form = join(path_mask, '{}_mask_min{}_{}_minwin{}_th{}_corr.npy') if corr == True else join(path_mask, '{}_mask_min{}_{}_minwin{}_th{}.npy')\n",
    "f_form_save = join(path2save, 'Correl_{}_signif_min{}_'+feat+'_{}_th{}_corr.png') if corr == True else join(path2save, 'Correl_{}_signif_min{}_'+feat+'_{}_th{}.png')\n",
    "###############################################################################\n",
    "\n",
    "subjects = ['CHAF','FERJ','LEFC','SEMC','PIRJ','MICP','VACJ']\n",
    "su_codes = ['S0','S1','S2','S3','S4','S5','S6']\n",
    "\n",
    "# Load mean results by subjects\n",
    "freqs = ['0_VLFC', '1_delta', '2_theta', '3_alpha', '4_beta','5_gamma1','6_gamma2']\n",
    "method, win = ['s_Mail_RL'], 1\n",
    "\n",
    "for freq in freqs:\n",
    "    # Power and classif results\n",
    "    arch_sig = np.load(npz_form.format('All_subjects',freq, 'odor'))\n",
    "    mask = np.load(masks_vis_form.format('MAI_RL',freq,str(win),th))\n",
    "    mask = np.logical_not(mask) #inverse True False\n",
    "    su_codes = arch_sig['su_codes'][mask]\n",
    "    s_Mai_RL = arch_sig['s_MAI_RL'][mask]\n",
    "    rois_list = np.unique(s_Mai_RL)\n",
    "    print(rois_list)\n",
    "    s_da, s_power = arch_sig['s_da'], ((arch_sig['s_elec_pow1']-arch_sig['s_elec_pow0'])/arch_sig['s_elec_pow0'])*100\n",
    "    s_time = np.arange(-1000,2500,100)\n",
    "    print(s_da.shape, s_power.shape,s_time.shape)\n",
    "    #Select the max AUC and corresponding power change for all electrodes\n",
    "    da_all, pow_all,time_all = np.array([]), np.array([]),np.array([])\n",
    "    for elec in range(s_da.shape[0]):\n",
    "        da_elec = s_da[elec]\n",
    "        idx = [i for i,j in enumerate(da_elec) if j ==max(da_elec)][0]\n",
    "        pow = s_power[elec][idx]\n",
    "        da = da_elec[idx]\n",
    "        time = s_time[idx]\n",
    "        pow_all = np.hstack((pow_all,pow)) if np.size(pow_all) else pow\n",
    "        da_all = np.hstack((da_all, da)) if np.size(da_all) else da\n",
    "        time_all = np.hstack((time_all,time)) if np.size(time_all) else time\n",
    "    print(da_all.shape, pow_all.shape,time_all.shape)\n",
    "    #Mask non-significant electrodes\n",
    "    da_all,pow_all,time_all = da_all[mask], pow_all[mask], time_all[mask]\n",
    "    #print(da_all.shape, pow_all.shape)\n",
    "    for roi in rois_list:\n",
    "        # Behavioral Performance\n",
    "        scores_tot = [12.3,2.4,8.0,2.1,7.7,6.3,8.3]\n",
    "        scores_low = [2.3,2.0,0.8,1.6,1.2,1.8,1.7]\n",
    "        scores_high = [22.3,2.8,15.2,2.9,14.2,8.9,15.5]\n",
    "        scores_diff = [scores_high[i]-scores_low[i] for i in range(len(scores_high))]\n",
    "        #Create an array of mean values by subject\n",
    "        da_by_su, pow_by_su, time_by_su = np.array([]), np.array([]),np.array([])\n",
    "        for s,su in enumerate(subjects):\n",
    "            da_su = np.mean(da_all[np.where((su_codes=='S'+str(s))&(s_Mai_RL==roi))])\n",
    "            pow_su = np.mean(pow_all[np.where((su_codes=='S'+str(s))&(s_Mai_RL==roi))])\n",
    "            time_su = np.mean(time_all[np.where((su_codes=='S'+str(s))&(s_Mai_RL==roi))])\n",
    "            da_by_su = np.hstack((da_by_su,da_su)) if np.size(da_by_su) else da_su\n",
    "            pow_by_su = np.hstack((pow_by_su,pow_su)) if np.size(pow_by_su) else pow_su\n",
    "            time_by_su = np.hstack((time_by_su,time_su)) if np.size(time_by_su) else time_su\n",
    "        #remove scores values when patient not included\n",
    "        scores_diff = np.array(scores_diff)[np.where(~np.isnan(da_by_su))]\n",
    "        scores_tot = np.array(scores_tot)[np.where(~np.isnan(da_by_su))]\n",
    "        print(scores_diff, scores_tot)\n",
    "        #remove nan values\n",
    "        da_by_su = da_by_su[np.logical_not(np.isnan(da_by_su))] \n",
    "        pow_by_su = pow_by_su[np.logical_not(np.isnan(pow_by_su))] \n",
    "        time_by_su = time_by_su[np.logical_not(np.isnan(time_by_su))]\n",
    "        print(da_by_su,pow_by_su,time_by_su)\n",
    "        \n",
    "        if da_by_su.shape[0] >= 4:\n",
    "            #Plot all correlations\n",
    "            scores, features = [scores_tot,scores_diff], [da_by_su,pow_by_su,time_by_su]\n",
    "            scores_names, feats_names= ['tot_EM','diff_EM',],['da_by_su','pow_by_su','time_by_su']\n",
    "            for i,score in enumerate(scores):\n",
    "                for j,feat in enumerate(features):\n",
    "                    R, p = stats.pearsonr(score,feat)\n",
    "                    R, p = round(R,2), round(p,3)\n",
    "                    if p <= 0.07:\n",
    "                        print('stats for',freq,scores_names[i],feats_names[j],R,p)\n",
    "                        fig, ax = plt.subplots()\n",
    "                        plt.title('Correlation btw '+scores_names[i]+' and '+feats_names[j]+' for '+freq)\n",
    "                        plt.xlabel(scores_names[i]), plt.ylabel(feats_names[j])\n",
    "                        anchored_text = AnchoredText('R coeff = %s, pval = %s' % (R, p), loc=2)\n",
    "                        ax.add_artist(anchored_text)\n",
    "                        fit = np.polyfit(score, feat, deg=1)\n",
    "                        ax.plot(sorted(score), fit[0] * np.array(sorted(score)) + fit[1], color='red')\n",
    "                        ax.scatter(score, feat, color = 'dodgerblue')\n",
    "                        plt.savefig(path2save+'Correlation_'+freq+'_'+roi+'_'+scores_names[i]+'_'+feats_names[j]+'_corr.png') if corr==True else plt.savefig(path2save+'Correlation_'+freq+'_'+roi+'_'+scores_names[i]+'_'+feats_names[j]+'.png')\n",
    "                        plt.clf()\n",
    "                        plt.close()\n",
    "                    else:\n",
    "                        continue\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations btw memory perf and encoding strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "th, bsl, feat = '01', 'None', 'pow'\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_npz = join(st.path, 'figure/0_Classif_Power_E_EpiPerf_LowHigh_'+bsl+'/')\n",
    "path_mask = join(path_npz, 'masks_visbrain'+th+'/')\n",
    "path2save = join(path_npz, 'Correlations/')\n",
    "npz_form = join(path_npz, '{}_sources_{}_{}_low_high_sel_physFT_{}.npz')\n",
    "masks_vis_form = join(path_mask, '{}_mask_min{}_{}_minwin{}_th{}.npy')\n",
    "f_form_save = join(path2save, 'Correl_{}_signif_min{}_'+feat+'_bsl_{}_th{}.png')\n",
    "###############################################################################\n",
    "\n",
    "subjects = ['CHAF','FERJ','LEFC','SEMC','PIRJ','MICP','VACJ']\n",
    "su_codes = ['S0','S1','S2','S3','S4','S5','S6']\n",
    "\n",
    "# Memory Performance\n",
    "scores_tot = [12.3,2.4,8.0,2.1,7.7,6.3,8.3]\n",
    "scores_low = [2.3,2.0,0.8,1.6,1.2,1.8,1.7]\n",
    "scores_high = [22.3,2.8,15.2,2.9,14.2,8.9,15.5]\n",
    "scores_diff = [scores_high[i]-scores_low[i] for i in range(len(scores_high))]\n",
    "\n",
    "#Encoding Performance\n",
    "count = [8.9,9.9,10.9,7.4,4.9,3.8,6.8]\n",
    "delta = [16.5,19.7,8.7,16.8,30.3,35.3,29.8]\n",
    "dur = [2.9,1.3,1.3,1.6,1.7,0.8,1.4]\n",
    "vol = [9.3,1.5,2.4,3.4,5.8,1.1,3.1]\n",
    "ampl = [4.5,2.0,3.0,3.5,4.5,2.3,3.2]\n",
    "    \n",
    "#Plot all correlations\n",
    "scores, features = [scores_tot,scores_diff], [count,delta,dur,vol,ampl]\n",
    "scores_names, feats_names= ['tot_EM','diff_EM'],['count','delta','dur','vol','ampl']\n",
    "for i,score in enumerate(scores):\n",
    "    for j,feat in enumerate(features):\n",
    "        R, p = stats.pearsonr(score,feat)\n",
    "        R, p = round(R,2), round(p,3)\n",
    "        print(p)\n",
    "        if p <= 0.06:\n",
    "            print('stats for',scores_names[i],feats_names[j],R,p)\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.title('Correlation btw '+scores_names[i]+' and '+feats_names[j]+' for '+freq)\n",
    "            plt.xlabel(scores_names[i]), plt.ylabel(feats_names[j])\n",
    "            anchored_text = AnchoredText('R coeff = %s, pval = %s' % (R, p), loc=2)\n",
    "            ax.add_artist(anchored_text)\n",
    "            fit = np.polyfit(score, feat, deg=1)\n",
    "            ax.plot(sorted(score), fit[0]*np.array(sorted(score)) + fit[1], color='red')\n",
    "            ax.scatter(score, feat, color = 'dodgerblue')\n",
    "            plt.savefig(path2save+'Correlation_'+freq+'_'+scores_names[i]+'_'+feats_names[j]+'.png')\n",
    "            plt.savefig(path2save+'Correlation_'+freq+'_'+scores_names[i]+'_'+feats_names[j]+'.pdf')\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "        else:\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
