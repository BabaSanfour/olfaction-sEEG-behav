{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "theta ['IFG' 'OFC_olf' 'aHC' 'pHC' 'pPirT']\n",
      "\n",
      ">>> for IFG in theta, 3 subjects have sig elecs\n",
      "AUC decoding score is 0.66 in average +/- 0.03\n",
      "6 electrodes showed increased TPSim, while 2 showed decrease out of 8 elecs\n",
      "NB of subjects with increase 3\n",
      "NB of subjects with decrease 2\n",
      "   subjects s_Mai_RL channels      x      y      z  elecs_num  theta_AUC  \\\n",
      "57     PIRJ      IFG  o12-o11  48.10  39.20 -13.15         26   0.708519   \n",
      "63     SEMC      IFG    e7-e6  53.65  19.75  13.70          8   0.648570   \n",
      "64     SEMC      IFG    e8-e7  57.75  19.75  13.95          9   0.620409   \n",
      "75     SEMC      IFG    u8-u7  33.10  43.35  -8.90         39   0.667719   \n",
      "77     SEMC      IFG   u10-u9  41.20  43.50  -8.30         41   0.648050   \n",
      "93     VACJ      IFG  e'9-e'8 -54.55  21.55   6.20         14   0.638222   \n",
      "\n",
      "    theta_Pow0  theta_Pow1  sig_theta  sign  \n",
      "57    0.132851    0.569755          1   1.0  \n",
      "63    0.048109    0.289836          1   1.0  \n",
      "64   -0.006798    0.254890          1   1.0  \n",
      "75    0.127256    0.500600          1   1.0  \n",
      "77    0.009293    0.326327          1   1.0  \n",
      "93   -0.046177    0.208142          1   1.0  \n",
      "\n",
      ">>> for OFC_olf in theta, 3 subjects have sig elecs\n",
      "AUC decoding score is 0.69 in average +/- 0.06\n",
      "1 electrodes showed increased TPSim, while 3 showed decrease out of 4 elecs\n",
      "NB of subjects with increase 1\n",
      "NB of subjects with decrease 2\n",
      "   subjects s_Mai_RL channels      x      y      z  elecs_num  theta_AUC  \\\n",
      "53     PIRJ  OFC_olf    o5-o4  21.45  38.35 -11.95         19   0.652222   \n",
      "55     PIRJ  OFC_olf    o7-o6  29.05  38.50 -12.25         21   0.796296   \n",
      "69     SEMC  OFC_olf    o5-o4  21.25  32.25  -7.90         26   0.629093   \n",
      "\n",
      "    theta_Pow0  theta_Pow1  sig_theta  sign  \n",
      "53    0.626724    0.346991          1  -1.0  \n",
      "55    0.648170    0.037961          1  -1.0  \n",
      "69    0.233984   -0.003652          1  -1.0  \n",
      "\n",
      ">>> for aHC in theta, 4 subjects have sig elecs\n",
      "AUC decoding score is 0.7 in average +/- 0.07\n",
      "7 electrodes showed increased TPSim, while 0 showed decrease out of 7 elecs\n",
      "NB of subjects with increase 4\n",
      "NB of subjects with decrease 0\n",
      "   subjects s_Mai_RL channels      x      y      z  elecs_num  theta_AUC  \\\n",
      "6      FERJ      aHC    b6-b5  38.85 -13.55 -20.90          6   0.660446   \n",
      "22     LEFC      aHC    b2-b1  30.65 -20.50 -10.75          3   0.658618   \n",
      "28     LEFC      aHC    d5-d4  36.80 -12.75 -26.35          9   0.690694   \n",
      "40     PIRJ      aHC    b3-b2  31.20 -16.45 -15.25          1   0.877778   \n",
      "42     PIRJ      aHC  b'2-b'1 -25.80 -16.20 -12.80          3   0.650000   \n",
      "58     SEMC      aHC    b2-b1  18.30  -9.10 -18.50          0   0.693108   \n",
      "61     SEMC      aHC    b5-b4  30.45  -9.15 -18.60          3   0.674931   \n",
      "\n",
      "    theta_Pow0  theta_Pow1  sig_theta  sign  \n",
      "6     0.065873    0.363610          1   1.0  \n",
      "22    0.056311    0.377420          1   1.0  \n",
      "28    0.055323    0.425676          1   1.0  \n",
      "40   -0.008511    0.792252          1   1.0  \n",
      "42   -0.035306    0.327247          1   1.0  \n",
      "58    0.139306    0.522072          1   1.0  \n",
      "61    0.019203    0.321674          1   1.0  \n",
      "\n",
      ">>> for pPirT in theta, 2 subjects have sig elecs\n",
      "AUC decoding score is 0.7 in average +/- 0.1\n",
      "4 electrodes showed increased TPSim, while 0 showed decrease out of 4 elecs\n",
      "NB of subjects with increase 2\n",
      "NB of subjects with decrease 0\n",
      "   subjects s_Mai_RL channels      x     y      z  elecs_num  theta_AUC  \\\n",
      "16     FERJ    pPirT  j'3-j'2 -32.10  3.70 -29.20         26   0.645849   \n",
      "17     FERJ    pPirT  j'4-j'3 -36.05  3.55 -29.45         27   0.651429   \n",
      "87     VACJ    pPirT  d'2-d'1 -21.35 -7.30 -19.65          7   0.871556   \n",
      "88     VACJ    pPirT  d'3-d'2 -24.95 -7.45 -19.90          8   0.634889   \n",
      "\n",
      "    theta_Pow0  theta_Pow1  sig_theta  sign  \n",
      "16    0.010077    0.278889          1   1.0  \n",
      "17    0.038628    0.269958          1   1.0  \n",
      "87    0.038110    0.936694          1   1.0  \n",
      "88    0.383431    0.569270          1   1.0  \n"
     ]
    }
   ],
   "source": [
    "from brainpipe.system import study\n",
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem\n",
    "\n",
    "st = study('Olfacto')\n",
    "exp, pval, met = 'E', '0.05', 'zFisher'\n",
    "pathdata = join(st.path, 'figure/TPSim_LDA_'+exp+'_by_cond_6freqs_3s_zFisher/')\n",
    "# pathdata = join(st.path, 'figure/0_clf_pow_sklearn_time_'+exp+'_by_cond/')\n",
    "\n",
    "leg = ['Poor', 'Rich']\n",
    "freqs = ['theta']\n",
    "#freqs = ['delta','theta', 'alpha', 'beta','low_gamma','high_gamma']\n",
    "#freqs = ['raw']\n",
    "\n",
    "dfname = '2_all_subjects_info_elecs_AUC_by_roi_'+pval+'_theta_corr.csv'\n",
    "df = pd.read_csv(pathdata+dfname)\n",
    "df_sel = df\n",
    "df_ = df_sel[['subjects','s_Mai_RL','channels','x','y','z','elecs_num']]\n",
    "\n",
    "#Select results significant for each frequency band and ROIs\n",
    "for freq in freqs:\n",
    "    df_freq = pd.concat([df_,df_sel.filter(like=freq[:])], axis=1)\n",
    "    #print(df_freq)\n",
    "    df_sig = df_freq.loc[df_freq['sig_'+freq[:]]>0]\n",
    "    sig_rois = np.unique(df_sig['s_Mai_RL'])\n",
    "    print(freq, sig_rois)\n",
    "    for roi in sig_rois:\n",
    "        df_plot = None\n",
    "        df_roi_f = df_sig.loc[df_sig['s_Mai_RL'] == roi]\n",
    "        #print(df_roi_f)\n",
    "        nb_su = len(np.unique(df_roi_f['subjects']))\n",
    "        #if roi == roi_sel and freq == freq_sel:\n",
    "        nb_elec_su = Counter(df_roi_f['subjects'])\n",
    "        if (nb_su >= 3 and roi != 'OFC') or (nb_su >=2 and roi in ['pPirT','OFC_olf']):\n",
    "            print('\\n>>> for %s in %s, %s subjects have sig elecs' % (roi,freq[:],nb_su))\n",
    "#             print('organized as follow', nb_elec_su)\n",
    "            auc = df_roi_f[freq+'_AUC'].values\n",
    "            auc_mean, std_auc = np.mean(auc), np.std(auc)\n",
    "            print('AUC decoding score is %s in average +/- %s' %(round(auc_mean,2),\n",
    "                                round(std_auc,2)))\n",
    "            #create a value of 1 for increase, -1 for decrease and 0 for no change\n",
    "            df_roi_f['sign'] = np.sign(df_freq[freq+'_Pow1'] - df_freq[freq+'_Pow0'])\n",
    "            inc = (df_roi_f.loc[df_roi_f.sign == 1.0]).shape[0]\n",
    "            dec = (df_roi_f.loc[df_roi_f.sign == -1.0]).shape[0]\n",
    "            print('%s electrodes showed increased TPSim, while %s showed decrease out of %s elecs' \n",
    "                  % (inc,dec,inc+dec))\n",
    "            df_inc = df_roi_f.loc[df_roi_f.sign == 1.0].groupby(['subjects']).count()\n",
    "            df_dec = df_roi_f.loc[df_roi_f.sign == -1.0].groupby(['subjects']).count()\n",
    "            print('NB of subjects with increase',df_inc.shape[0])\n",
    "            print('NB of subjects with decrease',df_dec.shape[0])\n",
    "            \n",
    "            if (df_inc.shape[0] >= 3) or (df_inc.shape[0] >=2 and roi in ['pPirT','OFC_olf']):\n",
    "                df_plot = df_roi_f.loc[df_roi_f.sign == 1.0]\n",
    "                n_subj = df_inc.shape[0]\n",
    "                print(df_plot)\n",
    "            if (df_dec.shape[0] >= 3) or (df_dec.shape[0] >=2 and roi in ['pPirT','OFC_olf']):\n",
    "                df_plot = df_roi_f.loc[df_roi_f.sign == -1.0]\n",
    "                n_subj = df_dec.shape[0]\n",
    "                print(df_plot)\n",
    "            \n",
    "            if df_plot is not None:\n",
    "                if not exists(pathdata+'npy_figs/'):\n",
    "                    makedirs(pathdata+'npy_figs/')\n",
    "                    \n",
    "                x = [np.mean(df_plot[freq+'_Pow0']),np.mean(df_plot[freq+'_Pow1'])]        \n",
    "                sd = [np.std(df_plot[freq+'_Pow0']),np.std(df_plot[freq+'_Pow1'])]        \n",
    "                title = '{} in {} at {} (p={}) \\n {} elecs in {} patients'.format(\n",
    "                                roi,freq,exp,pval,df_plot.shape[0],n_subj)\n",
    "                plt.title(title)\n",
    "                plt.bar(np.arange(len(leg)), x, width=0.5, yerr=sd)\n",
    "                plt.ylabel('Similarity (r)')\n",
    "                plt.xticks(np.arange(len(leg)), labels=leg)\n",
    "                plt.savefig(pathdata+'npy_figs/{}_{}_{}_{}_tps.png'.format(freq,roi,exp,pval))\n",
    "                plt.savefig(pathdata+'npy_figs/{}_{}_{}_{}_tps.pdf'.format(freq,roi,exp,pval))\n",
    "                df_plot.to_csv(pathdata+'npy_figs/{}_{}_{}_{}_tps.csv'.format(freq,roi,exp,pval))\n",
    "                plt.clf()\n",
    "                plt.close()\n",
    "                del df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = ['0_theta', '1_alpha', '2_beta', '3_gamma']\n",
    "su_odor_groups = {'CHAF' : {'low':['1','2','4','5'],\n",
    "                              'high':['3','8','7','9']},\n",
    "                    'VACJ' : {'low':['11','14','12','10'],\n",
    "                              'high':['15','17','16','13']},\n",
    "                    'SEMC' : {'low':['7','10','11','12','13'],\n",
    "                              'high':['5','8','9']},\n",
    "                    'PIRJ' : {'low':['1','9','5'],\n",
    "                              'high':['4','6','7','18']},\n",
    "                    'LEFC' : {'low':['15','2','1','16'],\n",
    "                              'high':['14','3','4','17']},\n",
    "                    'FERJ' : {'low':['7','2','16','17'],\n",
    "                              'high':['12','1','5','13']},}\n",
    "context_su = {'CHAF': {'M':[5,7,8,9],'F':[1,2,3,4]},\n",
    "              'LEFC': {'M':[1,2,3,4],'F':[14,15,16,17]},\n",
    "              'PIRJ': {'M':[4,9,1,18],'F':[6,5,7]}, #missing odor 15\n",
    "              'VACJ': {'M':[14,15,16,17],'F':[10,11,12,13]},\n",
    "              'SEMC': {'M':[10,11,12,13],'F':[5,7,8,9]},\n",
    "              'FERJ': {'M':[16,17,5,7],'F':[12,13,2,1]},}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot TPSim matrices (RDM) for all odors by subject \n",
    "Plot Graph 2D representations of RDM matrices\n",
    "\"\"\"\n",
    "from brainpipe.system import study\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import cm\n",
    "import seaborn as sns \n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.manifold import MDS\n",
    "import glob\n",
    "\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/TPSim_LDA_{}_by_cond_3s/npy_figs/')\n",
    "path_npz = join(st.path,'feature/TPSim_{}_By_Odor_By_Cond/')\n",
    "path_pow = join(path_npz, 'similarity_matrix_btw/TPS_spear_{}_{}_btw_odors_mean.npz')\n",
    "savename = join(pathdata, 'rdm_{}/{}_{}_{}_{}_{}_p={}_rdm.png')\n",
    "savename2 = join(pathdata, 'rdm_{}/{}_{}_{}_{}_{}_p={}_rdm.pdf')\n",
    "###############################################################################\n",
    "exp, pval = 'Ret', '0.01' #Ret, Enc\n",
    "freqs = ['0_theta', '1_alpha', '2_beta', '3_gamma']\n",
    "###############################################################################\n",
    "\n",
    "files = glob.glob(pathdata.format(exp[0])+'*'+pval+'_tps.csv')\n",
    "\n",
    "for fi in files:\n",
    "    freq, roi = fi.split('_')[10][-1]+'_'+fi.split('_')[11], fi.split('_')[12]\n",
    "    df = pd.read_csv(fi)\n",
    "    subjects, elecs = df['subjects'], df['elecs_num']\n",
    "    \n",
    "    for su, elec in zip(subjects,elecs):\n",
    "        mat = np.load(path_pow.format(exp,su,freq),allow_pickle=True)\n",
    "        combs, tps = mat['comb'], mat['tps'][elec,:]\n",
    "        n_od = len(np.unique(combs))\n",
    "        idx = list([combs[0,0]])+list([o for o in combs[:n_od-1,1]])\n",
    "        tri = np.zeros((n_od, n_od))\n",
    "        tri[np.triu_indices(n_od, 1)] = tps\n",
    "        tri[np.tril_indices(n_od, -1)] = tri.T[np.tril_indices(n_od, -1)]\n",
    "        model = MDS(n_components=2, dissimilarity='precomputed', random_state=1)\n",
    "        out = model.fit_transform(tri)\n",
    "        \n",
    "        #plot and save RDM matrices\n",
    "        fig, (ax1,ax2) = plt.subplots(1,2,figsize=(8,3))\n",
    "        title = 'Distance btw odors for {} in {} at {} (p={}) - Patient {} elec({})'.format(\n",
    "            roi, freq[2:], exp[0], pval, su, str(elec))\n",
    "        fig.suptitle(title)\n",
    "        \n",
    "        #subplot #1 Graph 2D \n",
    "        colors = ['red' if str(c) in su_odor_groups[su]['high'] else 'blue' for c in idx]\n",
    "        markers = ['o' if c in context_su[su]['M'] else '*' for c in idx]\n",
    "        for i, txt in enumerate(idx):\n",
    "            ax1.scatter(out[i,0], out[i,1], c=colors[i], marker=markers[i],\n",
    "                       label=['Rich' if colors[i]=='red' else 'Poor'])\n",
    "            ax1.annotate('O'+str(txt), (out[i,0], out[i,1]))\n",
    "        ax1.set_xlabel('component 1')\n",
    "        ax1.set_ylabel('component 2')\n",
    "        ax1.axis('equal')\n",
    "        legend_elements = [Line2D([0], [0], marker='o', color='b', label='Poor_M'),\n",
    "                           Line2D([0], [0], marker='*', color='b', label='Poor_C'),\n",
    "                           Line2D([0], [0], marker='o', color='r', label='Rich_M'),\n",
    "                           Line2D([0], [0], marker='*', color='r', label='Rich_C')]\n",
    "        ax1.legend(handles=legend_elements, loc='best')\n",
    "        \n",
    "        #subplot #1 Graph 2D \n",
    "        cmap = cm.get_cmap('jet', 30)\n",
    "        cax = ax2.imshow(tri, interpolation=\"none\", cmap=cmap)\n",
    "        ax2.set_xticks(np.arange(n_od))\n",
    "        ax2.set_yticks(np.arange(n_od))\n",
    "        ax2.set_xticklabels(idx,fontsize=11)\n",
    "        ax2.set_yticklabels(idx,fontsize=11)\n",
    "        plt.colorbar(cax)\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "#         plt.tight_layout()\n",
    "        plt.savefig(savename.format(exp[0],pval,freq[2:],roi,exp[0],su, str(elec),pval))\n",
    "        plt.savefig(savename2.format(exp[0],pval,freq[2:],roi,exp[0],su, str(elec),pval))\n",
    "        plt.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check whether there is difference btw EARLY and LATE similarities during E and R\n",
    "for High and Low conditions independantly\n",
    "\"\"\"\n",
    "from brainpipe.system import study\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import bonferroni_correction, fdr_correction\n",
    "import glob\n",
    "\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/TPSim_LDA_{}_by_cond_3s/npy_figs/')\n",
    "path_npz = join(st.path,'feature/TPSim_{}_By_Odor_By_Cond/')\n",
    "path_pow = join(path_npz, 'rdm_thgh_time/TPS_spear_{}_{}_{}_{}_btw_odors.npz.npy')\n",
    "\n",
    "savename = join(pathdata, '{}_{}_{}_p={}_time.png')\n",
    "savename2 = join(pathdata, '{}_{}_{}_p={}_time.pdf')\n",
    "###############################################################################\n",
    "exp, pval = 'Enc', '0.001' #Ret, Enc\n",
    "freqs = ['theta', 'alpha', 'beta', 'gamma']\n",
    "conds, wins = ['low','high'], ['early','late']\n",
    "###############################################################################\n",
    "\n",
    "files = glob.glob(pathdata.format(exp[0])+'*'+pval+'_tps.csv')\n",
    "\n",
    "for fi in files:\n",
    "    freq, roi = fi.split('_')[11:13]\n",
    "    df = pd.read_csv(fi)\n",
    "    subjects, elecs = df['subjects'], df['elecs_num']\n",
    "    \n",
    "    Tvals_l, pvals_l, Tvals_h, pvals_h = [],[],[],[]\n",
    "    Tvals_0, pvals_0, Tvals_1, pvals_1 = [],[],[],[]\n",
    "    early_l, early_h, late_l, late_h = [],[],[],[]\n",
    "    for su, elec in zip(subjects,elecs):\n",
    "        \n",
    "        rdm0 = np.load(path_pow.format(exp,su,'low',freq,'early'))[elec,:]\n",
    "        rdm1 = np.load(path_pow.format(exp,su,'low',freq,'late'))[elec,:]\n",
    "        rdm2 = np.load(path_pow.format(exp,su,'high',freq,'early'))[elec,:]\n",
    "        rdm3 = np.load(path_pow.format(exp,su,'high',freq,'late'))[elec,:]\n",
    "        \n",
    "        T0, p0 = stats.ttest_ind(rdm0,rdm1)\n",
    "        T_e, p_e = stats.ttest_ind(rdm0, rdm2)\n",
    "        T_l, p_l = stats.ttest_ind(rdm1, rdm3)\n",
    "        T1, p1 = stats.ttest_ind(rdm2,rdm3)\n",
    "        Tvals_l.append(T0), pvals_l.append(p0)\n",
    "        Tvals_h.append(T1), pvals_h.append(p1)\n",
    "        Tvals_0.append(T_e), pvals_0.append(p_e)\n",
    "        Tvals_1.append(T_l), pvals_1.append(p_l)\n",
    "        early_l.append(np.mean(rdm0)), early_h.append(np.mean(rdm2))\n",
    "        late_l.append(np.mean(rdm1)), late_h.append(np.mean(rdm3))\n",
    "    \n",
    "    T_low, p_low = stats.ttest_rel(early_l,late_l)\n",
    "    T_high, p_high = stats.ttest_rel(early_h,late_h)\n",
    "    T_hl_e, p_hl_e = stats.ttest_rel(early_l, early_h)\n",
    "    T_hl_l, p_hl_l = stats.ttest_rel(late_l, late_h)\n",
    "    df['tps_early_low'], df['tps_late_low'] = early_l, late_l\n",
    "    df['Tvals_low'], df['pvals_low'] = Tvals_l, pvals_l\n",
    "    df['pvals_low_b'], df['pvals_low_fdr'] = bonferroni_correction(pvals_l)[1], fdr_correction(pvals_l)[1]\n",
    "    df['tps_early_high'], df['tps_late_high'] = early_h, late_h\n",
    "    df['Tvals_high'], df['pvals_high'] = Tvals_h, pvals_h\n",
    "    df['pvals_high_b'], df['pvals_high_fdr'] = bonferroni_correction(pvals_h)[1], fdr_correction(pvals_h)[1]\n",
    "    df.to_csv(fi, index=False)\n",
    "    \n",
    "    nsig_l = np.sum(np.array(pvals_l) < 0.05)\n",
    "    nsig_h = np.sum(np.array(pvals_h) < 0.05)\n",
    "    print('High/Low - early', T_hl_e, p_hl_e)\n",
    "    print('High/Low - late', T_hl_l, p_hl_l)\n",
    "    n_subj = len(np.unique(subjects))\n",
    "    print(freq,roi,'For Low : {}/{} elecs sig in {} subjects'.format(nsig_l,len(df),n_subj))\n",
    "    print('Group level stat : T={}, p={}'.format(round(T_low,2),round(p_low,3)))\n",
    "    #print(df[['tps_early_low','tps_late_low','Tvals_low','pvals_low_b']])\n",
    "    df_print2 = df[['subjects','elecs_num','tps_early_low','tps_late_low','Tvals_low','pvals_low']]\n",
    "    df_print2 = df_print2.loc[(df_print2['pvals_low']<0.05)]\n",
    "    print(df_print2)\n",
    "    print(freq,roi,'For High : {}/{} elecs sig in {} subjects'.format(nsig_h,len(df),n_subj))\n",
    "    print('Group level stat : T={}, p={}'.format(round(T_high,2),round(p_high,3)))\n",
    "    df_print = df[['subjects','elecs_num','tps_early_high','tps_late_high','Tvals_high','pvals_high_b']]\n",
    "    df_print = df_print.loc[(df_print['pvals_high_b']<0.05)]\n",
    "    print(df_print)\n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(8,3))\n",
    "    title = 'Distance btw odors from LOW and HIGH in {} in {} at {} (p={})'.format(\n",
    "        roi, freq, exp[0], pval, su, str(elec))\n",
    "    fig.suptitle(title)\n",
    "     \n",
    "    x0, x1 = [np.mean(early_l),np.mean(late_l)], [np.mean(early_h), np.mean(late_h)]\n",
    "    sd0, sd1 = [np.std(early_l),np.std(late_l)], [np.std(early_h), np.std(late_h)] \n",
    "    \n",
    "    ax1.bar(np.arange(len(wins)), x0, width=0.5, yerr=sd0)\n",
    "    ax1.set_ylabel('Similarity (r)')\n",
    "    ax1.set_xticks(np.arange(len(wins)))\n",
    "    ax1.set_xticklabels(wins)\n",
    "    \n",
    "    ax2.bar(np.arange(len(wins)), x1, width=0.5, yerr=sd1)\n",
    "    ax2.set_ylabel('Similarity (r)')\n",
    "    ax2.set_xticks(np.arange(len(wins)))\n",
    "    ax2.set_xticklabels(wins)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    plt.savefig(savename.format(exp[0],freq,roi,exp,pval))\n",
    "    plt.savefig(savename2.format(exp[0],freq,roi,exp,pval))\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check distance btw High and Low odors at EARLY and LATE E and R\n",
    "\"\"\"\n",
    "from brainpipe.system import study\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import bonferroni_correction, fdr_correction\n",
    "import glob\n",
    "\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "pathdata = join(st.path, 'figure/TPSim_LDA_{}_by_cond_3s/npy_figs/')\n",
    "path_npz = join(st.path,'feature/TPSim_{}_By_Odor_By_Cond/')\n",
    "path_pow = join(path_npz, 'rdm_thgh_time/TPS_spear_{}_{}_{}_Low_High.npz.npy')\n",
    "\n",
    "savename = join(pathdata, '{}_{}_{}_p={}_high_low_time.png')\n",
    "savename2 = join(pathdata, '{}_{}_{}_p={}_high_low_time.pdf')\n",
    "###############################################################################\n",
    "exp, pval = 'Enc', '0.001' #Ret, Enc\n",
    "freqs = ['theta', 'alpha', 'beta', 'gamma']\n",
    "wins = ['early','late']\n",
    "###############################################################################\n",
    "\n",
    "files = glob.glob(pathdata.format(exp[0])+'*'+pval+'_tps.csv')\n",
    "\n",
    "for fi in files:\n",
    "    freq, roi = fi.split('_')[11:13]\n",
    "    df = pd.read_csv(fi)\n",
    "    subjects, elecs = df['subjects'], df['elecs_num']\n",
    "    \n",
    "    Tvals, pvals, early, late = [],[],[],[]\n",
    "    for su, elec in zip(subjects,elecs):\n",
    "        \n",
    "        rdm0 = np.load(path_pow.format(exp,su,freq,'early'))[elec,:]\n",
    "        rdm1 = np.load(path_pow.format(exp,su,freq,'late'))[elec,:]\n",
    "        T0, p0 = stats.ttest_ind(rdm0,rdm1)\n",
    "        Tvals.append(T0), pvals.append(p0)\n",
    "        early.append(np.mean(rdm0)), late.append(np.mean(rdm1))\n",
    "    \n",
    "    T_tot, p_tot = stats.ttest_rel(early,late)\n",
    "    df['tps_early_btw'], df['tps_late_btw'] = early, late\n",
    "    df['Tvals_btw'], df['pvals_btw'] = Tvals, pvals\n",
    "    df['pvals_btw_b'], df['pvals_btw_fdr'] = bonferroni_correction(pvals)[1], fdr_correction(pvals)[1]\n",
    "    df_print = df[['subjects','elecs_num','tps_early_btw','tps_late_btw','Tvals_btw','pvals_btw']]\n",
    "    df_print = df_print.loc[(df_print['pvals_btw']<0.05)]\n",
    "    print(df_print)\n",
    "    df.to_csv(fi, index=False)\n",
    "    \n",
    "    nsig = np.sum(bonferroni_correction(pvals)[1]<0.05)\n",
    "    n_subj = len(np.unique(subjects))\n",
    "    print(freq,roi,'Sig early/late : {}/{} elecs sig in {} subjects'.format(nsig,len(df),n_subj))\n",
    "    print('Group level stat : T={}, p={}'.format(round(T_tot,2),round(p_tot,3)))\n",
    "       \n",
    "    plt.figure()\n",
    "    title = 'Distance btw LOW and HIGH odors in {} in {} at {} (p={})'.format(\n",
    "        roi, freq, exp[0], pval, su, str(elec))\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    x0 = [np.mean(early),np.mean(late)]\n",
    "    sd0 = [stats.sem(early),stats.sem(late)]\n",
    "    \n",
    "    plt.bar(np.arange(len(wins)), x0, width=0.5, yerr=sd0)\n",
    "    plt.ylabel('Similarity (r)')\n",
    "    plt.xticks(np.arange(len(wins)), labels=wins)\n",
    "    \n",
    "    plt.savefig(savename.format(exp[0],freq,roi,exp,pval))\n",
    "    plt.savefig(savename2.format(exp[0],freq,roi,exp,pval))\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low -0.17061923469721746 -1.3461283937686765 1.2015538029460515\n",
      "high 0.19436950507887274 -0.6809540346905878 1.425538979071672\n",
      "Tests for FERJ in b2-b1\n",
      "Tests Low, T=-5.19, p=0.0\n",
      "Tests High, T=5.34, p=0.0\n",
      "low -0.2714783380194119 -1.1647884957256405 0.951487075475288\n",
      "high -0.04437149513364786 -0.9562155409679745 1.0350350151233372\n",
      "Tests for FERJ in b6-b5\n",
      "Tests Low, T=-9.26, p=0.0\n",
      "Tests High, T=-1.57, p=0.119\n",
      "low -0.1542512714432263 -0.8695406668046813 0.9514403198435546\n",
      "high 0.06241966948702271 -0.9897455161843556 1.2676214666950525\n",
      "Tests for PIRJ in b'4-b'3\n",
      "Tests Low, T=-6.17, p=0.0\n",
      "Tests High, T=1.83, p=0.069\n",
      "low -0.03318089861728152 -0.9788061288609202 0.8265226254581567\n",
      "high 0.38416516375575993 -0.39306087914256055 1.8890405653055053\n",
      "Tests for VACJ in b3-b2\n",
      "Tests Low, T=-0.88, p=0.382\n",
      "Tests High, T=9.05, p=0.0\n",
      "ALL Tests Low, T=-10.87, p=0.0\n",
      "ALL Tests High, T=7.29, p=0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Check whether reinstatement (TPSim between E and R) is significant\n",
    "in olfactory regions showing discriminant richness effets at E and R\n",
    "\"\"\"\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "###############################################################################\n",
    "dict_ = {'FERJ':[\"b2-b1\",\"b6-b5\"], 'PIRJ':[\"b'4-b'3\"], 'VACJ':[\"b3-b2\"]} #aHC\n",
    "#dict_ = {'FERJ':[\"b2-b1\",\"b6-b5\",\"b3-b2\",\"b'5-b'4\"],\n",
    "#         'PIRJ':[\"b'4-b'3\"], 'VACJ':[\"b3-b2\",\"b'2-b'1\"], 'SEMC':[\"b5-b4\"]} #aHC 10e-2\n",
    "#dict_ = {'FERJ':[\"o9-o8\",\"o10-o9\"], 'SEMC':[\"j2-j1\"], 'VACJ':[\"k'13-k'12\"]} #IFG\n",
    "#dict_ = {'FERJ':[\"o9-o8\",\"o10-o9\",\"o8-o7\"], 'SEMC':[\"j2-j1\"], 'VACJ':[\"k'13-k'12\"]} #IFG 10e-2\n",
    "#dict_ = {'LEFC':[\"o4-o3\"], 'SEMC':[\"o5-o4\",\"o6-o5\"], 'PIRJ':[\"o5-o4\"]} #OFC\n",
    "#dict_ = {'LEFC':[\"o4-o3\",\"o6-o5\"], 'SEMC':[\"o5-o4\",\"o6-o5\",\"o7-o6\"], 'PIRJ':[\"o5-o4\"]} #OFC 10e-2\n",
    "#dict_ = {'FERJ':[\"a3-a2\",\"j2-j1\"], 'VACJ':[\"d'2-d'1\"]} #PirC 10e-2\n",
    "###############################################################################\n",
    "freq = 'beta' #'1_alpha', '2_beta','3_gamma', high_gamma\n",
    "conds = ['low','high']\n",
    "tps_path = join(st.path, 'feature/TPSim_Enc_Ret_By_Odor_By_Cond/TPS_by_cond/6freqs/')\n",
    "tps_name = join(tps_path,'TPS_spear_{}_cond_{}_{}_3s_zFisher.npz')\n",
    "\n",
    "tps_h_all, tps_l_all = [], []\n",
    "for su in dict_:\n",
    "    for chan in dict_[su]:\n",
    "        mat = np.load(tps_name.format(su,conds[0],freq),allow_pickle=True)\n",
    "        idx_chan = [i for i,c in enumerate(mat['channel']) if c == chan][0]\n",
    "        lab = mat['label'][idx_chan]\n",
    "        \n",
    "        tps_l = mat['tps'][idx_chan]\n",
    "        tps_h = np.load(tps_name.format(su,conds[1],freq))['tps'][idx_chan]\n",
    "        \n",
    "        tps_h_all.extend([tps_h])\n",
    "        tps_l_all.extend([tps_l])\n",
    "        print('low', np.mean(tps_l), np.min(tps_l), np.max(tps_l))\n",
    "        print('high', np.mean(tps_h), np.min(tps_h), np.max(tps_h))\n",
    "        Tl, pl = ttest_1samp(tps_l, 0)\n",
    "        Th, ph = ttest_1samp(tps_h, 0)\n",
    "        \n",
    "        print('Tests for {} in {}'.format(su,chan,freq,lab))\n",
    "        print('Tests Low, T={}, p={}'.format(round(Tl,2),round(pl,3)))\n",
    "        print('Tests High, T={}, p={}'.format(round(Th,2),round(ph,3)))\n",
    "tps_h_all = np.concatenate(tps_h_all,axis=0)\n",
    "tps_l_all = np.concatenate(tps_l_all,axis=0)\n",
    "\n",
    "T_all_h, p_all_h = ttest_1samp(tps_h_all, 0)\n",
    "T_all_l, p_all_l = ttest_1samp(tps_l_all, 0)\n",
    "print('ALL Tests Low, T={}, p={}'.format(round(T_all_l,2),round(p_all_l,3)))\n",
    "print('ALL Tests High, T={}, p={}'.format(round(T_all_h,2),round(p_all_h,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "from itertools import product\n",
    "\n",
    "def tpsim_btw_cond(dataE, dataR, pow_data=None, stat='spearmanr'):\n",
    "    \"\"\"compute the Temporal Pattern Similarity (tpsim) for all combinations of\n",
    "    single-trial power in 2 different conditions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data1, data2 : arrays\n",
    "        Must be of shape (n_pts, n_trials)\n",
    "    stat : string\n",
    "        The stat correlation method to use. 'pearson' or 'spearman'\n",
    "    Returns\n",
    "    -------\n",
    "    tpsim : value\n",
    "        The mean TPSim value \n",
    "    \"\"\"\n",
    "    corr = pearsonr if stat == 'pearson' else spearmanr\n",
    "    assert (\n",
    "        dataE.shape[0] == dataR.shape[0]\n",
    "    ), \"Error: shape of trial1 and trial2 must have the same npts\"\n",
    "    n_trials0, n_trials1 = dataE.shape[1],dataR.shape[1]\n",
    "    \n",
    "    pow_data = dataE if pow_data is None else pow_data\n",
    "    list_tpsim = np.zeros((n_trials0*n_trials1))\n",
    "    list_pow = np.zeros((n_trials0*n_trials1))\n",
    "    i = 0\n",
    "    for trial0, trial1 in product(range(n_trials0),range(n_trials1)):\n",
    "        list_tpsim[i] += 1 -(corr(dataE[:,trial0],dataR[:,trial1])[0])\n",
    "        list_pow[i] += np.mean(pow_data[:,trial0])\n",
    "        i += 1\n",
    "    return list_tpsim, list_pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tpsim_btw_cond' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-ddf931abdcbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpow_roi_datal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     tpsER_l, powE_l = tpsim_btw_cond(dataE_l,dataR_l,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                                      pow_data=pow_roi_datal[e,...])        \n\u001b[1;32m     45\u001b[0m                     tpsER_h, powE_h = tpsim_btw_cond(dataE_h,dataR_h,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tpsim_btw_cond' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test if reinstatement is linked to power at encoding in same OR different brain regions\n",
    "\"\"\"\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from brainpipe.system import study\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "st = study('Olfacto')\n",
    "###############################################################################\n",
    "#dict_ = {'FERJ':[\"b2-b1\",\"b6-b5\"], 'PIRJ':[\"b'4-b'3\"], 'VACJ':[\"b3-b2\"]} #aHC\n",
    "#dict_ = {'FERJ':[\"b2-b1\",\"b6-b5\",\"b3-b2\",\"b'5-b'4\"],\n",
    "#         'PIRJ':[\"b'4-b'3\"], 'VACJ':[\"b3-b2\",\"b'2-b'1\"], 'SEMC':[\"b5-b4\"]} #aHC 10e-2\n",
    "#dict_ = {'FERJ':[\"o9-o8\",\"o10-o9\"], 'SEMC':[\"j2-j1\"], 'VACJ':[\"k'13-k'12\"]} #IFG\n",
    "#dict_ = {'FERJ':[\"o9-o8\",\"o10-o9\",\"o8-o7\"], 'SEMC':[\"j2-j1\"], 'VACJ':[\"k'13-k'12\"]} #IFG 10e-2\n",
    "#dict_ = {'LEFC':[\"o4-o3\"], 'SEMC':[\"o5-o4\",\"o6-o5\"], 'PIRJ':[\"o5-o4\"]} #OFC\n",
    "#dict_ = {'LEFC':[\"o4-o3\",\"o6-o5\"], 'SEMC':[\"o5-o4\",\"o6-o5\",\"o7-o6\"], 'PIRJ':[\"o5-o4\"]} #OFC 10e-2\n",
    "dict_ = {'FERJ':[\"a3-a2\",\"j2-j1\"], 'VACJ':[\"d'2-d'1\"]} #PirC 10e-2\n",
    "###############################################################################\n",
    "exp, roi_sel, freq = 'E_R', 'IFG', 'high_gamma'\n",
    "fnames = ['delta', 'theta', 'alpha', 'beta', 'low_gamma', 'high_gamma']\n",
    "i_freq = [i for i,f in enumerate(fnames) if f == freq]\n",
    "conds = ['low','high']\n",
    "pow_path = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_cond/')\n",
    "path_df = join(st.path, 'figure/TPSim_LDA_E_R_by_cond_6freqs_3s_zFisher/')\n",
    "dfname = join(path_df, '2_all_subjects_info_elecs_AUC_by_roi_0.001_corr.csv')\n",
    "pow_name = join(pow_path,'Pow_{}_{}_{}_allfreqs.npz')\n",
    "rois = ['aHC','OFC_olf']\n",
    "\n",
    "for su in elecs_d:\n",
    "    for elec in elecs_d[su]:\n",
    "        dataE_l = np.load(pow_name.format(su,'E','low'))['xpow'][i_freq,elec,17:47,:]       \n",
    "        dataE_h = np.load(pow_name.format(su,'E','high'))['xpow'][i_freq,elec,17:47,:]\n",
    "        data_E = np.concatenate((dataE_l,dataE_h),axis=-1)\n",
    "        #print(dataE_l.shape, dataE_h.shape, data_E.shape)\n",
    "        dataR_l = np.load(pow_name.format(su,'R','low'))['xpow'][i_freq,elec,17:47,:]       \n",
    "        dataR_h = np.load(pow_name.format(su,'R','high'))['xpow'][i_freq,elec,17:47,:]\n",
    "        data_R = np.concatenate((dataR_l,dataR_h),axis=-1)\n",
    "        #print(dataR_l.shape, dataR_h.shape, data_R.shape)\n",
    "        \n",
    "        for roi in rois:\n",
    "            df = pd.read_csv(dfname)\n",
    "            labels = df.loc[df['subjects'] == su]['s_Mai_RL'].values\n",
    "            idx = np.where(labels == roi)[0]\n",
    "            if len(idx) > 0 :\n",
    "                pow_roi_datal = np.load(pow_name.format(su,'E','low'))['xpow'][freq,idx,17:47,:]    \n",
    "                pow_roi_datah = np.load(pow_name.format(su,'E','high'))['xpow'][freq,idx,17:47,:]    \n",
    "                #pow_roi_datal = np.concatenate(pow_roi_datal,axis=-1)\n",
    "                #pow_roi_datah = np.concatenate(pow_roi_datah,axis=-1)\n",
    "                pow_roi_data_all = np.concatenate((pow_roi_datal, pow_roi_datah),axis=-1)    \n",
    "\n",
    "                for e in range(pow_roi_datal.shape[0]):\n",
    "                    tpsER_l, powE_l = tpsim_btw_cond(dataE_l,dataR_l,\n",
    "                                                     pow_data=pow_roi_datal[e,...])        \n",
    "                    tpsER_h, powE_h = tpsim_btw_cond(dataE_h,dataR_h,\n",
    "                                                     pow_data=pow_roi_datah[e,...])        \n",
    "                    tpsER_all = np.concatenate((tpsER_l,tpsER_h))\n",
    "                    powE_all = np.concatenate((powE_l, powE_h))\n",
    "\n",
    "                    R_l, p_l = spearmanr(tpsER_l,powE_l)      \n",
    "                    R_h, p_h = spearmanr(tpsER_h,powE_h)\n",
    "                    R_all, p_all = spearmanr(tpsER_all,powE_all)\n",
    "                    print('\\n correlation for {} in {} roi {}'.format(su,elec,roi))\n",
    "                    print('elec {} out of {}'.format(e,pow_roi_datal.shape[0]))\n",
    "                    print('Tests Low, R={}, p={}'.format(round(R_l,2),round(p_l,3)))\n",
    "                    print('Tests High, R={}, p={}'.format(round(R_h,2),round(p_h,3)))\n",
    "                    print('Tests ALL, R={}, p={}'.format(round(R_all,2),round(p_all,3))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test whether Temporal patterns are correlated btw E and R\n",
    "in frontal and olf/HC regions during encoding\n",
    "\"\"\"\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from brainpipe.system import study\n",
    "from scipy.stats import spearmanr, ttest_1samp\n",
    "\n",
    "st = study('Olfacto')\n",
    "elecs_d = {'PIRJ':[20],'SEMC':[26],'VACJ':[31]}\n",
    "freq = 0\n",
    "conds = ['low','high']\n",
    "pow_path = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_cond/')\n",
    "pow_name = join(pow_path,'Pow_{}_{}_{}_allfreqs.npz')\n",
    "path_df = join(st.path, 'figure/TPSim_LDA_E_by_cond_3s/')\n",
    "dfname = join(path_df, '2_all_subjects_info_elecs_AUC_Signif_th_0.001_mean_corr_all_11.csv')\n",
    "rois = ['aHC','OFC_olf','pPirT']\n",
    "\n",
    "for su in elecs_d:\n",
    "    for elec in elecs_d[su]:\n",
    "        data1_l = np.load(pow_name.format(su,'R','low'))['xpow'][freq,elec,17:47,:]       \n",
    "        data1_h = np.load(pow_name.format(su,'R','high'))['xpow'][freq,elec,17:47,:]\n",
    "        data1 = np.concatenate((data1_l,data1_h),axis=-1)\n",
    "        #print(dataR_l.shape, dataR_h.shape, data_R.shape)\n",
    "        \n",
    "        for roi in rois:\n",
    "            df = pd.read_csv(dfname)\n",
    "            labels = df.loc[df['subjects'] == su]['s_Mai_RL'].values\n",
    "            idx = np.where(labels == roi)[0]\n",
    "            data0_l = np.load(pow_name.format(su,'E','low'))['xpow'][freq,idx,17:47,:]       \n",
    "            data0_h = np.load(pow_name.format(su,'E','high'))['xpow'][freq,idx,17:47,:]\n",
    "            data0 = np.concatenate((data0_l,data0_h),axis=-1)\n",
    "            #print(dataE_l.shape, dataE_h.shape, data_E.shape)  \n",
    "\n",
    "            for e in range(data0_l.shape[0]):\n",
    "                tpsER_l, _ = tpsim_btw_cond(data0_l[e,...],data1_l)        \n",
    "                tpsER_h, _ = tpsim_btw_cond(data0_h[e,...],data1_h)     \n",
    "                tpsER_all = np.concatenate((tpsER_l,tpsER_h))\n",
    "\n",
    "                T_l, p_l = ttest_1samp(tpsER_l,1)      \n",
    "                T_h, p_h = ttest_1samp(tpsER_h,1)\n",
    "                T_all, p_all = ttest_1samp(tpsER_all,1)\n",
    "                if p_h < 0.05:\n",
    "                    print('\\ncorrelation for {} in {} roi {}'.format(su,idx[e],roi))\n",
    "                    print('elec {} out of {}'.format(e,data0_l.shape[0]))\n",
    "                    #print('Tests Low, R={}, p={}'.format(round(T_l,2),round(p_l,3)))\n",
    "                    print('Tests High, R={}, p={}'.format(round(T_h,2),round(p_h,3)))\n",
    "                    #print('Tests ALL, R={}, p={}'.format(round(T_all,2),round(p_all,3))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test whether Temporal patterns are correlated btw regions during E or R\n",
    "\"\"\"\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from brainpipe.system import study\n",
    "from scipy.stats import spearmanr, ttest_1samp\n",
    "from itertools import combinations\n",
    "\n",
    "st = study('Olfacto')\n",
    "elecs_d = ['PIRJ','SEMC','VACJ','FERJ','LEFC']\n",
    "freq = 0\n",
    "conds = ['low','high']\n",
    "pow_path = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_cond/')\n",
    "pow_name = join(pow_path,'Pow_{}_{}_{}_allfreqs.npz')\n",
    "path_df = join(st.path, 'figure/TPSim_LDA_E_by_cond_3s/')\n",
    "dfname = join(path_df, '2_all_subjects_info_elecs_AUC_Signif_th_0.001_mean_corr_all_11.csv')\n",
    "rois = ['aHC','OFC_olf','pPirT']\n",
    "\n",
    "for su in elecs_d:\n",
    "    for roi0, roi1 in combinations(rois,2):\n",
    "        print(su, roi0, roi1)\n",
    "        df = pd.read_csv(dfname)\n",
    "        labels = df.loc[df['subjects'] == su]['s_Mai_RL'].values\n",
    "        idx0 = np.where(labels == roi0)[0]\n",
    "        idx1 = np.where(labels == roi1)[0]\n",
    "\n",
    "        if (len(idx0) > 0 and len(idx1) > 0):\n",
    "            data0_l = np.load(pow_name.format(su,'E','low'))['xpow'][freq,idx0,17:47,:]       \n",
    "            data0_h = np.load(pow_name.format(su,'E','high'))['xpow'][freq,idx0,17:47,:]\n",
    "            data0_l = np.concatenate(data0_l,axis=-1)\n",
    "            data0_h = np.concatenate(data0_h,axis=-1)\n",
    "\n",
    "            data1_l = np.load(pow_name.format(su,'E','low'))['xpow'][freq,idx1,17:47,:]       \n",
    "            data1_h = np.load(pow_name.format(su,'E','high'))['xpow'][freq,idx1,17:47,:]\n",
    "            data1_l = np.concatenate(data1_h,axis=-1)\n",
    "            data1_h = np.concatenate(data1_h,axis=-1)\n",
    "\n",
    "            tpsER_l, _ = tpsim_btw_cond(data0_l,data1_l)\n",
    "            print('low',np.mean(tpsER_l)) \n",
    "            tpsER_h, _ = tpsim_btw_cond(data0_h,data1_h)    \n",
    "            print('high',np.mean(tpsER_h))\n",
    "            tpsER_all = np.concatenate((tpsER_l,tpsER_h))\n",
    "\n",
    "            T_l, p_l = ttest_1samp(tpsER_l,1)      \n",
    "            T_h, p_h = ttest_1samp(tpsER_h,1)\n",
    "            T_all, p_all = ttest_1samp(tpsER_all,1)\n",
    "            print('correlation for {} in {} and {}'.format(su,roi0,roi1))\n",
    "            print('Tests Low, T={}, p={}'.format(round(T_l,2),round(p_l,3)))\n",
    "            print('Tests High, T={}, p={}\\n'.format(round(T_h,2),round(p_h,3)))\n",
    "            #print('Tests ALL, R={}, p={}'.format(round(T_all,2),round(p_all,3)))\n",
    "        else:\n",
    "            print('roi missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test whether Temporal patterns are correlated btw regions during E or R\n",
    "ADD DELAY TO CHECK FOR TIME DIFFERENCE IN PATTERNS\n",
    "\"\"\"\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from brainpipe.system import study\n",
    "from scipy.stats import spearmanr, ttest_1samp\n",
    "from itertools import combinations\n",
    "\n",
    "st = study('Olfacto')\n",
    "elecs_d = ['PIRJ','SEMC','VACJ','FERJ','LEFC']\n",
    "freq = 0\n",
    "conds = ['low','high']\n",
    "pow_path = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_cond/')\n",
    "pow_name = join(pow_path,'Pow_{}_{}_{}_allfreqs.npz')\n",
    "path_df = join(st.path, 'figure/TPSim_LDA_E_by_cond_3s/')\n",
    "dfname = join(path_df, '2_all_subjects_info_elecs_AUC_Signif_th_0.001_mean_corr_all_11.csv')\n",
    "rois = ['aHC','pPirT']\n",
    "\n",
    "for su in elecs_d:\n",
    "    for roi0, roi1 in product(rois,rois):\n",
    "        if roi0 != roi1:\n",
    "            df = pd.read_csv(dfname)\n",
    "            labels = df.loc[df['subjects'] == su]['s_Mai_RL'].values\n",
    "            idx0 = np.where(labels == roi0)[0]\n",
    "            idx1 = np.where(labels == roi1)[0]\n",
    "            print(su, roi0, roi1)\n",
    "\n",
    "            if (len(idx0) > 0 and len(idx1) > 0):\n",
    "                for d in range(5):\n",
    "                    print(roi0, \"being delayed of {} win\".format(d))\n",
    "                    data0_l = np.load(pow_name.format(su,'E','low'))['xpow'][freq,idx0,17+d:47+d,:]       \n",
    "                    data0_h = np.load(pow_name.format(su,'E','high'))['xpow'][freq,idx0,17+d:47+d,:]\n",
    "                    data0_l = np.concatenate(data0_l,axis=-1)\n",
    "                    data0_h = np.concatenate(data0_h, axis=-1)\n",
    "\n",
    "                    data1_l = np.load(pow_name.format(su,'E','low'))['xpow'][freq,idx1,17:47,:]       \n",
    "                    data1_h = np.load(pow_name.format(su,'E','high'))['xpow'][freq,idx1,17:47,:]\n",
    "                    data1_l = np.concatenate(data1_l,axis=-1)\n",
    "                    data1_h = np.concatenate(data1_h,axis=-1)\n",
    "\n",
    "                    tpsER_l, _ = tpsim_btw_cond(data0_l,data1_l)\n",
    "                    print('low',np.mean(tpsER_l)) \n",
    "                    tpsER_h, _ = tpsim_btw_cond(data0_h,data1_h)    \n",
    "                    print('high',np.mean(tpsER_h))\n",
    "                    tpsER_all = np.concatenate((tpsER_l,tpsER_h))\n",
    "\n",
    "                    T_l, p_l = ttest_1samp(tpsER_l,1)      \n",
    "                    T_h, p_h = ttest_1samp(tpsER_h,1)\n",
    "                    T_all, p_all = ttest_1samp(tpsER_all,1)\n",
    "                    print('correlation for {} in {} and {}'.format(su,roi0,roi1))\n",
    "                    print('Tests Low, T={}, p={}'.format(round(T_l,2),round(p_l,3)))\n",
    "                    print('Tests High, T={}, p={}\\n'.format(round(T_h,2),round(p_h,3)))\n",
    "                    #print('Tests ALL, R={}, p={}'.format(round(T_all,2),round(p_all,3))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpsim_by_cond(pow1, pow_data, average=False):\n",
    "    \"\"\"\n",
    "    Compute tpsim within one condition for all combinations\n",
    "    Parameters\n",
    "    ----------\n",
    "    pow1 : array (npts x ntrials)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tpsim : array\n",
    "    \"\"\"\n",
    "    \n",
    "    pow_data = dataE if pow_data is None else pow_data\n",
    "    sim_trials = np.array([])\n",
    "    pow_trials = np.array([])\n",
    "    for t0, t1 in combinations(np.arange(pow1.shape[-1]),2):\n",
    "        R, _ = stats.spearmanr(pow1[:,t0],pow1[:,t1])\n",
    "        sim_trials = np.vstack((sim_trials,1-R)) if np.size(sim_trials) else 1-R\n",
    "        pow_trials = np.vstack((pow_trials,pow_data[:,t0])) if np.size(pow_trials) else pow_data[:,t0]\n",
    "    if np.size(sim_trials) == 1:\n",
    "        sim_trials = np.array([[sim_trials]])\n",
    "        pow_trials = np.array([[pow_trials]])\n",
    "    else:\n",
    "        sim_trials = sim_trials.swapaxes(0,1)\n",
    "        pow_trials = pow_trials.swapaxes(0,1)\n",
    "    if average == True:\n",
    "        sim_trials = np.mean(sim_trials)\n",
    "        pow_trials = np.mean(pow_trials)\n",
    "    return sim_trials, pow_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check whether the strength of TPSim values (reinstatement or retrieval) is related to \n",
    "power values during encoding in aHC\n",
    "Correlations by electrode and patient for 2 sig patients (LEFC & PIRJ)\n",
    "We take average values by odor\n",
    "\"\"\"\n",
    "\n",
    "from os import listdir\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns \n",
    "\n",
    "st = study('Olfacto')\n",
    "exp, roi_sel, freq = 'E_R', 'IFG', 'high_gamma'\n",
    "fnames = ['delta', 'theta', 'alpha', 'beta', 'low_gamma', 'high_gamma']\n",
    "i_freq = [i for i,f in enumerate(fnames) if f == freq]\n",
    "path_tps = join(st.path, 'feature/TPSim_Ret_By_Odor_By_Cond/TPS_by_odor/')\n",
    "path_df = join(st.path, 'figure/TPSim_LDA_E_by_cond_3s/')\n",
    "dfname = join(path_df, '2_all_subjects_info_elecs_AUC_Signif_th_0.001_mean_corr_all_11.csv')\n",
    "path_pow = join(st.path, 'feature/TPSim_power_data/Power_all_elecs_E_R_by_odor/')\n",
    "pow_name = join(path_pow, '{}_odor{}_{}_pow{}.npz')\n",
    "###############################################################################\n",
    "#dict_ = {'FERJ':[\"b2-b1\",\"b6-b5\"], 'PIRJ':[\"b'4-b'3\"], 'VACJ':[\"b3-b2\"]} #aHC\n",
    "#dict_ = {'FERJ':[\"b2-b1\",\"b6-b5\",\"b3-b2\",\"b'5-b'4\"],\n",
    "#         'PIRJ':[\"b'4-b'3\"], 'VACJ':[\"b3-b2\",\"b'2-b'1\"], 'SEMC':[\"b5-b4\"]} #aHC 10e-2\n",
    "#dict_ = {'FERJ':[\"o9-o8\",\"o10-o9\"], 'SEMC':[\"j2-j1\"], 'VACJ':[\"k'13-k'12\"]} #IFG\n",
    "#dict_ = {'FERJ':[\"o9-o8\",\"o10-o9\",\"o8-o7\"], 'SEMC':[\"j2-j1\"], 'VACJ':[\"k'13-k'12\"]} #IFG 10e-2\n",
    "#dict_ = {'LEFC':[\"o4-o3\"], 'SEMC':[\"o5-o4\",\"o6-o5\"], 'PIRJ':[\"o5-o4\"]} #OFC\n",
    "#dict_ = {'LEFC':[\"o4-o3\",\"o6-o5\"], 'SEMC':[\"o5-o4\",\"o6-o5\",\"o7-o6\"], 'PIRJ':[\"o5-o4\"]} #OFC 10e-2\n",
    "dict_ = {'FERJ':[\"a3-a2\",\"j2-j1\"], 'VACJ':[\"d'2-d'1\"]} #PirC 10e-2\n",
    "###############################################################################\n",
    "rois = ['aHC']\n",
    "odors_su = {'CHAF': {5:12,7:68,8:36,9:96,1:6,2:2,3:68,4:8},\n",
    "            'LEFC': {1:4,2:0,3:6,4:12,14:96,15:2,16:4,17:68},\n",
    "            'PIRJ': {4:36,9:2,1:4,18:32,6:34,5:4,7:68}, #missing odor 15\n",
    "            'VACJ': {14:6,15:64,16:68,17:8,10:6,11:4,12:4,13:40},\n",
    "            'SEMC': {10:2,11:6,12:6,13:6,5:8,7:4,8:8,9:10},\n",
    "            'FERJ': {16:6,17:6,5:8,7:6,12:8,13:8,2:6,1:10}}\n",
    "\n",
    "ALL_TPS, ALL_POW = [], []\n",
    "for su in elecs_tps:\n",
    "    for elec in elecs_tps[su]:\n",
    "        all_pow, all_tps = [], []\n",
    "        for od in odors_su[su]:\n",
    "            tps_od = np.load(path_tps+'TPS_spear_{}_odor_{}_{}_3s.npz'.format(su,\n",
    "                                                                od,freq))['tps'][elec,:]\n",
    "            mean_tps = np.mean(tps_od)\n",
    "            \n",
    "            for roi in rois:\n",
    "                df = pd.read_csv(dfname)\n",
    "                labels = df.loc[df['subjects'] == su]['s_Mai_RL'].values\n",
    "                idx = np.where(labels == roi)[0]\n",
    "                pow_roi = np.load(pow_name.format(su,od,'E',freq))['xpow'][idx,17:47,:]    \n",
    "                \n",
    "                mean_pow = np.mean(pow_roi)\n",
    "#                 mean_pow = np.mean(pow_roi,axis=(1,2))\n",
    "                all_tps.append(mean_tps)\n",
    "#                 all_tps.append(np.repeat(mean_tps,len(idx)))\n",
    "                all_pow.append(mean_pow)\n",
    "#                 ALL_TPS.append(np.repeat(mean_tps,len(idx)))\n",
    "#                 ALL_POW.append(mean_pow)\n",
    "#         R,p = spearmanr(np.concatenate(all_pow),np.concatenate(all_tps))\n",
    "        R,p = pea(all_pow,all_tps)\n",
    "        print(su, R, p)\n",
    "#         sns.regplot(x=np.concatenate(all_pow), y=np.concatenate(all_tps));\n",
    "        sns.regplot(x=all_pow, y=all_tps);\n",
    "# R_all, p_all = spearmanr(np.concatenate(ALL_POW),np.concatenate(ALL_TPS))\n",
    "# print('ALL', R_all, p_all)\n",
    "# sns.regplot(x=np.concatenate(ALL_POW),y=np.concatenate(ALL_TPS));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
