{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the list of rois to create the global matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 (6,)\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "###############################################################################################\n",
    "path = r'/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/'\n",
    "path_df = join(path,'Bilan_classif/2_signif_elecs_patients/')\n",
    "path2save = join(path,'Bilan_classif/3_Figures/')\n",
    "###############################################################################################\n",
    "\n",
    "freqs = ['2_theta','6_gamma2']#['1_delta','2_theta','3_alpha','4_beta','5_gamma1','6_gamma2']#\n",
    "option = '75' #'all'\n",
    "classif = 'all'\n",
    "\n",
    "if classif == 'all':\n",
    "    conds = {'0':['good','bad',4,5],'1':['poor','partial',4,5],'2':['partial','detailed',3,4],\n",
    "     '3':['poor','detailed',3,4]}\n",
    "if classif == 'obj':\n",
    "    conds = {'1':['poor','partial',4,5],'2':['partial','detailed',3,4],\n",
    "     '3':['poor','detailed',3,4]}\n",
    "\n",
    "#Create the list of rois to create the global matrix\n",
    "roi60, roi75 = np.array([]), np.array([])\n",
    "\n",
    "if option =='75':\n",
    "    for cond in conds:\n",
    "        for freq in freqs:\n",
    "            filename75 = path_df+cond+'_Classif_'+conds[cond][0]+'_'+conds[cond][1]+'_'+freq+'_win3_patients'+str(conds[cond][3])+'.csv'\n",
    "            if isfile(filename75):\n",
    "                df75 = pd.read_csv(filename75)\n",
    "                roi75 = np.hstack((roi75,df75['s_aal_RL'].values)) if np.size(roi75) else df75['s_aal_RL'].values\n",
    "    roi_all = np.unique(roi75)\n",
    "    \n",
    "if option =='all':\n",
    "    for cond in conds:\n",
    "        for freq in freqs:\n",
    "            filename60 = path_df+cond+'_Classif_'+conds[cond][0]+'_'+conds[cond][1]+'_'+freq+'_win3_patients'+str(conds[cond][2])+'.csv'\n",
    "            filename75 = path_df+cond+'_Classif_'+conds[cond][0]+'_'+conds[cond][1]+'_'+freq+'_win3_patients'+str(conds[cond][3])+'.csv'\n",
    "        if isfile(filename60):\n",
    "            df60 = pd.read_csv(filename60)\n",
    "            roi60 = np.hstack((roi60,df60['s_aal_RL'].values)) if np.size(roi60) else df60['s_aal_RL'].values\n",
    "        if isfile(filename75):\n",
    "            df75 = pd.read_csv(filename75)\n",
    "            roi75 = np.hstack((roi75,df75['s_aal_RL'].values)) if np.size(roi75) else df75['s_aal_RL'].values\n",
    "    roi60, roi75 = np.unique(roi60), np.unique(roi75)\n",
    "    roi60 = np.delete(roi60,np.where(roi60=='Not f'),axis=0)\n",
    "    roi75 = np.delete(roi75,np.where(roi75=='Not f'),axis=0)\n",
    "    roi_all = np.unique(np.concatenate((roi60,roi75), axis=0))\n",
    "print(option,roi_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FEATURE MATRIX by participant\n",
    "    Power, DA, Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the boolean matrix to show only regions sig in at least 60% of patients\n",
    "da_mat, pow_mat, time_mat = np.array([]),np.array([]),np.array([])\n",
    "x_freq, x_cond = [], []\n",
    "subjects = ['FERJ','MICP','VACJ','SEMC','LEFC','PIRJ','CHAF']\n",
    "feats = ['da','time','pow_change']\n",
    "groupby = 'cond'\n",
    "\n",
    "for cond,freq in product(sorted(conds),freqs[:]): #trick to impose iteration order for conds & freqs\n",
    "    x_cond.append(conds[cond][0][:2].capitalize()+'/'+conds[cond][1][:2].capitalize())\n",
    "    filename60 = path_df+cond+'_Classif_'+conds[cond][0]+'_'+conds[cond][1]+'_'+freq+'_win3_patients'+str(conds[cond][2])+'.csv'\n",
    "    sig60, data = pd.read_csv(filename60), np.array([])\n",
    "    sig60['pow_change']= (sig60['pow0']-sig60['pow1'])/sig60['pow1']\n",
    "    gr = sig60.groupby(['s_aal_RL','su_codes'])\n",
    "    sel = gr[feats].agg(('max','min','mean'))\n",
    "    da, time, rel_change = np.array([]), np.array([]), np.array([])\n",
    "    for roi in roi_all:\n",
    "        df_roi = sel[sel.index.get_level_values(0)==roi]\n",
    "        da_val = df_roi.filter(like='da').filter(like='max').mean().values\n",
    "        time_val = df_roi.filter(like='time').filter(like='mean').mean().values\n",
    "        pow_min = df_roi.filter(like='pow_change').filter(like='min').mean().values\n",
    "        pow_max = df_roi.filter(like='pow_change').filter(like='max').mean().values\n",
    "        rel_change_val = []\n",
    "        if abs(pow_min[0])>abs(pow_max[0]):\n",
    "            rel_change_val = pow_min\n",
    "        elif abs(pow_min[0])<abs(pow_max[0]):\n",
    "            rel_change_val = pow_max\n",
    "        elif abs(pow_min[0])==abs(pow_max[0]):\n",
    "            rel_change_val = pow_max\n",
    "        elif np.isnan(pow_min):\n",
    "            rel_change_val = [np.nan]\n",
    "        #print('value for',roi,pow_min, pow_max,rel_change_val, da_val, time_val)\n",
    "        \n",
    "        da = np.hstack((da,da_val)) if np.size(da) else da_val\n",
    "        time = np.hstack((time,time_val)) if np.size(time) else time_val\n",
    "        rel_change = np.hstack((rel_change,rel_change_val)) if np.size(rel_change) else rel_change_val\n",
    "        #print('vector',len(da),len(time),len(rel_change))\n",
    "    da_mat = np.vstack((da_mat,da)) if np.size(da_mat) else da\n",
    "    time_mat = np.vstack((time_mat,time)) if np.size(time_mat) else time\n",
    "    pow_mat = np.vstack((pow_mat,rel_change)) if np.size(pow_mat) else rel_change\n",
    "    #print('vector',len(da_mat),len(time_mat),len(pow_mat))\n",
    "da_mat,time_mat, pow_mat = da_mat.T, time_mat.T, pow_mat.T\n",
    "_, idx = np.unique(x_cond,return_index=True) #to keep order\n",
    "x_cond = [x_cond[i] for i in sorted(idx)]\n",
    "print(da_mat.shape, time_mat.shape, pow_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from confusion_matrix import plot_confusion_matrix\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "freqnames = ['θ','γ2']\n",
    "codes = {0:['da',plt.cm.BuPu,1],\n",
    "         1:['time',plt.cm.YlGn,1],\n",
    "         2:['pow_change',plt.cm.seismic,2]}\n",
    "feats_mat = [da_mat, time_mat, pow_mat]\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "for i,mat in enumerate(feats_mat):\n",
    "    print(i, len(mat))\n",
    "    groups = len(np.unique(x_cond))\n",
    "    print(groups, x_cond)\n",
    "    nconds = len(np.unique(x_cond))\n",
    "    plot_confusion_matrix(mat, xtickslabels1=freqnames*groups, xtickslabels2=x_cond, \n",
    "        ytickslabels=roi_all,cmap=codes[i][1], ylabel='Regions',size=(12,5),cbsides=codes[i][2])\n",
    "    plot_name = path2save+'Matrix_recap_'+codes[i][0]+'_by_'+groupby+'_'+str(nconds)+'conds_rois'+option+'.png'\n",
    "    plt.savefig(plot_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
