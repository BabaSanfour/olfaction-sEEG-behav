{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from brainpipe.system import study\n",
    "from utils import odor_list_su, rename_elecs\n",
    "from scipy.stats import ttest_ind, ttest_1samp\n",
    "from mne.stats import fdr_correction, bonferroni_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n"
     ]
    }
   ],
   "source": [
    "\"\"\"create diff wth - btw by odor and by Memory Richness conditions\"\"\"\n",
    "st = study('Olfacto')\n",
    "exp = 'Enc'#'Enc'\n",
    "freq = 'theta' #freqname in filename\n",
    "path_pow = path.join(st.path, 'feature/TPSim_3groups_'+exp+'/')\n",
    "path_save = path.join(path_pow, 'by_cont_{}_v=1_elecs=all/')\n",
    "filename = path.join(path_save, 'TPS_pears_{}_odor{}_{}_{}.npz')\n",
    "\n",
    "for su in odor_list_su(exp):\n",
    "    for od in odor_list_su(exp)[su]:\n",
    "        mat_wth = np.load(filename.format('wth',su,od,'wth',freq),allow_pickle=True)\n",
    "        tps_wth = mat_wth['tps']\n",
    "        tps_btw = np.load(filename.format('btw',su,od,'btw',freq))['tps']\n",
    "        diff = tps_wth - np.mean(tps_btw,axis=1)[:,np.newaxis]\n",
    "        \n",
    "        dict_save = {}\n",
    "        for file in mat_wth.files:\n",
    "            dict_save[file] = mat_wth[file] if file != 'tps' else diff\n",
    "        if not path.exists(path_save.format('diff')):\n",
    "            makedirs(path_save.format('diff'))\n",
    "        np.savez(filename.format('diff',su,od,'diff',freq),**dict_save)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "CHAF 2 low (61, 15) (61, 15)\n",
      "CHAF 8 mid (61, 30) (61, 30)\n",
      "CHAF 3 high (61, 15) (61, 15)\n",
      "CHAF 7 high (61, 36) (61, 51)\n",
      "CHAF 9 high (61, 40) (61, 91)\n",
      "VACJ 10 low (39, 27) (39, 27)\n",
      "VACJ 11 low (39, 27) (39, 54)\n",
      "VACJ 14 low (39, 21) (39, 75)\n",
      "VACJ 12 mid (39, 20) (39, 20)\n",
      "VACJ 17 mid (39, 16) (39, 36)\n",
      "VACJ 16 high (39, 21) (39, 21)\n",
      "VACJ 13 high (39, 32) (39, 53)\n",
      "VACJ 15 high (39, 16) (39, 69)\n",
      "SEMC 10 low (53, 140) (53, 140)\n",
      "SEMC 7 low (53, 36) (53, 176)\n",
      "SEMC 13 low (53, 170) (53, 346)\n",
      "SEMC 11 mid (53, 92) (53, 92)\n",
      "SEMC 12 mid (53, 126) (53, 218)\n",
      "SEMC 5 high (53, 30) (53, 30)\n",
      "SEMC 9 high (53, 30) (53, 60)\n",
      "SEMC 8 high (53, 30) (53, 90)\n",
      "PIRJ 9 low (18, 96) (18, 96)\n",
      "PIRJ 1 low (18, 105) (18, 201)\n",
      "PIRJ 18 mid (18, 85) (18, 85)\n",
      "PIRJ 4 mid (18, 72) (18, 157)\n",
      "LEFC 2 low (27, 50) (27, 50)\n",
      "LEFC 1 low (27, 26) (27, 76)\n",
      "LEFC 16 low (27, 384) (27, 460)\n",
      "LEFC 15 mid (27, 319) (27, 319)\n",
      "LEFC 3 mid (27, 44) (27, 363)\n",
      "LEFC 4 high (27, 44) (27, 44)\n",
      "LEFC 17 high (27, 231) (27, 275)\n",
      "LEFC 14 high (27, 204) (27, 479)\n",
      "FERJ 16 low (32, 45) (32, 45)\n",
      "FERJ 17 low (32, 81) (32, 126)\n",
      "FERJ 12 low (32, 36) (32, 162)\n",
      "FERJ 7 mid (32, 45) (32, 45)\n",
      "FERJ 13 mid (32, 30) (32, 75)\n",
      "FERJ 5 high (32, 45) (32, 45)\n",
      "FERJ 2 high (32, 22) (32, 67)\n",
      "FERJ 1 high (32, 36) (32, 103)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"concat diff wth - btw into Low Mid High conditions\"\"\"\n",
    "from utils import odor_groups_3wgth\n",
    "\n",
    "st = study('Olfacto')\n",
    "exp = 'Enc'#'Enc'\n",
    "freq = 'theta' #freqname in filename\n",
    "path_pow = path.join(st.path, 'feature/TPSim_3groups_'+exp+'/')\n",
    "filename = path.join(path_pow, 'by_cont_{}_v=1_elecs=all/TPS_pears_{}_odor{}_{}_{}.npz')\n",
    "savename = path.join(path_pow, 'by_cont_{}_v=1_elecs=all/TPS_pears_{}_{}_{}_{}.npz')\n",
    "\n",
    "for su in odor_groups_3wgth:\n",
    "    for cond in odor_groups_3wgth[su]:\n",
    "        tps_data = np.array([])\n",
    "        for od in odor_groups_3wgth[su][cond]:\n",
    "            if int(od) in odor_list_su(exp)[su]:\n",
    "                mat = np.load(filename.format('diff',su,od,'diff',freq),allow_pickle=True)\n",
    "                tps_data = np.concatenate((tps_data, mat['tps']),axis=-1) if np.size(tps_data) else mat['tps']\n",
    "                print(su, od, cond, mat['tps'].shape,tps_data.shape)\n",
    "        dict_tps = {}\n",
    "        for file in mat.files:\n",
    "            dict_tps[file] = mat[file]\n",
    "        dict_tps['xpow'] = tps_data\n",
    "        np.savez(savename.format('diff',su,cond,'diff',freq),**dict_tps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_CHAF_odor7_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (61, 36)\n",
      "btw (61, 32)\n",
      "CHAF 7 61 (61, 36) (61,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_CHAF_odor8_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (61, 30)\n",
      "btw (61, 24)\n",
      "CHAF 8 61 (61, 30) (61,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_CHAF_odor9_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (61, 40)\n",
      "btw (61, 40)\n",
      "CHAF 9 61 (61, 40) (61,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_CHAF_odor2_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (61, 15)\n",
      "btw (61, 39)\n",
      "CHAF 2 61 (61, 15) (61,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_CHAF_odor3_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (61, 15)\n",
      "btw (61, 39)\n",
      "CHAF 3 61 (61, 15) (61,)\n",
      "CHAF theta wth (61, 136) btw (61, 174) diff (61, 136)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_LEFC_odor1_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (27, 26)\n",
      "btw (27, 80)\n",
      "LEFC 1 27 (27, 26) (27,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_LEFC_odor2_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (27, 50)\n",
      "btw (27, 200)\n",
      "LEFC 2 27 (27, 50) (27,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_LEFC_odor3_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (27, 44)\n",
      "btw (27, 160)\n",
      "LEFC 3 27 (27, 44) (27,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_LEFC_odor4_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (27, 44)\n",
      "btw (27, 160)\n",
      "LEFC 4 27 (27, 44) (27,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_LEFC_odor14_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (27, 204)\n",
      "btw (27, 90)\n",
      "LEFC 14 27 (27, 204) (27,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_LEFC_odor15_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (27, 319)\n",
      "btw (27, 165)\n",
      "LEFC 15 27 (27, 319) (27,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_LEFC_odor16_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (27, 384)\n",
      "btw (27, 240)\n",
      "LEFC 16 27 (27, 384) (27,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_LEFC_odor17_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (27, 231)\n",
      "btw (27, 105)\n",
      "LEFC 17 27 (27, 231) (27,)\n",
      "LEFC theta wth (27, 1302) btw (27, 1200) diff (27, 1302)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_PIRJ_odor4_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (18, 72)\n",
      "btw (18, 84)\n",
      "PIRJ 4 18 (18, 72) (18,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_PIRJ_odor9_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (18, 96)\n",
      "btw (18, 126)\n",
      "PIRJ 9 18 (18, 96) (18,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_PIRJ_odor1_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (18, 105)\n",
      "btw (18, 147)\n",
      "PIRJ 1 18 (18, 105) (18,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_PIRJ_odor18_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (18, 85)\n",
      "btw (18, 105)\n",
      "PIRJ 18 18 (18, 85) (18,)\n",
      "PIRJ theta wth (18, 358) btw (18, 462) diff (18, 358)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_VACJ_odor14_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (39, 21)\n",
      "btw (39, 36)\n",
      "VACJ 14 39 (39, 21) (39,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_VACJ_odor15_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (39, 16)\n",
      "btw (39, 24)\n",
      "VACJ 15 39 (39, 16) (39,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_VACJ_odor16_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (39, 21)\n",
      "btw (39, 36)\n",
      "VACJ 16 39 (39, 21) (39,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_VACJ_odor17_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (39, 16)\n",
      "btw (39, 24)\n",
      "VACJ 17 39 (39, 16) (39,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_VACJ_odor10_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (39, 27)\n",
      "btw (39, 30)\n",
      "VACJ 10 39 (39, 27) (39,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_VACJ_odor11_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (39, 27)\n",
      "btw (39, 30)\n",
      "VACJ 11 39 (39, 27) (39,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_VACJ_odor12_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (39, 20)\n",
      "btw (39, 20)\n",
      "VACJ 12 39 (39, 20) (39,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_VACJ_odor13_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (39, 32)\n",
      "btw (39, 40)\n",
      "VACJ 13 39 (39, 32) (39,)\n",
      "VACJ theta wth (39, 180) btw (39, 240) diff (39, 180)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_SEMC_odor10_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (53, 140)\n",
      "btw (53, 91)\n",
      "SEMC 10 53 (53, 140) (53,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_SEMC_odor11_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (53, 92)\n",
      "btw (53, 52)\n",
      "SEMC 11 53 (53, 92) (53,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_SEMC_odor12_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (53, 126)\n",
      "btw (53, 78)\n",
      "SEMC 12 53 (53, 126) (53,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_SEMC_odor13_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (53, 170)\n",
      "btw (53, 130)\n",
      "SEMC 13 53 (53, 170) (53,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_SEMC_odor5_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (53, 30)\n",
      "btw (53, 81)\n",
      "SEMC 5 53 (53, 30) (53,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_SEMC_odor7_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (53, 36)\n",
      "btw (53, 108)\n",
      "SEMC 7 53 (53, 36) (53,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_SEMC_odor8_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (53, 30)\n",
      "btw (53, 81)\n",
      "SEMC 8 53 (53, 30) (53,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_SEMC_odor9_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (53, 30)\n",
      "btw (53, 81)\n",
      "SEMC 9 53 (53, 30) (53,)\n",
      "SEMC theta wth (53, 654) btw (53, 702) diff (53, 654)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_FERJ_odor16_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (32, 45)\n",
      "btw (32, 39)\n",
      "FERJ 16 32 (32, 45) (32,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_FERJ_odor17_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (32, 81)\n",
      "btw (32, 117)\n",
      "FERJ 17 32 (32, 81) (32,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_FERJ_odor5_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (32, 45)\n",
      "btw (32, 39)\n",
      "FERJ 5 32 (32, 45) (32,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_FERJ_odor7_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (32, 45)\n",
      "btw (32, 39)\n",
      "FERJ 7 32 (32, 45) (32,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_FERJ_odor12_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (32, 36)\n",
      "btw (32, 72)\n",
      "FERJ 12 32 (32, 36) (32,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_FERJ_odor13_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (32, 30)\n",
      "btw (32, 54)\n",
      "FERJ 13 32 (32, 30) (32,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_FERJ_odor2_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (32, 22)\n",
      "btw (32, 36)\n",
      "FERJ 2 32 (32, 22) (32,)\n",
      "/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_3groups_Enc/by_cont_wth_v=1_elecs=all/TPS_pears_FERJ_odor1_wth_theta.npz ['tps', 'pval', 'label', 'channel', 'xyz']\n",
      "wth (32, 36)\n",
      "btw (32, 72)\n",
      "FERJ 1 32 (32, 36) (32,)\n",
      "FERJ theta wth (32, 340) btw (32, 468) diff (32, 340)\n",
      "(230, 22)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Ttests for significance of Wth - Btw and Diff consistancy\"\"\"\n",
    "st = study('Olfacto')\n",
    "exp = 'Enc'#'Enc'\n",
    "exp2 = 'Enc'\n",
    "freqs = ['theta'] #freqname in filename\n",
    "path_pow = path.join(st.path, 'feature/TPSim_3groups_'+exp+'/')\n",
    "filename = path.join(path_pow, 'by_cont_{}_v=1_elecs=all/TPS_pears_{}_odor{}_{}_{}.npz')\n",
    "save_path = path.join(path_pow, 'Ttest_cont_identity_v=1_elecs=all/')\n",
    "if not path.exists(save_path):\n",
    "    makedirs(save_path)\n",
    "df_name = path.join(save_path, '{}_Ttests_1samp_{}_{}_fsf.csv') #su, conds0, conds1, freq\n",
    "rois_sel = ['aHC','MFG','ACC','IFG','Amg','pPirT','PHG','Ins_olf','OFC_olf','SFG']\n",
    "\n",
    "for freq in freqs:\n",
    "    subjects_c, elecs_c, labels_c = np.array([]), np.array([]), np.array([])\n",
    "    channels_c, x_c, y_c, z_c = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "    tps0_c, tps1_c, tps2_c = np.array([]), np.array([]), np.array([])\n",
    "    T_vals_c_wth, T_vals_c_btw, T_vals_c_diff = np.array([]), np.array([]), np.array([])\n",
    "    p_vals_c_wth, p_fdr_c_wth, p_bf_c_wth = np.array([]), np.array([]), np.array([])\n",
    "    p_vals_c_btw, p_fdr_c_btw, p_bf_c_btw = np.array([]), np.array([]), np.array([])\n",
    "    p_vals_c_diff, p_fdr_c_diff, p_bf_c_diff = np.array([]), np.array([]), np.array([])\n",
    "    \n",
    "    for su in odor_list_su(exp2):\n",
    "        #diff tps => wth_tps - btw tps (averaged) nelecs x ncombs\n",
    "        wth_tps, btw_tps, diff_tps = np.array([]), np.array([]), np.array([])\n",
    "        for od in odor_list_su(exp2)[su]:\n",
    "            #load within and between data by odor\n",
    "            mat0 = np.load(filename.format('wth',su,od,'wth',freq),allow_pickle=True)\n",
    "            print(filename.format('wth',su,od,'wth',freq),mat0.files)\n",
    "            print('wth',mat0['tps'].shape)\n",
    "            tps_btw = np.load(filename.format('btw',su,od,'btw',freq))['tps']\n",
    "            print('btw',tps_btw.shape)\n",
    "            mean_btw = np.mean(tps_btw,axis=-1)[:,np.newaxis]\n",
    "            diff_ = mat0['tps'] - mean_btw\n",
    "            \n",
    "            #select electrodes\n",
    "            labels, channels = mat0['label'], mat0['channel']\n",
    "            x, y, z = mat0['xyz'][:,0], mat0['xyz'][:,1], mat0['xyz'][:,2]\n",
    "            labels_new = rename_elecs(labels,x,y,z)\n",
    "            idx_sel = [i for i,lab in enumerate(labels_new) if lab in rois_sel]\n",
    "            nelecs = len(idx_sel)\n",
    "            print(su,od,nelecs,mat0['tps'].shape,mat0['channel'].shape)\n",
    "            labels, channels = labels_new[idx_sel], channels[idx_sel]\n",
    "            x, y, z = x[idx_sel], y[idx_sel], z[idx_sel]\n",
    "            \n",
    "            #select electrodes and concatenate data\n",
    "            wth_tps = np.concatenate((wth_tps,mat0['tps'][idx_sel,:]),axis=-1) if np.size(wth_tps) else mat0['tps'][idx_sel,:]\n",
    "            btw_tps = np.concatenate((btw_tps,tps_btw[idx_sel,:]),axis=-1) if np.size(btw_tps) else tps_btw[idx_sel,:]\n",
    "            diff_tps = np.concatenate((diff_tps,diff_[idx_sel,:]),axis=-1) if np.size(diff_tps) else diff_[idx_sel,:]\n",
    "        \n",
    "        print(su,freq,'wth',wth_tps.shape,'btw',btw_tps.shape,'diff',diff_tps.shape)\n",
    "        \n",
    "        #compute stats for all similarities compared to 0\n",
    "        wth_tps, btw_tps = wth_tps.swapaxes(0,1), btw_tps.swapaxes(0,1) #ntrials x nelecs\n",
    "        diff_tps = diff_tps.swapaxes(0,1)\n",
    "\n",
    "        Tvals_wth, unc_p_wth = ttest_1samp(wth_tps, 0.0, axis=0)\n",
    "        Tvals_btw, unc_p_btw = ttest_1samp(btw_tps, 0.0, axis=0)\n",
    "        Tvals_diff, unc_p_diff = ttest_1samp(diff_tps, 0.0, axis=0)\n",
    "        \n",
    "        #as it is a one sided one sample t-test (only interested in positive values)\n",
    "        unc_p_wth, unc_p_btw, unc_p_diff = unc_p_wth/2, unc_p_btw/2, unc_p_diff/2\n",
    "        _, p_fdr_wth = fdr_correction(unc_p_wth)\n",
    "        _, p_fdr_btw = fdr_correction(unc_p_btw)\n",
    "        _, p_fdr_diff = fdr_correction(unc_p_diff)\n",
    "        _, p_bf_wth = bonferroni_correction(unc_p_wth)\n",
    "        _, p_bf_btw = bonferroni_correction(unc_p_btw)\n",
    "        _, p_bf_diff = bonferroni_correction(unc_p_diff)\n",
    "\n",
    "        #Fill the csv file with elec infos and stats\n",
    "        subjects_c = np.hstack((subjects_c,np.array([su]*nelecs))) if np.size(subjects_c) else np.array([su]*nelecs)\n",
    "        elecs_c = np.hstack((elecs_c,np.arange(nelecs))) if np.size(elecs_c) else np.arange(nelecs)\n",
    "        labels_c = np.hstack((labels_c,labels)) if np.size(labels_c) else labels\n",
    "        channels_c = np.hstack((channels_c,channels)) if np.size(channels_c) else channels\n",
    "        x_c = np.hstack((x_c,x)) if np.size(x_c) else x\n",
    "        y_c = np.hstack((y_c,y)) if np.size(y_c) else y\n",
    "        z_c = np.hstack((z_c,z)) if np.size(z_c) else z\n",
    "        \n",
    "        tps0_c = np.hstack((tps0_c,np.mean(wth_tps, axis=0))) if np.size(tps0_c) else np.mean(wth_tps, axis=0)\n",
    "        tps1_c = np.hstack((tps1_c,np.mean(btw_tps, axis=0))) if np.size(tps1_c) else np.mean(btw_tps, axis=0)\n",
    "        tps2_c = np.hstack((tps2_c,np.mean(diff_tps, axis=0))) if np.size(tps2_c) else np.mean(diff_tps, axis=0)\n",
    "        \n",
    "        T_vals_c_wth = np.hstack((T_vals_c_wth,Tvals_wth)) if np.size(T_vals_c_wth) else Tvals_wth\n",
    "        T_vals_c_btw = np.hstack((T_vals_c_btw,Tvals_btw)) if np.size(T_vals_c_btw) else Tvals_btw\n",
    "        T_vals_c_diff = np.hstack((T_vals_c_diff,Tvals_diff)) if np.size(T_vals_c_diff) else Tvals_diff\n",
    "        \n",
    "        p_vals_c_wth = np.hstack((p_vals_c_wth,unc_p_wth)) if np.size(p_vals_c_wth) else unc_p_wth\n",
    "        p_vals_c_btw = np.hstack((p_vals_c_btw,unc_p_btw)) if np.size(p_vals_c_btw) else unc_p_btw\n",
    "        p_vals_c_diff = np.hstack((p_vals_c_diff,unc_p_diff)) if np.size(p_vals_c_diff) else unc_p_diff\n",
    "        \n",
    "        p_fdr_c_wth = np.hstack((p_fdr_c_wth,p_fdr_wth)) if np.size(p_fdr_c_wth) else p_fdr_wth\n",
    "        p_fdr_c_btw = np.hstack((p_fdr_c_btw,p_fdr_btw)) if np.size(p_fdr_c_btw) else p_fdr_btw\n",
    "        p_fdr_c_diff = np.hstack((p_fdr_c_diff,p_fdr_diff)) if np.size(p_fdr_c_diff) else p_fdr_diff\n",
    "        \n",
    "        p_bf_c_wth = np.hstack((p_bf_c_wth,p_bf_wth)) if np.size(p_bf_c_wth) else p_bf_wth\n",
    "        p_bf_c_btw = np.hstack((p_bf_c_btw,p_bf_btw)) if np.size(p_bf_c_btw) else p_bf_btw\n",
    "        p_bf_c_diff = np.hstack((p_bf_c_diff,p_bf_diff)) if np.size(p_bf_c_diff) else p_bf_diff\n",
    "        \n",
    "    data = np.concatenate((subjects_c[:,np.newaxis],labels_c[:,np.newaxis],\n",
    "                channels_c[:,np.newaxis],x_c[:,np.newaxis],y_c[:,np.newaxis],\n",
    "                z_c[:,np.newaxis],elecs_c[:,np.newaxis],\n",
    "                tps0_c[:,np.newaxis], tps1_c[:,np.newaxis], tps2_c[:,np.newaxis],\n",
    "                T_vals_c_wth[:,np.newaxis],p_vals_c_wth[:,np.newaxis],p_fdr_c_wth[:,np.newaxis],p_bf_c_wth[:,np.newaxis],\n",
    "                T_vals_c_btw[:,np.newaxis],p_vals_c_btw[:,np.newaxis],p_fdr_c_btw[:,np.newaxis],p_bf_c_btw[:,np.newaxis],\n",
    "                T_vals_c_diff[:,np.newaxis],p_vals_c_diff[:,np.newaxis],p_fdr_c_diff[:,np.newaxis], p_bf_c_diff[:,np.newaxis]),axis=1)\n",
    "    df = pd.DataFrame(data, columns=['subjects','labels','channels','x','y','z','elecs_num',\n",
    "                'tps_wth', 'tps_btw', 'tps_diff','Tvals_wth','unc_wth','fdr_wth','bonf_wth',\n",
    "                'Tvals_btw','unc_btw','fdr_btw','bonf_btw','Tvals_diff','unc_diff','fdr_diff',\n",
    "                'bonf_diff'])\n",
    "    print(df.shape)\n",
    "    df.to_csv(df_name.format('All_subjects','by_cont_wth_btw_diff',freq),index=False)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial df shape (230, 22) Index(['subjects', 'labels', 'channels', 'x', 'y', 'z', 'elecs_num', 'tps_wth',\n",
      "       'tps_btw', 'tps_diff', 'Tvals_wth', 'unc_wth', 'fdr_wth', 'bonf_wth',\n",
      "       'Tvals_btw', 'unc_btw', 'fdr_btw', 'bonf_btw', 'Tvals_diff', 'unc_diff',\n",
      "       'fdr_diff', 'bonf_diff'],\n",
      "      dtype='object')\n",
      "\n",
      " stats at p <  0.05 correction :  fdr_ (14, 23)\n",
      "Counter({'aHC': 7, 'MFG': 2, 'IFG': 1, 'OFC_olf': 1, 'ACC': 1, 'pPirT': 1, 'Ins_olf': 1})\n",
      "aHC NB of subjects with SIMILAR 3  subjects\n",
      "#electrodes in total >>>  7\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from os import path\n",
    "\n",
    "fold, freq = 'Enc', 'theta'\n",
    "olf_regions = ['Amg','pPirT','OFC_olf']\n",
    "\n",
    "path_file = path.join(st.path, 'feature/TPSim_3groups_'+fold+'/Ttest_cont_identity_v=1_elecs=all/')\n",
    "df_name = path.join(path_file, 'All_subjects_Ttests_1samp_by_cont_wth_btw_diff_'+freq+'_fsf.csv') #su, conds0, conds1, freq\n",
    "df_save = path.join(path_file, 'Bilan_All_subjects_Ttests_1samp_{}_{}_'+freq+'.csv')\n",
    "df_init = pd.read_csv(df_name)\n",
    "print('Initial df shape', df_init.shape,df_init.columns)\n",
    "\n",
    "thrs = [0.05]\n",
    "corrections = ['fdr_']\n",
    "\n",
    "for th, corr in product(thrs,corrections):\n",
    "    df = df_init.loc[(df_init['tps_wth']>0) & (df_init['tps_btw']>0) & (df_init['tps_diff']>0)]\n",
    "    #df_sel = df.loc[(df[corr+'wth']<th) & (df[corr+'btw']<th) & (df[corr+'diff']<th)] #& (df[corr+'btw']<th)\n",
    "    #df = df_init.loc[(df_init['tps_wth']>0)]\n",
    "    df_sel = df.loc[(df[corr+'wth']<th)&(df[corr+'diff']<th)]\n",
    "    df_sel['sign'] = ['similar' if t > 0 else 'different' for t in df_sel['Tvals_diff']]\n",
    "    print('\\n stats at p < ',th, 'correction : ',corr, df_sel.shape)\n",
    "    print(Counter(df_sel['labels']))\n",
    "        \n",
    "    rois = np.unique(df_sel['labels'])\n",
    "    for roi in rois:\n",
    "        if roi == 'Amg':\n",
    "            roi = 'Amg_pPirT'\n",
    "            df_roi = df_sel.loc[df_sel['labels'].isin(['Amg','pPirT'])]\n",
    "        elif roi != 'Amg':\n",
    "            df_roi = df_sel.loc[df_sel['labels']==roi]\n",
    "        df_inc = df_roi.loc[df_roi['sign']=='different'].groupby(['subjects']).count()\n",
    "        df_dec = df_roi.loc[df_roi['sign']=='similar'].groupby(['subjects']).count()\n",
    "           \n",
    "        if (df_dec.shape[0] >= 3) or (df_dec.shape[0] >=2 and roi in olf_regions):\n",
    "            print(roi, 'NB of subjects with SIMILAR',df_dec.shape[0],' subjects')\n",
    "            df_plot = df_roi.loc[df_roi['sign']=='similar']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "            #print(df_plot)\n",
    "            df_plot.to_csv(df_save.format(roi,corr+str(th)))\n",
    "            df_all = df.loc[df['labels']==roi]\n",
    "        if roi == 'OFC_olf':\n",
    "            df_all.to_csv(df_save.format(roi,corr+str(th)).replace('.csv','_all_elecs.csv'))\n",
    "            #if roi in ['Amg_pPirT','pPirT']:\n",
    "                #print(df_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early/Late effect on uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = study('Olfacto')\n",
    "exp = 'Enc'#'Enc'\n",
    "exp2 = 'Enc'\n",
    "freqs = ['theta'] #freqname in filename\n",
    "path_pow = path.join(st.path, 'feature/TPSim_3groups_'+exp+'/')\n",
    "filename = path.join(path_pow, \n",
    "            'by_odor_{}_thgh_time_v=1_elecs=all/TPS_pears_learn_{}_{}_{}_{}_2gr.npz')\n",
    "save_path = path.join(path_pow, 'Ttest_odor_identity_v=1_elecs=all/')\n",
    "if not path.exists(save_path):\n",
    "    makedirs(save_path)\n",
    "df_name = path.join(save_path, '{}_Ttests_1samp_{}_{}_learn2gr.csv') #su, conds0, conds1, freq\n",
    "rois_sel = ['aHC','MFG','ACC','IFG','Amg','pPirT','PHG','Ins_olf','OFC_olf','SFG']\n",
    "\n",
    "for freq in freqs:\n",
    "    subjects_c, elecs_c, labels_c = np.array([]), np.array([]), np.array([])\n",
    "    channels_c, x_c, y_c, z_c = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "    tps0_c, tps1_c, tps2_c, tps3_c = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "    tps4_c, tps5_c, T_vals_c_diff = np.array([]), np.array([]), np.array([])\n",
    "    p_vals_c_diff, p_fdr_c_diff, p_bf_c_diff = np.array([]), np.array([]), np.array([])\n",
    "    \n",
    "    for su in odor_list_su(exp2):\n",
    "        #diff tps => wth_tps - btw tps (averaged) nelecs x ncombs\n",
    "        wth_tps0, btw_tps0, diff_tps0 = np.array([]), np.array([]), np.array([])\n",
    "        wth_tps1, btw_tps1, diff_tps1 = np.array([]), np.array([]), np.array([])\n",
    "        for od in odor_list_su(exp2)[su]:\n",
    "            #load within and between data by odor\n",
    "            mat0 = np.load(filename.format('wth',su,'wth',freq,od),allow_pickle=True)\n",
    "            print(filename.format('wth',su,od,'wth',freq),mat0.files)\n",
    "            print('wth0',mat0['tps_0'].shape, mat0['tps_1'].shape)\n",
    "            wth0, wth1 = mat0['tps_0'], mat0['tps_1']\n",
    "            \n",
    "            if wth0.shape[0] > 0: #make sure that odors have an E and L TPSim\n",
    "            \n",
    "                mat1 = np.load(filename.format('btw',su,'btw',od,freq),allow_pickle=True)\n",
    "                print(mat1.files)\n",
    "                btw0, btw1 = mat1['tps_0'], mat1['tps_1']\n",
    "                print('btw',btw0.shape, btw1.shape)\n",
    "                mean_btw0 = np.mean(btw0,axis=-1)[:,np.newaxis]\n",
    "                mean_btw1 = np.mean(btw1,axis=-1)[:,np.newaxis]\n",
    "\n",
    "                diff_0 = wth0 - mean_btw0\n",
    "                diff_1 = wth1 - mean_btw1\n",
    "\n",
    "                #select electrodes\n",
    "                labels, channels = mat0['label'], mat0['channel']\n",
    "                x, y, z = mat0['xyz'][:,0], mat0['xyz'][:,1], mat0['xyz'][:,2]\n",
    "                labels_new = rename_elecs(labels,x,y,z)\n",
    "                idx_sel = [i for i,lab in enumerate(labels_new) if lab in rois_sel]\n",
    "                nelecs = len(idx_sel)\n",
    "                print(su,od,nelecs,mat0['tps_0'].shape,mat0['channel'].shape)\n",
    "                labels, channels = labels_new[idx_sel], channels[idx_sel]\n",
    "                x, y, z = x[idx_sel], y[idx_sel], z[idx_sel]\n",
    "\n",
    "                #select electrodes and concatenate data\n",
    "                wth_tps0 = np.concatenate((wth_tps0,wth0[idx_sel,:]),axis=-1) \\\n",
    "                                                if np.size(wth_tps0) else wth0[idx_sel,:]\n",
    "                wth_tps1 = np.concatenate((wth_tps1,wth1[idx_sel,:]),axis=-1) \\\n",
    "                                                if np.size(wth_tps1) else wth1[idx_sel,:]\n",
    "                btw_tps0 = np.concatenate((btw_tps0,btw0[idx_sel,:]),axis=-1) \\\n",
    "                                                if np.size(btw_tps0) else btw0[idx_sel,:]\n",
    "                btw_tps1 = np.concatenate((btw_tps1,btw1[idx_sel,:]),axis=-1) \\\n",
    "                                                if np.size(btw_tps1) else btw1[idx_sel,:]\n",
    "                diff_tps0 = np.concatenate((diff_tps0,diff_0[idx_sel,:]),axis=-1) \\\n",
    "                                                if np.size(diff_tps0) else diff_0[idx_sel,:]\n",
    "                diff_tps1 = np.concatenate((diff_tps1,diff_1[idx_sel,:]),axis=-1) \\\n",
    "                                                if np.size(diff_tps1) else diff_1[idx_sel,:]\n",
    "\n",
    "        print(su,freq,'0 wth',wth_tps0.shape,'btw',btw_tps0.shape,'diff',diff_tps0.shape)\n",
    "        print(su,freq,'1 wth',wth_tps1.shape,'btw',btw_tps1.shape,'diff',diff_tps1.shape)\n",
    "        \n",
    "        #compute stats for all similarities compared to 0\n",
    "        wth_tps0, wth_tps1 = wth_tps0.swapaxes(0,1), wth_tps1.swapaxes(0,1) #ntrials x nelecs\n",
    "        btw_tps0, btw_tps1 = btw_tps0.swapaxes(0,1), btw_tps1.swapaxes(0,1) #ntrials x nelecs\n",
    "        diff_tps0, diff_tps1 = diff_tps0.swapaxes(0,1), diff_tps1.swapaxes(0,1) #ntrials x nelecs\n",
    "        Tvals_diff, unc_p_diff = ttest_ind(diff_tps0, diff_tps1, axis=0)\n",
    "        \n",
    "        #as it is a one sided one sample t-test (only interested in positive values)\n",
    "        _, p_fdr_diff = fdr_correction(unc_p_diff)\n",
    "        _, p_bf_diff = bonferroni_correction(unc_p_diff)\n",
    "        \n",
    "        #Fill the csv file with elec infos and stats\n",
    "        subjects_c = np.hstack((subjects_c,np.array([su]*nelecs))) if np.size(subjects_c) else np.array([su]*nelecs)\n",
    "        elecs_c = np.hstack((elecs_c,np.arange(nelecs))) if np.size(elecs_c) else np.arange(nelecs)\n",
    "        labels_c = np.hstack((labels_c,labels)) if np.size(labels_c) else labels\n",
    "        channels_c = np.hstack((channels_c,channels)) if np.size(channels_c) else channels\n",
    "        x_c = np.hstack((x_c,x)) if np.size(x_c) else x\n",
    "        y_c = np.hstack((y_c,y)) if np.size(y_c) else y\n",
    "        z_c = np.hstack((z_c,z)) if np.size(z_c) else z\n",
    "        \n",
    "        tps0_c = np.hstack((tps0_c,np.mean(wth_tps0, axis=0))) if np.size(tps0_c) \\\n",
    "                                                            else np.mean(wth_tps0, axis=0)\n",
    "        tps1_c = np.hstack((tps1_c,np.mean(wth_tps1, axis=0))) if np.size(tps1_c) \\\n",
    "                                                            else np.mean(wth_tps1, axis=0)\n",
    "        tps2_c = np.hstack((tps2_c,np.mean(btw_tps0, axis=0))) if np.size(tps2_c) \\\n",
    "                                                            else np.mean(btw_tps0, axis=0)\n",
    "        tps3_c = np.hstack((tps3_c,np.mean(btw_tps1, axis=0))) if np.size(tps3_c) \\\n",
    "                                                            else np.mean(btw_tps1, axis=0)\n",
    "        tps4_c = np.hstack((tps4_c,np.mean(diff_tps0, axis=0))) if np.size(tps4_c) \\\n",
    "                                                            else np.mean(diff_tps0, axis=0)\n",
    "        tps5_c = np.hstack((tps5_c,np.mean(diff_tps1, axis=0))) if np.size(tps5_c) \\\n",
    "                                                            else np.mean(diff_tps1, axis=0)\n",
    "        \n",
    "        T_vals_c_diff = np.hstack((T_vals_c_diff,Tvals_diff)) if np.size(T_vals_c_diff) else Tvals_diff\n",
    "        p_vals_c_diff = np.hstack((p_vals_c_diff,unc_p_diff)) if np.size(p_vals_c_diff) else unc_p_diff\n",
    "        p_fdr_c_diff = np.hstack((p_fdr_c_diff,p_fdr_diff)) if np.size(p_fdr_c_diff) else p_fdr_diff\n",
    "        p_bf_c_diff = np.hstack((p_bf_c_diff,p_bf_diff)) if np.size(p_bf_c_diff) else p_bf_diff\n",
    "    \n",
    "    print(subjects_c.shape,labels_c.shape, channels_c.shape,tps0_c.shape)\n",
    "    data = np.concatenate((subjects_c[:,np.newaxis],labels_c[:,np.newaxis],\n",
    "                channels_c[:,np.newaxis],x_c[:,np.newaxis],y_c[:,np.newaxis],\n",
    "                z_c[:,np.newaxis],elecs_c[:,np.newaxis],\n",
    "                tps0_c[:,np.newaxis], tps1_c[:,np.newaxis], tps2_c[:,np.newaxis],\n",
    "                tps3_c[:,np.newaxis], tps4_c[:,np.newaxis], tps5_c[:,np.newaxis],\n",
    "                T_vals_c_diff[:,np.newaxis],p_vals_c_diff[:,np.newaxis],\n",
    "                p_fdr_c_diff[:,np.newaxis], p_bf_c_diff[:,np.newaxis]),axis=1)\n",
    "    df = pd.DataFrame(data, columns=['subjects','labels','channels','x','y','z','elecs_num',\n",
    "                'tps_wth0', 'tps_wth1', 'tps_btw0', 'tps_btw1', 'tps_diff0','tps_diff1',\n",
    "                'Tvals_diff','unc_diff','fdr_diff','bonf_diff'])\n",
    "    print(df.shape)\n",
    "    df.to_csv(df_name.format('All_subjects','by_odor_wth_btw_diff',freq),index=False)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Find significant electrodes for Early Late effects among GLOBAL SIGNIF ELECS\"\"\"\n",
    "from collections import Counter\n",
    "from os import path\n",
    "\n",
    "############################################################################################\n",
    "fold, freq = 'Enc', 'theta'\n",
    "path_file = path.join(st.path, 'feature/TPSim_3groups_'+fold+'/Ttest_odor_identity_v=1_elecs=all/')\n",
    "df_name_global = path.join(path_file, 'All_subjects_Ttests_1samp_by_odor_wth_btw_diff_'+freq+'.csv') #su, conds0, conds1, freq\n",
    "df_name_learn = path.join(path_file, 'All_subjects_Ttests_1samp_by_odor_wth_btw_diff_'+freq+'_learn2gr.csv') #su, conds0, conds1, freq\n",
    "df_save = path.join(path_file, 'Bilan_All_subjects_Ttests_1samp_{}_{}_'+freq+'_learn.csv')\n",
    "############################################################################################\n",
    "thrs = [0.05]\n",
    "corrections = ['fdr'] #'bf'\n",
    "\n",
    "for th, corr in product(thrs,corrections):\n",
    "    df_init = pd.read_csv(df_name_global)\n",
    "    df_learn = pd.read_csv(df_name_learn)\n",
    "    df_init['learn_'+corr] = df_learn['unc_diff']\n",
    "    print('Initial df shape', df_init.shape,df_init.columns)\n",
    "    print('Learn df shape', df_learn.shape,df_learn.columns)\n",
    "\n",
    "    #select significant electrodes for GLOBAL\n",
    "    df = df_init.loc[(df_init['tps_wth']>0) & (df_init['tps_btw']>0) & (df_init['tps_diff']>0)]\n",
    "    df_sel = df.loc[(df[corr+'_wth']<th) & (df[corr+'_btw']<th) & (df[corr+'_diff']<th)\\\n",
    "                   & (df_init['learn_'+corr]<th)] #& (df[corr+'btw']<th)\n",
    "    \n",
    "    #df_sel = df.loc[(df[corr+'btw']<th)]\n",
    "    df_sel['sign'] = ['similar' if t > 0 else 'different' for t in df_sel['Tvals_diff']]\n",
    "    print('\\n stats at p < ',th, 'correction : ',corr, df_sel.shape)\n",
    "    print(Counter(df_sel['labels']))\n",
    "    print(df_sel)\n",
    "        \n",
    "    rois = np.unique(df_sel['labels'])\n",
    "    for roi in rois:\n",
    "        if roi == 'Amg':\n",
    "            roi = 'Amg_pPirT'\n",
    "            df_roi = df_sel.loc[df_sel['labels'].isin(['Amg','pPirT'])]\n",
    "        elif roi != 'Amg':\n",
    "            df_roi = df_sel.loc[df_sel['labels']==roi]\n",
    "        df_inc = df_roi.loc[df_roi['sign']=='different'].groupby(['subjects']).count()\n",
    "        df_dec = df_roi.loc[df_roi['sign']=='similar'].groupby(['subjects']).count()\n",
    "\n",
    "        if (df_inc.shape[0] >= 3) :#or (df_inc.shape[0] >=2 and roi in olf_regions):\n",
    "            print(roi, 'NB of subjects with DIFFERENT',df_inc.shape[0],' subjects')\n",
    "            df_plot = df_roi.loc[df_roi['sign']=='different']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "            #df_plot.to_csv(df_save.format(roi,corr+str(th)))\n",
    "            #print(df_plot)\n",
    "            \n",
    "        if (df_dec.shape[0] >= 3) :#or (df_dec.shape[0] >=1 and roi in olf_regions):\n",
    "            print(roi, 'NB of subjects with SIMILAR',df_dec.shape[0],' subjects')\n",
    "            df_plot = df_roi.loc[df_roi['sign']=='similar']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "            print(df_plot)\n",
    "            \n",
    "            #df_plot.to_csv(df_save.format(roi,corr+str(th)))\n",
    "            #if roi in ['Amg','pPirT']:\n",
    "                #print(df_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "Bilan_All_subjects_Ttests_1samp_aHC_fdr_0.05_theta.csv\n",
      ">>>> processing  Bilan_All_subjects_Ttests_1samp_aHC_fdr_0.05_theta.csv aHC\n",
      ">>>> 5 subjects significant in 1st analysis\n",
      "['FERJ' 'LEFC' 'PIRJ' 'SEMC' 'VACJ']\n",
      "not enough trials VACJ\n",
      "nb of subjects sig Low High 4\n",
      "aHC ['FERJ' 'LEFC' 'PIRJ' 'SEMC'] ['FERJ' 'LEFC' 'PIRJ' 'SEMC']\n",
      "Bilan_All_subjects_Ttests_1samp_Amg_pPirT_fdr_0.05_theta.csv\n",
      ">>>> processing  Bilan_All_subjects_Ttests_1samp_Amg_pPirT_fdr_0.05_theta.csv Amg\n",
      ">>>> 3 subjects significant in 1st analysis\n",
      "['FERJ' 'LEFC' 'VACJ']\n",
      "not enough trials VACJ\n",
      "nb of subjects sig Low High 0\n",
      "Amg ['FERJ' 'LEFC'] []\n",
      "Bilan_All_subjects_Ttests_1samp_IFG_fdr_0.05_theta.csv\n",
      ">>>> processing  Bilan_All_subjects_Ttests_1samp_IFG_fdr_0.05_theta.csv IFG\n",
      ">>>> 3 subjects significant in 1st analysis\n",
      "['FERJ' 'SEMC' 'VACJ']\n",
      "not enough trials VACJ\n",
      "nb of subjects sig Low High 1\n",
      "IFG ['FERJ' 'SEMC'] ['SEMC']\n",
      "Bilan_All_subjects_Ttests_1samp_MFG_fdr_0.05_theta.csv\n",
      ">>>> processing  Bilan_All_subjects_Ttests_1samp_MFG_fdr_0.05_theta.csv MFG\n",
      ">>>> 4 subjects significant in 1st analysis\n",
      "['CHAF' 'LEFC' 'SEMC' 'VACJ']\n",
      "not enough trials VACJ\n",
      "nb of subjects sig Low High 1\n",
      "MFG ['SEMC'] ['SEMC']\n",
      "Bilan_All_subjects_Ttests_1samp_OFC_olf_fdr_0.05_theta.csv\n",
      ">>>> processing  Bilan_All_subjects_Ttests_1samp_OFC_olf_fdr_0.05_theta.csv OFC_olf\n",
      ">>>> 4 subjects significant in 1st analysis\n",
      "['LEFC' 'PIRJ' 'SEMC' 'VACJ']\n",
      "not enough trials VACJ\n",
      "nb of subjects sig Low High 3\n",
      "OFC_olf ['LEFC' 'PIRJ' 'SEMC'] ['LEFC' 'PIRJ' 'SEMC']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ttests 2-samples comparing Low and High (Wth-btw)\n",
    "ONLY for ELECS signif in the first analysis (Wth Btw and Wth-Btw)\n",
    "Load Mid but select Low and High for stats\n",
    "\"\"\"\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from os import path\n",
    "import pingouin as pg\n",
    "from utils import odor_groups_3wgth\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "############################################################################################\n",
    "st = study('Olfacto')\n",
    "fold, freq = 'Enc', 'theta'\n",
    "path_df = path.join(st.path, 'feature/TPSim_3groups_'+fold+'/Ttest_odor_identity_v=1_elecs=all/')\n",
    "path_data = path.join(st.path, 'feature/TPSim_3groups_'+fold+'/by_odor_{}_v=1_elecs=all/')\n",
    "filename = path.join(path_data, 'TPS_pears_{}_{}_diff_theta.npz')\n",
    "############################################################################################\n",
    "corr = 'fdr'\n",
    "conds = ['low','mid','high']\n",
    "files = st.search('Bilan_All_subjects_Ttests_1samp',\n",
    "              folder='feature/TPSim_3groups_'+fold+'/Ttest_odor_identity_v=1_elecs=all/')\n",
    "dict_score = {'low':0, 'mid':1, 'high':2}\n",
    "features = ['diff_low','diff_mid','diff_high']\n",
    "\n",
    "for fi in files:\n",
    "    print(fi)\n",
    "    if corr in fi.split('_'):\n",
    "        roi = fi.split('_')[5]\n",
    "        roi = 'OFC_olf' if roi == 'OFC' else roi\n",
    "        #if roi in ['OFC','aHC','Amg']:\n",
    "        print('>>>> processing ',fi, roi)\n",
    "        df = pd.read_csv(path_df+fi)\n",
    "        _, idx = np.unique(df['subjects'], return_index=True)\n",
    "        subjects = df['subjects'][np.sort(idx)]\n",
    "        print('>>>> {} subjects significant in 1st analysis'.format(len(subjects)))\n",
    "        print(np.unique(subjects))\n",
    "        pvals, Tvals, subj, chans = [], [], [], []\n",
    "        tps_low, tps_high, sem_low, sem_high = [], [], [], []\n",
    "        tps_mid, sem_mid = [], []\n",
    "        for su in subjects:\n",
    "            #print(su)\n",
    "            df_su = df.loc[df['subjects']==su]\n",
    "            chans_df = df_su['channels'].values\n",
    "\n",
    "            all_su_tps = []\n",
    "            for cond in conds:\n",
    "                mat = np.load(filename.format('diff',su,cond),allow_pickle=True)\n",
    "                idx = [i for i,chan in enumerate(mat['channel']) if chan in chans_df]\n",
    "                \n",
    "                #To take all electrodes within an ROI\n",
    "                #if roi != 'Amg':\n",
    "                    #idx = [i for i,lab in enumerate(mat['label']) if lab == roi]\n",
    "                #if roi == 'Amg':\n",
    "                    #idx = [i for i,lab in enumerate(mat['label']) if lab in ['Amg','pPirT']]\n",
    "                channels = mat['channel'][idx]\n",
    "                data = mat['tps'][idx,:]\n",
    "                all_su_tps.append(data)\n",
    "                \n",
    "            if all_su_tps[-1].shape[-1] > 1: #pass subjects without enough trials\n",
    "                for elec in range(len(idx)):\n",
    "                    df_ = pd.DataFrame()\n",
    "                    df_['tps'] = np.concatenate([x[elec] for x in all_su_tps])\n",
    "                    df_['mem_score'] = np.concatenate([[cond]*x.shape[1] for cond,x in zip(conds,all_su_tps)])\n",
    "                    df_['mem_val'] = df_['mem_score'].map(dict_score)\n",
    "                    df_ = df_.loc[df_['mem_score']!='mid']\n",
    "\n",
    "                    ttests = pg.pairwise_gameshowell(data=df_, dv='tps',\n",
    "                                                    tail='one-sided',between='mem_score') \n",
    "                    stats_ = np.round(ttests['T'].values,3),np.round(ttests['pval'].values,3)\n",
    "                    pvals.append(stats_[1]), Tvals.append(stats_[0])\n",
    "                    subj.append(su), chans.append(channels[elec])\n",
    "                    tps_low.append(np.mean(all_su_tps[0][elec]))\n",
    "                    tps_mid.append(np.mean(all_su_tps[1][elec]))\n",
    "                    tps_high.append(np.mean(all_su_tps[2][elec]))\n",
    "                    sem_low.append(stats.sem(all_su_tps[0][elec]))\n",
    "                    sem_mid.append(stats.sem(all_su_tps[1][elec]))\n",
    "                    sem_high.append(stats.sem(all_su_tps[2][elec]))\n",
    "            \n",
    "            else :#VACJ for aHC\n",
    "                print('not enough trials',su)\n",
    "                #print('low ',su,roi,np.mean(all_su_tps[0]))\n",
    "                #print('high ',su,roi,np.mean(all_su_tps[2]))\n",
    "                #print('sem low ',su,roi,stats.sem(all_su_tps[0]))\n",
    "                #print('sem high ',su,roi,stats.sem(all_su_tps[2]))\n",
    "                    \n",
    "        pvals = [p if not math.isnan(p) else 1 for p in pvals]\n",
    "        _, pvals_fdr = fdr_correction(pvals)\n",
    "        _, pvals_bonf = bonferroni_correction(pvals)\n",
    "        \n",
    "        subj, chans = np.array(subj),np.array(chans)\n",
    "        tps_low, tps_high, Tvals = np.array(tps_low),np.array(tps_high), np.array(Tvals)\n",
    "        sem_low, sem_high, pvals = np.array(sem_low),np.array(sem_high),np.array(pvals)\n",
    "        sem_mid, tps_mid = np.array(sem_mid),np.array(tps_mid)\n",
    "        \n",
    "        data_final = np.concatenate([subj[:,np.newaxis],chans[:,np.newaxis],\n",
    "                tps_low[:,np.newaxis], sem_low[:,np.newaxis],\n",
    "                tps_mid[:,np.newaxis], sem_mid[:,np.newaxis],\n",
    "                tps_high[:,np.newaxis],sem_high[:,np.newaxis],\n",
    "                Tvals,pvals,pvals_fdr,pvals_bonf],axis=1)\n",
    "        \n",
    "        df = pd.DataFrame(data_final, columns=['subjects','channels',\n",
    "                    'tps_low', 'sem_low', 'tps_mid', 'sem_mid','tps_high', 'sem_high', \n",
    "                    'Tvals_diff','unc_diff','fdr_diff','bonf_diff'])\n",
    "        df['fdr_diff'] = df['fdr_diff'].astype(float)\n",
    "        df['Tvals_diff'] = df['Tvals_diff'].astype(float)\n",
    "        df_sig = df.loc[(df['fdr_diff']<0.05)&(df['Tvals_diff']>0)]\n",
    "        df_all = df.loc[(df['Tvals_diff']>0)]\n",
    "        su_all, su_sig = np.unique(df_all['subjects']), np.unique(df_sig['subjects'])\n",
    "        print('nb of subjects sig Low High', df_sig.groupby(['subjects']).count().shape[0])\n",
    "        print(roi, su_all, su_sig)\n",
    "        if set(su_all) == set(su_sig):\n",
    "            df_sig.to_csv(path_df+fi.replace('1samp','Low_High_final_sig_elecs'))        \n",
    "        else:\n",
    "            df_sig.to_csv(path_df+fi.replace('1samp','Low_High_final_sig_elecs'))        \n",
    "            missing_su = [su for su in su_all if su not in su_sig]\n",
    "            df_not_sig = df_all.loc[df_all['subjects'].isin(missing_su)]\n",
    "            df_not_sig.to_csv(path_df+fi.replace('1samp','Low_High_not_sig_elecs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "not enough trials CHAF aHC [(0, 3), (0, 3), (0, 10)]\n",
      "not enough trials FERJ OFC_olf [(0, 6), (0, 3), (0, 6)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karim/anaconda3/envs/mne_coreg/lib/python3.6/site-packages/numpy/core/_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/karim/anaconda3/envs/mne_coreg/lib/python3.6/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ttests 2-samples comparing Low and High (Wth-btw)\n",
    "FOR ALL SUBJECTS WITH ELECTRODES IN ROIS\n",
    "\"\"\"\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from os import path\n",
    "import pingouin as pg\n",
    "from utils import odor_groups_3wgth\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "############################################################################################\n",
    "st = study('Olfacto')\n",
    "fold, freq = 'Enc', 'theta'\n",
    "path_df = path.join(st.path, 'feature/TPSim_3groups_'+fold+'/Ttest_cont_identity_v=1_elecs=all/')\n",
    "path_data = path.join(st.path, 'feature/TPSim_3groups_'+fold+'/by_cont_{}_v=1_elecs=all/')\n",
    "filename = path.join(path_data, 'TPS_pears_{}_{}_diff_theta.npz')\n",
    "df_save = path.join(path_df, 'Bilan_All_subjects_Ttests_{}_{}_{}.csv')\n",
    "############################################################################################\n",
    "corr, rois = 'fdr', ['aHC','OFC_olf']\n",
    "conds = ['low','mid','high']\n",
    "features = ['diff_low','diff_mid','diff_high']\n",
    "\n",
    "for roi in rois:\n",
    "    subj, chans = [], []\n",
    "    tps_low, tps_high, sem_low, sem_high = [], [], [], []\n",
    "    tps_mid, sem_mid = [], []\n",
    "    for su in odor_groups_3wgth:\n",
    "        all_su_tps = []\n",
    "        for cond in conds:\n",
    "            mat = np.load(filename.format('diff',su,cond),allow_pickle=True)\n",
    "            idx = [i for i,lab in enumerate(mat['label']) if lab == roi]\n",
    "            channels = mat['channel'][idx]\n",
    "            data = mat['tps'][idx,:]\n",
    "            all_su_tps.append(data)\n",
    "\n",
    "        if len(idx) > 0: #pass subjects without enough trials\n",
    "            for elec in range(len(idx)):\n",
    "                subj.append(su), chans.append(channels[elec])\n",
    "                tps_low.append(np.mean(all_su_tps[0][elec]))\n",
    "                tps_mid.append(np.mean(all_su_tps[1][elec]))\n",
    "                tps_high.append(np.mean(all_su_tps[2][elec]))\n",
    "                sem_low.append(stats.sem(all_su_tps[0][elec]))\n",
    "                sem_mid.append(stats.sem(all_su_tps[1][elec]))\n",
    "                sem_high.append(stats.sem(all_su_tps[2][elec]))\n",
    "        else:\n",
    "            print('not enough trials', su, roi, [x.shape for x in all_su_tps])\n",
    "\n",
    "    subj, chans = np.array(subj),np.array(chans)\n",
    "    tps_low, tps_high = np.array(tps_low),np.array(tps_high)\n",
    "    sem_low, sem_high = np.array(sem_low),np.array(sem_high)\n",
    "    sem_mid, tps_mid = np.array(sem_mid),np.array(tps_mid)\n",
    "\n",
    "    data_final = np.concatenate([subj[:,np.newaxis],chans[:,np.newaxis],\n",
    "            tps_low[:,np.newaxis], sem_low[:,np.newaxis],\n",
    "            tps_mid[:,np.newaxis], sem_mid[:,np.newaxis],\n",
    "            tps_high[:,np.newaxis],sem_high[:,np.newaxis]],axis=1)\n",
    "\n",
    "    df = pd.DataFrame(data_final, columns=['subjects','channels',\n",
    "                'tps_low', 'sem_low', 'tps_mid', 'sem_mid','tps_high', 'sem_high'])\n",
    "\n",
    "    df.to_csv(df_save.format('Low_High_all_not_sig',roi,freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results by subject for NOT SIG elecs or SIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "IFG FERJ [0.47251254 0.50797095] [nan nan]\n",
      "Amg_pPirT FERJ [0.3457534  0.58904411] [nan nan]\n",
      "Amg_pPirT LEFC [0.19044021 0.39859797] [nan nan]\n"
     ]
    }
   ],
   "source": [
    "from brainpipe.system import study\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "st = study('Olfacto')\n",
    "PATH = join(st.path, 'feature/TPSim_3groups_{}/Ttest_odor_identity_v=1_elecs=all/')\n",
    "#file_name = join(PATH, 'Bilan_All_subjects_LinReg_all_roi_3gr_{}_fdr_0.05_theta.csv')\n",
    "file_name = join(PATH, 'Bilan_All_subjects_Ttests_Low_High_not_sig_elecs_{}_fdr_0.05_theta.csv')\n",
    "SAVE_PATH = join(PATH, 'Ind_elecs_{}_{}_avg_subj_Ttests_not_sig.png')\n",
    "meth, exp, freq, rois = 'btw', 'Enc', 'theta', ['IFG','Amg_pPirT']\n",
    "features = ['tps_low','tps_high']\n",
    "#features = ['tps_wth','tps_btw','tps_diff']\n",
    "\n",
    "for roi in rois:\n",
    "    df = pd.read_csv(file_name.format(exp,roi))\n",
    "    df_m = df.groupby(['subjects']).agg(['mean','sem'])\n",
    "    nelecs = df_m.shape[0]\n",
    "\n",
    "    fig, axs = plt.subplots(2,4, figsize=(15, 6), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    for i in range(nelecs):\n",
    "        df_sel = df_m.iloc[i,:].unstack().T\n",
    "        #print(df_sel)\n",
    "\n",
    "        su =  df_m.index[i]\n",
    "        data = df_sel[features].iloc[0,:].values\n",
    "#         yerr = df_sd.iloc[i,:][features].values\n",
    "        yerr = df_sel[features].iloc[1,:].values\n",
    "        print(roi, su, data,yerr)\n",
    "\n",
    "        xticks, w = np.arange((len(features))), 0.8\n",
    "        axs[i].set_xticks(xticks,features)\n",
    "        axs[i].bar(xticks,data,yerr=yerr,color='blue')\n",
    "        axs[i].set_title('{} in {}'.format(su,roi))\n",
    "    \n",
    "    plt.setp(axs, ylim=(0,1.)) if roi == 'aHC' else plt.setp(axs, ylim=(0,1.3))\n",
    "    plt.savefig(SAVE_PATH.format(exp,'diff_wth',roi))\n",
    "    plt.savefig(SAVE_PATH.format(exp,'diff_wth',roi).replace('.png','.pdf'))\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot elec number by patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "FERJ 4\n",
      "LEFC 2\n",
      "VACJ 1\n",
      "LEFC 1\n",
      "SEMC 4\n",
      "VACJ 5\n",
      "LEFC 1\n",
      "SEMC 5\n",
      "VACJ 3\n",
      "SEMC 1\n",
      "VACJ 1\n",
      "FERJ 1\n"
     ]
    }
   ],
   "source": [
    "from brainpipe.system import study\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "st = study('Olfacto')\n",
    "PATH = join(st.path, 'feature/TPSim_3groups_{}/Ttest_cont_identity_v=1_elecs=all/')\n",
    "SAVE_PATH = join(PATH, 'Nb_elecs_{}_{}_by_patient_sig.png')\n",
    "meth, exp, freq = 'wth_diff', 'Enc', 'theta'\n",
    "files = st.search('Bilan_wth_Ttests_1samp', folder=PATH.format(exp))\n",
    "\n",
    "for fi in files:\n",
    "    roi = fi.split('_')[-4]\n",
    "    roi = 'OFC_'+roi if roi =='olf' else roi\n",
    "    \n",
    "    df_roi = pd.read_csv(join(PATH.format(exp)+fi))\n",
    "    df_su = df_roi.groupby(['subjects']).count()\n",
    "    \n",
    "    #Plot nb of significant electrodes by win and subjects\n",
    "    colors = {'CHAF':'darkblue', 'FERJ':'royalblue', 'LEFC':'deepskyblue', \n",
    "            'PIRJ':'yellow','SEMC':'darkorange', 'VACJ':'red'}\n",
    "    \n",
    "    xticks, w = np.arange(0,1), 0.5\n",
    "    fig = plt.figure()\n",
    "    bottom = np.zeros(1)\n",
    "    for i,su in enumerate(df_su.index):\n",
    "        count = df_su.iloc[i,0]\n",
    "        print(su, count)\n",
    "        plt.bar(1, count, color=colors[su], label=su, bottom=bottom)\n",
    "        bottom += count\n",
    "    plt.title('Significant electrodes by patient in '+roi)\n",
    "    plt.ylabel('Nb of electrodes')\n",
    "    plt.xticks(xticks,freq)\n",
    "    plt.legend(loc=0,handletextpad=0.1, frameon=False)\n",
    "    plt.savefig(SAVE_PATH.format(exp,meth,roi))\n",
    "    plt.savefig(SAVE_PATH.format(exp,meth,roi).replace('.png','.pdf'))\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot average TPS (wth and wth-btw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n"
     ]
    }
   ],
   "source": [
    "from brainpipe.system import study\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "st = study('Olfacto')\n",
    "PATH = join(st.path, 'feature/TPSim_3groups_{}/Ttest_odor_identity_v=1_elecs=all/')\n",
    "by_subj = False\n",
    "if by_subj == True:\n",
    "    SAVE_PATH = join(PATH, 'TPS_avg_su={}_roi={}_meth={}_freq={}.png')\n",
    "else:\n",
    "    SAVE_PATH = join(PATH, 'TPS_avg_all_su_roi={}_meth={}_freq={}.png')\n",
    "meth, exp, freq = 'wth_diff', 'Enc', 'theta'\n",
    "#features = ['subjects','tps_wth','tps_btw','tps_diff']\n",
    "features = ['subjects','tps_low','tps_high']\n",
    "\n",
    "#files = st.search('Bilan_wth_Ttests_1samp', folder=PATH.format(exp))\n",
    "files = st.search('Bilan_All_subjects_Ttests_Low_High_not_sig_elecs_Amg', folder=PATH.format(exp))\n",
    "\n",
    "for fi in files:\n",
    "    roi = fi.split('_')[-4]\n",
    "    roi = 'OFC_'+roi if roi =='olf' else roi\n",
    "    \n",
    "    df_roi = pd.read_csv(join(PATH.format(exp)+fi))[features]\n",
    "    \n",
    "    if by_subj == True:\n",
    "        means = df_roi.groupby(['subjects']).mean()\n",
    "        stds = df_roi.groupby(['subjects']).sem()\n",
    "        for i,su in enumerate(means.index):\n",
    "            mean, std = means.iloc[i], stds.iloc[i]\n",
    "            xticks, w = np.arange(0,len(rois)), 0.8\n",
    "            fig = plt.figure()\n",
    "            plt.bar(np.arange(2), mean, yerr=std, color='orange', width=w)\n",
    "            plt.title('Average TPS for all sig electrodes in '+roi)\n",
    "            plt.ylabel('Mean TPS')\n",
    "            plt.xticks(xticks,rois)\n",
    "            plt.ylim(0,1)\n",
    "            plt.savefig(SAVE_PATH.format(exp,su,roi,meth,freq))\n",
    "            plt.savefig(SAVE_PATH.format(exp,su,roi,meth,freq).replace('png','pdf'))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "    \n",
    "    elif by_subj == False:\n",
    "        mean, std = df_roi.mean(), df_roi.sem()\n",
    "        xticks, w = np.arange(0,len(features)-1), 0.8\n",
    "        fig = plt.figure()\n",
    "        plt.bar(np.arange(len(features)-1), mean, yerr=std, color='orange', width=w)\n",
    "        plt.title('Average TPS for all sig electrodes in '+roi)\n",
    "        plt.ylabel('Mean TPS')\n",
    "        plt.xticks(xticks,[feat for feat in features if feat != 'subjects'])\n",
    "        plt.ylim(0,1)\n",
    "        plt.savefig(SAVE_PATH.format(exp,roi,meth,freq))\n",
    "        plt.savefig(SAVE_PATH.format(exp,roi,meth,freq).replace('png','pdf'))\n",
    "        plt.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      ">>>> processing  Bilan_All_subjects_Ttests_1samp_aHC_fdr_0.05_theta.csv aHC\n",
      ">>>> 5 subjects significant\n",
      "0     LEFC\n",
      "7     PIRJ\n",
      "11    VACJ\n",
      "17    SEMC\n",
      "20    FERJ\n",
      "Name: subjects, dtype: object\n",
      "INCREASE aHC 4 sig\n",
      ">>>> processing  Bilan_All_subjects_Ttests_1samp_Amg_pPirT_fdr_0.05_theta.csv Amg\n",
      ">>>> 3 subjects significant\n",
      "0    LEFC\n",
      "1    VACJ\n",
      "3    FERJ\n",
      "Name: subjects, dtype: object\n",
      ">>>> processing  Bilan_All_subjects_Ttests_1samp_IFG_fdr_0.05_theta.csv IFG\n",
      ">>>> 3 subjects significant\n",
      "0     VACJ\n",
      "7     SEMC\n",
      "15    FERJ\n",
      "Name: subjects, dtype: object\n",
      ">>>> processing  Bilan_All_subjects_Ttests_1samp_MFG_fdr_0.05_theta.csv MFG\n",
      ">>>> 4 subjects significant\n",
      "0    CHAF\n",
      "4    LEFC\n",
      "5    VACJ\n",
      "9    SEMC\n",
      "Name: subjects, dtype: object\n",
      ">>>> processing  Bilan_All_subjects_Ttests_1samp_OFC_olf_fdr_0.05_theta.csv OFC_olf\n",
      ">>>> 4 subjects significant\n",
      "0    LEFC\n",
      "4    PIRJ\n",
      "7    VACJ\n",
      "8    SEMC\n",
      "Name: subjects, dtype: object\n",
      "INCREASE OFC_olf 2 sig\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Linear Regression of uniqueness with memory richness\n",
    "Only subjects and ROIs with significant results in Wth > Btw \n",
    "Take ALL electrodes within ROI and FDR correct across subjects\n",
    "\"\"\"\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from os import path\n",
    "import pingouin as pg\n",
    "from utils import odor_groups_3wgth\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "############################################################################################\n",
    "st = study('Olfacto')\n",
    "fold, freq = 'Enc', 'theta'\n",
    "path_df = path.join(st.path, 'feature/TPSim_3groups_'+fold+'/Ttest_odor_identity_v=1_elecs=all/')\n",
    "path_data = path.join(st.path, 'feature/TPSim_3groups_'+fold+'/by_odor_{}_v=1_elecs=all/')\n",
    "filename = path.join(path_data, 'TPS_pears_{}_{}_diff_theta.npz')\n",
    "############################################################################################\n",
    "corr = 'fdr'\n",
    "conds = ['low','mid','high']\n",
    "files = st.search('Bilan_All_subjects_Ttests_1samp',\n",
    "              folder='feature/TPSim_3groups_'+fold+'/Ttest_odor_identity_v=1_elecs=all/')\n",
    "dict_score = {'low':0, 'mid':1, 'high':2}\n",
    "features = ['diff_low','diff_mid','diff_high']\n",
    "\n",
    "for fi in files:\n",
    "    if corr in fi.split('_'):\n",
    "        roi = fi.split('_')[5]\n",
    "        roi = 'OFC_olf' if roi == 'OFC' else roi\n",
    "        #if roi in ['OFC','aHC','Amg']:\n",
    "        print('>>>> processing ',fi, roi)\n",
    "        df = pd.read_csv(path_df+fi)\n",
    "        _, idx = np.unique(df['subjects'], return_index=True)\n",
    "        subjects = df['subjects'][np.sort(idx)]\n",
    "        print('>>>> {} subjects significant'.format(len(subjects)))\n",
    "        print(subjects)\n",
    "        pvals, Tvals, subj, chans = [], [], [], []\n",
    "        tps_low, tps_high, sem_low, sem_high = [], [], [], []\n",
    "        tps_mid, sem_mid = [], []\n",
    "        for su in subjects:\n",
    "            df_su = df.loc[df['subjects']==su]\n",
    "            #idx = df_su['elecs_num']\n",
    "            all_su_tps, all_scores = [], []\n",
    "            for cond in conds:\n",
    "                mat = np.load(filename.format('diff',su,cond),allow_pickle=True)\n",
    "                if roi != 'Amg':\n",
    "                    idx_elecs = [i for i,lab in enumerate(mat['label']) if lab == roi]\n",
    "                if roi == 'Amg':\n",
    "                    idx_elecs = [i for i,lab in enumerate(mat['label']) if lab in ['Amg','pPirT']]\n",
    "                channels = mat['channel'][idx_elecs]\n",
    "                data = mat['tps'][idx_elecs,:]\n",
    "                nelecs, ntrials = data.shape\n",
    "                all_su_tps.append(data)\n",
    "                score_ = np.array([dict_score[cond]]*ntrials)\n",
    "                all_scores.append(score_)\n",
    "            \n",
    "            #print([x.shape for x in all_su_tps])\n",
    "            if all_su_tps[-1].shape[-1] > 1: #pass subjects without enough trials\n",
    "                all_tps_concat = np.concatenate(all_su_tps,axis=1)\n",
    "                all_scores_concat = np.concatenate(all_scores,axis=0)\n",
    "                T, unc_p = [], []\n",
    "                for elec in range(nelecs):\n",
    "                    Y = np.array(all_tps_concat[elec])\n",
    "                    X = sm.add_constant(np.array(all_scores_concat))\n",
    "                    model_ols = sm.OLS(Y,X).fit()\n",
    "                    Tval, pval = np.round(model_ols.tvalues[1],3),model_ols.pvalues[1]\n",
    "                    Tvals.append(Tval), pvals.append(pval)\n",
    "    \n",
    "                    subj.append(su), chans.append(channels[elec])\n",
    "                    tps_low.append(np.mean(all_su_tps[0][elec]))\n",
    "                    tps_mid.append(np.mean(all_su_tps[1][elec]))\n",
    "                    tps_high.append(np.mean(all_su_tps[2][elec]))\n",
    "                    sem_low.append(stats.sem(all_su_tps[0][elec]))\n",
    "                    sem_mid.append(stats.sem(all_su_tps[1][elec]))\n",
    "                    sem_high.append(stats.sem(all_su_tps[2][elec]))\n",
    "\n",
    "        _, pvals_fdr = fdr_correction(pvals)\n",
    "        _, pvals_bonf = bonferroni_correction(pvals)\n",
    "        \n",
    "        subj, chans = np.array(subj),np.array(chans)\n",
    "        tps_low, tps_high, Tvals = np.array(tps_low),np.array(tps_high), np.array(Tvals)\n",
    "        sem_low, sem_high, pvals = np.array(sem_low),np.array(sem_high),np.array(pvals)\n",
    "        sem_mid, tps_mid = np.array(sem_mid),np.array(tps_mid)\n",
    "        #print(pvals.shape, pvals_fdr.shape,pvals_bonf.shape, Tvals.shape)\n",
    "        data_final = np.concatenate([subj[:,np.newaxis],chans[:,np.newaxis],\n",
    "                tps_low[:,np.newaxis], sem_low[:,np.newaxis],\n",
    "                tps_mid[:,np.newaxis], sem_mid[:,np.newaxis],\n",
    "                tps_high[:,np.newaxis],sem_high[:,np.newaxis],\n",
    "                Tvals[:,np.newaxis],pvals[:,np.newaxis],\n",
    "                pvals_fdr[:,np.newaxis],pvals_bonf[:,np.newaxis]],axis=1)\n",
    "        \n",
    "        df = pd.DataFrame(data_final, columns=['subjects','channels',\n",
    "                    'tps_low', 'sem_low', 'tps_mid', 'sem_mid','tps_high', 'sem_high', \n",
    "                    'Tvals_diff','unc_diff','fdr_diff','bonf_diff'])\n",
    "        \n",
    "        df['fdr_diff'] = df['fdr_diff'].astype(float)\n",
    "        df['Tvals_diff'] = df['Tvals_diff'].astype(float)\n",
    "        df_sig = df.loc[(df['fdr_diff']<0.05)&(df['Tvals_diff']>0)]\n",
    "        nb_su = df_sig.groupby(['subjects']).count().shape[0]\n",
    "        if nb_su >= 2:\n",
    "            print('INCREASE' ,roi, nb_su, 'sig')\n",
    "            df_sig.to_csv(path_df+fi.replace('Ttests_1samp','LinReg_all_roi_3gr'))            \n",
    "            df.to_csv(path_df+fi.replace('Ttests_1samp','LinReg_all_roi_3gr_all_eles'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ODOR \n",
    "____________________________________\n",
    "/// AT ENCODING\n",
    "wth > 0 btw > 0 AND wth > btw \n",
    "0.05 (Amg/pPirT,aHC,OFC)\n",
    "0.01 (OFC,Amg/PirT)\n",
    "\n",
    "/// AT RETRIEVAL\n",
    "0.05 (Amg/Pir, IFG, Ins, OFC,SFG, aHC)\n",
    "0.01 (Amg/Pir,IFG,SFG,aHC,Ins)\n",
    "\n",
    "/// REINSTATEMENT (even in FDR)\n",
    "nothing sig (distinct representations btw E and R even with the same odor)\n",
    "Wth > 0 (Amg,IFG,OFC)\n",
    "Btw > 0 (IFG, OFC and MFG representation different)\n",
    "Wth > Btw (SFG, IFG)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "CONTEXT\n",
    "__________________________________\n",
    "nothing in Bonferoni \n",
    "fdr 0.05 retrieval OFC (2 patients)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "PLACE \n",
    "__________________________________\n",
    "close/far (3 vs 4) nothing\n",
    "close/far (2 vs 2)\n",
    "at encoding OFC (and at R and ER OFC but one person)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "aHC 4.548683205170504 1.8991468572266996 0.011663920312600549\n",
      "OFC_olf 5.958577811306919 2.2274736085545648 0.013824906833690344\n",
      "Amg_pPirT 5.159190668511457 1.538865214997055 0.020837305251126474\n",
      "IFG 4.46354983458307 1.5579412088879216 0.01637591659046668\n",
      "MFG 4.2313884026634225 1.2148659040910557 0.017312614111290387\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sum-up stats for the results part\"\"\"\n",
    "\n",
    "st = study('Olfacto')\n",
    "exp = 'Enc'#'Enc'\n",
    "path_pow = path.join(st.path, 'feature/TPSim_3groups_'+exp+'/')\n",
    "path_df = path.join(path_pow, 'Ttest_odor_identity_v=1_elecs=all/')\n",
    "df_name = path.join(path_df, 'Bilan_All_subjects_Ttests_1samp_{}_fdr_0.05_theta.csv') #su, conds0, conds1, freq\n",
    "\n",
    "rois = ['aHC','OFC_olf','Amg_pPirT','IFG','MFG']\n",
    "for roi in rois:\n",
    "    df = pd.read_csv(df_name.format(roi))\n",
    "    T_m = df[['Tvals_wth','Tvals_diff']].values.mean()    \n",
    "    T_sd = df[['Tvals_wth','Tvals_diff']].values.std()\n",
    "    p_max = df[['fdr_wth','fdr_diff']].values.max()\n",
    "    print(roi, T_m, T_sd, p_max)\n",
    "    \n",
    "    df_su = df[['subjects','Tvals_wth','Tvals_diff','fdr_wth',\n",
    "                        'fdr_diff']].groupby(['subjects']).agg(['count','mean','std','max'])\n",
    "    df_su.to_csv(df_name.format(roi).replace('.csv','stat_sum.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "aHC 2.9598333333333335 0.7205184283247414 0.03666666666666667\n",
      "OFC_olf 3.7718000000000003 1.411374280621551 0.045\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sum-up stats for the results part\"\"\"\n",
    "\n",
    "st = study('Olfacto')\n",
    "exp = 'Enc'#'Enc'\n",
    "path_pow = path.join(st.path, 'feature/TPSim_3groups_'+exp+'/')\n",
    "path_df = path.join(path_pow, 'Ttest_odor_identity_v=1_elecs=all/')\n",
    "df_name = path.join(path_df, 'Bilan_All_subjects_Ttests_Low_High_final_sig_elecs_{}_fdr_0.05_theta.csv') #su, conds0, conds1, freq\n",
    "\n",
    "rois = ['aHC']#,'OFC_olf']#,'Amg_pPirT','IFG','MFG']\n",
    "for roi in rois:\n",
    "    df = pd.read_csv(df_name.format(roi))\n",
    "    T_m = df[['Tvals_diff']].values.mean()    \n",
    "    T_sd = df[['Tvals_diff']].values.std()\n",
    "    p_max = df[['fdr_diff']].values.max()\n",
    "    print(roi, T_m, T_sd, p_max)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
