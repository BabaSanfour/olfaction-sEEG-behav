{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from brainpipe.system import study\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, gls, wls\n",
    "from mne.stats import fdr_correction, bonferroni_correction\n",
    "from utils import rename_elecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "['/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_Enc_By_Odor_By_Cond/TPS_by_odor/by_odor_wth/TPS_pears_VACJ_odor_10_theta.npz', '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_Enc_By_Odor_By_Cond/TPS_by_odor/by_odor_wth/TPS_pears_VACJ_odor_11_theta.npz', '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_Enc_By_Odor_By_Cond/TPS_by_odor/by_odor_wth/TPS_pears_VACJ_odor_12_theta.npz', '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_Enc_By_Odor_By_Cond/TPS_by_odor/by_odor_wth/TPS_pears_VACJ_odor_13_theta.npz', '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_Enc_By_Odor_By_Cond/TPS_by_odor/by_odor_wth/TPS_pears_VACJ_odor_14_theta.npz', '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_Enc_By_Odor_By_Cond/TPS_by_odor/by_odor_wth/TPS_pears_VACJ_odor_15_theta.npz', '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_Enc_By_Odor_By_Cond/TPS_by_odor/by_odor_wth/TPS_pears_VACJ_odor_16_theta.npz', '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/Olfacto/feature/TPSim_Enc_By_Odor_By_Cond/TPS_by_odor/by_odor_wth/TPS_pears_VACJ_odor_17_theta.npz']\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-18bd5ce8fac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_pow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'TPS_pears_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msu\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_odor*_theta.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;36m0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mmat0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Linear Regression using statsmodel by electrode (ols, wls, gls)\n",
    ">>> Learning effect in the data during encoding\n",
    "\"\"\"\n",
    "\n",
    "st = study('Olfacto')\n",
    "exp = 'Enc'#'Enc'\n",
    "perf, meth = 'wth','WTH'\n",
    "conds, subjects = ['high','low'],['VACJ','SEMC','LEFC','PIRJ','FERJ','CHAF']\n",
    "freqs = ['theta']\n",
    "path_pow = path.join(st.path, 'feature/TPSim_'+exp+'_By_Odor_By_Cond/TPS_by_odor/by_odor_{}/')\n",
    "filename = path.join(path_pow, 'TPS_pears_{}_{}_{}_{}.npz')\n",
    "df_name = path.join(path_pow, '{}_LReg_Learning_'+meth+'_{}_{}_{}.csv') #su, conds0, conds1, freq\n",
    "\n",
    "rois_sel = ['aHC','MFG','ACC','IFG','Amg','pPirT','PHG','Ins_olf','OFC_olf','SFG']\n",
    "\n",
    "for freq in freqs:\n",
    "    subjects_c, elecs_c, labels_c = np.array([]), np.array([]), np.array([])\n",
    "    channels_c, x_c, y_c, z_c = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "    tps0_c, tps1_c = np.array([]), np.array([])\n",
    "    T_vals_c, p_vals_c, p_max_c = np.array([]), np.array([]), np.array([])\n",
    "    p_fdr_c, p_bf_c = np.array([]), np.array([])\n",
    "    \n",
    "    for su in subjects:\n",
    "        files = glob.glob(path_pow.format(perf)+'TPS_pears_'+su+'_odor*_theta.npz')\n",
    "        for f in files:\n",
    "            mat0 = np.load(f,allow_pickle=True)\n",
    "            tps0 = mat0['tps']\n",
    "            labels, channels = mat0['label'], mat0['channel']\n",
    "            x, y, z = mat0['xyz'][:,0], mat0['xyz'][:,1], mat0['xyz'][:,2]\n",
    "            mat1 = np.load(filename.format(su,conds[0],perf[1],freq))['tps']\n",
    "            mat1b = np.load(filename.format(su,conds[1],perf[1],freq))['tps']\n",
    "            tps1 = np.concatenate((mat1,mat1b),axis=-1)\n",
    "            print(np.mean(tps0),np.mean(tps1))\n",
    "            print (su,mat0.files, 'TPS shape: ', tps0.shape, tps1.shape)\n",
    "            \n",
    "            #rename electrodes labels and select only specific electrodes\n",
    "            labels_new = rename_elecs(labels,x,y,z)\n",
    "            idx_sel = [i for i,lab in enumerate(labels_new) if lab in rois_sel]\n",
    "            tps0, labels, channels = tps0[idx_sel,:], labels_new[idx_sel], channels[idx_sel]\n",
    "            x, y, z, tps1 = x[idx_sel], y[idx_sel], z[idx_sel], tps1[idx_sel,:]\n",
    "            nelecs = len(idx_sel)\n",
    "            \n",
    "            #compute stats Ttests-unpaired\n",
    "            tps0, tps1 = tps0.swapaxes(0,1), tps1.swapaxes(0,1) #ntrials x nelecs\n",
    "            Tvals, unc_p = ttest_ind(tps0, tps1, equal_var=False)\n",
    "            Tvals2, pvals = ttest_perm(tps0, tps1, n_perm=nperm, correction='maxstat',\n",
    "                                  two_tailed=False, paired=False, equal_var=False, n_jobs=-1)\n",
    "            _, p_fdr = fdr_correction(unc_p)\n",
    "            _, p_bf = bonferroni_correction(unc_p)\n",
    "            #print(Tvals,unc_p, p_fdr)\n",
    "            #print(Tvals2,pvals)\n",
    "\n",
    "            #Fill the csv file with elec infos and stats\n",
    "            subjects_c = np.hstack((subjects_c,np.array([su]*nelecs))) if np.size(subjects_c) else np.array([su]*nelecs)\n",
    "            elecs_c = np.hstack((elecs_c,np.arange(nelecs))) if np.size(elecs_c) else np.arange(nelecs)\n",
    "            labels_c = np.hstack((labels_c,labels)) if np.size(labels_c) else labels\n",
    "            channels_c = np.hstack((channels_c,channels)) if np.size(channels_c) else channels\n",
    "            x_c = np.hstack((x_c,x)) if np.size(x_c) else x\n",
    "            y_c = np.hstack((y_c,y)) if np.size(y_c) else y\n",
    "            z_c = np.hstack((z_c,z)) if np.size(z_c) else z\n",
    "            tps0_c = np.hstack((tps0_c,np.mean(tps0, axis=0))) if np.size(tps0_c) else np.mean(tps0, axis=0)\n",
    "            tps1_c = np.hstack((tps1_c,np.mean(tps1, axis=0))) if np.size(tps1_c) else np.mean(tps1, axis=0)\n",
    "            T_vals_c = np.hstack((T_vals_c,Tvals)) if np.size(T_vals_c) else Tvals\n",
    "            p_vals_c = np.hstack((p_vals_c,unc_p)) if np.size(p_vals_c) else unc_p\n",
    "            p_max_c = np.hstack((p_max_c,pvals)) if np.size(p_max_c) else pvals\n",
    "            p_fdr_c = np.hstack((p_fdr_c,p_fdr)) if np.size(p_fdr_c) else p_fdr\n",
    "            p_bf_c = np.hstack((p_bf_c,p_bf)) if np.size(p_bf_c) else p_bf\n",
    "        \n",
    "    data = np.concatenate((subjects_c[:,np.newaxis],labels_c[:,np.newaxis],channels_c[:,np.newaxis],x_c[:,np.newaxis],y_c[:,np.newaxis],z_c[:,np.newaxis],elecs_c[:,np.newaxis],\n",
    "                          tps0_c[:,np.newaxis], tps1_c[:,np.newaxis], T_vals_c[:,np.newaxis],\n",
    "                           p_vals_c[:,np.newaxis], p_max_c[:,np.newaxis], p_fdr_c[:,np.newaxis],\n",
    "                          p_bf_c[:,np.newaxis]), axis=1)\n",
    "    df = pd.DataFrame(data, columns=['subjects','labels','channels','x','y','z',\n",
    "                            'elecs_num', 'tps_'+conds[0], 'tps_'+conds[1], 'Tvals', 'unc_p', 'max_p', \n",
    "                            'fdr_p', 'bonf_p'])\n",
    "    print(df.shape)\n",
    "    df.to_csv(df_name.format('All_subjects',conds[0],conds[1],freq),index=False)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial df shape (232, 14)\n",
      "\n",
      " stats at p <  0.05 correction :  bonf_p (219, 15)\n",
      "Counter({'OFC_olf': 3, 'SFG': 3, 'ACC': 2, 'Ins_olf': 2, 'IFG': 1, 'pPirT': 1, 'MFG': 1})\n",
      "ACC NB of subjects with separation 4  subjects\n",
      "#electrodes in total >>>  11\n",
      "Amg NB of subjects with separation 2  subjects\n",
      "#electrodes in total >>>  5\n",
      "IFG NB of subjects with separation 5  subjects\n",
      "#electrodes in total >>>  31\n",
      "Ins_olf NB of subjects with separation 2  subjects\n",
      "#electrodes in total >>>  7\n",
      "MFG NB of subjects with separation 4  subjects\n",
      "#electrodes in total >>>  36\n",
      "OFC_olf NB of subjects with separation 4  subjects\n",
      "#electrodes in total >>>  16\n",
      "PHG NB of subjects with separation 3  subjects\n",
      "#electrodes in total >>>  18\n",
      "SFG NB of subjects with separation 4  subjects\n",
      "#electrodes in total >>>  55\n",
      "aHC NB of subjects with separation 5  subjects\n",
      "#electrodes in total >>>  35\n",
      "pPirT NB of subjects with separation 3  subjects\n",
      "#electrodes in total >>>  5\n",
      "\n",
      " stats at p <  0.01 correction :  bonf_p (206, 15)\n",
      "Counter({'OFC_olf': 5, 'SFG': 5, 'IFG': 4, 'ACC': 3, 'aHC': 2, 'Ins_olf': 2, 'MFG': 2, 'Amg': 1, 'pPirT': 1, 'PHG': 1})\n",
      "ACC NB of subjects with separation 4  subjects\n",
      "#electrodes in total >>>  10\n",
      "Amg NB of subjects with separation 2  subjects\n",
      "#electrodes in total >>>  4\n",
      "IFG NB of subjects with separation 5  subjects\n",
      "#electrodes in total >>>  28\n",
      "Ins_olf NB of subjects with separation 2  subjects\n",
      "#electrodes in total >>>  7\n",
      "MFG NB of subjects with separation 4  subjects\n",
      "#electrodes in total >>>  35\n",
      "OFC_olf NB of subjects with separation 4  subjects\n",
      "#electrodes in total >>>  14\n",
      "PHG NB of subjects with separation 3  subjects\n",
      "#electrodes in total >>>  17\n",
      "SFG NB of subjects with separation 4  subjects\n",
      "#electrodes in total >>>  53\n",
      "aHC NB of subjects with separation 5  subjects\n",
      "#electrodes in total >>>  33\n",
      "pPirT NB of subjects with separation 3  subjects\n",
      "#electrodes in total >>>  5\n",
      "\n",
      " stats at p <  0.001 correction :  bonf_p (179, 15)\n",
      "Counter({'SFG': 16, 'IFG': 8, 'OFC_olf': 7, 'MFG': 5, 'ACC': 5, 'Ins_olf': 4, 'aHC': 3, 'pPirT': 3, 'Amg': 1, 'PHG': 1})\n",
      "ACC NB of subjects with separation 4  subjects\n",
      "#electrodes in total >>>  8\n",
      "Amg NB of subjects with separation 2  subjects\n",
      "#electrodes in total >>>  4\n",
      "IFG NB of subjects with separation 5  subjects\n",
      "#electrodes in total >>>  24\n",
      "Ins_olf NB of subjects with separation 2  subjects\n",
      "#electrodes in total >>>  5\n",
      "MFG NB of subjects with separation 4  subjects\n",
      "#electrodes in total >>>  32\n",
      "OFC_olf NB of subjects with separation 4  subjects\n",
      "#electrodes in total >>>  12\n",
      "PHG NB of subjects with separation 3  subjects\n",
      "#electrodes in total >>>  17\n",
      "SFG NB of subjects with separation 4  subjects\n",
      "#electrodes in total >>>  42\n",
      "aHC NB of subjects with separation 5  subjects\n",
      "#electrodes in total >>>  32\n",
      "pPirT NB of subjects with separation 3  subjects\n",
      "#electrodes in total >>>  3\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "fold = 'Ret'\n",
    "perf, meth = 'all', 'WTH_BTW'\n",
    "conds = ['high','low']\n",
    "olf_regions = ['Amg','pPirT','OFC_olf','Ins_olf']\n",
    "\n",
    "save_path = path.join(st.path, 'feature/TPSim_'+fold+'_By_Odor_By_Cond/TPS_by_odor/')\n",
    "#save_path = path.join(st.path, 'feature/TPSim_'+fold+'_By_Odor_By_Cond/TPS_by_odor/')\n",
    "#save_path = path.join(st.path, 'classified/TPSim_classif_'+fold+'_by_cond_dissim/')\n",
    "df_name = path.join(save_path, '{}_Ttests_'+meth+'_{}_{}_{}.csv') #su, conds0, conds1, freq\n",
    "#df_name = path.join(save_path, '{}_Ttests_{}_{}_{}.csv') #su, conds0, conds1, freq\n",
    "\n",
    "df = pd.read_csv(df_name.format('All_subjects',conds[0], conds[1],'theta'))\n",
    "print('Initial df shape', df.shape)\n",
    "\n",
    "thrs = [0.05, 0.01, 0.001]\n",
    "corrections = ['bonf_p']\n",
    "\n",
    "for th, corr in product(thrs,corrections):\n",
    "    df_sel = df.loc[df[corr]<th]\n",
    "    df_sel['sign'] = ['separation' if t > 0 else 'completion' for t in df_sel['Tvals']]\n",
    "    print('\\n stats at p < ',th, 'correction : ',corr, df_sel.shape)\n",
    "    print(Counter(df['labels'].loc[df[corr]>th]))\n",
    "    \n",
    "    rois = np.unique(df_sel['labels'])\n",
    "    for roi in rois:\n",
    "        df_roi = df_sel.loc[df_sel['labels']==roi]\n",
    "        df_inc = df_roi.loc[df_roi['sign']=='completion'].groupby(['subjects']).count()\n",
    "        df_dec = df_roi.loc[df_roi['sign']=='separation'].groupby(['subjects']).count()\n",
    "            \n",
    "        if (df_inc.shape[0] >= 3) or (df_inc.shape[0] >=2 and roi in olf_regions):\n",
    "            print(roi, 'NB of subjects with completion',df_inc.shape[0],' subjects')\n",
    "            df_plot = df_roi[['subjects','labels','channels','tps_'+conds[0],\n",
    "                              'tps_'+conds[1]]].loc[df_roi['sign']=='completion']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "            \n",
    "        if (df_dec.shape[0] >= 3) or (df_dec.shape[0] >=2 and roi in olf_regions):\n",
    "            print(roi, 'NB of subjects with separation',df_dec.shape[0],' subjects')\n",
    "            df_plot = df_roi[['subjects','labels','channels','tps_'+conds[0],\n",
    "                              'tps_'+conds[1]]].loc[df_roi['sign']=='separation']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "            #print(df_plot)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
