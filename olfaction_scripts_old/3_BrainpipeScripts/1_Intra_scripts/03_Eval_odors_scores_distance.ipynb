{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "from itertools import product, combinations\n",
    "import numpy as np\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from brainpipe.system import study\n",
    "from utils import subjects, score_odor_su\n",
    "from similarity_funcs import compute_tps_btw\n",
    "from scipy.stats import ttest_ind, ttest_1samp, pearsonr, spearmanr, kendalltau\n",
    "from mne.stats import fdr_correction, bonferroni_correction\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute similarity btw all odors by subject PLEASANTNESS FAMILIARITY or BOTH\n",
    "RDM MATRICES (Perceptual) // RDMs TPS already computed\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_pow = join(st.path, 'feature_new/TPSim_power_data/')\n",
    "pow_file = join(path_pow, '{}_odors=all_elecs=psd_freq=l_theta_pow_EL.npz')\n",
    "path_save = join(st.path, 'feature_new/RDM_Perceptual/')\n",
    "save_file = join(path_save, '{}_odors=all_dims=all_df={}_RDM_{}.npz')\n",
    "PATH = '/media/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "df_od_avg = join(PATH, 'Recap_Odeurs_Evaluations.xlsx')\n",
    "###############################################################################\n",
    "if not exists(path_save):\n",
    "    makedirs(path_save)\n",
    "###############################################################################\n",
    "sheet = 'Final_Lucile' #,'Final_Lucile','Final_avg' \n",
    "#Final (just 2 odors added from Lucile) Final Lucile (all data available from Lucile taken)\n",
    "#Final avg (Lucile's and my data are averaged when possible)\n",
    "col_sel = ['od_num','odors','Pleasantness','Familiarity']\n",
    "dims = ['Pleasantness','Familiarity', ['Pleasantness','Familiarity']]\n",
    "steps = ['E','L']\n",
    "\n",
    "df = pd.read_excel(df_od_avg,sheet_name=sheet)\n",
    "\n",
    "for su in subjects:\n",
    "    mat = np.load(pow_file.format(su),allow_pickle=True)\n",
    "    odor_su = np.unique(mat['od_'+steps[0]])\n",
    "    combs = [o1+'_'+o2 for o1,o2 in combinations(odor_su,2)]\n",
    "    \n",
    "    #compute distance for all pairs of odors along dims\n",
    "    dico_dist = {}\n",
    "    for dim in dims:\n",
    "        dist_su = np.zeros((len(combs)))\n",
    "        for i, odors in enumerate(combinations(odor_su,2)):\n",
    "            rating_o1 = df[dim].loc[df['od_num']=='O'+odors[0]].values\n",
    "            rating_o2 = df[dim].loc[df['od_num']=='O'+odors[1]].values\n",
    "            dist_od = np.round(np.linalg.norm(rating_o1-rating_o2),2)            \n",
    "            dist_su[i] += dist_od\n",
    "        dim = 'both' if dim == ['Pleasantness','Familiarity'] else dim\n",
    "        dico_dist[dim] = dist_su\n",
    "    dico_dist['combs'] = combs\n",
    "    np.savez(save_file.format(su,sheet,steps[0]),**dico_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Correlation between TPS and Perceptual distances\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_tps = join(st.path, 'feature_new/TPSim_by_odor_btw/')\n",
    "tps_file = join(path_tps, '{}_odors=all_tps=btw_elecs=psd_freq={}_xpow_L.npz')\n",
    "path_rdm = join(st.path, 'feature_new/RDM_Perceptual/')\n",
    "rdm_file = join(path_rdm, '{}_odors=all_dims=all_df={}_RDM_L.npz')\n",
    "path_save = join(st.path, 'feature_new/Corr_RDMs_TPS=btw/')\n",
    "save_file = join(path_save, '{}_corr_RDMs_freq={}_dims=all_df={}_L.npz')\n",
    "###############################################################################\n",
    "if not exists(path_save):\n",
    "    makedirs(path_save)\n",
    "###############################################################################\n",
    "sheets = ['Final_avg','Final_Lucile','Final'] \n",
    "dims = ['Pleasantness','Familiarity','both']\n",
    "freqs = ['l_theta','h_theta']\n",
    "\n",
    "for su,freq,sheet in product(subjects,freqs,sheets):\n",
    "    mat = np.load(tps_file.format(su,freq),allow_pickle=True)\n",
    "    combs_l, TPD = mat['combs'], 1-mat['tps']\n",
    "    nelecs, ncombs = TPD.shape\n",
    "    rdms = np.load(rdm_file.format(su,sheet),allow_pickle=True)\n",
    "    \n",
    "    #create vector with odors dist same order as TPS\n",
    "    all_corr, all_p = np.zeros((len(dims),nelecs)), np.zeros((len(dims),nelecs))\n",
    "    for d,dim in enumerate(dims):\n",
    "        dico_dist = {comb:dist for comb,dist in zip(rdms['combs'],rdms[dim])}\n",
    "        dico_dist.update({comb.split('_')[1]+'_'+comb.split('_')[0]:dist \\\n",
    "                                      for comb,dist in zip(rdms['combs'],rdms[dim])})\n",
    "        dim_comb = [dico_dist[comb] for comb in combs_l]\n",
    "        \n",
    "        elecs_corr, elecs_p = np.zeros((nelecs)), np.zeros((nelecs))\n",
    "        for elec in range(nelecs):\n",
    "            R, p = kendalltau(TPD[elec],dim_comb)\n",
    "            elecs_corr[elec] += R\n",
    "            elecs_p[elec] += p\n",
    "        \n",
    "        all_corr[d] += elecs_corr\n",
    "        all_p[d] += elecs_p\n",
    "    \n",
    "    dico_rdm = {}\n",
    "    for fi in mat.files:\n",
    "        if fi != ['xpow','tps','pvals']:\n",
    "            dico_rdm[fi] = mat[fi]\n",
    "    dico_rdm['corr'] = all_corr\n",
    "    dico_rdm['pvals'] = all_p\n",
    "    dico_rdm['dims'] = dims\n",
    "    np.savez(save_file.format(su,freq,sheet),**dico_rdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sum up correlations into DF with all subjects and electrodes\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_ken = join(st.path, 'feature_new/Corr_RDMs_TPS=btw/')\n",
    "corr_file = join(path_ken, '{}_corr_RDMs_freq={}_dims=all_df={}_L.npz')\n",
    "df_path = join(path_ken, 'dfs_results/')\n",
    "dfsave = join(df_path, 'df_elecs=ALL_OFC_freq={}_dim={}_df={}_L.csv')\n",
    "###############################################################################\n",
    "if not exists(df_path):\n",
    "    makedirs(df_path)\n",
    "###############################################################################\n",
    "sheets = ['Final'] \n",
    "dims = ['Pleasantness','Familiarity','both']\n",
    "freqs = ['l_theta','h_theta']\n",
    "rois = ['OFC','OFC_olf']\n",
    "\n",
    "for sheet,freq in product(sheets,freqs):\n",
    "    for d,dim in enumerate(dims):\n",
    "        subjects_c, elecs_c, labels_c = np.array([]), np.array([]), np.array([])\n",
    "        channels_c, x_c, y_c, z_c = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "        R_vals, pvals, pval_fdr = np.array([]), np.array([]), np.array([])\n",
    "\n",
    "        for su in subjects:\n",
    "            mat0 = np.load(corr_file.format(su,freq,sheet),allow_pickle=True)\n",
    "            labels, channels = mat0['labels'], mat0['channels']\n",
    "            x, y, z = mat0['xyz'][:,0], mat0['xyz'][:,1], mat0['xyz'][:,2]\n",
    "            \n",
    "            #select electrodes in ROIS\n",
    "            idx_sel = [i for i,lab in enumerate(labels) if lab in rois]\n",
    "            nelecs = len(idx_sel)\n",
    "            labels, channels = labels[idx_sel], channels[idx_sel]\n",
    "            x, y, z = x[idx_sel], y[idx_sel], z[idx_sel]\n",
    "            corr, ps = mat0['corr'][d,idx_sel], mat0['pvals'][d,idx_sel]\n",
    "            ps_fdr = fdr_correction(ps)[1]\n",
    "            \n",
    "            #Fill the csv file with elec infos and stats\n",
    "            subjects_c = np.hstack((subjects_c,np.array([su]*nelecs))) if np.size(subjects_c) else np.array([su]*nelecs)\n",
    "            elecs_c = np.hstack((elecs_c,np.arange(nelecs))) if np.size(elecs_c) else np.arange(nelecs)\n",
    "            labels_c = np.hstack((labels_c,labels)) if np.size(labels_c) else labels\n",
    "            channels_c = np.hstack((channels_c,channels)) if np.size(channels_c) else channels\n",
    "            x_c = np.hstack((x_c,x)) if np.size(x_c) else x\n",
    "            y_c = np.hstack((y_c,y)) if np.size(y_c) else y\n",
    "            z_c = np.hstack((z_c,z)) if np.size(z_c) else z\n",
    "\n",
    "            R_vals = np.hstack((R_vals,corr)) if np.size(R_vals) else corr\n",
    "            pvals = np.hstack((pvals,ps)) if np.size(pvals) else ps\n",
    "            pval_fdr = np.hstack((pval_fdr,ps_fdr)) if np.size(pval_fdr) else ps_fdr\n",
    "            \n",
    "        data = np.concatenate((subjects_c[:,np.newaxis],labels_c[:,np.newaxis],\n",
    "                    channels_c[:,np.newaxis],x_c[:,np.newaxis],y_c[:,np.newaxis],\n",
    "                    z_c[:,np.newaxis],elecs_c[:,np.newaxis],R_vals[:,np.newaxis],\n",
    "                    pvals[:,np.newaxis],pval_fdr[:,np.newaxis]),axis=1)\n",
    "        df = pd.DataFrame(data, columns=['subjects','labels','channels','x','y','z',\n",
    "                                         'elecs_num','R_'+dim,'unc_'+dim,'fdr_'+dim])\n",
    "        print(df.shape)\n",
    "        df.to_csv(dfsave.format(freq,dim,sheet),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summarize stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "df_path = join(path_ken, 'dfs_results/')\n",
    "dfname = join(df_path, 'df_elecs=ALL_OFC_freq={}_dim={}_df={}_E.csv')\n",
    "###############################################################################\n",
    "sheets = ['Final']#,'Final_avg','Final'] #'Final_avg','Final_Lucile',\n",
    "dims = ['Pleasantness','Familiarity','both']\n",
    "freqs = ['l_theta','h_theta']\n",
    "\n",
    "thrs = [0.05]\n",
    "corrections = ['fdr_']\n",
    "\n",
    "for freq,dim,sheet in product(freqs,dims,sheets):\n",
    "    print('\\n Processing',freq,dim,sheet)\n",
    "    df = pd.read_csv(dfname.format(freq,dim,sheet))\n",
    "    \n",
    "    for th, corr in product(thrs,corrections):\n",
    "        df_sel = df.loc[(df[corr+dim]<th)&(df['R_'+dim]>0)]\n",
    "        print('stats at p < ',th, 'correction : ',corr, df_sel.shape, \n",
    "                                                      'for dimension',dim)\n",
    "        if df_sel.shape[0] >= 3:\n",
    "            print(Counter(df_sel['labels']))\n",
    "            print(df_sel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Only consider specific ROIs and not ALL brain regions\"\"\"\n",
    "from brainpipe.system import study\n",
    "from mne.stats import bonferroni_correction, fdr_correction\n",
    "from collections import Counter\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "st = study('Olfacto')\n",
    "fold, freq, sheet = 'Enc', 'theta', 'Final'\n",
    "# cond = 'high'\n",
    "path_file = path.join(st.path, \n",
    "          'feature/TPSim_3groups_'+fold+'/similarity_matrix_btw_v=1_elecs=all_early_late/')\n",
    "df_name = path.join(path_file, \n",
    "                'All_subjects_correl_rdm_pleas_fam_score_'+freq+'_mean=False_'+sheet+'_E.csv') #su, conds0, conds1, freq\n",
    "df_save = path.join(path_file, \n",
    "                'All_subjects_correl_{}_{}_{}_'+freq+'_'+sheet+'_mean=False_{}_E.csv')\n",
    "\n",
    "thrs = [0.05]\n",
    "corrections = ['unc_']#['fdr_','bonf_']\n",
    "dims = ['pl','fam']\n",
    "rois = ['OFC_olf','pPirT']\n",
    "olf_regions = ['OFC_olf','pPirT']\n",
    "\n",
    "df_init = pd.read_csv(df_name)\n",
    "#print('Initial df shape', df_init.shape,df_init.columns)\n",
    "# combine Amg/pPirT together\n",
    "df_init['labels'] = [x if x != 'Amg' else 'pPirT' for x in df_init['labels']]\n",
    "\n",
    "for th, dim, corr in product(thrs,dims,corrections):\n",
    "    for roi in rois:\n",
    "        print('>>> processing', roi, dim, corr, th)\n",
    "        df_roi = df_init.loc[df_init['labels']==roi]\n",
    "        pvals = [p if not math.isnan(p) else 1 for p in df_roi['unc_'+dim].values]\n",
    "        df_roi['new_pvalues'] = fdr_correction(pvals)[1]\n",
    "        #print(df_roi[['subjects','labels','channels','R_'+dim]].mean())\n",
    "        #print(df_roi[['subjects','labels','channels','R_'+dim]].sem())\n",
    "        #             'unc_'+dim, 'fdr_'+dim, 'new_pvalues']].loc[df_roi['unc_'+dim]<th])\n",
    "        df_sel = df_roi.loc[df_roi['new_pvalues']<th]\n",
    "        print('sig results',df_sel)\n",
    "        df_sel['sign'] = ['similar' if t > 0 else 'different' for t in df_sel['R_'+dim]]\n",
    "        print('\\n stats at p < ',th, 'correction : ',corr, df_sel.shape, 'for dimension',dim)\n",
    "        print(Counter(df_sel['labels']))\n",
    "\n",
    "        df_dec = df_sel.loc[df_sel['sign']=='similar'].groupby(['subjects']).count()\n",
    "        if (df_dec.shape[0] >= 3) or (df_dec.shape[0] >=2 and roi in olf_regions):\n",
    "            print(roi, 'NB of subjects with SIMILAR',df_dec.shape[0],' subjects')\n",
    "            df_plot = df_sel.loc[df_sel['sign']=='similar']\n",
    "            print('#electrodes in total >>> ',df_plot.shape[0])\n",
    "            df_plot[['subjects','labels','channels','x','y','z','R_'+dim,\n",
    "                         'unc_'+dim, 'fdr_'+dim,'new_pvalues']].to_csv(df_save.format(roi,corr+str(th),'late',dim))\n",
    "            print(df_plot[['subjects','labels','channels','x','y','z','R_'+dim,\n",
    "                         'unc_'+dim, 'fdr_'+dim,'new_pvalues']])\n",
    "            print(df_plot['R_'+dim].mean(), df_plot['R_'+dim].std())\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "//// PLEASANTNESS + FAMILIARITY ////\n",
    "Final OFC (2 patients 3 elecs)\n",
    "Final avg OFC (3 patients 5 elecs) + MFG (3 patients 4 elecs)\n",
    "\n",
    "//// FAMILIARITY ////\n",
    "Final OFC (2P,3elecs), MFG (3P, 5elecs)\n",
    "Final avg MFG (3P,6elecs), OFC (2P 2elecs 2 sens), aHC (3P,4elecs)\n",
    "\n",
    "//// PLEASANTNESS ////\n",
    "Final OFC (3P, 4elecs)\n",
    "Final avg OFC (3P, 4elecs)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from brainpipe.system import study\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "st = study('Olfacto')\n",
    "PATH = '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "filename = 'Recap_Odeurs_Evaluations.xlsx'\n",
    "PATH_SAVE = join(st.path, 'feature/TPSim_3groups_Enc/similarity_matrix_btw/')\n",
    "savename = 'dist_pl_fam_all_odors_pleas.npz'\n",
    "\n",
    "df = pd.read_excel(PATH+filename, sheet_name='Final')\n",
    "odors = df[['od_num']].values[:,0]\n",
    "#odors = [14,10,3,8,13,6,12,9,1,18,4,15,5,17,11,2,16,7] #ordered by Fam\n",
    "odors = [10,1,12,3,9,13,6,5,8,14,16,4,18,11,15,7,2,17] #ordered by Pleas\n",
    "#odors = [10,3,9,1,13,12,6,14,8,5,4,18,16,15,7,2,11,17] #fam * pleas\n",
    "#odors = [10,3,9,13,1,6,12,14,8,5,4,18,16,15,7,2,11,17] #fam + pleas\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "dist_f, dist_p, dist_fp = [], [], []\n",
    "for o1,o2 in combinations(odors,2):\n",
    "    f1 = df.loc[df['od_num']=='O'+str(o1)]['Familiarity'].values\n",
    "    f2 = df.loc[df['od_num']=='O'+str(o2)]['Familiarity'].values\n",
    "    p1 = df.loc[df['od_num']=='O'+str(o1)]['Pleasantness'].values\n",
    "    p2 = df.loc[df['od_num']=='O'+str(o2)]['Pleasantness'].values\n",
    "    fp1, fp2 = np.array([f1,p1]), np.array([f2,p2])\n",
    "    dist_f.append(np.round(np.linalg.norm(f1-f2),2))\n",
    "    dist_p.append(np.round(np.linalg.norm(p1-p2),2))\n",
    "    dist_fp.append(np.round(np.linalg.norm(fp1-fp2),2))\n",
    "print(len(dist_f))\n",
    "np.savez(PATH_SAVE+savename,d_f=np.array(dist_f),d_p=np.array(dist_p),\n",
    "        d_fp=np.array(dist_fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot odors RDM matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import cm\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.manifold import MDS\n",
    "\"\"\"\n",
    "Plot TPSim matrices (RDM) for all odors (Familiarity Pleasantness, both)\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "st = study('Olfacto')\n",
    "path_npz = join(st.path,'feature/TPSim_3groups_Enc/')\n",
    "path_pow = join(path_npz, 'similarity_matrix_btw/dist_pl_fam_all_odors_mult.npz')\n",
    "savename = join(path_npz, 'distance_graphs/Plot_distance_{}_all_odors_mult.png')\n",
    "###############################################################################\n",
    "exp = 'Enc' #Ret, Enc\n",
    "###############################################################################\n",
    "#new_order = [10,1,12,3,9,13,6,5,8,14,16,4,18,11,15,7,2,17] #Pleas order\n",
    "new_order = [10,3,9,1,13,12,6,14,8,5,4,18,16,15,7,2,11,17] #fam * pleas\n",
    "#new_order = [10,3,9,13,1,6,12,14,8,5,4,18,16,15,7,2,11,17] #fam + pleas\n",
    "#new_order = [14,10,3,8,13,6,12,9,1,18,4,15,5,17,11,2,16,7] #Fam order\n",
    "mat = np.load(path_pow)\n",
    "features = mat.files\n",
    "\n",
    "for feat in features:\n",
    "    combs = mat[feat]\n",
    "    n_od = 18\n",
    "    idx = list(np.arange(1,n_od+1))\n",
    "    tri = np.zeros((n_od, n_od))\n",
    "    tri[np.triu_indices(n_od,1)] = combs\n",
    "    tri[np.tril_indices(n_od, -1)] = tri.T[np.tril_indices(n_od, -1)]\n",
    "\n",
    "    model = MDS(n_components=2, dissimilarity='precomputed', random_state=None)\n",
    "    out = model.fit_transform(tri)\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(8,3))\n",
    "    colors = 'black'\n",
    "    markers = 'o'\n",
    "\n",
    "    for i, txt in enumerate(idx):\n",
    "        ax1.scatter(out[i,0], out[i,1], c=colors, marker=markers)\n",
    "        ax1.annotate('O'+str(txt), (out[i,0], out[i,1]))\n",
    "    ax1.set_xlabel('component 1')\n",
    "    ax1.set_ylabel('component 2')\n",
    "    #ax1.axis('equal')\n",
    "        \n",
    "    #subplot #1 Graph 2D \n",
    "    cmap = cm.get_cmap('viridis', 30)\n",
    "    mask =  np.tri(tri.shape[0], k=0) #mask upper triangle\n",
    "    A = np.ma.array(tri, mask=mask) # mask out the lower triangle\n",
    "    cax = ax2.imshow(A, vmin=0,vmax=3,interpolation=\"nearest\", cmap=cmap)\n",
    "    ax2.set_xticks(np.arange(n_od))\n",
    "    ax2.set_yticks(np.arange(n_od))\n",
    "    ax2.set_xticklabels(new_order,fontsize=11)\n",
    "    ax2.set_yticklabels(new_order,fontsize=11)\n",
    "    plt.colorbar(cax)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    title = 'Distance btw odors in {} domaine )'.format(feat)\n",
    "    fig.suptitle(title, fontsize=12)\n",
    "    \n",
    "    plt.savefig(savename.format(feat))\n",
    "    plt.savefig(savename.format(feat).replace('.png','.pdf'))\n",
    "    plt.clf()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/media/karim/Datas4To/1_Analyses_Intra_EM_Odor/1bis_OE_BaseSam/JPlailly201306_seeg_ALS/behavior/'\n",
    "filename = 'Recap_Odeurs_Evaluations.xlsx'\n",
    "PATH_SAVE = join(st.path, 'feature/TPSim_3groups_Enc/distance_graphs/')\n",
    "savename = 'Correl_Fam_Pleas.png'\n",
    "\n",
    "df = pd.read_excel(PATH+filename, sheet_name='Final')\n",
    "pleas = df[['Pleasantness']]\n",
    "fam = df[['Familiarity']]\n",
    "R,p = pearsonr(pleas.values[:,0],fam.values[:,0])\n",
    "print(R,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/karim/.local/lib/python3.9/site-packages/pyrfume']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/karim/.local/lib/python3.9/site-packages/pyrfume-data/sigma/sigma_ff_catalog.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aee049b09a0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get raw data from the Sigma Fragrance & Flavor Catalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyrfume\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msigma_ff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdescriptors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma_ff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Get a PubChem CID-indexed dataframe of the odorant and descriptor data from that catalog:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pyrfume/sigma_ff.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCATALOG_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/karim/.local/lib/python3.9/site-packages/pyrfume-data/sigma/sigma_ff_catalog.txt'"
     ]
    }
   ],
   "source": [
    "import pyrfume\n",
    "print(pyrfume.__path__)\n",
    "# Get raw data from the Sigma Fragrance & Flavor Catalog\n",
    "from pyrfume import sigma_ff\n",
    "descriptors, data = sigma_ff.get_data()\n",
    "\n",
    "# Get a PubChem CID-indexed dataframe of the odorant and descriptor data from that catalog:\n",
    "sigma = pyrfume.load_data('sigma/sigma.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
