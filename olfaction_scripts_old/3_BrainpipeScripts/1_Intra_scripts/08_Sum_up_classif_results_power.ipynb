{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a df to sum up all results from all classif\n",
    "    0-Good/Bad 1-Poor/Partial 2-Partial/Detailed 3-Poor/Detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "['s_time', 's_channels', 's_aal', 'su_codes', 's_th_05', 's_BA', 's_labels', 's_xyz', 's_elec_pow0', 's_da', 's_elec_pow1', 's_aal_RL', 's_th_01', 's_elec', 's_MAI', 's_MAI_RL']\n",
      "['s_time', 's_channels', 's_aal', 'su_codes', 's_th_05', 's_BA', 's_labels', 's_xyz', 's_elec_pow0', 's_da', 's_elec_pow1', 's_aal_RL', 's_th_01', 's_elec', 's_MAI', 's_MAI_RL']\n",
      "['s_time', 's_channels', 's_aal', 'su_codes', 's_th_05', 's_BA', 's_labels', 's_xyz', 's_elec_pow0', 's_da', 's_elec_pow1', 's_aal_RL', 's_th_01', 's_elec', 's_MAI', 's_MAI_RL']\n",
      "['s_time', 's_channels', 's_aal', 'su_codes', 's_th_05', 's_BA', 's_labels', 's_xyz', 's_elec_pow0', 's_da', 's_elec_pow1', 's_aal_RL', 's_th_01', 's_elec', 's_MAI', 's_MAI_RL']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from brainpipe.system import study\n",
    "\n",
    "st = study('Olfacto')\n",
    "conds, th = ['low','high'],'01'\n",
    "for cond in conds:\n",
    "    ###############################################################################\n",
    "    path_npz = join(st.path, 'figure/0_Classif_Power_E_EpiPerf_LowHigh_'+bsl+'/')\n",
    "    path2save = join(path_npz, 'Bilan_classif/')\n",
    "    path_mask = join(path_npz, 'masks_visbrain'+th+'/')\n",
    "    npz_form = join(path_npz, '{}_sources_{}_{}_low_high_sel_physFT_{}.npz')\n",
    "    masks_vis_form = join(path_mask, '{}_mask_min{}_{}_minwin{}_th{}.npy')    \n",
    "    ###############################################################################\n",
    "    if not exists(path2save):\n",
    "        makedirs(path2save)\n",
    "    ###############################################################################\n",
    "\n",
    "    freqs = ['2_theta','6_gamma2']#['0_VLFC','1_delta','2_theta', '3_alpha','4_beta','5_gamma1','6_gamma2']\n",
    "\n",
    "    for freq in freqs:\n",
    "        #Load all data for one classif one freq\n",
    "        arch_sig = np.load(npz_form.format('All_subjects',freq, 'odor',bsl))\n",
    "        print(arch_sig.files)\n",
    "        #Create a df with all electrodes info\n",
    "        features = ['su_codes','s_elec','s_channels','s_MAI','s_MAI_RL']\n",
    "        df_elec = np.array([])\n",
    "        for f in features:\n",
    "            data = arch_sig[f]\n",
    "            df_elec = np.vstack((df_elec,data)) if np.size(df_elec) else data\n",
    "        xyz = arch_sig['s_xyz']\n",
    "        x,y,z = xyz[:,0],xyz[:,1],xyz[:,2]\n",
    "        df_elec = np.vstack((df_elec,x,y,z))\n",
    "        df0 = pd.DataFrame(data=df_elec.T, columns=features+['x','y','z'])\n",
    "        #Select max values for power and AUC scores and create Time array\n",
    "        da = arch_sig['s_da']\n",
    "        pow0_max, pow1_max, idx_max, da_max, time_max = np.array([]), np.array([]), np.array([]), np.array([]),np.array([])\n",
    "        for elec in range(da.shape[0]):\n",
    "            #print('shape da',da.shape)\n",
    "            idx = [i for i,j in enumerate(da[elec]) if j == max(da[elec])][0]\n",
    "            pow0, pow1 = arch_sig['s_elec_pow0'][elec][idx], arch_sig['s_elec_pow1'][elec][idx]\n",
    "            time = arch_sig['s_time'][idx]\n",
    "            da_elec = da[elec][idx]\n",
    "            pow0_max = np.hstack((pow0_max,pow0)) if np.size(pow0_max) else pow0\n",
    "            pow1_max = np.hstack((pow1_max,pow1)) if np.size(pow1_max) else pow1\n",
    "            time_max = np.hstack((time_max,time)) if np.size(time_max) else time\n",
    "            idx_max = np.hstack((idx_max,idx)) if np.size(idx_max) else idx\n",
    "            da_max = np.hstack((da_max, da_elec)) if np.size(da_max) else da_elec\n",
    "        df_data = np.concatenate((pow0_max[:,np.newaxis],pow1_max[:,np.newaxis],\n",
    "                da_max[:,np.newaxis],idx_max[:,np.newaxis], time_max[:,np.newaxis]),axis=1)\n",
    "        df1 = pd.DataFrame(data=df_data, columns=['p0','p1','da','idx','time'])\n",
    "        df_all = pd.concat((df0,df1),axis=1)\n",
    "        df_name = 'Mai_Classif_'+conds[0]+'_'+conds[1]+'_'+freq+'_all_elecs.csv'\n",
    "        df_all.to_csv(path2save+df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask significant results as function of time of the effect (wins)\n",
    "    statistics p < 0.05 corrected over electrodes and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "(456, 1) 14\n",
      "(456, 14)\n",
      "(456, 1) 14\n",
      "(456, 14)\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "conds, bsl, th,win,min_sig = ['low','high'], 'None','01',1,1\n",
    "###############################################################################################\n",
    "st = study('Olfacto')\n",
    "path = join(st.path, 'figure/0_Classif_Power_E_EpiPerf_LowHigh_'+bsl+'/')\n",
    "path_df = join(path, 'Bilan_classif/')\n",
    "path2save = path_df\n",
    "###############################################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "##############################################################################################\n",
    "freqs = ['2_theta','6_gamma2']#['0_VLFC','1_delta','2_theta', '3_alpha','4_beta','5_gamma1','6_gamma2']\n",
    "\n",
    "for freq in freqs:\n",
    "    df = pd.read_csv(path_df+'Mai_Classif_'+conds[0]+'_'+conds[1]+'_'+freq+'_all_elecs.csv')\n",
    "    path_mask = join(path_npz, 'masks_stat/')\n",
    "    #load data to plot and mask\n",
    "    mask = np.load(masks_vis_form.format('MAI_RL',min_sig,freq,str(win),th))[:,np.newaxis]\n",
    "    print(mask.shape, df.shape[1])\n",
    "    mask = np.repeat(mask,df.shape[1],axis=1)\n",
    "    print(mask.shape)\n",
    "    if mask.dtype == bool:\n",
    "        df_sel = df.mask(mask).dropna()\n",
    "        df_name = 'Mai_Classif_'+conds[0]+'_'+conds[1]+'_'+freq+'_win'+str(win)+'.csv'\n",
    "        df_sel.to_csv(path2save+df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask significant results as function of time and nb of patients\n",
    "    statistics p < 0.05 corrected over electrodes and time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "(49, 14) Index(['old_idx', 'su_codes', 's_elec', 's_channels', 's_MAI', 's_MAI_RL', 'x',\n",
      "       'y', 'z', 'p0', 'p1', 'da', 'idx', 'time'],\n",
      "      dtype='object')\n",
      "['ACC', 'Amg', 'FuG', 'HC', 'IFG', 'ITG', 'Ins', 'MFG', 'MTG', 'OFC', 'SFG', 'STG'] ['ACC', 'Amg', 'FuG', 'HC', 'IFG', 'ITG', 'Ins', 'MFG', 'MTG', 'OFC', 'STG'] ['FuG', 'IFG', 'MTG', 'OFC'] [] [] []\n",
      "No rois4\n",
      "No rois5\n",
      "No rois6\n",
      "no df4 saved\n",
      "no df5 saved\n",
      "no df6 saved\n",
      "(156, 14) Index(['old_idx', 'su_codes', 's_elec', 's_channels', 's_MAI', 's_MAI_RL', 'x',\n",
      "       'y', 'z', 'p0', 'p1', 'da', 'idx', 'time'],\n",
      "      dtype='object')\n",
      "['ACC', 'Amg', 'FuG', 'HC', 'IFG', 'ITG', 'Ins', 'MFG', 'MTG', 'OFC', 'PHG', 'SFG', 'STG', 'pPirT'] ['ACC', 'FuG', 'HC', 'IFG', 'MFG', 'MTG', 'OFC', 'PHG', 'SFG', 'STG'] ['FuG', 'HC', 'IFG', 'MFG', 'MTG', 'OFC', 'SFG', 'STG'] ['HC', 'IFG', 'MFG', 'MTG', 'OFC', 'STG'] ['HC', 'IFG', 'MTG', 'OFC'] []\n",
      "No rois6\n",
      "no df6 saved\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "conds, bsl, th,win,min_sig = ['low','high'], 'None','01',1,1\n",
    "###############################################################################################\n",
    "st = study('Olfacto')\n",
    "path = join(st.path, 'figure/0_Classif_Power_E_EpiPerf_LowHigh_'+bsl+'/')\n",
    "path_df = join(path, 'Bilan_classif/')\n",
    "path2save = path_df\n",
    "###############################################################################################\n",
    "if not exists(path2save):\n",
    "    makedirs(path2save)\n",
    "##############################################################################################\n",
    "freqs = ['2_theta','6_gamma2']#['0_VLFC','1_delta','2_theta', '3_alpha','4_beta','5_gamma1','6_gamma2']\n",
    "\n",
    "df1,df2,df3,df4,df5,df6 = None, None, None,None,None,None\n",
    "for freq in freqs:\n",
    "    df = pd.read_csv(path_df+'Mai_Classif_'+conds[0]+'_'+conds[1]+'_'+freq+'_win'+str(win)+'.csv')\n",
    "    df = df.drop(['Unnamed: 0.1'], axis=1)\n",
    "    df = df.rename(index=str,columns={'Unnamed: 0':'old_idx'})\n",
    "    print(df.shape, df.columns)\n",
    "    \n",
    "    #count and select regions with enough patients\n",
    "    count = df.groupby(['s_MAI_RL']).nunique()\n",
    "    count = count['su_codes']\n",
    "    rois_sig1,rois_sig2,rois_sig3, rois_sig4, rois_sig5, rois_sig6 = [],[],[],[],[],[]\n",
    "    for i,row in count.iteritems():\n",
    "        #print('how many patients',row, 'for roi', i)\n",
    "        if row >=1:\n",
    "            rois_sig1.append(i)\n",
    "        if row >=2:\n",
    "            rois_sig2.append(i)\n",
    "        if row >=3:\n",
    "            rois_sig3.append(i)\n",
    "        if row >=4:\n",
    "            rois_sig4.append(i)\n",
    "        if row >=5:\n",
    "            rois_sig5.append(i)\n",
    "        if row >=6:\n",
    "            rois_sig6.append(i)\n",
    "    print(rois_sig1,rois_sig2,rois_sig3,rois_sig4,rois_sig5,rois_sig6)\n",
    "    \n",
    "    # select data only in selected regions \n",
    "    df1 = df[df['s_MAI_RL'].isin(rois_sig1)] if rois_sig1 else print('No rois1')\n",
    "    df2 = df[df['s_MAI_RL'].isin(rois_sig2)] if rois_sig2 else print('No rois2')\n",
    "    df3 = df[df['s_MAI_RL'].isin(rois_sig3)] if rois_sig3 else print('No rois3')\n",
    "    df4 = df[df['s_MAI_RL'].isin(rois_sig4)] if rois_sig4 else print('No rois4')\n",
    "    df5 = df[df['s_MAI_RL'].isin(rois_sig5)] if rois_sig5 else print('No rois5')\n",
    "    df6 = df[df['s_MAI_RL'].isin(rois_sig6)] if rois_sig6 else print('No rois6')\n",
    "    # save data for selected regions\n",
    "    df1_name = 'Mai_Classif_'+conds[0]+'_'+conds[1]+'_'+freq+'_win'+str(win)+'_patients1.csv'\n",
    "    df2_name = 'Mai_Classif_'+conds[0]+'_'+conds[1]+'_'+freq+'_win'+str(win)+'_patients2.csv'\n",
    "    df3_name = 'Mai_Classif_'+conds[0]+'_'+conds[1]+'_'+freq+'_win'+str(win)+'_patients3.csv'\n",
    "    df4_name = 'Mai_Classif_'+conds[0]+'_'+conds[1]+'_'+freq+'_win'+str(win)+'_patients4.csv'\n",
    "    df5_name = 'Mai_Classif_'+conds[0]+'_'+conds[1]+'_'+freq+'_win'+str(win)+'_patients5.csv'\n",
    "    df6_name = 'Mai_Classif_'+conds[0]+'_'+conds[1]+'_'+freq+'_win'+str(win)+'_patients6.csv'\n",
    "    df1.to_csv(path2save+df1_name) if df1 is not None else print('no df1 saved')\n",
    "    df2.to_csv(path2save+df2_name) if df2 is not None else print('no df2 saved')\n",
    "    df3.to_csv(path2save+df3_name) if df3 is not None else print('no df3 saved')\n",
    "    df4.to_csv(path2save+df4_name) if df4 is not None else print('no df4 saved')\n",
    "    df5.to_csv(path2save+df5_name) if df5 is not None else print('no df5 saved')\n",
    "    df6.to_csv(path2save+df6_name) if df6 is not None else print('no df6 saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
