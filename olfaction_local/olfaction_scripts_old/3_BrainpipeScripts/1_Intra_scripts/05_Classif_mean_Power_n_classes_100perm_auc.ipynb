{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, MaxNLocator\n",
    "import scipy.io as sio\n",
    "\n",
    "from brainpipe.classification import *\n",
    "from brainpipe.system import study\n",
    "from brainpipe.feature import power, amplitude, sigfilt\n",
    "from brainpipe.visual import *\n",
    "from brainpipe.statistics import *\n",
    "from scipy.stats import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Decoding - Partial//Detailed Encoding\n",
    "### For ALL time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_freqname(freq):\n",
    "    freqnames = ['0_theta', '1_alpha', '2_beta', '3_gamma']\n",
    "    freqname = freqnames[freq]\n",
    "    return freqname\n",
    "\n",
    "def odor_su_dict(phase):\n",
    "    if phase == 'Encoding':\n",
    "        odors_su = {'CHAF': {5:12,7:68,8:36,9:96,1:6,2:2,3:68,4:8},\n",
    "                'LEFC': {1:4,2:0,3:6,4:12,14:96,15:2,16:4,17:68},\n",
    "                'PIRJ': {4:36,9:2,1:4,18:32,6:34,5:4,7:68}, #missing odor 15\n",
    "                'VACJ': {14:6,15:64,16:68,17:8,10:6,11:4,12:4,13:40},\n",
    "                'SEMC': {10:2,11:6,12:6,13:6,5:8,7:4,8:8,9:10},\n",
    "                'MICP': {2:6,12:8,6:96,8:8,3:12,18:4,9:6,14:10},\n",
    "                'FERJ': {16:6,17:6,5:8,7:6,12:8,13:8,2:6,1:10}}\n",
    "    else:\n",
    "        odors_su = {'CHAF': {5:12,7:68,8:36,9:96,1:6,2:2,3:68,4:8},\n",
    "                'LEFC': {1:4,2:0,3:6,4:12,14:96,15:2,16:4,17:68},\n",
    "                'PIRJ': {4:36,9:2,1:4,18:32,6:34,5:4,7:68},#15:4 #remove for TPSim 15:4\n",
    "                'VACJ': {14:6,15:64,16:68,17:8,10:6,11:4,12:4,13:40},\n",
    "                'SEMC': {10:2,11:6,12:6,13:6,5:8,7:4,8:8,9:10},\n",
    "                'FERJ': {16:6,17:6,5:8,7:6,12:8,13:8,2:6,1:10}}\n",
    "    return odors_su\n",
    "\n",
    "def norm_power_by_roi(phase,su,roi,freq,val):\n",
    "    if val == 'xpow':\n",
    "        path_pow = path.join(st.path, 'feature/0_Power_'+phase+'_By_Odor/')\n",
    "        mat_file = path_pow+'{}_odor_{}_bipo_sel_physFT_pow.npz'\n",
    "    elif val == 'tps':\n",
    "        path_pow = path.join(st.path, 'feature/TPSim_Enc_Ret_By_Odor_all/TPS_R_p_by_odor/')\n",
    "        mat_file = path.join(path_pow, 'TPS_spear_{}_odor_{}_{}.npz')\n",
    "        \n",
    "    all_odor_pow, scores = np.array([]), []\n",
    "    odors_su = odor_su_dict(phase)\n",
    "    fname = def_freqname(freq)\n",
    "    for odor in odors_su[su]:\n",
    "        if val == 'tps':\n",
    "            mat = np.load(mat_file.format(su,odor,fname))\n",
    "            xpow, Mai_RL, channels = mat[val], mat['label'], mat['channel']\n",
    "        else:\n",
    "            mat = np.load(mat_file.format(su,odor))\n",
    "            xpow, Mai_RL, channels = mat[val][freq,...], mat['Mai_RL'], mat['channels']      \n",
    "        if roi == 'pPirT':\n",
    "            id_rois = [r in ['pPirT','Amg','Amg-PirT'] for r in Mai_RL]\n",
    "        else:\n",
    "            id_rois = [r == roi for r in Mai_RL]\n",
    "        xpow = np.mean(xpow[id_rois,27:47,:],axis=-2) if val == 'xpow' else xpow[id_rois,...]\n",
    "        #xpow_b = np.mean(xpow[id_rois,22:27,:],axis=-2)\n",
    "        #xpow = (xpow_a - xpow_b) / xpow_b#\n",
    "        score_roi = [odors_su[su][odor]]*xpow.shape[-1]\n",
    "        scores.append(score_roi)\n",
    "        all_odor_pow = np.concatenate((all_odor_pow,xpow),axis=-1) if np.size(all_odor_pow) else xpow\n",
    "    scores = np.concatenate(scores,axis=0)\n",
    "    #score_su_norm = (scores - scores.mean())/scores.std()\n",
    "    #mean_roi, std_roi = np.mean(np.ravel(all_odor_pow)), np.std(np.ravel(all_odor_pow))\n",
    "    #all_odor_pow = (all_odor_pow - mean_roi)/ std_roi\n",
    "    kwargs = {}\n",
    "    kwargs['label'], kwargs['channels']= Mai_RL[id_rois], channels[id_rois]\n",
    "    kwargs['xyz'], kwargs[val] = mat['xyz'][id_rois], all_odor_pow\n",
    "    kwargs['fname'], kwargs['nelecs'] = fname, all_odor_pow.shape[0]\n",
    "    kwargs['scores'] = np.array(scores)\n",
    "    return kwargs\n",
    "\n",
    "def groups_pow_scores(phase,su,roi,freq,val):\n",
    "    dict_ = norm_power_by_roi(phase,su,roi,freq,val)\n",
    "    scores = dict_['scores']\n",
    "    pow_norm = dict_[val]\n",
    "    #print(len(scores),pow_norm.shape)\n",
    "    #steps = np.percentile(scores,[0,25,50,75,100])\n",
    "    steps = np.percentile(scores,[0,100])\n",
    "    pow_groups = []\n",
    "    if pow_norm.shape[0] == 1:\n",
    "        for g,step in enumerate(steps[:-1]):\n",
    "            pow_groups.append(pow_norm[:,np.where((step<=scores)&(scores<=(steps[g+1])))[0]])\n",
    "    else:\n",
    "        for g,step in enumerate(steps[:-1]):\n",
    "            pow_groups.append(np.squeeze(pow_norm[:,np.where((step<=scores)&(scores<=(steps[g+1])))]))\n",
    "            \n",
    "    print('groups shapes',[pow.shape for pow in pow_groups])\n",
    "    labels, weights = [], []\n",
    "    for i,_ in enumerate(pow_groups):\n",
    "        labels.append([i]*pow_groups[i].shape[1])\n",
    "        weights.append([pow_groups[i].shape[1]])\n",
    "    labels = np.concatenate(labels,axis=0)\n",
    "    weights = np.concatenate(weights,axis=0)\n",
    "    return pow_groups, labels, weights, dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold as SKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from numpy.random import permutation\n",
    "from scipy import stats\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "st = study('Olfacto')\n",
    "save_path = path.join(st.path, 'classified/_multi_classes/LDA_Power_E_2classes_BBG_no_norm_k5_auc_all/')\n",
    "subjects = ['LEFC','MICP','VACJ','SEMC','FERJ','PIRJ','CHAF']\n",
    "rois = ['ACC','HC','IFG','Ins','MFG','OFC','PHG','SFG','pPirT']\n",
    "phase = 'Encoding'\n",
    "freqs = 4\n",
    "nperm = 1000\n",
    "val = 'xpow'\n",
    "\n",
    "def classif_n_classes_by_subj(su):\n",
    "    for freq in range(freqs):\n",
    "        for roi in rois:\n",
    "            pow_groups, labels, weights, dict_ = groups_pow_scores(phase,su,roi,freq,val)\n",
    "            freq_name, nelecs = dict_['fname'], dict_['nelecs']\n",
    "            if nelecs > 0:\n",
    "                for elec_num in range(nelecs): \n",
    "                    elec, elec_label = dict_['channels'][elec_num], dict_['label'][elec_num]\n",
    "                    xyz = dict_['xyz'][elec_num]\n",
    "#                     print ('elec ', elec, 'elec_label ', elec_label)\n",
    "\n",
    "                    #Filenames to save\n",
    "                    name_auc = (save_path+freq_name+'/auc/'+su +'_auc_3classes_'+roi+'_('+str(elec_num)+').npy')\n",
    "                    name_perm = (save_path+freq_name+'/auc/'+su +'_perm_3classes_'+roi+'_('+str(elec_num)+').npy')\n",
    "                    plot_name = (save_path+freq_name+'/fig/'+su +'_Power_3classes_'+roi+'_('+str(elec_num)+').png')    \n",
    "                    \n",
    "                    if path.exists(name_auc):\n",
    "                        print(su,phase,elec_num,freq,'already computed')\n",
    "                    else:\n",
    "                        print('--» processing',roi, su, 'elec', elec_num,'/',nelecs, 'freq',freq)\n",
    "\n",
    "                        pow_data_elec = []\n",
    "                        for i,power in enumerate(pow_groups):\n",
    "                            pow_data_elec.append(power[elec_num])\n",
    "                # =============================  Classification Computation ============================================================           \n",
    "                        # create a data matrix, concatenate along the trial dimension\n",
    "                        x = np.concatenate(pow_data_elec, axis=0)[:,np.newaxis]\n",
    "                        print ('Size of the concatenated data: ', x.shape)\n",
    "                        y = labels\n",
    "                        print ('Size of label for classif: ', len(y))\n",
    "\n",
    "                        auc = np.array([])\n",
    "                        for t in range(x.shape[1]):\n",
    "                            X = x[:,t]\n",
    "                            X = X.reshape(-1, 1)\n",
    "                            score_rep = []\n",
    "                            for i in range(5):\n",
    "                                k = 5\n",
    "                                skf = SKFold(n_splits=k, random_state=None, shuffle=True)\n",
    "                                skf.get_n_splits(X, y)\n",
    "                                score_cv = []\n",
    "                                for train_index, test_index in skf.split(X, y):\n",
    "                                    clf = LDA()\n",
    "                                    X_train, X_test = X[train_index], X[test_index]\n",
    "                                    y_train, y_test = y[train_index], y[test_index]\n",
    "                                    clf.fit(X=X_train, y=y_train)\n",
    "                                    y_pred = clf.predict(X_test)\n",
    "                                    score_cv.append(roc_auc_score(y_test,y_pred))\n",
    "                                score_rep.append(np.mean(score_cv))\n",
    "                            score_rep = np.asarray(score_rep).reshape(1,len(score_rep))\n",
    "                            auc = np.vstack((auc, score_rep)) if np.size(auc) else score_rep\n",
    "                        auc = np.swapaxes(auc,0,1)\n",
    "                        DA = np.mean(auc)\n",
    "\n",
    "                        perm_scores = np.array([])\n",
    "                        for t in range(x.shape[1]):\n",
    "                            X = x[:,t]\n",
    "                            X = X.reshape(-1, 1)\n",
    "                            perm_rep = []\n",
    "                            for perm in range(nperm):\n",
    "                                y_perm = y[permutation(len(y))]\n",
    "                                score_cv = []\n",
    "                                for train_index, test_index in skf.split(X, y_perm):\n",
    "                                    clf = LDA()\n",
    "                                    X_train, X_test = X[train_index], X[test_index]\n",
    "                                    y_train, y_test = y_perm[train_index], y_perm[test_index]\n",
    "                                    clf.fit(X=X_train, y=y_train)\n",
    "                                    y_pred = clf.predict(X_test)\n",
    "                                    score_cv.append(roc_auc_score(y_test,y_pred))\n",
    "                                perm_rep.append(np.mean(score_cv))\n",
    "                            perm_rep = np.asarray(perm_rep).reshape(1,len(perm_rep))\n",
    "                            perm_scores = np.vstack((perm_scores, perm_rep)) if np.size(perm_scores) else perm_rep\n",
    "                        perm_scores = np.swapaxes(perm_scores,0,1)           \n",
    "                        th_0_05_perm = perm_pvalue2level(perm_scores, p=0.05, maxst=True)\n",
    "                        th_0_01_perm = perm_pvalue2level(perm_scores, p=0.01, maxst=True)\n",
    "                        print('th_perm 005: ', th_0_05_perm[0], '001',th_0_01_perm[0], \n",
    "                              'auc_max', np.max(auc), 'auc_mean', np.mean(auc))\n",
    "\n",
    "                # ============================== PLOT POWER ANALYSIS + STATS & DECODING ACCURACY ===================================================\n",
    "                        #if DA >= th_0_05_perm[0]:\n",
    "                        # plot and figure parameters\n",
    "                        xfmt = ScalarFormatter(useMathText=True)\n",
    "                        xfmt.set_powerlimits((0,3))\n",
    "                        fig, ax = plt.subplots(figsize=(7,7))\n",
    "                        title = freq_name+' for '+su+' 4 classes '+str(elec)+' '+str(elec_label)+' coord '+str(xyz)\n",
    "                        fig.suptitle(title, fontsize=12)\n",
    "\n",
    "                        # Plot the POW + STATS\n",
    "                        plt.xlabel('EpiScore'), plt.ylabel(freq_name)\n",
    "                        anchored_text = AnchoredText('DA = %s, th = %s' % (np.round(DA,2), round(th_0_05_perm[0],2)), loc=2)\n",
    "                        ax.add_artist(anchored_text)\n",
    "                        xticks, w = np.arange(0,2), 0.8\n",
    "                        means = [pow.mean()for pow in pow_data_elec]\n",
    "                        stds = [stats.sem(pow) for pow in pow_data_elec]\n",
    "                        plt.bar(xticks,means,color='blue',yerr=stds)\n",
    "                        plt.savefig(plot_name, dpi=300, bbox_inches='tight')\n",
    "                        plt.clf()\n",
    "                        plt.close()\n",
    "\n",
    "                        #Save plots\n",
    "                        np.save(name_auc, auc)\n",
    "                        np.save(name_perm, perm_scores)\n",
    "                        del X, auc, pow_data_elec\n",
    "            del pow_groups\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Parallel(n_jobs=-1)(delayed(classif_n_classes_by_subj)(su) for su in subjects)\n",
    "    #classif_4_classes_by_subj('LEFC') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-features electrodes by roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold as SKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from numpy.random import permutation\n",
    "from scipy import stats\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "st = study('Olfacto')\n",
    "save_path = path.join(st.path, 'classified/LDA_Power_E_3classes_BBG_no_norm_k5_multi/')\n",
    "subjects = ['LEFC','MICP','VACJ','SEMC','FERJ','PIRJ','CHAF']\n",
    "rois = ['ACC','HC','IFG','Ins','MFG','OFC','PHG','SFG','pPirT']\n",
    "phase = 'Encoding'\n",
    "freqs = 4\n",
    "nperm = 1000\n",
    "val = 'xpow'\n",
    "\n",
    "def classif_4_classes_by_subj(su):\n",
    "    for freq in range(freqs):\n",
    "        for roi in rois:\n",
    "            pow_groups, labels, weights, dict_ = groups_pow_scores(phase,su,roi,freq,val)\n",
    "            freq_name, nelecs = dict_['fname'], dict_['nelecs']\n",
    "            if nelecs > 0:\n",
    "                #Filenames to save\n",
    "                name_auc = (save_path+freq_name+'/auc/'+su +'_auc_3classes_'+roi+'.npy')\n",
    "                name_perm = (save_path+freq_name+'/auc/'+su +'_perm_3classes_'+roi+'.npy')\n",
    "                plot_name = (save_path+freq_name+'/fig/'+su +'_Power_3classes_'+roi+'.png')    \n",
    "                if path.exists(name_auc):\n",
    "                    print(su,phase,freq,'already computed')\n",
    "                else:\n",
    "                    print('--» processing',roi, su, 'freq',freq)\n",
    "\n",
    "                    pow_data_elec = []\n",
    "                    for i,power in enumerate(pow_groups):\n",
    "                        pow_data_elec.append(np.ravel(power))\n",
    "            # =============================  Classification Computation ============================================================           \n",
    "                    # create a data matrix, concatenate along the trial dimension\n",
    "                    x = np.concatenate(pow_data_elec, axis=0)[:,np.newaxis]\n",
    "                    print ('Size of the concatenated data: ', x.shape)\n",
    "                    y = np.concatenate([labels]*nelecs,axis=0)\n",
    "                    print ('Size of label for classif: ', len(y))\n",
    "\n",
    "                    auc = np.array([])\n",
    "                    for t in range(x.shape[1]):\n",
    "                        X = x[:,t]\n",
    "                        X = X.reshape(-1, 1)\n",
    "                        score_rep = []\n",
    "                        for i in range(5):\n",
    "                            k = 5\n",
    "                            skf = SKFold(n_splits=k, random_state=None, shuffle=True)\n",
    "                            skf.get_n_splits(X, y)\n",
    "                            score_cv = []\n",
    "                            for train_index, test_index in skf.split(X, y):\n",
    "                                clf = LDA()\n",
    "                                X_train, X_test = X[train_index], X[test_index]\n",
    "                                y_train, y_test = y[train_index], y[test_index]\n",
    "                                clf.fit(X=X_train, y=y_train)\n",
    "                                y_pred = clf.predict(X_test)\n",
    "                                score_cv.append(accuracy_score(y_test,y_pred))\n",
    "                            score_rep.append(np.mean(score_cv))\n",
    "                        score_rep = np.asarray(score_rep).reshape(1,len(score_rep))\n",
    "                        auc = np.vstack((auc, score_rep)) if np.size(auc) else score_rep\n",
    "                    auc = np.swapaxes(auc,0,1)\n",
    "                    DA = np.mean(auc)\n",
    "\n",
    "                    perm_scores = np.array([])\n",
    "                    for t in range(x.shape[1]):\n",
    "                        X = x[:,t]\n",
    "                        X = X.reshape(-1, 1)\n",
    "                        perm_rep = []\n",
    "                        for perm in range(nperm):\n",
    "                            y_perm = y[permutation(len(y))]\n",
    "                            score_cv = []\n",
    "                            for train_index, test_index in skf.split(X, y_perm):\n",
    "                                clf = LDA()\n",
    "                                X_train, X_test = X[train_index], X[test_index]\n",
    "                                y_train, y_test = y_perm[train_index], y_perm[test_index]\n",
    "                                clf.fit(X=X_train, y=y_train)\n",
    "                                y_pred = clf.predict(X_test)\n",
    "                                score_cv.append(accuracy_score(y_test,y_pred))\n",
    "                            perm_rep.append(np.mean(score_cv))\n",
    "                        perm_rep = np.asarray(perm_rep).reshape(1,len(perm_rep))\n",
    "                        perm_scores = np.vstack((perm_scores, perm_rep)) if np.size(perm_scores) else perm_rep\n",
    "                    perm_scores = np.swapaxes(perm_scores,0,1)           \n",
    "                    th_0_05_perm = perm_pvalue2level(perm_scores, p=0.05, maxst=True)\n",
    "                    th_0_01_perm = perm_pvalue2level(perm_scores, p=0.01, maxst=True)\n",
    "                    print('th_perm 005: ', th_0_05_perm[0], '001',th_0_01_perm[0], \n",
    "                          'auc_max', np.max(auc), 'auc_mean', np.mean(auc))\n",
    "\n",
    "            # ============================== PLOT POWER ANALYSIS + STATS & DECODING ACCURACY ===================================================\n",
    "                    if DA >= th_0_05_perm:\n",
    "                        # plot and figure parameters\n",
    "                        xfmt = ScalarFormatter(useMathText=True)\n",
    "                        xfmt.set_powerlimits((0,3))\n",
    "                        fig, ax = plt.subplots(figsize=(7,7))\n",
    "                        title = freq_name+' for '+su+' 4 classes in '+roi\n",
    "                        fig.suptitle(title, fontsize=12)\n",
    "\n",
    "                        # Plot the POW + STATS\n",
    "                        plt.xlabel('EpiScore'), plt.ylabel(freq_name)\n",
    "                        anchored_text = AnchoredText('DA = %s, th = %s' % (np.round(DA,2), round(th_0_05_perm[0],2)), loc=2)\n",
    "                        ax.add_artist(anchored_text)\n",
    "                        xticks, w = np.arange(0,3), 0.8\n",
    "                        means = [pow.mean()for pow in pow_data_elec]\n",
    "                        stds = [stats.sem(pow) for pow in pow_data_elec]\n",
    "                        plt.bar(xticks,means,color='blue',yerr=stds)\n",
    "                        plt.savefig(plot_name, dpi=300, bbox_inches='tight')\n",
    "                        plt.clf()\n",
    "                        plt.close()\n",
    "\n",
    "                    #Save plots\n",
    "                    np.save(name_auc, auc)\n",
    "                    np.save(name_perm, perm_scores)\n",
    "\n",
    "                    del X, auc, pow_data_elec\n",
    "            del pow_groups\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Parallel(n_jobs=-1)(delayed(classif_4_classes_by_subj)(su) for su in subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
