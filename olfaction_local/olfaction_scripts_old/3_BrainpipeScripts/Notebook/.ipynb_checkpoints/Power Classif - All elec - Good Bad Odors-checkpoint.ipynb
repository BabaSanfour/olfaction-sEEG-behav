{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification Power Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, MaxNLocator\n",
    "import scipy.io as sio\n",
    "#%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "from brainpipe.classification import *\n",
    "from brainpipe.system import study\n",
    "from brainpipe.feature import power, amplitude, sigfilt\n",
    "from brainpipe.visual import *\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import expon\n",
    "\n",
    "from brainpipe.statistics import *\n",
    "from os import path\n",
    "from mne.stats import *\n",
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification across time for all freq bands and subjects\n",
    "### Encoding Good vs Bad odors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Olfacto loaded\n",
      "bad shape:  (21, 29) good shape:  (19, 29)\n",
      "elec  b2-b1 elec_label  aHC&aHC-Ent\n",
      "Size of the concatenated data:  (38, 29) Number of features :  29\n",
      "Size of label for classif:  38\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "[joblib] Attempting to do parallel computing without protecting your import on a system that does not support forking. To use parallel-computing in a script, you must protect your main loop using \"if __name__ == '__main__'\". Please see the joblib documentation on Parallel for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fd3b151607c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m                                             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                                             cv=cv)\n\u001b[0;32m---> 95\u001b[0;31m                                 \u001b[0mRS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbad_good\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                                 \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                                 \u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'balanced'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1188\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m                                           random_state=self.random_state)\n\u001b[0;32m-> 1190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_effective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_initialize_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             return self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n\u001b[0;32m--> 540\u001b[0;31m                                            **self._backend_args)\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFallbackToBackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;31m# Recursively initialize the backend in case of requested fallback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karim/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mconfigure\u001b[0;34m(self, n_jobs, parallel, **backend_args)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malready_forked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             raise ImportError(\n\u001b[0;32m--> 299\u001b[0;31m                 \u001b[0;34m'[joblib] Attempting to do parallel computing '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;34m'without protecting your import on a system that does '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;34m'not support forking. To use parallel-computing in a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: [joblib] Attempting to do parallel computing without protecting your import on a system that does not support forking. To use parallel-computing in a script, you must protect your main loop using \"if __name__ == '__main__'\". Please see the joblib documentation on Parallel for more information"
     ]
    }
   ],
   "source": [
    "# Importing files \n",
    "st = study('Olfacto')\n",
    "pathfiles = path.join(st.path, 'feature/6_Power_E1E2_Odor_Good_Bad_700_100/')\n",
    "elecfiles = path.join(st.path, 'database/TS_E_all_by_odor_th40_art400_30_250_5s_concatOK/')\n",
    "path2save = path.join(st.path, 'classified/8_Classif_Power_Good_Bad_across_time_700ms_step100ms_subset/svm_optimized/')\n",
    "\n",
    "test = 'subset' \n",
    "classifs = ['svm']\n",
    "\n",
    "if test == True:\n",
    "    n_elec = {'VACJ' :1}\n",
    "    subjects = ['VACJ']\n",
    "    nfreq = 1\n",
    "    \n",
    "elif test == False :\n",
    "    subjects = ['SEMC','PIRJ','LEFC','MICP','CHAF','VACJ'] \n",
    "    n_elec = {\n",
    "    'CHAF' : 107,\n",
    "    'VACJ' : 139, \n",
    "    'SEMC' : 107,\n",
    "    'PIRJ' : 106,\n",
    "    'LEFC' : 193,\n",
    "    'MICP' : 105,\n",
    "        }\n",
    "    nfreq = 6\n",
    "    \n",
    "elif test == 'subset': #HC, PHC, Amg, Pir\n",
    "    subjects = ['SEMC','PIRJ','LEFC','MICP','VACJ'] \n",
    "    n_elec = {\n",
    "    'VACJ' : [1,2,3,11,12,13,14,15,16,17,22,23,24,60,61,62],\n",
    "    'SEMC' : [0,1,2,3,4],\n",
    "    'PIRJ' : [0,1,2,3,4,11,12,13,14,15,16,22,23,24,25,26,33,34,35,36,37,38],\n",
    "    'LEFC' : [0,1,11,12,13,14,22,23,24,25,26,27],\n",
    "    'MICP' : [0,1,2,3,9,18,10,11,12,19,20,21,22,23,29,30,31,32,33,40,41,42,43,44],\n",
    "        }\n",
    "    nfreq = 6\n",
    "    \n",
    "for classif in classifs:\n",
    "    for su in subjects:\n",
    "        #for elec_num in range(n_elec[su]):\n",
    "        for elec_num in n_elec[su]:\n",
    "            for freq in range(nfreq):\n",
    "                #files & data to load\n",
    "                bad_data = np.load(path.join(pathfiles, su+'_concat_odor_bad_bipo_power.npz'))['xpow'][freq,elec_num] #take power for one freq band, one elec\n",
    "                bad_data = bad_data.swapaxes(0,1)\n",
    "                good_data = np.load(path.join(pathfiles, su+'_concat_odor_good_bipo_power.npz'))['xpow'][freq,elec_num] #take power for one freq band, one elec\n",
    "                good_data = good_data.swapaxes(0,1)\n",
    "                nwin = good_data.shape[1]\n",
    "                print ('bad shape: ', bad_data.shape, 'good shape: ', good_data.shape)\n",
    "                elec = np.load(path.join(elecfiles, su+'_concat_odor_bad_bipo.npz'))['channel'][elec_num]\n",
    "                elec_label = np.load(path.join(elecfiles, su+'_concat_odor_bad_bipo.npz'))['label'][elec_num]\n",
    "                freq_name = np.load(path.join(pathfiles, su+'_concat_odor_bad_bipo_power.npz'))['fname'][freq]\n",
    "                print ('elec ', elec, 'elec_label ', elec_label)\n",
    "\n",
    "# ================================  STATISTICS FOR POWER  =====================================\n",
    "                n_rep = 10\n",
    "                T_rep, p_val_rep = np.array([]), np.array([])\n",
    "                da_rep, daperm_rep = np.array([]), np.array([])\n",
    "                alpha = 0.05\n",
    "                \n",
    "                first = True\n",
    "                for i in range(n_rep):\n",
    "                    #reshape data to have the exact same nb of trials (mandatory for t-tests)\n",
    "                    if bad_data.shape[0] > good_data.shape[0]:\n",
    "                        bad_data = bad_data[np.random.randint(bad_data.shape[0], size=good_data.shape[0]), :] #reshape bad_data to fit good_data shape\n",
    "                    if bad_data.shape[0] < good_data.shape[0]:\n",
    "                        good_data = good_data[np.random.randint(good_data.shape[0], size=bad_data.shape[0]), :]\n",
    "                    ntrials = bad_data.shape[0]\n",
    "                    X = bad_data - good_data #the last dimension needs to be time\n",
    "                    T0, p_values, H0 = permutation_t_test(X, n_permutations=1000, tail=0, n_jobs=1, verbose=None)\n",
    "                    T_rep = np.vstack((T_rep,T0)) if np.size(T_rep) else T0\n",
    "                    p_val_rep = np.vstack((p_val_rep,p_values)) if np.size(p_val_rep) else p_values\n",
    "\n",
    "# =============================  CLASSIFICATION COMPUTATION ============================================================           \n",
    "                    #create a data matrix, concatenate along the trial dimension\n",
    "                    bad_good = np.concatenate((bad_data, good_data), axis=0)\n",
    "                    print ('Size of the concatenated data: ', bad_good.shape, 'Number of features : ', bad_good.shape[1])\n",
    "\n",
    "                    #create label vector (0 for rest and 1 for odor)\n",
    "                    y = [0]*bad_data.shape[0] + [1]*good_data.shape[0]\n",
    "                    print ('Size of label for classif: ', len(y))\n",
    "                    \n",
    "                    da_final = []\n",
    "                    for i in range(bad_good.shape[1]):\n",
    "                        if first:\n",
    "                            cv = StratifiedKFold(n_splits=10)\n",
    "                            clf = SVC(class_weight='balanced', kernel='rbf')\n",
    "                            params = {'C': expon(scale=100), 'gamma': expon(scale=.1)}\n",
    "                            RS = RandomizedSearchCV(estimator=clf,\n",
    "                                        param_distributions=params,\n",
    "                                        n_iter=100,\n",
    "                                        n_jobs=-1,\n",
    "                                        cv=cv)\n",
    "                            RS.fit(X=bad_good[:,i].reshape(-1,1), y=y)\n",
    "                            best_params = RS.best_params_\n",
    "                            best_params['class_weight'] = 'balanced'\n",
    "                            best_params['kernel'] = 'rbf'\n",
    "\n",
    "                        # Define a cross validation:\n",
    "                        cv = defCv(y, n_folds=10, cvtype='skfold', rep=10)\n",
    "                        # Define classifier technique\n",
    "                        clf = defClf(y=y, clf=classif, kern='rbf',\n",
    "                                     C=best_params['C'], gamma=best_params['gamma'],\n",
    "                                     class_weight=best_params['class_weight'])#,n_tree=200, random_state=100)\n",
    "                        #Classify rest and odor\n",
    "                        cl = classify(y, clf=clf, cvtype=cv)\n",
    "\n",
    "                        # Evaluate the classifier on data:\n",
    "                        da,pvalue,daperm = cl.fit(bad_good[:,i].reshape(-1,1), n_perm=100,method='bino',mf=False)\n",
    "                        da_final.append(da.tolist())\n",
    "                    da = np.asarray(da_final).squeeze().swapaxis(0,1)\n",
    "                    print(da.shape)\n",
    "                    print ('decoding accuracy',da.shape, 'pvalues ', pvalue.shape,)\n",
    "                    da_rep = np.vstack((da_rep,da)) if np.size(da_rep) else da\n",
    "                    first = False\n",
    "                    \n",
    "# =============================== TAKE MAX STATS TO PLOT =====================================\n",
    "                # Take the max pvalues for each time window\n",
    "                idx_pval_max = []\n",
    "                for s in range(nwin):\n",
    "                    pval_max = p_val_rep[:,s].max()\n",
    "                    idx_pval_max.append(pval_max)\n",
    "                #print (p_val_rep.shape, idx_pval_max)\n",
    "\n",
    "                #Save da accuracy\n",
    "                np.save(path2save+su+'_da_Bad_vs_Good__'+str(freq_name)+'_'+classif+'_'+str(elec_label)+'_('+str(elec_num)+')',da_rep)\n",
    "\n",
    "# ============================== PLOT POWER ANALYSIS + STATS & DECODING ACCURACY ===================================================\n",
    "                # data to plot\n",
    "                bad_to_plot = np.load(path.join(pathfiles, su+'_concat_odor_bad_bipo_power.npz'))['xpow'][freq,elec_num]\n",
    "                bad_to_plot = bad_to_plot.swapaxes(0,1)\n",
    "                good_to_plot = np.load(path.join(pathfiles, su+'_concat_odor_good_bipo_power.npz'))['xpow'][freq,elec_num] #take power for one freq band, one elec\n",
    "                good_to_plot = good_to_plot.swapaxes(0,1)\n",
    "                bad_good_plot = np.concatenate((bad_to_plot, good_to_plot), axis=0)\n",
    "                y_plot = [0]*bad_to_plot.shape[0] + [1]*good_to_plot.shape[0]\n",
    "    \n",
    "                # plot and figure parameters\n",
    "                xfmt = ScalarFormatter(useMathText=True)\n",
    "                xfmt.set_powerlimits((0,3))\n",
    "                fig = plt.figure(1,figsize=(7,7))\n",
    "                step = 3700/ bad_to_plot.shape[1]\n",
    "                time = np.arange(-700, 3000, step)\n",
    "                print (len(time))\n",
    "                title = 'Power and DA for '+str(freq_name)+' '+su+' '+classif+' '+str(elec_label)+' ('+str(elec_num)+')'\n",
    "                fig.suptitle(title, fontsize=12)\n",
    "\n",
    "                # Plot the ERPs and the stats\n",
    "                plt.subplot(211)\n",
    "                BorderPlot(time, bad_good_plot, y=y_plot, kind='sem', alpha=0.2, color=['b', 'm'], \n",
    "                           linewidth=2, ncol=1, xlabel='Time (ms)', ylabel = r' $\\mu$V', \n",
    "                           legend = ['bad', 'good'])\n",
    "                addPval(plt.gca(), idx_pval_max, p=0.05, x=time, y=5, color='0.5', lw=2)\n",
    "                addPval(plt.gca(), idx_pval_max, p=0.01, x=time, y=0.2, color='0.7', lw=2)\n",
    "                addPval(plt.gca(), idx_pval_max, p=0.001, x=time, y=0.3, color='0.9', lw=2)\n",
    "                addLines(plt.gca(), vLines=[0], vColor=['black'], vWidth=[2], hLines=[0], \n",
    "                         hColor=['#000000'], hWidth=[2])\n",
    "                rmaxis(plt.gca(), ['right', 'top'])\n",
    "                plt.legend(loc=0, handletextpad=0.1, frameon=False)\n",
    "                plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "\n",
    "                #Plot the da\n",
    "                plt.subplot(212)\n",
    "                BorderPlot(time, da_rep, color='darkslateblue', kind='std',xlabel='Time (ms)', ylim=[da.min()-10,da.max()+10],\n",
    "                           ylabel='Decoding accuracy (%)',linewidth=2,alpha=0.3)\n",
    "                rmaxis(plt.gca(), ['right', 'top'])\n",
    "                addLines(plt.gca(), vLines=[0], vColor=['black'], vWidth=[2], hLines=[50], \n",
    "                         hColor=['#000000'], hWidth=[2])\n",
    "                plt.gca().yaxis.set_major_locator(MaxNLocator(3,integer=True))\n",
    "                th_0_05 = 100*np.around(binom.isf(0.05, good_data.shape[0], 0.5)/good_data.shape[0],2)\n",
    "                th_0_01 = 100*np.around(binom.isf(0.01, good_data.shape[0], 0.5)/good_data.shape[0],2)\n",
    "                th_0_001 = 100*np.around(binom.isf(0.001, good_data.shape[0], 0.5)/good_data.shape[0],2)\n",
    "                plt.plot(time, th_0_05*np.ones(len(time)), '--', color='orange', \n",
    "                          linewidth=2, label= str(th_0_05)+' - p < .05')\n",
    "                plt.plot(time, th_0_01*np.ones(len(time)), '--', color='orangered', \n",
    "                          linewidth=2, label= str(th_0_01)+' - p < .01')\n",
    "                plt.plot(time, th_0_001*np.ones(len(time)), '--', color='r', \n",
    "                          linewidth=2, label= str(th_0_001)+' - p < .001')\n",
    "                plt.legend(loc=0, handletextpad=0.1, frameon=False)\n",
    "\n",
    "# =========================== SAVE FIGURES & CLEAN MEMORY ==========================================================================\n",
    "                #Save the plot\n",
    "                fname = path.join(path2save, su + '_'+freq_name+'_'+str(elec_label)+'_('+str(elec_num)+')_'+'0.01.png')\n",
    "                fig.savefig(fname, dpi=300, bbox_inches='tight')\n",
    "                print ('saving --Â»' ,fname)\n",
    "                plt.clf()\n",
    "                plt.close()\n",
    "                del bad_good, good_data, bad_data, elec, elec_label, freq_name, da, daperm, pvalue, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "binom.isf(0.01, good_data.shape[0], 0.5)/good_data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
