{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Atlas:\n",
    "    \"\"\"\n",
    "    Holds a single atlas and its metadata.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        Human-readable identifier of the atlas (e.g., \"aal\" or \"brodmann\").\n",
    "    vol : np.ndarray, shape (I, J, K)\n",
    "        The 3D integer/float array representing the atlas, where each voxel \n",
    "        corresponds to a labeled region index (e.g., 0, 1, 2, ...).\n",
    "    hdr : np.ndarray, shape (4, 4)\n",
    "        The affine transform for voxel->world coordinates.\n",
    "    labels : array-like or dict, optional\n",
    "        A structure mapping region indices to region names. \n",
    "        Could be a list, a numpy array, or a dict {index: label}.\n",
    "        By default, None if not provided.\n",
    "    index : np.ndarray or list, optional\n",
    "        Explicit numeric indices that correspond to `labels`.\n",
    "        For example, if `index = [1,2,3]` and `labels = [\"Area1\",\"Area2\",\"Area3\"]`,\n",
    "        then a voxel labeled '2' in `vol` => \"Area2\".\n",
    "        If you supply a dict to `labels` keyed by these index values, you may leave\n",
    "        `index` as None. Default is None.\n",
    "    system : {\"mni\", \"tal\", \"unknown\"}, default \"mni\"\n",
    "        The anatomical coordinate space or reference system.\n",
    "        Commonly 'mni' or 'tal'. Use \"unknown\" if not sure.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    name : str\n",
    "    vol : np.ndarray\n",
    "    hdr : np.ndarray\n",
    "    labels : array-like or dict, optional\n",
    "    index : np.ndarray or list, optional\n",
    "    system : str\n",
    "    offset : int or float\n",
    "    shape : tuple of int\n",
    "        The shape (I, J, K) of the atlas data.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    get_label(value):\n",
    "        Returns the label corresponding to a given index (int) value in `vol`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 name,\n",
    "                 vol,\n",
    "                 hdr,\n",
    "                 labels=None,\n",
    "                 index=None,\n",
    "                 system='mni'):\n",
    "        self.name = name\n",
    "        self.vol = np.asarray(vol)\n",
    "        self.hdr = hdr\n",
    "        self.labels = labels\n",
    "        self.index = index\n",
    "        self.system = system\n",
    "\n",
    "        # Basic checks\n",
    "        if not isinstance(vol, np.ndarray) or vol.ndim != 3:\n",
    "            raise ValueError(\"`vol` must be a 3D numpy array.\")\n",
    "        if not isinstance(hdr, np.ndarray) or hdr.shape != (4, 4):\n",
    "            raise ValueError(\"`hdr` must be a 4x4 transform matrix.\")\n",
    "\n",
    "        self.shape = vol.shape  # convenience\n",
    "        if isinstance(self.labels, dict):\n",
    "            self._label2index = {v: k for k, v in self.labels.items()}\n",
    "        else:\n",
    "            self._label2index = None\n",
    "\n",
    "    def _get_region_name(self, value):\n",
    "        \"\"\"\n",
    "        Return the label corresponding to the integer `value` in the volume.\n",
    "\n",
    "        If `labels` is:\n",
    "          - a dict {region_index: region_name}, we use `labels.get(value, 'Unknown')`.\n",
    "          - a list or np.ndarray, we find where `index == value`.\n",
    "          - None, returns 'Unknown'.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The label (region name), or 'Unknown' if not found.\n",
    "        \"\"\"\n",
    "        value = str(value) #TODO: Check if this is necessary/could be problematic\n",
    "        if isinstance(self.labels, dict):\n",
    "            return self.labels.get(value, \"Unknown\")\n",
    "\n",
    "        # Otherwise, if we have an array-like `labels` plus a separate `index` array,\n",
    "        if self.index is not None and len(self.index) == len(self.labels):\n",
    "            try:\n",
    "                idx_pos = self.index.index(value) if isinstance(self.index, list) else np.where(self.index == value)[0][0]\n",
    "                return self.labels[idx_pos]\n",
    "            except (ValueError, IndexError):\n",
    "                return \"Unknown\"\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    def get_region_name(self, value):\n",
    "        \"\"\"\n",
    "        Return the clean region name for a given index value in the volume.\n",
    "        \"\"\"\n",
    "        #TODO: Implement this method, for now just return the raw label\n",
    "        return self._get_region_name(value)\n",
    "\n",
    "    def get_region_index(self, label):\n",
    "        \"\"\"\n",
    "        Return the index corresponding to the label in the volume.\n",
    "\n",
    "        If `labels` is:\n",
    "          - a dict {region_index: region_name}, we use `labels.get(value, 'Unknown')`.\n",
    "          - a list or np.ndarray, we find where `index == value`.\n",
    "          - None, returns 'Unknown'.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The index (region index), or 'Unknown' if not found.\n",
    "        \"\"\"\n",
    "        if self._label2index is not None:\n",
    "            return self._label2index.get(label, \"Unknown\")\n",
    "        \n",
    "        \n",
    "        if self.index is not None and len(self.index) == len(self.labels):\n",
    "            try:\n",
    "                idx_pos = self.labels.index(label) if isinstance(self.labels, list) else np.where(self.labels == label)[0][0]\n",
    "                return self.index[idx_pos]\n",
    "            except (ValueError, IndexError):\n",
    "                return \"Unknown\"\n",
    "            \n",
    "        return \"Unknown\"\n",
    "    \n",
    "    def _get_hemisphere(self, region):\n",
    "        \"\"\"\n",
    "        Return the hemisphere (left/right) of the region name/index.\n",
    "        \"\"\"\n",
    "        if not isinstance(region, str):\n",
    "            region = self.get_region_name(region)\n",
    "        if region is None or region == \"Unknown\":\n",
    "            return None\n",
    "        region_lower = region.lower()\n",
    "        if region_lower.endswith('_l'):\n",
    "            return 'L'\n",
    "        elif region_lower.endswith('_r'):\n",
    "            return 'R'\n",
    "        return None\n",
    "    \n",
    "    def get_list_of_regions(self):\n",
    "        \"\"\"\n",
    "        Return a list of all unique region names in the atlas.\n",
    "        \"\"\"\n",
    "        #TODO: Implement this method\n",
    "        return None\n",
    "    \n",
    "    def pos_to_source(self, pos):\n",
    "        \"\"\"\n",
    "        Return the source indices (i, j, k) for a given MNI coordinate using hdr.\n",
    "        \"\"\"\n",
    "        pos = np.asarray(pos)\n",
    "        if pos.shape != (3,):\n",
    "            raise ValueError(\"pos must be a 3-element coordinate (x,y,z).\")\n",
    "        xyz = np.linalg.inv(self.hdr) @ np.array([*pos, 1])\n",
    "        return tuple(map(int, np.round(xyz)[:3]))\n",
    "    \n",
    "    def pos_to_index(self, pos):\n",
    "        \"\"\"\n",
    "        Return the region index for a given MNI coordinate using hdr.\n",
    "        \"\"\"\n",
    "        ijk = self.pos_to_source(pos)\n",
    "        # Check bounds\n",
    "        if any(i < 0 or i >= s for i, s in zip(ijk, self.shape)):\n",
    "            return \"Unknown\"  # or None\n",
    "        return int(self.vol[ijk])\n",
    "    \n",
    "    def pos_to_region(self, pos):\n",
    "        \"\"\"\n",
    "        Return the region name for a given MNI coordinate using hdr.\n",
    "        \"\"\"\n",
    "        index = self.pos_to_index(pos)\n",
    "        if index == \"Unknown\":\n",
    "            return \"Unknown\"\n",
    "        return self.get_region_name(index)\n",
    "    \n",
    "    def source_to_pos(self, source):\n",
    "        \"\"\"\n",
    "        Return the MNI coordinate for a given source indices (i, j, k) using hdr.\n",
    "        \"\"\"\n",
    "        source = np.atleast_2d(source)  # Ensure shape is (N, 3) even if (3,)\n",
    "        source = np.hstack([source, np.ones((source.shape[0], 1))])  # (N, 4)\n",
    "        transformed = source @ self.hdr.T \n",
    "        xyz = transformed[:, :3] / transformed[:, 3, np.newaxis]\n",
    "        return xyz if len(source) > 1 else xyz[0]  \n",
    "        \n",
    "    def index_to_pos(self, index):\n",
    "        \"\"\"\n",
    "        Return the MNI coordinate for a given region index.\n",
    "        \"\"\"\n",
    "        index = int(index) #TODO: Check if this is necessary/could be problematic\n",
    "        coords = np.argwhere(self.vol == index)  # shape (N,3)\n",
    "        if coords.size == 0:\n",
    "            return np.empty((0, 3))  # empty array if none found\n",
    "        return self.source_to_pos(coords)\n",
    "    \n",
    "    def region_to_pos(self, region):\n",
    "        \"\"\"\n",
    "        Return the MNI coordinate for a given region name.\n",
    "        \"\"\"\n",
    "        index = self.get_region_index(region)\n",
    "        if index == \"Unknown\":\n",
    "            return np.empty((0, 3))\n",
    "        return self.index_to_pos(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[get_dataset_dir] Dataset found in /Users/hamzaabdelhedi/Projects/olfaction_local/aal_SPM12\n"
     ]
    }
   ],
   "source": [
    "from sourcelocalizer.load_atlas_data import fetch_atlas\n",
    "from sourcelocalizer import Atlas\n",
    "atlas = fetch_atlas('aal')\n",
    "atlas = Atlas(name='aal', vol=atlas['vol'], hdr=atlas['hdr'], labels=atlas['labels'], system='mni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atlas\n",
      "Index: 2001, Name: Precentral_L\n",
      "Index: 2002, Name: Precentral_R\n",
      "Index: 2101, Name: Frontal_Sup_L\n",
      "Index: 2102, Name: Frontal_Sup_R\n",
      "Index: 2111, Name: Frontal_Sup_Orb_L\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "path_xml = \"/Users/hamzaabdelhedi/nilearn_data/aal_SPM12/aal/ROI_MNI_V4.xml\"\n",
    "# Parse the XML file\n",
    "tree = ET.parse(path_xml)  # Replace \"file.xml\" with your actual file path\n",
    "root = tree.getroot()  # Get the root element\n",
    "\n",
    "# Print the root tag\n",
    "print(root.tag)\n",
    "\n",
    "# Extract labels inside <data> section\n",
    "regions = []\n",
    "\n",
    "for label in root.find(\"data\").findall(\"label\"):\n",
    "    index = label.find(\"index\").text\n",
    "    name = label.find(\"name\").text\n",
    "    regions.append((index, name))\n",
    "\n",
    "# Print first 5 brain regions\n",
    "for idx, name in regions[:5]:\n",
    "    print(f\"Index: {idx}, Name: {name}\")\n",
    "\n",
    "# Optional: Convert to dictionary\n",
    "region_dict = {idx: name for idx, name in regions}\n",
    "\n",
    "# Optional: Save as CSV\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(regions, columns=[\"Index\", \"Region Name\"])\n",
    "df.to_csv(\"aal_brain_regions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precentral_L\n",
      "2001\n",
      "L\n",
      "R\n",
      "(52, 47, 59)\n",
      "4011\n",
      "Cingulum_Mid_L\n",
      "[-14. -32.  46.]\n",
      "[[-14. -20.  70.]\n",
      " [-14. -18.  68.]\n",
      " [-14. -18.  70.]\n",
      " ...\n",
      " [-62.   8.  30.]\n",
      " [-62.   8.  32.]\n",
      " [-62.   8.  34.]]\n",
      "[[-14. -20.  70.]\n",
      " [-14. -18.  68.]\n",
      " [-14. -18.  70.]\n",
      " ...\n",
      " [-62.   8.  30.]\n",
      " [-62.   8.  32.]\n",
      " [-62.   8.  34.]]\n"
     ]
    }
   ],
   "source": [
    "print(atlas.get_region_name(2001))\n",
    "print(atlas.get_region_index('Precentral_L'))\n",
    "print(atlas._get_hemisphere(2001))\n",
    "print(atlas._get_hemisphere('Precentral_R'))\n",
    "print(atlas.pos_to_source([-14.7, -31.2, 45.45]))\n",
    "print(atlas.pos_to_index([-14.7, -31.2, 45.45]))\n",
    "print(atlas.pos_to_region([-14.7, -31.2, 45.45]))\n",
    "print(atlas.source_to_pos([52, 47, 59]))\n",
    "print(atlas.index_to_pos(2001))\n",
    "print(atlas.region_to_pos('Precentral_L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNI: (-14.7, -31.2, 45.45) -> Closest Region: Cingulum_Mid_L (Distance: 0 mm)\n",
      "MNI: (-15.5, -31.45, 49.3) -> Closest Region: Cingulum_Mid_L (Distance: 1.74 mm)\n",
      "MNI: (-17.1, -31.75, 56.95) -> Closest Region: Postcentral_L (Distance: 3.06 mm)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# ---- STEP 1: Load AAL Atlas ---- #\n",
    "nii_path = \"/Users/hamzaabdelhedi/nilearn_data/aal_SPM12/aal/ROI_MNI_V4.nii\"\n",
    "nii_img = nib.load(nii_path)\n",
    "atlas_data = nii_img.get_fdata()\n",
    "affine = nii_img.affine  # Transformation matrix\n",
    "\n",
    "# ---- STEP 2: Load AAL Labels from XML ---- #\n",
    "xml_path = \"/Users/hamzaabdelhedi/nilearn_data/aal_SPM12/aal/ROI_MNI_V4.xml\"\n",
    "tree = ET.parse(xml_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Create a dictionary: {index -> region name}\n",
    "region_dict = {}\n",
    "for label in root.find(\"data\").findall(\"label\"):\n",
    "    index = int(label.find(\"index\").text)  # Convert index to int\n",
    "    name = label.find(\"name\").text\n",
    "    region_dict[index] = name\n",
    "\n",
    "# ---- STEP 3: Convert MNI Coordinates to Region Names ---- #\n",
    "def find_closest_region(mni_coord, search_radius=5):\n",
    "    \"\"\"\n",
    "    Convert MNI coordinate to the closest AAL region if an exact match is not found.\n",
    "    \n",
    "    :param mni_coord: (X, Y, Z) MNI coordinate\n",
    "    :param search_radius: Search radius (in mm) to find the closest region\n",
    "    :return: (Region Name, Distance in mm)\n",
    "    \"\"\"\n",
    "    # Convert MNI to voxel coordinates\n",
    "    voxel_coord = np.round(nib.affines.apply_affine(np.linalg.inv(affine), mni_coord)).astype(int)\n",
    "\n",
    "    # Ensure voxel is inside image bounds\n",
    "    if not (0 <= voxel_coord[0] < atlas_data.shape[0] and\n",
    "            0 <= voxel_coord[1] < atlas_data.shape[1] and\n",
    "            0 <= voxel_coord[2] < atlas_data.shape[2]):\n",
    "        return \"Out of bounds\", None\n",
    "\n",
    "    # Check if voxel has a direct region match\n",
    "    region_index = int(atlas_data[tuple(voxel_coord)])\n",
    "    if region_index in region_dict:\n",
    "        return region_dict[region_index], 0  # Distance = 0 if exact match\n",
    "\n",
    "    # ---- STEP 4: Search for the Nearest Labeled Voxel ---- #\n",
    "    # Get all nonzero voxel coordinates (labeled regions)\n",
    "    labeled_voxels = np.array(np.where(atlas_data > 0)).T  # Transpose to (N,3)\n",
    "    \n",
    "    # Convert labeled voxels to MNI space\n",
    "    labeled_mni_coords = nib.affines.apply_affine(affine, labeled_voxels)\n",
    "    \n",
    "    # Compute Euclidean distances to the given MNI coordinate\n",
    "    distances = distance.cdist([mni_coord], labeled_mni_coords)[0]  # Compute distance from the given MNI coord\n",
    "    \n",
    "    # Find the closest labeled voxel\n",
    "    min_index = np.argmin(distances)\n",
    "    closest_mni = labeled_mni_coords[min_index]\n",
    "    closest_voxel = labeled_voxels[min_index]\n",
    "    closest_index = int(atlas_data[tuple(closest_voxel)])\n",
    "    \n",
    "    # Get the closest region name\n",
    "    closest_region = region_dict.get(closest_index, \"Unknown Region\")\n",
    "    \n",
    "    return closest_region, round(distances[min_index], 2)  # Return region name and distance\n",
    "\n",
    "# ---- STEP 4: Example Usage ---- #\n",
    "# Example MNI coordinates\n",
    "example_coords = [(-14.7, -31.2, 45.45), (-15.50, -31.45, 49.30), (-17.10, -31.75, 56.95)]  # Replace with actual coordinates\n",
    "\n",
    "for coord in example_coords:\n",
    "    region, dist = find_closest_region(coord)\n",
    "    print(f\"MNI: {coord} -> Closest Region: {region} (Distance: {dist} mm)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[get_dataset_dir] Dataset found in /Users/hamzaabdelhedi/nilearn_data/fsl\n",
      "The voxel [-14.7  -31.2   45.45] belongs to the region: Precentral Gyrus\n"
     ]
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "from nilearn.image import load_img\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the atlas and labels\n",
    "atlas = datasets.fetch_atlas_harvard_oxford('cort-maxprob-thr25-1mm')\n",
    "atlas_img = load_img(atlas.maps)  # This is the atlas image\n",
    "atlas_labels = atlas.labels       # This is a list of region labels\n",
    "\n",
    "# Step 2: Load the voxel coordinates (example: [x, y, z] in MNI space)\n",
    "voxel_coords = np.array(example_coords[0])  # Replace with your voxel coordinates\n",
    "\n",
    "# Step 3: Map voxel to atlas index\n",
    "# Affine transformation to convert real-world coordinates to voxel indices\n",
    "affine = atlas_img.affine\n",
    "voxel_indices = nib.affines.apply_affine(np.linalg.inv(affine), voxel_coords).astype(int)\n",
    "\n",
    "# Step 4: Find the atlas region corresponding to the voxel\n",
    "atlas_data = atlas_img.get_fdata()\n",
    "region_index = atlas_data[tuple(voxel_indices)]\n",
    "\n",
    "# Step 5: Retrieve the label of the region\n",
    "if region_index > 0:  # Check if the voxel belongs to a labeled region\n",
    "    region_name = atlas_labels[int(region_index)]\n",
    "    print(f\"The voxel {voxel_coords} belongs to the region: {region_name}\")\n",
    "else:\n",
    "    print(f\"The voxel {voxel_coords} is not assigned to any region in the atlas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###############################################################################\n",
    "# Coordinate transform stubs (MNI <-> TAL, etc.)\n",
    "# You can expand or replace as needed.\n",
    "###############################################################################\n",
    "def mni_to_tal(xyz):\n",
    "    \"\"\"\n",
    "    Convert MNI coordinates to approximate Talairach coordinates using\n",
    "    a simple linear transform (the \"Brett transform\").\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyz : np.ndarray of shape (N, 3) or (3,)\n",
    "        MNI coordinates. If shape is (3,), we interpret it as a single point.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tal_xyz : np.ndarray of the same shape\n",
    "        Approximated Talairach coordinates.\n",
    "    \"\"\"\n",
    "    xyz = np.asarray(xyz, dtype=np.float32)\n",
    "\n",
    "    # Handle single point or multiple points\n",
    "    if xyz.ndim == 1 and xyz.size == 3:\n",
    "        xyz = xyz.reshape(1, 3)\n",
    "        single_input = True\n",
    "    else:\n",
    "        single_input = False\n",
    "\n",
    "    # Brett transform (one of several variants). \n",
    "    # The exact numbers are \"best guess\" approximations.\n",
    "    # You can replace them with your own or more official transformations.\n",
    "    x_tal = 0.9900 * xyz[:, 0]\n",
    "    y_tal = 0.9688 * xyz[:, 1] + 0.0420\n",
    "    z_tal = 0.8390 * xyz[:, 2] + 0.1300\n",
    "\n",
    "    tal_xyz = np.column_stack((x_tal, y_tal, z_tal))\n",
    "\n",
    "    if single_input:\n",
    "        tal_xyz = tal_xyz[0]  # return shape (3,)\n",
    "\n",
    "    return tal_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceLocalizer:\n",
    "    \"\"\"\n",
    "    A brand-new, independent class that locates (x,y,z) source positions\n",
    "    in one or more atlas volumes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    atlases : list of AtlasVolume or str\n",
    "        Either a list of AtlasVolume objects or a path/string pointing\n",
    "        to an atlas. If a string or list of strings is provided, we'll\n",
    "        try to load from disk (using `load_volume_from_file` stub).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, atlases, offset=0):\n",
    "        self._atlas_list = []\n",
    "\n",
    "        # If user passes a single string or single AtlasVolume, unify to a list\n",
    "        if isinstance(atlases, (str, Atlas)):\n",
    "            atlases = [atlases]\n",
    "\n",
    "        # Build up our list of AtlasVolume\n",
    "        for atlas in atlases:\n",
    "            if isinstance(atlas, Atlas):\n",
    "                self._atlas_list.append(atlas)\n",
    "            elif isinstance(atlas, str):\n",
    "                # Try to load from file or interpret atlas name\n",
    "                vol, hdr, labels, index, system = load_volume_from_file(atlas)\n",
    "                name = atlas.split('.')[0]  # naive\n",
    "                av = Atlas(\n",
    "                    name=name,\n",
    "                    vol=vol,\n",
    "                    hdr=hdr,\n",
    "                    labels=labels,\n",
    "                    index=index,\n",
    "                    system=system,\n",
    "                    offset=offset\n",
    "                )\n",
    "                self._atlas_list.append(av)\n",
    "            else:\n",
    "                raise TypeError(f\"Invalid atlas type: {type(atlas)}\")\n",
    "\n",
    "        self._analysis = None  # Will store last result\n",
    "\n",
    "    def localize_sources(self,\n",
    "                         xyz,\n",
    "                         source_names=None,\n",
    "                         replace_bad=True,\n",
    "                         bad_patterns=None,\n",
    "                         replace_with='Not found',\n",
    "                         distance=None,\n",
    "                         keep_only=None):\n",
    "        \"\"\"\n",
    "        Localize each source in xyz to one or more atlas volumes.\n",
    "\n",
    "        If multiple atlases are in self._atlas_list, we merge their results.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        xyz : np.ndarray, shape (N, 3)\n",
    "            Source coordinates.\n",
    "        source_names : list of str, optional\n",
    "            If provided, must match len(xyz). Used as labels in the output.\n",
    "        replace_bad : bool\n",
    "            Whether to replace missing or bad pattern values with `replace_with`.\n",
    "        bad_patterns : list\n",
    "            Values considered 'bad' (e.g. [-1, None, 'undefined']).\n",
    "        replace_with : str\n",
    "            Replace any 'bad' values with this string.\n",
    "        distance : float or None\n",
    "            If provided, tries to reassign 'bad' or 'Not found' points\n",
    "            from the nearest valid-labeled source within this distance.\n",
    "        keep_only : list of str or None\n",
    "            If provided, keep only sources that match these labels (in any column).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df : pd.DataFrame\n",
    "            The localized results. One row per source coordinate,\n",
    "            plus columns for each atlas’s label.\n",
    "        \"\"\"\n",
    "        if not isinstance(xyz, np.ndarray) or xyz.ndim != 2 or xyz.shape[1] != 3:\n",
    "            raise ValueError(\"xyz must be a (N, 3) array of coordinates.\")\n",
    "        n_sources = xyz.shape[0]\n",
    "\n",
    "        if source_names is None:\n",
    "            source_names = [f\"s{i}\" for i in range(n_sources)]\n",
    "        elif len(source_names) != n_sources:\n",
    "            raise ValueError(\"source_names length must match xyz rows.\")\n",
    "\n",
    "        if bad_patterns is None:\n",
    "            bad_patterns = [-1, None, 'undefined', 'None']\n",
    "\n",
    "        # Localize for each atlas\n",
    "        dataframes = []\n",
    "        for atlas_vol in self._atlas_list:\n",
    "            colname = atlas_vol.name  # e.g. \"brodmann\" or \"myAtlas\"\n",
    "            results_col = []\n",
    "            for i in range(n_sources):\n",
    "                label = atlas_vol.label_at_coordinate(xyz[i])\n",
    "                results_col.append(label if label is not None else 'Not found')\n",
    "            df_atlas = pd.DataFrame({\n",
    "                'Text': source_names,\n",
    "                'X': xyz[:, 0],\n",
    "                'Y': xyz[:, 1],\n",
    "                'Z': xyz[:, 2],\n",
    "                'hemisphere': np.where(xyz[:, 0] > 0, 'Right', 'Left'),\n",
    "                colname: results_col\n",
    "            })\n",
    "            dataframes.append(df_atlas)\n",
    "\n",
    "        # If multiple atlases, merge\n",
    "        if len(dataframes) == 1:\n",
    "            df_merged = dataframes[0]\n",
    "        else:\n",
    "            # merge on Text, X, Y, Z, hemisphere\n",
    "            df_merged = dataframes[0]\n",
    "            for df in dataframes[1:]:\n",
    "                df_merged = pd.merge(\n",
    "                    df_merged,\n",
    "                    df,\n",
    "                    on=['Text', 'X', 'Y', 'Z', 'hemisphere'],\n",
    "                    how='outer'\n",
    "                )\n",
    "\n",
    "        # Replace bad patterns if requested\n",
    "        if replace_bad:\n",
    "            replace_map = {bp: replace_with for bp in bad_patterns}\n",
    "            df_merged.replace(replace_map, inplace=True, regex=False)\n",
    "\n",
    "        # Distance-based fix if requested\n",
    "        if distance is not None:\n",
    "            self._distance_fix(df_merged, distance, replace_with)\n",
    "\n",
    "        # Keep only certain labels if requested\n",
    "        if keep_only is not None:\n",
    "            df_merged = self._filter_dataframe(df_merged, keep_only)\n",
    "\n",
    "        self._analysis = df_merged\n",
    "        return df_merged\n",
    "\n",
    "    @staticmethod\n",
    "    def _distance_fix(df, distance, replace_with):\n",
    "        \"\"\"\n",
    "        Reassign 'replace_with' rows to the nearest valid-labeled row\n",
    "        if within `distance`. Works on a per-atlas basis.\n",
    "\n",
    "        This is an adaptation of the distance-based fix used in the\n",
    "        original ROI code.\n",
    "        \"\"\"\n",
    "        coords = df[['X', 'Y', 'Z']].values\n",
    "        dist_matrix = cdist(coords, coords, metric='euclidean')\n",
    "\n",
    "        # For each atlas column:\n",
    "        # if row is \"Not found\", see if there's a row within `distance`\n",
    "        # that has a valid label. Then copy that label.\n",
    "        # This is fairly naive, but consistent with typical usage.\n",
    "\n",
    "        # Identify non-key columns that contain atlas labels\n",
    "        key_cols = {'Text', 'X', 'Y', 'Z', 'hemisphere'}\n",
    "        atlas_cols = [c for c in df.columns if c not in key_cols]\n",
    "\n",
    "        for c in atlas_cols:\n",
    "            col_data = df[c].values\n",
    "            for i in range(len(col_data)):\n",
    "                if col_data[i] == replace_with:\n",
    "                    # find any row j within distance that has a valid label\n",
    "                    # that is not 'replace_with'\n",
    "                    row_dists = dist_matrix[i, :]\n",
    "                    valid_candidates = np.where((row_dists <= distance) &\n",
    "                                                (col_data != replace_with))[0]\n",
    "                    if len(valid_candidates) > 0:\n",
    "                        # pick the closest one\n",
    "                        j = valid_candidates[row_dists[valid_candidates].argmin()]\n",
    "                        col_data[i] = col_data[j]\n",
    "            df[c] = col_data\n",
    "\n",
    "    @staticmethod\n",
    "    def _filter_dataframe(df, keep_only):\n",
    "        \"\"\"\n",
    "        Keep only rows where at least one atlas label matches any value in keep_only.\n",
    "        \"\"\"\n",
    "        if isinstance(keep_only, str):\n",
    "            keep_only = [keep_only]\n",
    "\n",
    "        mask = np.zeros(len(df), dtype=bool)\n",
    "        key_cols = {'Text', 'X', 'Y', 'Z', 'hemisphere'}\n",
    "        # Only consider atlas columns\n",
    "        atlas_cols = [c for c in df.columns if c not in key_cols]\n",
    "\n",
    "        for c in atlas_cols:\n",
    "            for pattern in keep_only:\n",
    "                mask |= (df[c].values == pattern)\n",
    "\n",
    "        return df[mask]\n",
    "\n",
    "    @property\n",
    "    def analysis(self):\n",
    "        \"\"\"Return the last DataFrame produced by localize_sources.\"\"\"\n",
    "        return self._analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Localized Results ---\n",
      "  Text     X     Y     Z hemisphere my_atlas_file\n",
      "0   S1  10.0 -15.0  35.0      Right       Unknown\n",
      "1   S2 -12.0  22.0  48.0       Left       Unknown\n",
      "2   S3  50.0  50.0  50.0      Right       Unknown\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    xyz_coords = np.array([\n",
    "        [10.0, -15.0, 35.0],\n",
    "        [-12.0, 22.0, 48.0],\n",
    "        [50.0, 50.0, 50.0]  # possibly out of volume => \"Not found\"\n",
    "    ])\n",
    "    # You can pass a single string (path) or multiple:\n",
    "    #   atlases=['brodmann.nii', 'aal.npz']  # for instance\n",
    "    # Or you can create an AtlasVolume manually and pass it:\n",
    "    localizer = SourceLocalizer(\"my_atlas_file.nii\")\n",
    "\n",
    "    results_df = localizer.localize_sources(\n",
    "        xyz=xyz_coords,\n",
    "        source_names=[\"S1\", \"S2\", \"S3\"],\n",
    "        replace_bad=True,\n",
    "        bad_patterns=[None, -1, \"undefined\", \"Not found\"],\n",
    "        replace_with=\"Unknown\",\n",
    "        distance=10.0,\n",
    "        keep_only=None\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Localized Results ---\")\n",
    "    print(results_df)\n",
    "    \"\"\"\n",
    "    Example output:\n",
    "         Text     X     Y     Z hemisphere   my_atlas_file\n",
    "    0       S1  10.0 -15.0  35.0       Right        \"Area 4\"\n",
    "    1       S2 -12.0  22.0  48.0        Left        \"Area 9\"\n",
    "    2       S3  50.0  50.0  50.0       Right       \"Unknown\"\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_example.py (an illustrative example, not real data)\n",
    "\n",
    "label4mri_metadata = {\n",
    "    \"aal\": {\n",
    "        \"coordinate_list\": None,   # <-- This will be a NumPy array or nested list shape (3, N)\n",
    "        \"coordinate_label\": None,  # <-- This will be a list or array shape (N,)\n",
    "        \"label\": None              # <-- This might be a pandas DataFrame or a list of dicts\n",
    "    },\n",
    "    \"ba\": {\n",
    "        \"coordinate_list\": None,\n",
    "        \"coordinate_label\": None,\n",
    "        \"label\": None\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers.py (or put them inside mni_to_region_name.py, etc.)\n",
    "\n",
    "import numpy as np\n",
    "# from .metadata_example import label4mri_metadata\n",
    "\n",
    "def _mni_to_region_index(x, y, z, distance=True, template=None):\n",
    "    \"\"\"\n",
    "    Python equivalent of mni_to_region_index in R.\n",
    "    Finds the region index for a given MNI coordinate (x, y, z).\n",
    "    If exact match is not found and distance=True, finds nearest coordinate.\n",
    "    \"\"\"\n",
    "    if template not in label4mri_metadata:\n",
    "        raise ValueError(f\"Template '{template}' does not exist in metadata.\")\n",
    "    \n",
    "    data = label4mri_metadata[template]\n",
    "\n",
    "    # coordinate_list = shape (3, N)\n",
    "    coords = data[\"coordinate_list\"]  # e.g., a NumPy array\n",
    "    labels = data[\"coordinate_label\"] # shape (N,)\n",
    "\n",
    "    # 1) Round the MNI coordinate as in R\n",
    "    x, y, z = round(x), round(y), round(z)\n",
    "\n",
    "    # 2) Find all columns in coords that match x, y, z exactly\n",
    "    #    coords[0,:] -> all x's, coords[1,:] -> all y's, coords[2,:] -> all z's\n",
    "    match_x = np.where(coords[0, :] == x)[0]\n",
    "    # refine by y\n",
    "    match_y = match_x[coords[1, match_x] == y]\n",
    "    # refine by z\n",
    "    match_xyz = match_y[coords[2, match_y] == z]\n",
    "\n",
    "    if len(match_xyz) > 0:\n",
    "        # found exact match\n",
    "        region_index = labels[match_xyz[0]]   # take first match if multiple\n",
    "        region_distance = 0 if distance else None\n",
    "    else:\n",
    "        # no exact match\n",
    "        if distance:\n",
    "            # compute squared distances to all coordinates\n",
    "            diff = coords - np.array([[x],[y],[z]])\n",
    "            # shape of diff is still (3, N), sum of squares across axis=0\n",
    "            sqdist = np.sum(diff**2, axis=0)  # shape (N,)\n",
    "            min_idx = np.argmin(sqdist)\n",
    "            region_index = labels[min_idx]\n",
    "            region_distance = np.sqrt(sqdist[min_idx])\n",
    "        else:\n",
    "            region_index = None\n",
    "            region_distance = None\n",
    "\n",
    "    return region_index, region_distance\n",
    "\n",
    "\n",
    "\n",
    "def _region_index_to_mni(region_index, template=None):\n",
    "    \"\"\"\n",
    "    Python equivalent of region_index_to_mni in R.\n",
    "    Returns all coordinates for which coordinate_label == region_index.\n",
    "    \"\"\"\n",
    "    if template not in label4mri_metadata:\n",
    "        raise ValueError(f\"Template '{template}' does not exist in metadata.\")\n",
    "    \n",
    "    coords = label4mri_metadata[template][\"coordinate_list\"]  # shape (3, N)\n",
    "    labels = label4mri_metadata[template][\"coordinate_label\"]  # shape (N,)\n",
    "\n",
    "    # find all columns with label == region_index\n",
    "    match_cols = np.where(labels == region_index)[0]\n",
    "    matched_coords = coords[:, match_cols]  # shape (3, k)\n",
    "    \n",
    "    # Return as a Python list of [x, y, z], or as an Nx3 array\n",
    "    # Let’s return a list of dicts, e.g. [{'x': x, 'y': y, 'z': z}, ...]\n",
    "    out = []\n",
    "    for col in range(matched_coords.shape[1]):\n",
    "        out.append({\n",
    "            \"x\": int(matched_coords[0, col]),\n",
    "            \"y\": int(matched_coords[1, col]),\n",
    "            \"z\": int(matched_coords[2, col])\n",
    "        })\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mni_to_region_name.py\n",
    "\n",
    "# from .helpers import _mni_to_region_index\n",
    "# from .metadata_example import label4mri_metadata\n",
    "\n",
    "def mni_to_region_name(x, y, z, distance=True, template=[\"aal\",\"ba\"]):\n",
    "    \"\"\"\n",
    "    Python equivalent of mni_to_region_name in R.\n",
    "    \"\"\"\n",
    "    # Validate template\n",
    "    not_found = [t for t in template if t not in label4mri_metadata]\n",
    "    if len(not_found) > 0:\n",
    "        raise ValueError(f\"Template(s) {not_found} do not exist in the metadata.\")\n",
    "\n",
    "    # For each template, find region index + distance, then map index -> label\n",
    "    output = {}\n",
    "    for t in template:\n",
    "        region_index, dist_val = _mni_to_region_index(x, y, z, distance=distance, template=t)\n",
    "\n",
    "        # Now find the region_name from region_index\n",
    "        if region_index is not None:\n",
    "            # look up region_name from label\n",
    "            label_df = label4mri_metadata[t][\"label\"]\n",
    "            # get region name\n",
    "            region_name = \"NULL\"\n",
    "            for row in label_df:\n",
    "                if row[\"Region_index\"] == region_index:\n",
    "                    region_name = row[\"Region_name\"]\n",
    "                    break\n",
    "        else:\n",
    "            region_name = \"NULL\"\n",
    "\n",
    "        # Build keys that mimic the R structure: e.g. aal.distance, aal.label\n",
    "        output[f\"{t}.distance\"] = dist_val if dist_val is not None else \"NULL\"\n",
    "        output[f\"{t}.label\"]    = region_name\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_name_to_mni.py\n",
    "\n",
    "# from .helpers import _region_name_to_index, _region_index_to_mni\n",
    "# from .metadata_example import label4mri_metadata\n",
    "\n",
    "def region_name_to_mni(region_names, template=\"aal\"):\n",
    "    \"\"\"\n",
    "    Python equivalent of region_name_to_mni in R.\n",
    "    region_names: list or single string of region names\n",
    "    template: \"aal\" or \"ba\"\n",
    "    \"\"\"\n",
    "    if isinstance(region_names, str):\n",
    "        region_names = [region_names]  # handle single string\n",
    "\n",
    "    if template not in label4mri_metadata:\n",
    "        raise ValueError(f\"Template '{template}' does not exist in the metadata.\")\n",
    "\n",
    "    # Validate each region name\n",
    "    # We'll gather them all in a dict\n",
    "    results = {}\n",
    "    for name in region_names:\n",
    "        # get index\n",
    "        r_index = _region_name_to_index(name, template=template)\n",
    "        if r_index is None:\n",
    "            raise ValueError(f\"Region '{name}' does not exist in template '{template}'.\")\n",
    "        # get MNI coordinates\n",
    "        coords = _region_index_to_mni(r_index, template=template)\n",
    "        results[f\"{template}.{name}\"] = coords\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_cluster_composition.py\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "# from .mni_to_region_name import mni_to_region_name\n",
    "# from .metadata_example import label4mri_metadata\n",
    "\n",
    "def show_cluster_composition(coordinate_matrix, template=[\"aal\",\"ba\"]):\n",
    "    \"\"\"\n",
    "    Python equivalent of show_cluster_composition in R.\n",
    "    coordinate_matrix: shape (3, N) (x in row 0, y in row 1, z in row 2).\n",
    "    template: list of templates (e.g. [\"aal\",\"ba\"])\n",
    "    \"\"\"\n",
    "    # Validate template\n",
    "    not_found = [t for t in template if t not in label4mri_metadata]\n",
    "    if len(not_found) > 0:\n",
    "        raise ValueError(f\"Template(s) {not_found} do not exist in the metadata.\")\n",
    "\n",
    "    # coordinate_matrix can be a list of lists, so let's ensure it's an array\n",
    "    coords = np.array(coordinate_matrix)\n",
    "    if coords.shape[0] != 3:\n",
    "        raise ValueError(\"coordinate_matrix must have shape (3, N).\")\n",
    "\n",
    "    n_coords = coords.shape[1]\n",
    "\n",
    "    results = {}\n",
    "    for t in template:\n",
    "        # We'll collect the label for each coordinate\n",
    "        labels_for_all_coords = []\n",
    "        for col in range(n_coords):\n",
    "            x, y, z = coords[0, col], coords[1, col], coords[2, col]\n",
    "            out = mni_to_region_name(x, y, z, distance=False, template=[t])\n",
    "            # out might look like {\"aal.distance\": None, \"aal.label\": \"Putamen_R\"}\n",
    "            label_key = f\"{t}.label\"\n",
    "            region_label = out[label_key]\n",
    "            labels_for_all_coords.append(region_label)\n",
    "        \n",
    "        # Now we have a list of region labels (some might be \"NULL\").\n",
    "        freq_counter = Counter(labels_for_all_coords)  # e.g., {\"NULL\": 6, \"Caudate_R\": 2, ...}\n",
    "        \n",
    "        # Create a table-like structure: each row = (region_label, count, percentage)\n",
    "        table = []\n",
    "        for region_label, count in freq_counter.most_common():\n",
    "            percentage = round((count / n_coords)*100, 1)\n",
    "            table.append({\n",
    "                \"region\": region_label,\n",
    "                \"Number of coordinates\": count,\n",
    "                \"Percentage (%)\": percentage\n",
    "            })\n",
    "        \n",
    "        results[f\"{t}.cluster.composition\"] = table\n",
    "\n",
    "    return results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
